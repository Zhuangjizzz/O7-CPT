# Chapter6 FILTERS

## 6.1 Introduction

With only the techniques of transistors and op-amps it is possible to delve into a number of interesting areas of linear (as contrasted with digital) circuitry. We believe that it is important to spend some time doing this now, in order to strengthen understanding of some of these difficult concepts (transistor behavior, feedback, op-amp limitations, etc.) before introducing more new devices and techniques and getting into the large area of digital electronics. Therefore, in this chapter we treat the topic of filters, and particularly active filters. The latter use resistors and capacitors, in combination with amplifiers (usually op-amps), to produce filters with well-defined frequency response. As we'll see, these filters (along with the classic $L C$ passive filters that they can emulate) can be much sharper than the simple $R C$ filters we saw in Chapter 1.

The three following chapters will continue with additional topics in analog electronics: Chapter 7 (Oscillators and timers), Chapter 8 (Low-noise techniques), and Chapter 9 (Voltage regulation and power conversion). Then, following two chapters on digital logic, we revisit analog electronics, happily harmonized with the intervening digital teachings, in Chapter 12 (Logic interfacing), Chapter 13 (Digital meets analog), and Chapter 15 (Microcontrollers).

## 6.2 Passive filters

In Chapter 1 we began a discussion of filters made from resistors and capacitors. Those simple $R C$ filters produced gentle highpass or lowpass gain characteristics, with a $6 \mathrm{~dB} /$ octave falloff well beyond the -3 dB point. By cascading highpass and lowpass filters, we showed how to obtain bandpass filters, again with gentle $6 \mathrm{~dB} /$ octave "skirts." Such filters are sufficient for many purposes, especially if the signal being rejected by the filter is far removed in frequency from the desired signal passband. Some examples are bypassing of radiofrequency signals in audio circuits, "blocking" capacitors for elimination of dc levels, and separation of modulation from a communications "carrier."

### 6.2.1 Frequency response with RC filters

Often, however, filters with flatter passbands and steeper skirts are needed. This happens whenever signals must be filtered from other interfering signals nearby in frequency. The obvious next question is whether or not (by cascading a number of identical lowpass filters, say) we can generate an approximation to the ideal "brick-wall" lowpass frequency response, as in Figure 6.1.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-091.jpg?height=258&width=353&top_left_y=973&top_left_x=1298)

Figure 6.1. Ideal brick-wall lowpass filter.
We know already that simple cascading won't work, because each section's input impedance will seriously load the previous section, degrading the response. But with buffers between each section (or by arranging to have each section of much higher impedance than the one preceding it), it would seem possible. Nonetheless, the answer is no. Cascaded $R C$ filters do produce a steep ultimate falloff, but the "knee" of the curve of response versus frequency is not sharpened. We might restate this as "many soft knees do not a hard knee make." To make the point graphically, we plotted some graphs of gain response (i.e., $V_{\text {out }} / V_{\text {in }}$ ) versus frequency for lowpass filters constructed from $1,2,4,8$, 16, and 32 identical $R C$ sections, perfectly buffered (Figure 6.2).

The first graph shows the effect of cascading several $R C$ sections, each with its 3 dB point at unit frequency. As more sections are added, the overall 3 dB point is pushed downward in frequency, as you could easily have predicted. ${ }^{1}$ To compare filter characteristics fairly, the rolloff

[^68]![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-092.jpg?height=1810&width=754&top_left_y=207&top_left_x=141)

Figure 6.2. Frequency responses of multisection $R C$ filters. Graphs $A$ and $B$ are linear plots, whereas $C$ is logarithmic. The filter responses in $B$ and $C$ have been normalized (or scaled) for 3 dB attenuation at unit frequency.
frequencies of the individual sections should be adjusted so that the overall 3 dB point is always at the same frequency. For this reason, the other graphs in Figure 6.2 are all "normalized" in frequency, meaning that the -3 dB point (or breakpoint, however defined) is at a frequency of 1 radian per second (or at 1 Hz ). To determine the response of a filter whose breakpoint is set at some other frequency, simply multiply the values on the frequency axis by the actual breakpoint frequency $f_{\mathrm{c}}$. In general, we will also stick with the log-log graph of frequency response when talking about filters because it tells the most about the frequency response. It lets you see the approach to the ultimate rolloff slope, and it permits you to read off accurate values of attenuation. In this case (cascaded $R C$ sections), the normalized graphs in Figures 6.2B and 6.2C demonstrate the soft knee characteristic of passive $R C$ filters.

It's interesting to look also at the phase shift of an $R C$ lowpass cascade, again adjusted to put the overall 3 dB points at unit frequency; these are plotted in Figure 6.3. The lagging phase shift reaches $90^{\circ} \times n$ asymptotically, for $n$ cascaded sections, as you might expect (recall the smooth transition from $0^{\circ}$ to $90^{\circ}$ lagging phase shift of a single $R C$ section, Figure 1.104). Perhaps non-intuitively, however, the phase shift at the 3 dB point grows progressively with larger cascades. Phase-shift characteristics are important, as we'll see presently, because they determine the filter's in-band waveform distortion.

#### A. Degradation of ultimate attenuation: non-ideal capacitors

Unlike ideal capacitors, real capacitors exhibit some extra "parasitic" elements - most prominently an effective series resistance (ESR) and an effective series inductance (ESL). So at very high frequencies (where the capacitor's ESR becomes comparable to the capacitive reactance $1 / \omega C$ ) a real $R C$ filter stops rolling off. We modeled this by using SPICE (see Appendix J) for the cascaded multisection $R C$ filter, see Figure 6.4. For this comparison we assumed that you want to do some $R C$ filtering of a dc rail that supplies a low-level stage, to suppress higher frequency switching noise, coupled signals, and the like. So we gave ourselves a "budget" of $100 \Omega$ total series resistance (consistent with a load current of a few milliamps); and we limited ourselves to $20 \mu \mathrm{~F}$ total capacitance (to maintain reasonable physical size). Then we ran simulations of three filters: a single $100 \Omega, 20 \mu \mathrm{~F} R C$ stage; a 2-section filter with $50 \Omega$ and $10 \mu \mathrm{~F}$ in each section; and a 4-section filter with $25 \Omega$ and $5 \mu \mathrm{~F}$ in each section. We ran plots of the response of these three filters, first with perfect capacitors (no ESR), then
with realistic ESR values, taken from capacitor datasheets (e.g., $1 \Omega$ for a $5 \mu \mathrm{~F}$ electrolytic capacitor rated at 100 V ).

You can see the effect of the series resistance, namely a loss of ultimate attenuation at high frequencies, where the impedance of the capacitors asymptotes to the ESR value, rather than continuing to fall as $1 / f$. Nevertheless, it is clear that spreading the total capacitance into several filter sections makes good sense.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-093.jpg?height=552&width=802&top_left_y=579&top_left_x=219)

Figure 6.3. Phase shift versus frequency for the multisection $R C$ lowpass filters of Figure 6.2C.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-093.jpg?height=537&width=799&top_left_y=1298&top_left_x=218)

Figure 6.4. Real capacitors include some irreducible series resistance, which limits the ultimate attenuation of $R C$ filters. This SPICE simulation compares ideal (dotted curves) and real (solid curves) cascaded $R C$ lowpass filters.

### 6.2.2 Ideal performance with LC filters

As we pointed out in Chapter 1, filters made with inductors and capacitors can have very sharp responses (§1.7.14). We discussed the parallel $L C$ resonant circuit as an example, as
well as the series $L C$ trap. And we showed a dramatic comparison of an $R C$ and an $L C$ lowpass filter, each with the same 1 MHz cutoff frequency (Figure 1.112). By including inductors in the design, it is possible to create filters with any desired flatness of passband combined with sharpness of transition and steepness of falloff outside the band. Figure 6.5 shows an example of a telephone filter and its stunning bandpass characteristics. ${ }^{2}$

Obviously the inclusion of inductors into the design brings about some magic that cannot be performed without them. In the terminology of network analysis, that magic consists of the use of "off-axis poles" (see Chapter $1 x$ ). Even so, the complexity of the filter increases according to the required flatness of passband and steepness of falloff outside the band, accounting for the large number of components used in the preceding filter. The transient response and phase-shift characteristics are also generally degraded as the amplitude response is improved to approach the ideal brick-wall characteristic.

### 6.2.3 Several simple examples

The impressive Orchard and Sheahan filter of Figure 6.5 is a frighteningly complex design, showing what can be done with sophisticated classic $L C$ filter synthesis. ${ }^{3}$ But you don't have to be a filter wizard to make "good enough" filters ${ }^{4}$ that solve most of the problems you are likely to

[^69]![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-094.jpg?height=289&width=1304&top_left_y=345&top_left_x=116)
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-094.jpg?height=435&width=327&top_left_y=219&top_left_x=1454)

Figure 6.5. Left: An unusually good $L C$ bandpass filter (inductances in mH , capacitances in pF ). Right: measured response of the filter circuit. The admirably sharp frequency response comes at the expense of degraded phase response; see discussion in $\S 6.2 .5$. The 0 dB value in the response curve corresponds to $\sim 9 \mathrm{~dB}$ of loss, assuming 10 k source and load impedances.
encounter. Here we show three simple filters that we used in recent designs at our radiotelescope observatory.

#### A. Sinewave from digital square wave

With digital electronics it is very easy to make and manipulate pulses or square waves of precise frequency. But at our observatory we wanted sine waves, not square waves. Figure 6.6 shows a simple way to produce a sinewave output from a fixed-frequency square wave, namely the use of a tuned series $L C$. It behaves like a very low impedance at resonance ${ }^{5}\left(f_{0}=1 / 2 \pi \sqrt{L C}\right)$, rising on either side (asymptotically as $1 / f$ at low frequencies, and as $f$ at high frequencies).
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-094.jpg?height=302&width=799&top_left_y=1410&top_left_x=126)

Figure 6.6. A series $L C$ bandpass filter converts a square wave into a sinewave suitable for driving a $50 \Omega$ load.

Here we chose the product $L C$ for resonance at 1.0 MHz , and the value of $L$ such that its impedance at 3 MHz (the next frequency component of a 1 MHz square wave, which has only odd harmonics) is large compared with the $50 \Omega$ load impedance. For $L_{1}=100 \mu \mathrm{H}$, the reactance at 3 MHz is $X_{\mathrm{L}}=2 \pi f L \approx 2 \mathrm{k} \Omega$ 。

Figure 6.7 shows the measured performance. The slight bowing of the square wave is due to loading by the filter

[^70]![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-094.jpg?height=402&width=802&top_left_y=840&top_left_x=974)

Figure 6.7. Input (lower trace) and output (upper trace) of the series $L C$ bandpass (sinewave) filter of Figure 6.6, loaded with $50 \Omega$. Vertical: $1 \mathrm{~V} /$ div (top trace), $5 \mathrm{~V} / \mathrm{div}$ (bottom trace). Horizontal: $400 \mathrm{~ns} / \mathrm{div}$.
and $50 \Omega$ load. We included a simple $R C$ prefilter to slow the rise time, because the very fast edges of the square wave coupled through the parasitic shunt capacitance of the inductor to cause small notches on the sinewave output. The " $3 \times$ 'HC04" designation refers to the type of digital logic component we used; see Chapter 10.

#### B. "Spur" removal

An elegant technique known as phase-locked loop (PLL) frequency synthesis, discussed later in Chapter 13 (§§13.13.6A and 13.13.6B), permits you to generate a desired precise frequency of your choosing, beginning with a standard "reference" frequency, for example 10.0 MHz . Figure 6.8 shows a portion of a 78.0 MHz PLL synthesizer we built, in block diagram form. The basic idea is to use a voltage-tunable oscillator (VCO), and compare an integer subdivision of its desired output frequency with a different subdivision of the reference frequency such that those frequencies will agree when the output frequency is correct. A frequency error produces a correction signal to steer the

VCO toward the correct oscillation frequency. Here we divided the 10 MHz reference by 50 (producing 200 kHz ), to be compared with the VCO's output after division by 390; those divided frequencies will agree when the VCO is oscillating at 78.0 MHz .
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-095.jpg?height=682&width=802&top_left_y=460&top_left_x=219)

Figure 6.8. A series LC "trap" suppresses spurs at the 200 kHz reference frequency in this phase-locked loop (PLL) oscillator.

We engineered a simple but quite good JFET oscillator (shown later, in Figure 7.29), with its output energy almost entirely at its central frequency. It was so "clean" that the dominant undesired component of its output was a bit of residual energy at $78.0 \mathrm{MHz} \pm 0.2 \mathrm{MHz}$, caused by the 200 kHz internal comparison frequency. The simple cure here was to put a series $L C$ trap, tuned to 200 kHz , across the analog tuning voltage, as shown. The three other components ( $R_{1} R_{2} C_{1}$ ) form the classic PLL loop filter, as we'll see in §13.13.

#### C. Anti-alias lowpass filter

An analog waveform can be digitized, by sampling its amplitude periodically and converting each sample to a numeric quantity. We'll see later (Chapter 13, e.g., Figure 13.60) that the process can introduce artifacts, both from the finite accuracy with which the amplitudes are quantized, and from the finite rate at which those samples are taken. These artifacts can be suppressed, to any required degree, by adequate choice of quantization depth (amplitude accuracy) and rate (sampling frequency).

The important fact, for this filter example, is that the signal being digitized must not contain signals whose frequency exceeds half the sampling rate $f_{\mathrm{S}}$; this is known as
the Nyquist criterion. ${ }^{6}$ The usual way this is accomplished is by passing the predigitized signals through a lowpass "anti-aliasing" filter, whose cutoff ensures thorough attenuation of signals above the Nyquist frequency $f_{\mathrm{S}} / 2$. This usually requires a sharp filter cutoff, because otherwise you would have to go to a much higher sampling rate to escape signals that pass through the soft cutoff; furthermore you want a filter that is flat throughout the desired signal passband.

In this radiotelescope receiver example (Figure 6.9) we use a mixer (a device that multiplies two signals together to produce its output) to convert a 2 MHz band of signal frequencies centered on 78 MHz (the "IF" band) to a band centered on dc (known as "baseband"). A mixer can do this sort of frequency shifting, because the product of two sinusoids is a pair of waves at the sum and difference frequencies: $\cos \left(\omega_{1} t\right) \cos \left(\omega_{2} t\right)=\frac{1}{2}\left\{\cos \left(\omega_{1}-\omega_{2}\right) t+\right.$ $\left.\cos \left(\omega_{1}+\omega_{2}\right) t\right\}$. Here the signal band drives one input to the mixer, and a fixed oscillator at 78 MHz (the "local oscillator," or LO) drives the other input. The difference frequency at the output of the mixer is the baseband, ${ }^{7}$ in which the band from dc to 1 MHz contains the signals we want to digitize in this example. ${ }^{8}$

Here we amplified the baseband, then passed it through a serious anti-aliasing filter, specifically a " 7 -section $L C$ Chebyshev lowpass filter with 1.0 MHz cutoff frequency and 0.1 dB peak-to-peak ripple."9 We designed the filter with a weird input and output impedance ( $378 \Omega$ ) to take advantage of standard value tunable inductors. The filter removes signal components above 1 MHz , and this filtered baseband is then amplified (again) and digitized (by the device labeled ADC - analog-to-digital-converter) at a sampling rate of 2.5 Msps (megasamples/s). The corresponding Nyquist frequency of 1.25 MHz is well into the stopband of the very sharp lowpass filter; in fact, the calculated and measured performance are in close agreement, demonstrating that the input signals are reduced by 20 dB at that
${ }^{6}$ Violating this rule produces aliasing, the creation, in the digitized output, of nonexistent in-band frequency components; see §13.5.1B.
7 The sum frequency, centered on 156 MHz , is discarded in subsequent filtering.
${ }^{8}$ So we can Fourier transform them to get a radio spectrum. More precisely, the baseband contains frequencies from " -1 MHz " to +1 MHz , which a single mixer folds into a single dc -1 MHz band; but we recover the unfolded baseband by using a pair of mixers, driven with sine and cosine LO signals. The pair of filtered baseband signals, commonly called $I$ and $Q$ (for in-phase and quadrature), are individually digitized to create the complex input time series to the (complex) Discrete Fourier Transform.
${ }^{9}$ This is the filter we used for the linear swept response of Figure 1.112.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-096.jpg?height=429&width=1370&top_left_y=214&top_left_x=264)

Figure 6.9. A sharp 7 -section $L C$ lowpass filter prevents aliasing in this radioastronomy receiver by eliminating any signal frequencies above the Nyquist frequency ( 1.25 MHz , or half the sampling rate). We built 126 of these puppies; see the photograph in Figure 1.111.
frequency and that the worst-case aliased signals (at 1.5 MHz ) are reduced by an additional 16 dB . This is stunning performance for a filter that is easily designed and constructed, especially when compared with an $R C$ filter of similar component count, where the attenuation at $1.25 f_{\mathrm{c}}$ is just 1.6 dB relative to that at $f_{\mathrm{c}}$; Figures 6.10 and 6.11 make the comparison graphically.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-096.jpg?height=575&width=789&top_left_y=1121&top_left_x=126)

Figure 6.10. The abrupt cutoff of the 7 -section $L C$ filter of Figure 6.9 compared with the soft rolloff of a 7 -section $R C$ filter with the same 1 MHz cutoff.

#### D. Passive differential filter

Most high-frequency ADCs have differential inputs, see §13.6.2, and many require a low input-signal source impedance, terminated in many cases by a differential capacitor. We discussed low-impedance high-frequency differential-output amplifiers in §5.17, where, for example, Figure 5.102 shows a differential lowpass filter consisting of two $50 \Omega$ resistors and a 100 pF capacitor, as specified for the AD9225 25 MSps ADC (see also Figure 13.28).
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-096.jpg?height=514&width=792&top_left_y=789&top_left_x=979)

Figure 6.11. The same filter pair of Figure 6.10, here plotted on a linear scale. The Chebyshev's passband "ripple" (of $+0 \mathrm{~dB} /-0.1 \mathrm{~dB}$, or $\pm 0.6 \%$ in amplitude) is more easily seen, but the details of stopband attenuation are lost.

Frequently you'll want an anti-alias filter between the amplifier and the ADC input. For example, if the sampling frequency is 25 MHz , you may want a steep rolloff input filter starting at 10 MHz . Texas Instruments has a nice application note describing how to convert a single-ended filter to differential form (SLWA053B: Design of differential filters for high-speed signal chains, available at www.ti.com).

### 6.2.4 Enter active filters: an overview

The synthesis of filters from passive components ( $R, L$, and $C$ ) is a highly developed subject, with a rich literature of traditional handbooks (e.g., the authoritative work by Zverev; see Appendix N), now supplemented by elegant software tools that make such designs a routine task. However, inductors as circuit elements frequently leave much to be desired. They are often bulky and expensive, and they depart from the ideal by being "lossy," i.e., by having
significant series resistance, as well as other "pathologies" such as nonlinearity, distributed winding capacitance, and susceptibility to magnetic pickup of interference. Furthermore, the inductances needed for low-frequency filters may dictate unmanageably large components. Finally, classic filters made with $L$ 's and $C$ 's are not electrically tunable.

What is needed is a way to make inductorless filters with the characteristics of ideal RLC filters. Ideally we might hope for tunability, either by an analog tuning voltage or a varying pulse frequency.

By using op-amps as part of the filter design, we can synthesize any RLC filter characteristic without using inductors. Such inductorless filters are known as active filters because of the inclusion of an active element (the amplifier). We'll see another class of active filter - the switched capacitor filter - that adds MOSFET switches to produce, in effect, a frequency-tunable resistor. These deliver performance similar to that of the standard active filter (sometimes called a "continuous-time" filter), but with the added feature of precise tuning of its characteristic frequency breakpoints (with an externally applied clocking frequency) over a wide range. (This tunability comes at a price, though, namely some switching noise and a reduced dynamic range; see §6.3.6.)

Active filters can be used to make lowpass, highpass, bandpass, and band-reject filters, with a choice of filter types according to the important features of the response, e.g., maximal flatness of passband, steepness of skirts, or uniformity of time delay versus frequency (more on this shortly). In addition, "allpass filters" with flat amplitude response but tailored phase versus frequency can be made (they're also known as "delay equalizers"), as well as the opposite - a filter with constant phase shift but tailored amplitude response.

#### A. Negative-impedance converter, gyrator, and generalized impedance converter

Three interesting circuit elements that should be mentioned in any overview are the negative-impedance converter (NIC), the gyrator, and the generalized impedance converter ${ }^{10}$ (GIC). These devices can mimic the properties of inductors while using only resistors and capacitors in addition to op-amps.

Once you can do that, you can build inductorless filters with the ideal properties of any RLC filter, thus providing at least one way to make active filters.

[^71]
#### B. Negative-impedance converter

The NIC converts an impedance to its negative, whereas the gyrator converts an impedance to its inverse. The following exercises will help you discover for yourself how that works out.

Exercise 6.1. Show that the circuit in Figure 6.12 is a negativeimpedance converter, in particular that $Z_{\text {in }}=-Z$. Hint: apply some input voltage $V$ and compute the input current $I$. Then take the ratio to find $Z_{\text {in }}=V / I$.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-097.jpg?height=368&width=470&top_left_y=650&top_left_x=1301)

Figure 6.12. Negative-impedance converter.
The NIC therefore converts a capacitor to a "backward" inductor:

$$
\begin{equation*}
Z_{\mathrm{C}}=1 / j \omega C \rightarrow Z_{\text {in }}=j / \omega C, \tag{6.1}
\end{equation*}
$$

i.e., it is inductive in the sense of generating a current that lags the applied voltage, but its impedance has the wrong frequency dependence (it goes down, instead of up, with increasing frequency).

#### C. Gyrator

The gyrator, on the other hand, converts a capacitor to a true inductor:

$$
\begin{equation*}
Z_{\mathrm{C}}=1 / j \omega C \rightarrow Z_{\text {in }}=j \omega C R^{2} \tag{6.2}
\end{equation*}
$$

i.e., an inductor with inductance $L=C R^{2}$.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-097.jpg?height=381&width=597&top_left_y=1738&top_left_x=1176)

Figure 6.13. Gyrator implemented with NICs.
The existence of the gyrator makes it intuitively reasonable that inductorless filters can be built to mimic any filter
using inductors by simply replacing each inductor with a gyrated capacitor. ${ }^{11}$ The use of gyrators in just that manner is perfectly OK ; and in fact the telephone filter illustrated previously, though designed as a classic $L C$ filter, was implemented with gyrators (in a configuration known as a Riordan gyrator, which looks different from Figure 6.13). In addition to simple gyrator substitution into pre-existing RLC designs, it is possible to synthesize many other filter configurations.

Exercise 6.2. Show that the circuit in Figure 6.13 is a gyrator, in particular that $Z_{\text {in }}=R^{2} / Z$. Hint: you can analyze it as a set of voltage dividers, beginning at the right.

#### D. Generalized impedance converter

The configuration of Figure 6.14 is known as a generalized impedance converter ${ }^{12}$ (GIC); it multiplies the impedance attached at $Z_{5}$ by the factor $Z_{1} Z_{3} / Z_{2} Z_{4}$. So, for example, if you put a capacitor at $Z_{4}$, and resistors everywhere else, you get an inductor whose value is $L=\left(R_{1} R_{3} R_{5} / R_{2}\right) C$; that is, it becomes a gyrator. But you can do more amusing things with a GIC: for example, if you put capacitors at $Z_{3}$ and $Z_{5}$, you wind up with a frequency-dependent negative resistor (FDNR). Filter implementations with GICimplemented FDNRs have been popular in the audio design field, where it is claimed that they have superior noise and distortion characteristics compared with something like a Sallen-and-Key filter (next section). The field of inductorless filter design is both lively and rich with detail, with new designs appearing in the journals every month.

#### Performance limits

As with any op-amp circuit, the performance of gyrators and GICs at high frequencies depends on the op-amp's bandwidth (and other characteristics). So a GIC configured as an inductor (capacitor at $Z_{4}$, resistors elsewhere) will stop looking like an inductor at frequencies greater than a few percent of the op-amp's bandwidth $f_{\mathrm{T}}$. The simulation results in Figure 6.15 show the kind of behavior you'll see. Roughly speaking, the nearly perfect inductor (at low frequencies) becomes something approximating a capacitor at high frequencies, with a resonance in between. ${ }^{13}$ This may look ugly, on this extended graph; but notice that the "inductor" appears to have an astonishingly high quality factor

[^72]![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-098.jpg?height=682&width=822&top_left_y=205&top_left_x=954)

Figure 6.14. Generalized impedance converter. If $Z_{4}$ is a capacitor, the circuit behaves like an inductor, with value as shown. From A. Antoniou, IEE Proc., 116, 1838-1850 (1969).
$Q$ of about $2 \times 10^{5}$ at 1 kHz if you assume that the $4.6 \mathrm{~m} \Omega$ impedance floor on the graph properly represents the inductor's loss (i.e., equivalent series resistance, ESR). (In reality there are other losses, so realizable $Q$ values are in the range of $1000 \ldots$ still pretty darn good for an inductor that's a fraction of a henry !). And, for the highest-bandwidth op$\mathrm{amp}\left(f_{\mathrm{T}}=50 \mathrm{MHz}\right.$ ) the capacitance is just 2.3 pF ; you could never make a 160 mH inductor with such a tiny "winding capacitance," nor with such a high self-resonant frequency.

Gyrators are used in real-world filters: in an App Note, Texas Instruments suggests using multiple GIC stages to make anti-alias filters. ${ }^{14}$ And Stanford Research Systems uses four GIC stages acting as an $R+L C$ ladder to make an 8-zero 9-pole elliptical lowpass filter for their SR830 DSPbased lock-in amplifier, "so that all frequency components greater than half the sampling frequency are attenuated by at least 96 dB ." The A/D samples at 256 kHz and the filter passes signals from dc to 102 kHz ; they've allowed themselves a $25 \%$ frequency margin to get the attenuation down to $96 \mathrm{~dB} .{ }^{15}$ The full schematic of the filter is included in the

[^73]![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-099.jpg?height=697&width=756&top_left_y=213&top_left_x=239)

Figure 6.15. Finite op-amp bandwidth degrades the ideal GIC inductor, which becomes capacitive at frequencies beginning at a small fraction of $f_{\mathrm{T}}$, as seen in these plots derived from SPICE simulations. When compared with a physical inductor, with its winding capacitance and self-resonant frequency, the GIC inductor's analogous capacitance and self-resonant frequency (which depend on the op-amp's bandwidth) can be significantly better, as suggested in these plots (which, however, are predicated on the use of an ideal capacitor).
instrument's wonderfully informative manual - a hallmark of all SRS products.

#### E. Sallen-and-Key filter

Figure 6.16 shows an example of a simple and even partly intuitive filter topology, an example of which we saw earlier in §4.3.6. These are known as Sallen-and-Key filters, after the inventors. ${ }^{16}$ The unity-gain amplifier can be an op-amp connected as a follower, or just an emitter follower or source follower. The particular filters shown are 2-pole lowpass and highpass filters. Taking the example of the lowpass filter (Figure 6.16A), note that it would be simply two cascaded $R C$ lowpass filter sections, except for the fact that the bottom of the first capacitor is bootstrapped by the output. It is easy to see that at very high frequencies it falls off just like a cascaded $R C$, because the output is essentially

[^74]zero. As the output rises at decreasing frequency, however, the bootstrap action tends to reduce the attenuation, giving a sharper knee. Of course, such hand-waving cannot substitute for honest analysis, which luckily has already been done for a prodigious variety of nice filters. We will come back to active filter circuits in $\S 6.3$, after a short introduction to filter performance parameters and filter types.
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-099.jpg?height=565&width=598&top_left_y=529&top_left_x=1178)

Figure 6.16. Sallen-and-Key lowpass and highpass active filters. The ultimate performance of these simple-looking filters is affected by the non-zero output impedance of the follower, see Figure 6.36.

### 6.2.5 Key filter performance criteria

There are some standard terms that keep appearing when we talk about filters and try to specify their performance. It is worth getting it all straight at the beginning.

#### A. Frequency domain

The most obvious characteristic of a filter is its gain versus frequency, typified by the sort of lowpass characteristic shown in Figure 6.17.

The passband is the region of frequencies that are relatively unattenuated by the filter. Most often the passband is considered to extend to the -3 dB point, but with certain filters (most notably the "equiripple" types) the end of the passband may be defined somewhat differently. Within the passband the response may show variations or ripples, defining a ripple band, as shown. The cutoff frequency, $f_{c}$, is the end of the passband. The response of the filter then drops off through a transition region (also colorfully known as the skirt of the filter's response) to a stopband, the region of significant attenuation. The stopband may be defined by some minimum attenuation, e.g., 40 dB .

Along with the gain response, the other parameter of importance in the frequency domain is the phase shift of the
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-100.jpg?height=845&width=802&top_left_y=210&top_left_x=119)

Figure 6.17. Filter characteristics versus frequency.
output signal relative to the input signal. In other words, we are interested in the complex response of the filter, which usually goes by the name of $\mathbf{H}(\mathbf{s})$, where $\mathbf{s}=j \omega$, and $\mathbf{H}$ and $\mathbf{s}$ are complex. Phase is important because a signal entirely within the passband of a filter will emerge with its waveform distorted if the time delay of different frequencies in going through the filter is not constant. Constant time delay corresponds to a phase shift increasing linearly with frequency ( $\Delta t=-d \phi / d \omega=-\frac{1}{2 \pi} d \phi / d f$ ); hence the term linear-phase filter applied to a filter that is ideal in this respect. Figure 6.18 shows a typical graph of amplitude response and phase shift for a lowpass filter that is definitely not a linear-phase filter. Graphs of phase shift versus frequency are best plotted on a linear frequency axis.

#### B. Time domain

As with any ac circuit, filters can be described in terms of their time-domain properties: rise time, overshoot, ringing, and settling time. This is of particular importance where steps or pulses may be present. Figure 6.19 shows a typical lowpass-filter step response. Here, rise time is, as usual, the time required to go from $10 \%$ to $90 \%$ of the final value. Of greater interest is the settling time, which is the time required to get within some specified amount of the final value and stay there. The delay time is the time duration from the input step to the output reaching
![](https://cdn.mathpix.com/cropped/2024_11_07_1cc047cc725f90585669g-100.jpg?height=488&width=697&top_left_y=218&top_left_x=1019)

Figure 6.18. Phase shift (lagging) and amplitude response for an 8 -pole Chebyshev lowpass filter ( 2 dB passband ripple). The normalization shown is conventional: 0 dB corresponds to the top of the ripple band, and the cutoff (or "critical") frequency is the frequency at which the response leaves the ripple band. The filter's actual dc gain is unity ( 0 dB ); for even-order filters (like this one) the ripple rises from dc, whereas for odd-order filters the ripple drops from dc.
$50 \%$ of its final value. ${ }^{17}$ Overshoot and ringing are selfexplanatory terms for some undesirable properties of filters. The phase-shifting characteristics of filters imply a corresponding time delay, which you sometimes see plotted (or tabulated) as group delay versus frequency. ${ }^{18}$

### 6.2.6 Filter types

Suppose you want a lowpass filter with flat passband and sharp transition to the stopband. The ultimate rate of falloff, well into the stopband, will always be $6 \mathrm{ndB} /$ octave, where $n$ is the number of "poles." You need one capacitor (or inductor) for each pole, so the required ultimate rate of falloff of filter response determines, roughly, the complexity of the filter.

Now, assume that you have decided to use a 6-pole lowpass filter. You are guaranteed an ultimate rolloff of $36 \mathrm{~dB} /$ octave at high frequencies. It turns out that the filter design can now be optimized for maximum flatness of passband response, at the expense of a slow transition from passband to stopband. Alternatively, by allowing some

[^75]
[^0]:    ${ }^{14}$ Assuming care is taken in the wiring layout to maintain the low 0.2 pF capacitance of the HOLD signal.

[^1]:    ${ }^{15}$ Making this quantitative, the LF412's maximum quiescent current is 6.5 mA , thus 195 mW dissipation when run from $\pm 15 \mathrm{~V}$ supplies. In a DIP-8 package that produces a $22^{\circ} \mathrm{C}$ temperature rise (the thermal resistance $\left.R_{\Theta J A}=115^{\circ} \mathrm{C} / \mathrm{W}\right)$, with a consequent quadrupling of the specified $I_{\mathrm{B}}=200 \mathrm{pA}$ (max). If the op-amp were driving a load, you'd have yet more dissipation. To put this in perspective, though, note that the driving impedance seen at the op-amp's input would have to be greater than $1 \mathrm{M} \Omega$ in order for this current-induced error to exceed the 1 mV (typ) input offset-voltage error.

[^2]:    ${ }^{16}$ In the previous edition of this book we awarded that honor to the MAX400M, with its specified worst-case $V_{\text {OS }}$ of $10 \mu \mathrm{~V}$. With confi-

[^3]:    dence we added that "we expect to see further incremental improvements in this area." That confidence was evidently misplaced: the Maxim website now says of the MAX400 "This product was manufactured for Maxim by an outside wafer foundry using a process that is no longer available. It is not recommended for new designs. The datasheet remains available for existing users." Sic transit...

[^4]:    ${ }^{17}$ In fact, if noise is of primary concern you could substitute the $\times 4$ quieter INA103 instrumentation amplifier at the front-end, paying the price in input offset current: a whopping $1 \mu \mathrm{~A}$ (thus $\pm 350 \mu \mathrm{~V}$ ) of static offset voltage created by the $350 \Omega$ differential source resistance here.

[^5]:    18 We've simplified it slightly: the input stage of Widlar's original LM101 used a pnp differential pair, but it was configured as a common-base amplifier driven by an $n p n$ follower pair.

[^6]:    ${ }^{19}$ National Semiconductor App Note AN-1485: The Effect of Heavy Loads on the Accuracy and Linearity of Operational Amplifier Circuits

[^7]:    ${ }^{20}$ See "Active Feedback Improves Amplifier Phase Accuracy," by J. Wong, EDN Magazine, 17 Sept 1987; reprinted as Analog Devices AN-107. Wong credits the idea to Soliman in a 1979 paper, and Soliman credits the idea to Brackett and Sedra in a 1976 paper. But Wong's paper is the most useful reference for understanding the configuration of Figure 5.25.
${ }^{21}$ In SPICE simulations we found that the peaking increased to $\sim 7 \mathrm{~dB}$ for the LF412 model configured for $G=2$; this can be tamed by adding a compensation capacitor $C_{c}$ across feedback resistor $R_{2}$. Choosing $C_{c}$ to match the op-amp's $f_{\mathrm{T}}$ (i.e., $C_{c}=1 / 2 \pi f_{\mathrm{T}} R_{2}$ ) reduced the peaking to 4 dB , at the expense of tripling the (pretty small) phase error. In his article, James Wong warns that the technique may result in an unstable amplifier for low gains, below $G=5$ for example. He shows also how the technique can be further improved if $A_{2}$ is made from two amplifiers.

[^8]:    22 We went back to the bench and measured a handful of LF412 dual opamps. Among different specimens the $f_{\mathrm{T}}$ values ranged over $\pm 20 \%$, but within any single part the $f_{\mathrm{T}}$ 's of its two op-amps matched typically to $0.1 \%$, with one outlier showing a $1.5 \%$ mismatch.

[^9]:    ${ }^{23}$ Or sometimes called "double-terminated", as in Figure 12.110. We suggest trying your amplifier of choice, taking care to terminate the second op-amp with $150 \Omega$.

[^10]:    ${ }^{24}$ Playfully named "Zer $\varnothing$-Crossover" amplifiers, or ZCOs.

[^11]:    ${ }^{27}$ It's unusual to see plots (or even tabulated values) of open-loop output impedance on datasheets; and in cases where a graph is shown, it rarely extends to very low frequencies. It is likely that other op-amps, including some with conventional (follower) output stages, also exhibit a rise in open-loop output impedance at very low frequencies. This is rarely of concern, though, owing to the very high loop gain down there.

[^12]:    ${ }^{30}$ In $\S 8.6 .3$ we show a discrete op-amp circuit where both of these goals are achieved.

[^13]:    ${ }^{31}$ A phrase lifted from a student's reply in an end-of-course questionnaire: "This course was not superficial enough for me."
32 There was traditionally a problem peculiar to MOSFETs, which has been largely solved through process improvements. MOS transistors

[^14]:    are susceptible to a unique debilitating effect that neither FETs nor bipolar transistors have. It turns out that sodium-ion impurity migration and/or phosphorus polarization effects in the gate insulating layer can cause offset voltage drifts under closed-loop conditions, in extreme cases as much as 0.5 mV over a period of years. The effect is increased for elevated temperatures and for a large applied differential-input signal, with some datasheets showing a typical 5 mV change of $V_{\mathrm{OS}}$ over 3000 hours of operation at $125^{\circ} \mathrm{C}$ with 2 V across the input. This sodium-ion disease can be alleviated by introducing phosphorus into the gate region. Texas Instruments, for example, uses a phosphorusdoped polysilicon gate in its "LinCMOS" series of op-amps (TLC270series) and comparators (TLC339 and TLC370-series). These popular inexpensive parts come in a variety of packages and speed/power selections and maintain respectable offset voltages with time ( $50 \mu \mathrm{~V}$ eventual offset drift per volt of differential input).

[^15]:    ${ }^{33}$ Many op-amps can do this, but without saying so. That's because their pullup transistor and drivers work all the way down to the negative

[^16]:    rail, without sourcing current to the output. Some require a minimum pull-down current, e.g., 0.5 mA for the OPA364.

[^17]:    ${ }^{35}$ Well, not exactly: if the noise power density were truly to continue rising as $1 / f$, the integral would diverge at zero frequency (dc). For Figure 5.54 we set the low frequency limit to be 0.01 Hz .
${ }^{36}$ How to determine the corner frequency? See the discussion in §8.13.4.
${ }^{37}$ The LT1012 and OPA277 are BJT parts, and the TLC2272 is a CMOS op-amp. The ' 2272 boasts a miniscule 60 pA max bias current, far better than the '277's 1 nA , but not much better than the '1012's amazing 100 pA .

[^18]:    38 Note 13 on the LMC6482 datasheet says "Guaranteed limits are dictated by tester limitations and not device performance. Actual performance is reflected in the typical value." That's illuminating, but not entirely helpful for the designer of a mass-production instrument.

[^19]:    ${ }^{39}$ Based on nice techniques worked out by Paul Grohe and Bob Pease at National Semiconductor. See Paul Rako's article "Measuring Nanoamperes" (EDN, 26 April 2007), and two riffs by Pease from his series in Electronic Design: "What's All This Teflon Stuff, Anyhow?" (14 Feb 1991) and "What's All This Femtoampere Stuff, Anyhow" (2 Sept 1993). Nicely readable versions currently available at http://electronicdesign.com/ test-amp-measurement/whats-all-teflon-stuff-anyhow and.../whats-all-femtoampere-stuff-anyhow.

[^20]:    ${ }^{40}$ The LT1677 listed in Table 8.3a is an exception. Its datasheet has a graph labelled "Input Bias Current Over the Common Mode Range," showing that the bottom 1.4 V and top 0.7 V of the common-mode range suffer from high bias currents. The op-amp's offset voltage is also degraded in these regions. But, hey, we warned you about that in §5.9.1!

[^21]:    ${ }^{41}$ Datasheets for the closely similar OP-97 and LT1097 make the same error, evidently corrected in that of the later LT6010 (the recommended successor to the LT1012).

[^22]:    42 Three-legged, or four? We've found that city folks don't know why it is that milking stools have three legs, whereas barstools have four. Those with rural upbringing can tell you, in a flash.

[^23]:    ${ }^{43}$ Yeah, OK, but read carefully: on page 10 of the datasheet you'll see that there are $\sim 1 \mathrm{mV}$ shifts of offset voltage when the input is within 1.5 V of the rail! A powerful incentive to use inverting mode!

[^24]:    ${ }^{44}$ Manufacturers use different voltage levels ( $2 \mathrm{Vpp}, 3 \mathrm{Vrms}, 10 \mathrm{~V}$ peak, and 20 Vpp ), different loads ( $100 \Omega, 600 \Omega, 2 \mathrm{k}, 10 \mathrm{k}$ and open circuit), different common-mode voltages, different analyzer filters, and even different gains for their measurements.

[^25]:    ${ }^{45} \mathrm{OK}$, we plead guilty-as-charged to that conclusion favored by all academics - "needs more study (and a grant proposal is in the mail)."

[^26]:    ${ }^{46}$ If you're considering piezo positioners for a precision application, be aware that they exhibit some nonlinearity and hysteresis when driven from a voltage source. These issues are said to be ameliorated when the drive signal is quantified by charge instead of voltage. See Chapter $3 x$ for a precision current-drive circuit that circumvents this problem and makes fast linear piezo steps.

[^27]:    47 Unlike an earlier generation of synchronous amplifiers that were also called "chopper amplifiers," but that had bandwidth limited to a fraction of the chopping clock frequency.

[^28]:    ${ }^{48}$ Some old high-voltage types that require external (correction-signal) capacitors may still be available.

[^29]:    52 Some parts warn that for high source impedances the bias current may change dramatically as a function of input capacitance! For example, the input current of an LMP2021 with $R_{\mathrm{S}}=1 \mathrm{G} \Omega$ varies from -25 to +25 pA for an input shunt capacitance $C_{\mathrm{s}}$ ranging from 2 to 500 pF . Note that such input currents create large offsets with such high source resistances: 25 pA into $1 \mathrm{G} \Omega$ is 25 mV . A graph in the datasheet shows that the input current $I_{\mathrm{B}}$ goes through zero for $C_{\mathrm{S}}=22 \mathrm{pF}$. Other manufacturer's parts show similar effects. In a transimpedance amplifier with high $R_{\mathrm{F}}$, using a large feedback capacitor $C_{\mathrm{F}}$ can dramatically reduce the bias-current error.

[^30]:    ${ }^{54}$ At 10 Hz , who knows about higher frequencies?!
${ }^{55}$ The curious part number reminds us old timers of a favorite vacuum tube of yesteryear.

[^31]:    ${ }^{56}$ In the good ol' days, manufacturers proudly published their circuits. Nowadays it's far less common - for example, circuit diagrams are absent from the service manual for the Agilent 34410A (successor to the 34401A). Happily, some manufacturers (e.g., Stanford Research Systems) continue to display their circuit ingenuity, with full schematics and parts lists.
57 A further trick is to average many such calibrate-measure cycles (up to 2 minutes' worth, in the 34420A) to beat down the scatter.

[^32]:    58 All have $20 \%$ "overrange," e.g., $\pm 12 \mathrm{~V}$ on the " 10 V " range.

[^33]:    ${ }^{59}$ It's necessary that $Q_{1}$ 's $V_{\mathrm{GS}}$ at 0.7 mA be less than $Q_{2}$ 's $V_{\mathrm{GS}}$ at 1.4 mA , because the difference is $Q_{1}$ 's $V_{\mathrm{DS}}$ operating voltage. It's likely that Agilent has an incoming batch inspection to ensure that this condition is met.

[^34]:    ${ }^{60}$ For single-ended amplifiers we would want the current-source noise $i_{\mathrm{n}}$ to be less than $e_{\mathrm{n}}(\mathrm{amp}) g_{m}$. We can use the expression $e_{\mathrm{n}}(\mathrm{ref}) / e_{\mathrm{n}}(\mathrm{amp})=g_{m} R_{\mathrm{S}}$ to determine the allowable voltage noise in the current-source reference. For this circuit that ratio is 37 , thus only $11 \mathrm{nV} / \sqrt{\mathrm{Hz}}$ for a noise contribution comparable to that of the $0.3 \mathrm{nV} / \sqrt{\mathrm{Hz}} \mathrm{JFET}$. The MC1403 reference is about $20 \times$ worse than this. Evidently the Agilent engineers are relying on the matched noise currents in the two JFETs to cancel to better than 5\%, enforced by the $1 \%$ current-mirror resistors. At frequencies above about 10 Hz , however, the 10 nF capacitor defeats this cancellation.

[^35]:    ${ }^{61}$ We'll see the strain gauge again, in connection with analog-to-digital converters, in §13.9.11C (Figure 13.67). A similar biased bridge arrangement is used in the platinum resistance temperature detector (RTD), which is the sensor used in the microcontroller-based thermal controller in $\S 15.6$.

[^36]:    ${ }^{62}$ You can define an effective current-source output capacitance $C_{\text {eff }}=I_{\text {out }} / S$ (where $S$ is the output slew rate) as a way to characterize this shortcoming.

[^37]:    ${ }^{64}$ You've got to keep source impedances quite low in order not to degrade such a low $e_{\mathrm{n}}$; even a $100 \Omega$ resistor has an open-circuit voltage noise of $1.3 \mathrm{nV} / \sqrt{\mathrm{Hz}}$. See Chapter 8 .

[^38]:    ${ }^{65}$ And the overall resistor scaling is typically good to only $\pm 20 \%$ of the nominal value on the datasheet: absolute resistance value is sacrificed on the altar of resistor ratio matching.

[^39]:    ${ }^{66}$ Some manufacturers specify half that value, i.e., the impedance with both terminals tied together; the datasheet usually tells you which they mean.

[^40]:    ${ }^{67}$ There's another way to boost $V_{\mathrm{CM}}$ without such compromise, by using a second op-amp to cancel the common-mode signal; see Figure 7.27 in the previous edition of this book. We are unaware of any commercial difference amplifiers that use this trick.

[^41]:    ${ }^{70}$ At least at dc. At higher frequencies it again becomes important to

[^42]:    ${ }^{71}$ More precisely, it includes an on-chip resistor, ratio matched to $R_{\mathrm{f}}$, to produce an overall guaranteed gain of $100.0 \pm 0.25 \%$.
${ }^{72}$ The datasheet separates out the front-end and second-stage contributions, $1 \mathrm{nV} / \sqrt{\mathrm{Hz}}$ and $65 \mathrm{nV} / \sqrt{\mathrm{Hz}}$, respectively. From these you can calculate the input-referred noise $e_{\mathrm{n}}(\mathrm{RTI})=$ $\left\{e_{\mathrm{n}}(\text { in })^{2}+\left[e_{\mathrm{n}}(\text { out }) / G\right]^{2}+4 k T R_{\mathrm{g}}\right\}^{1 / 2}$. The last term is the square of the Johnson noise voltage $e_{\mathrm{n}}=0.13 \sqrt{R_{\mathrm{g}}} \mathrm{nV} / \sqrt{\mathrm{Hz}}$.

[^43]:    ${ }^{73}$ Put another way, the cable's capacitance degrades the CMRR by creating differential phase shifts between the two signals, owing to their unbalanced source impedances.
${ }^{74}$ Instruments for measuring very low currents - "electrometers" and "source measure units" - include guard outputs and (usually) special BNC-like "triax" connectors for use with triaxial shielded cables.

[^44]:    ${ }^{75}$ Highland Technology's V490 VME Multi-Range Digitizer.
${ }^{76}$ The gain-setting resistors are chosen from standard "E96" $1 \%$ resistor values, so the actual gains differ from round-number values (with $\pm 1 \%$ tolerance they would never be perfect, anyway). This front end would form part of a data-acquisition system, with overall gain and offset data held in software, from a calibration procedure carried out by relays $K_{1}$ and $K_{2}$.

[^45]:    ${ }^{77}$ Larkin sings the praises of Fujitsu FTR-B3GA4.5Z DPDT relays, with their sub-picofarad capacitances.

[^46]:    78 They're rated at 500 V , and come in three small package styles (TO-92, SOT23, and SOT89 with tab). The alternative BSS126 from Infineon is rated at 600 V , and costs less ( $\$ 0.15$ in small quantities). It comes only in the SOT-23 package, whereas the LND150 is available in three package styles, including a 1.5 W TO-243 small power package.
${ }^{79}$ Be sure to check that the op-amp does not suffer from phase reversal (see, e.g., §4.6.6), if you care about the output during input overdrive. A robust cure is to use a pair of input clamp diodes, as in Figure 5.81.

[^47]:    ${ }^{80}$ And a momentary $500 \mathrm{~V}, 250 \mathrm{~W}$ surge in $R_{1}$, which should be a bulkcomposition type, or several SMT resistors in series, to handle both the voltage and the energy transient; see Chapter $1 x$.

[^48]:    ${ }^{81}$ See also related material in the second edition, pp. 422-428.

[^49]:    ${ }^{82}$ L. Vestergaard Hau, S. E. Harris, Z. Dutton, and C. H. Behroozi, "Light speed reduction to 17 metres per second in an ultracold atomic gas," Nature 397 594-598 (1999).
${ }^{83}$ A smallish voltage, but already an uncomfortably large power dissipation $(\sim 75 \mathrm{~W})$, requiring a temperature stabilized oil bath.

[^50]:    84 The AD8227 variant allows $V_{\mathrm{CM}}$ to the negative rail, so you could run it single supply; but you pay a price in larger $V_{\mathrm{OS}}$ and $I_{\mathrm{B}}$, and its CMRR degrades at a lower frequency.

[^51]:    ${ }^{85}$ Some of these have back-to-back clamp diodes across the inputs (true also of some op-amps and comparators), for which the damage is

[^52]:    ${ }^{86}$ To achieve low input currents with the C configuration, LTC uses superbeta BJTs with base-current cancellation in some of the listed parts $\left(I_{\mathrm{B}} \approx 50 \mathrm{pA}\right)$; Analog Devices does even better using JFETs, but with greater offset and noise. Some of the TI/Burr-Brown INAs listed as A types may in fact use the C configuration; their datasheets are silent on the circuit details.
${ }^{87}$ BJT-input amplifiers are prone to RFI upset, because their inputs are forward-biased base-emitter (diode) junctions. And RFI is a real problem in these low-level circuits with inputs from remote sensors. Better to use a JFET-input amplifier if you are bedeviled by RFI.

[^53]:    ${ }^{88}$ Because they contain only a few MOSFETs, current sources, and current mirrors, devices of configuration F can be quite inexpensive. For example, the AD8293 (an AZ with fixed $G=80$ or 160) sells for only \$0.97 (qty 100).

[^54]:    ${ }^{89}$ Some E types (e.g., the AD8130, a variant of the AD8129 in Table 5.8) are specified and characterized only for $G=1$. These are especially useful as differential line receivers, etc., but they are generally limited in swing, typically in the range of 3 to 4 Vpp (the AD8237, with its flying switched capacitors, is an exception). See also $\S 12.10$ for a discussion of differential signaling in the digital context.

[^55]:    ${ }^{90}$ Which may not be evident from the datasheets, which sometimes omit spectral noise plots.

[^56]:    ${ }^{91}$ Or you can power the output from a split supply, staying within that total supply range.
92 See, for example, Dollar and Howe, "The Highly Adaptive SDM Hand: Design and Performance Evaluation", International Journal of Robotics Research 29, (5), 585-597 (2010), available at the web page of The Harvard BioRobotics Laboratory: biorobotics.harvard. edu.

[^57]:    ${ }^{95}$ See also the parts listed under "single-ended to differential" in Table 5.10 (page 375).

[^58]:    100 You can look at this another way: the manufacturer's recommended gain-setting resistor values are chosen such that a small amount of peaking is exploited to extend the amplifier's natural bandwidth.
${ }^{101}$ Many parts (the D and E configurations) let you add feedback capacitors to reduce the bandwidth. With some parts this may introduce instability at low gains, but with others it may improve the stability, especially when larger resistor values are used.

[^59]:    102 Omit the small bypass capacitor shown, if this mode of operation is anticipated.
${ }^{103}$ A member of the hard-to-Google corporate name club, which includes AND Displays, and ON Semiconductor. (Try it: you'll get more than ten billion Google hits for "AND" or "ON.")

[^60]:    ${ }^{104}$ Repeating some important advice: when designing with high-speed ICs, it's particularly important to pay attention to special instructions in the datasheet; the AD9255, for example, devotes nearly a full page to a discussion of input $R$ 's and $C$ 's.
${ }^{105}$ Except when operating at low gain: here that would require $G \leq 1$, so that the AD8139's input terminals are brought up to 1 V or more by the $R_{\mathrm{f}} R_{\mathrm{g}}$ divider. See the discussion in $\S 5.17 .1$.

[^61]:    106 Other differential amplifiers whose feedback inputs can operate at or near ground are indicated with $\mathbf{w}$ or $\mathbf{v}$ in Table 5.10 (page 375), and include the LTC1992, LTC6605, LTC6601, LTC6404, THS4508, and THS4511. These parts span the bandwidth range from 3 MHz to 2000 MHz .

[^62]:    107 But sometimes a little bit of noise can be a good thing, as it can improve ADC linearity and dynamic range by way of "dithering." See, for example, The Art of Digital Audio by John Watkinson (3rd ed., 2001); or Vanderkooy and Lipshitz "Dither in digital audio," J. Audio Eng. Soc., 35, (12), 966-975, (1987).

[^63]:    108 And perhaps read the helpful Analog Devices MT-076 "Differential Driver Analysis."

[^64]:    ${ }^{109}$ Some parts (for example the THS4008 and THS4511) even specify " $V_{S-}=0$ " and "input referenced to ground" as the operating condition for their specifications.
${ }^{110}$ For the latter you can substitute the improved LT1013/1014, which eschew that nasty habit and provide better performance overall; but no such solution is available for differential amplifiers.

[^65]:    111 Taking the example of the LMH6553 and LMH6552 CFB amplifiers, these are specified with $R_{\mathrm{f}}=274 \Omega$ and $357 \Omega$, at which the respective bandwidths are 900 and 1500 MHz , and the slew rates are 2300 and $3800 \mathrm{~V} / \mu \mathrm{s}$. These specs are for $G=1$, but with CFB op-amps you can dramatically increase their gain without losing too much bandwidth. For example the 1500 MHz LMH6552 claims to have 800 MHz of bandwidth still at $G=4$. For higher gain you may prefer not to reduce $R_{\mathrm{i}}$ much, but rather to increase $R_{\mathrm{f}}$. With CFB amplifiers a primary effect of increasing $R_{\mathrm{f}}$ is to reduce the slew rate proportionally; but, hey, you had plenty to begin with! Increasing $R_{\mathrm{f}}$ with CFB does cause an increase in noise.

[^66]:    112 The AD8351 (not in our table, but similar to the AD8352), offers 3 GHz bandwidth with $13 \mathrm{~V} / \mathrm{ns}$ slew rate and 2 Vpp capability to nearly 2 GHz .

[^67]:    115 Throughout the book we use $f_{\mathrm{T}}$ as shorthand for the proper term gainbandwidth product (GBP, GBW, or GBWP), which is the extrapolated unity-gain crossover frequency.

[^68]:    ${ }^{1}$ This downward shift in rolloff frequency is sometimes called the "shrinkage factor"; for a cascade of $n$ identical and buffered $R C$ lowpass sections, the 3 dB frequency is given by $f_{3 \mathrm{~dB}}(n) / f_{3 \mathrm{~dB}}(1)=\sqrt{2^{1 / n}-1}$.

[^69]:    ${ }^{2}$ Not shown is its less-than-stunning in-band-phase characteristics: $495^{\circ}$ phase lag at 16.5 kHz , rising nonlinearly (writhing might be a better term) to $1270^{\circ}$ at 19.5 kHz . Fortunately, phase has little effect upon audio intelligibility.
${ }^{3}$ Based on Figures 11 and 12 from Orchard, H. J., and Sheahan, D. F., "Inductorless Bandpass Filters, "IEEE Journal of Solid-State Circuits, Vol. SC-5, No. 3 (1970), where the designers illustrated an activefilter implementation of this passive-element design. The essence of their paper was that you could implement such an $L C$ filter with better performance and smaller size by replacing the real inductors with gyrators (§6.2.4C). In their implementation the inductors were implemented with inductorless "Riordan gyrators," with each $\pi$-inductor (set of three inductors, including the floating inductor) requiring one quad op-amp, nine resistors and two capacitors. The authors state that inductor Q's greater than 1000 are practical, with the available op-amp gainbandwidth product being the primary limitation. Their 1970-technology gyrator implementation (occupying one cubic inch) was far superior to what was possible with conventional inductors. Interested readers may wish to read R. H. S. Riordan, "Simulated inductors using differential amplifiers," Electronic. Letters 3, pp. 50-51 (Feb. 1967).
${ }^{4}$ Better is the enemy of good enough. (Proverb attributed, variously, to the Soviet Admiral Sergei Gorshkov, to Carl von Clausewitz, and to Voltaire.)

[^70]:    5 Where it would have zero impedance were it not for losses in the inductor and capacitor.

[^71]:    ${ }^{10}$ Also known as a generalized immittance converter.

[^72]:    ${ }^{11}$ Most gyrator implementations are ground referenced; they can replace an inductor that is returned to ground, but not a floating inductor.
${ }^{12}$ Or, equivalently, a generalized immittance converter.
${ }^{13}$ The peaking can be eliminated by adding a resistor in series with the gyrator's capacitor, roughly equal to its reactance at the peaking frequency.

[^73]:    ${ }^{14}$ Application Note AB-026A, by Rick Downs (TI document sbaa001, 1991).
${ }^{15}$ According to SRS, "The architecture of the filter is based on a singly terminated passive $L C$ ladder filter. $L$ 's are simulated with active gyrators formed by op-amp pairs. Passive $L C$ ladder filters have the special characteristic of being very tolerant of variations in component values. Because no section of the ladder is completely isolated from the other, a change in value of any single component affects the entire ladder. The design of the $L C$ ladder however, is such that the characteristics of the rest of the ladder will shift to account for the change in such a

[^74]:    way as to minimize its effect on the ladder. Not only does this loosen the requirement for extremely high accuracy resistors and capacitors, but it also makes the filter extremely stable despite wide temperature variations. As such, the anti-aliasing filter used in the SR830 does not ever require calibration to meet its specifications."
${ }^{16}$ R. P. Sallen and E. L. Key, "A practical method of designing RC active filters," IRE Trans. Circuit Theory, 2 (1), 74-85 (1955).

[^75]:    ${ }^{17}$ Sometimes $t_{\mathrm{d}}$ is defined to $10 \%$ (rather than $50 \%$ ) output.
18 That term comes from wave analysis in dispersive materials, where one distinguishes phase velocity and group velocity. The latter refers to the speed with which a group of frequencies, together making up a characteristic wave shape, moves through the medium. The group delay is the analogous quantity, expressed as a time delay $T_{\mathrm{g}}$, for a signal passing through a filter. The connection between phase shift and group delay is $T_{\mathrm{g}}=-d \phi / d \omega=-\frac{1}{2 \pi} d \phi / d f$.

![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-001.jpg?height=550&width=795&top_left_y=220&top_left_x=220)

Figure 6.19. Time-domain filter characteristics. A simple $R C$ lowpass filter, for example, would have no overshoot or ringing, and would be characterized by a rise time of $t_{\mathrm{r}}=2.2 R C\left(\approx 0.35 / f_{3 \mathrm{~dB}}\right)$, a delay time of $t_{\mathrm{d}}=0.69 R C$, and a settling time (to $1 \%$ ) of $t_{\mathrm{s}}=4.6 R C$.
ripple in the passband characteristic, the transition from pass-band to stopband can be steepened considerably. A third criterion that may be important is the ability of the filter to pass signals within the passband without distortion of their waveforms caused by phase shifts. You may also care about rise time, overshoot, and settling time. Generally speaking, you've got to make tradeoffs among these characteristics - a filter with a sharp cutoff will exhibit poor time-domain properties such as ringing and phase shifts.

There are filter designs available to optimize each of these characteristics, or combinations of them. In fact, rational filter selection will not be carried out as just described; rather, it normally begins with a set of requirements on passband flatness, attenuation at some frequency outside the passband, and whatever else matters. You will then choose the best design for the job, using the number of poles necessary to meet the requirements. ${ }^{19}$ In the next few sections we introduce the three popular classics - the Butterworth filter (maximally flat passband), the Chebyshev filter (steepest transition from passband to stopband), and the Bessel filter (maximally flat time delay). Each of these filter responses can be produced with a variety of different filter circuits, some of which we discuss later. They are

[^0]all available in lowpass, highpass, bandpass, and band-stop (notch) versions. ${ }^{20}$

#### A. Butterworth and Chebyshev filters

The Butterworth filter produces the flattest passband response, at the expense of steepness in the transition region from passband to stopband. As you will see later, it has only mediocre phase and transient characteristics. The amplitude response is given by

$$
\begin{equation*}
\frac{V_{\text {out }}}{V_{\text {in }}}=\frac{1}{\left[1+\left(f / f_{\mathrm{c}}\right)^{2 n}\right]^{\frac{1}{2}}} \tag{6.3}
\end{equation*}
$$

where $n$ is the order of the filter (number of poles). Increasing the number of poles flattens the passband response and steepens the stopband falloff, as shown in Figure 6.20.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-001.jpg?height=575&width=725&top_left_y=850&top_left_x=1107)

Figure 6.20. Normalized lowpass Butterworth filter response curves. Note the improved attenuation characteristics for the higher-order filters.

The Butterworth filter trades off everything else for maximum flatness of response. It starts out extremely flat at zero frequency and bends over near the cutoff frequency $f_{\mathrm{c}}$ (which is usually the -3 dB point).

In most applications, all that really matters is that the wiggles in the passband response be kept less than some amount, say 1 dB . The Chebyshev filter responds to this reality by allowing some ripples throughout the passband, with greatly improved sharpness of the knee (compared with the "maximally flat" Butterworth, for example). A Chebyshev filter is specified in terms of its number of poles

[^1]and passband ripple. By allowing greater passband ripple, you get a sharper knee. The amplitude is given by
\$\$

$$
\begin{equation*}
\frac{V_{\mathrm{out}}}{V_{\mathrm{in}}}=\frac{1}{\left[1+\varepsilon^{2} C_{n}^{2}\left(f / f_{\mathrm{c}}\right)\right]^{\frac{1}{2}}} \tag{6.4}
\end{equation*}
$$

\$\$
where $C_{n}$ is the Chebyshev polynomial of the first kind of degree $n$, and $\varepsilon$ is a constant that sets the passband ripple. Like the Butterworth (but in even greater degree), the Chebyshev has phase and transient characteristics that are far from ideal.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-002.jpg?height=1213&width=749&top_left_y=623&top_left_x=146)

Figure 6.21. Comparison of some common 6-pole lowpass filters. The same filters are plotted on both linear and logarithmic scales. The actual gains of the filters are shown, rather than the "topadjusted" 0 dB convention.

Figure 6.21 presents graphs comparing the responses of Chebyshev and Butterworth 6-pole lowpass filters. As you can see, they're both tremendous improvements over a 6pole $R C$ filter.

As a practical reality, the Butterworth, with its "maximally flat" passband, may not be as attractive as it might
appear, since you are always accepting some variation in passband response anyway (with the Butterworth it is a gradual rolloff near $f_{\mathrm{c}}$, whereas with the Chebyshev it is a set of equal-amplitude ripples spread throughout the passband). Furthermore, active filters constructed with components of finite tolerance will deviate from the predicted response, which means that a real Butterworth filter will exhibit some passband ripple anyway. The graph in Figure 6.22 illustrates the effects of worst-case variations in resistor and capacitor values on filter response.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-002.jpg?height=493&width=690&top_left_y=667&top_left_x=1025)

Figure 6.22. The effect of component tolerance on active-filter performance.

Viewed in this light, the Chebyshev is a very rational filter design. It manages to improve the situation in the transition region by spreading equal-size ripples ${ }^{21}$ throughout the passband, the number of ripples increasing with the order of the filter. Even with rather small ripples (as little as 0.1 dB ) the Chebyshev filter offers considerably improved sharpness of the knee compared with the Butterworth. To make the improvement quantitative, suppose that you need a filter with flatness to 0.1 dB within the passband and 20 dB attenuation at a frequency $25 \%$ beyond the top of the passband. By actual calculation, that will require a 19-pole Butterworth, but only an 8-pole Chebyshev.

The idea of accepting some passband ripple in exchange for improved steepness in the transition region, as in the equiripple Chebyshev filter, is carried to its logical limit in the so-called elliptic (or Cauer) filter by trading ripple in both passband and stopband for an even steeper transition region than that of the Chebyshev filter. ${ }^{22}$ Such a filter does the job, if you are satisfied with an amplitude characteristic that reaches and maintains some minimum attenuation throughout the stopband (rather than continuing to fall

[^2]off with a $6 n \mathrm{~dB} /$ octave ultimate slope). The payback is a simpler filter, with better phase and amplitude characteristics (see below). With computer-aided design techniques, the design of elliptic filters is as straightforward as for the classic Butterworth and Chebyshev filters.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-003.jpg?height=509&width=812&top_left_y=526&top_left_x=219)

Figure 6.23. Specifying filter frequency-response parameters.
Figure 6.23 shows how you specify filter frequency response graphically. In this case (a lowpass filter) you indicate the allowable range of filter gain (i.e., the ripple) in the passband, the minimum frequency at which the response leaves the passband, the maximum frequency at which the response enters the stopband, and the minimum attenuation in the stopband. As an example, Figure 6.24 compares the responses for Chebyshev and elliptic lowpass filter implementations to meet a specified performance, here requiring an 11-pole Chebyshev or a 6-pole elliptic (to meet the same specifications with a Butterworth would require a 32 -pole implementation!). The simpler elliptic filter has the better phase characteristics, but its response does not continue to fall off monotonically with frequency once it has reached the specified stopband attenuation.

#### B. Bessel filter

As we've suggested, the amplitude versus frequency response of a filter does not tell the whole story. A filter characterized by a flat amplitude response may exhibit rapidly changing phase shifts, which produce unequal time delays for signals within its passband. The result is that a signal in the passband will suffer distortion of its waveform. In situations where the shape of the waveform is paramount, a linear-phase filter (or constant-time-delay filter) is desirable. A filter whose phase shift varies linearly with frequency is equivalent to a constant time delay for signals within the passband; i.e., the waveform is not distorted. The
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-003.jpg?height=491&width=799&top_left_y=219&top_left_x=1075)

Figure 6.24. Lowpass filter example: a 6-pole elliptic filter with both passband and stopband ripple (dashed curve) meets the performance specifications shown here, whereas you would need an 11-pole Chebyshev (which has ripple only in its passband) or a 32-pole Butterworth ("maximally flat" - no ripple in passband or stopband) to do as well.

Bessel filter (also called the Thomson filter) ${ }^{23}$ has maximally flat time delay within its passband in analogy with the Butterworth, which has maximally flat amplitude response.

To see the kind of improvement in time-domain performance you get with the Bessel filter, look at Figure 6.25 for a comparison of phase shift and time delay versus frequency for the Bessel filter compared with two classic filters that exhibit more abrupt frequency characteristics (Butterworth and Chebyshev). The poor time-delay performance of the Butterworth (and to a greater extent of the Chebyshev) gives rise to effects such as waveform distortion and overshoot when driven with pulse signals - see Figure 6.26. On the other hand, the price you pay for the Bessel's constancy of time delay is an amplitude response with even less steepness than that of the Butterworth or Chebyshev in the transition region between passband and stopband. An important point: adding sections to a Bessel filter (i.e., making it of higher order) does not significantly increase the steepness of transition into the stopband; it does, however, improve the phase linearity (constancy of time delay), as well as increasing the ultimate rate of falloff, reaching the usual $6 n \mathrm{~dB} /$ octave asymptotic limit (look ahead to Figure 6.30).

23 That's the legendary German mathematician Friedrich Bessel (17841846) who, though not a practicing circuit designer, developed the mathematics. The label Bessel-Thomson recognizes Thomson's application to filters: Thomson, W. E., "Delay Networks having Maximally Flat Frequency Characteristics," Proceedings of the Institution of Electrical Engineers, Part III, 96 44, pp. 487-490 (1949).
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-004.jpg?height=1488&width=1654&top_left_y=210&top_left_x=117)

Figure 6.25. A. Phase shift vs. frequency for three lowpass filter types, each configured with a cutoff frequency of 1 kHz (vertical line). B. Time delay vs. frequency for the adjacent filters; note change of vertical-scale units and linear frequency axis. If you like normalized units, use $f / f_{\mathrm{c}}$ for the horizontal axes, and $t_{\mathrm{d}} / T$ for the time delay.

There are numerous filter designs that attempt to improve on the Bessel's good time-domain performance by compromising some of the constancy of time delay for improved rise time and amplitude-versus-frequency characteristics. The Gaussian filter has phase characteristics nearly as good as those of the Bessel, with improved step response. In another class there are interesting filters that allow uniform ripples in the passband time delay (in analogy with the Chebyshev's ripples in its amplitude response)
and yield approximately constant time delays even for signals well into the stopband; these are sometimes called simply "linear phase" filters, characterized with a parameter that sets the phase ripple (e.g., $0.5^{\circ}$ ) within the passband. Another approach to the problem of making filters with uniform time delays is to use allpass filters (also known as delay equalizers). These have constant amplitude response with frequency, with a phase shift that can be tailored to individual requirements. Thus they can be used to
improve the time-delay constancy of any filter, including Butterworth and Chebyshev types.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-005.jpg?height=1458&width=772&top_left_y=322&top_left_x=234)

Figure 6.26. Response to a 1 V step input at $t=0$, for the three 1 kHz lowpass filters of the previous figures.

#### C. Filter comparison

In spite of the preceding comments about the Bessel filter's frequency response, it still has vastly superior properties in the time domain compared with the Butterworth and Chebyshev. The Chebyshev, with its highly desirable amplitude-versus-frequency characteristics, actually has the poorest time-domain performance of the three. The Butterworth is in between in both frequency- and time-
domain properties. Table 6.1 on the next page and Figures 6.26 and 6.27 give more information about timedomain performance for these three kinds of filters to complement the frequency-domain graphs presented earlier. They make it clear that the Bessel is a desirable filter when performance in the time domain is important.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-005.jpg?height=509&width=774&top_left_y=488&top_left_x=1082)

Figure 6.27. Step-response comparison for 8-pole lowpass filters normalized to 1 Hz cutoff frequency.

### 6.2.7 Filter implementation

We'll see in the next section how to implement these classic filters with R's, C's, and op-amps. These are called active filters, and have the advantage of requiring no inductors. This is good, because inductors tend to be bulky, imperfect, and not inexpensive.

However, for use at frequencies above roughly 100 kHz , it is often preferable to build passive filters like the antialias lowpass filter example we showed in Figure 6.9. You have two choices: you can build your own, or you can buy what you need. To make your own, you can use any of numerous design tables (we give a set in Appendix E) or filter-design software (see §6.3.8) to calculate the $L$ and $C$ values for the particular filter you want. If you are making only a few, you may wish to use slug-tuned inductors (adjusted with an inductance meter or bridge), and either $1 \%$ capacitors or hand-trimmed pairs of paralleled capacitors, to get the precision you need.

Alternatively, you can just throw money at the problem: there are dozens of manufacturers of standard and custom filters, and they are happy to build anything you want. At the low end of the frequency spectrum (say below 100 MHz ) they will use lumped elements ( $L$ 's and $C$ 's); above that you'll get coaxial or cavity filters. If the filter you want is a standard unit (e.g., in the MiniCircuits Labs catalog), it will be inexpensive and generally

Table 6.1 Time-domain Performance Comparison for Lowpass Filters ${ }^{a}$

| Type | $f_{3 \mathrm{~dB}}$ <br> (Hz) | Poles | Step risetime (0-90\%) <br> (s) | Overshoot (\%) | Settling time |  | Stopband attenuation |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  |  |  |  | $\text { to } 1 \%$ <br> (s) | to 0.1\% <br> (s) | $\begin{array}{r} f=2 f_{\mathrm{C}} \\ (\mathrm{~dB}) \end{array}$ | $\begin{gathered} f=10 f_{\mathrm{C}} \\ (\mathrm{~dB}) \end{gathered}$ |
| $\begin{aligned} & \text { Bessel } \\ & (-3 \mathrm{~dB} \text { at } \\ & \left.f_{\mathrm{c}}=1 \mathrm{~Hz}\right) \end{aligned}$ | 1.0 | 2 | 0.4 | 0.4 | 0.6 | 1.1 | 10 | 36 |
|  | 1.0 | 4 | 0.5 | 0.8 | 0.7 | 1.2 | 13 | 66 |
|  | 1.0 | 6 | 0.6 | 0.6 | 0.7 | 1.2 | 14 | 92 |
|  | 1.0 | 8 | 0.7 | 0.3 | 0.8 | 1.2 | 14 | 114 |
| $\begin{gathered} \text { Butterworth } \\ (-3 \mathrm{~dB} \text { at } \\ \left.f_{\mathrm{C}}=1 \mathrm{~Hz}\right) \end{gathered}$ | 1.0 | 2 | 0.4 | 4 | 0.8 | 1.7 | 12 | 40 |
|  | 1.0 | 4 | 0.6 | 11 | 1.0 | 2.8 | 24 | 80 |
|  | 1.0 | 6 | 0.9 | 14 | 1.3 | 3.9 | 36 | 120 |
|  | 1.0 | 8 | 1.1 | 16 | 1.6 | 5.1 | 48 | 160 |
| $\begin{gathered} \text { Chebyshev } \\ 0.5 \mathrm{~dB} \text { ripple } \\ (-0.5 \mathrm{~dB} \text { at } \\ \left.f_{\mathrm{C}}=1 \mathrm{~Hz}\right) \end{gathered}$ | 1.39 | 2 | 0.4 | 11 | 1.1 | 1.6 | 8 | 37 |
|  | 1.09 | 4 | 0.7 | 18 | 3.0 | 5.4 | 31 | 89 |
|  | 1.04 | 6 | 1.1 | 21 | 5.9 | 10.4 | 54 | 141 |
|  | 1.02 | 8 | 1.4 | 23 | 8.4 | 16.4 | 76 | 193 |
| Chebyshev <br> 2dB ripple <br> (-2dB at <br> $f_{\mathrm{C}}=1 \mathrm{~Hz}$ ) | 1.07 | 2 | 0.4 | 21 | 1.6 | 2.7 | 15 | 44 |
|  | 1.02 | 4 | 0.7 | 28 | 4.8 | 8.4 | 37 | 96 |
|  | 1.01 | 6 | 1.1 | 32 | 8.2 | 16.3 | 60 | 148 |
|  | 1.01 | 8 | 1.4 | 34 | 11.6 | 24.8 | 83 | 200 |
| Notes: (a) a design procedure for these filters is presented in the section "VCVS circuits." |  |  |  |  |  |  |  |  |

delivered from stock. Otherwise you will pay at least a hundred dollars, and wait at least a few weeks. Some manufacturers we've used are Lark Engineering, Mini-Circuits Laboratories, Trilithic (Cir-Q-Tel), and TTE.

## 6.3 Active-filter circuits

A lot of ingenuity has been used in inventing clever active circuits, each of which can be used to generate response functions such as the Butterworth, Chebyshev, etc. You might wonder why the world needs more than one activefilter circuit. The reason is that various circuit realizations excel in one or another desirable property, so there is no all-around best circuit.

Active filters can be built using discrete op-amps as the active elements. ${ }^{24}$ In that case you must provide the resistors and capacitors that set the filter characteristics. These passive components must generally be accurate and stable, particularly in filters with sharp frequency characteristics. An attractive alternative is to take advantage of the rich variety of IC active filters, in which most of the hard work has been done, including the on-chip integration of matched passive components.

[^3]Active filters come in two basic varieties: "continuoustime" filters, and switched-capacitor filters. Continuoustime filters are analog circuits made from op-amps, resistors, and capacitors; the filter characteristics are set by the component values and, of course, the circuit configuration. The thing just sits there and acts like a filter. Switchedcapacitor filters use a capacitor combined with a MOSFET switch, turned on and off by an externally applied clocking signal, to substitute for the input resistor in the classic op-amp integrator. The effective resistor value is set by the clocking frequency. A typical switched-capacitor filter uses several such integrators in combination with additional opamps to implement the desired filter function. ${ }^{25}$ Switchedcapacitor filters have the advantages of being simply tuned over a wide range (by the applied clocking frequency), of maintaining stable characteristics, and of being particularly easy to fabricate as ICs. However, they are generally noisier (i.e., with smaller dynamic range), have higher distortion, and can introduce switching artifacts such as aliasing and clock feedthrough.

Some of the features to look for in active filters are (a) small numbers of parts, both active and passive, (b) ease

[^4]of adjustability, (c) small spread of parts values, especially the capacitor values, (d) undemanding use of the op-amp, especially requirements on slew rate, bandwidth, and output impedance, (e) the ability to make high- $Q$ filters, (f) electrical tunability, and (g) sensitivity of filter characteristics to component values and op-amp gain (in particular, the gain-bandwidth product, $f_{\mathrm{T}}$ ). In many ways, the last feature is one of the most important. A filter that requires parts of high precision is difficult to adjust, and it will drift as the components age; in addition, there is the nuisance that it requires components of good initial accuracy. The VCVS circuit probably owes most of its popularity to its simplicity and its low parts count, but it suffers from high sensitivity to component variations. By comparison, recent interest in more complicated filter realizations is motivated by the benefits of insensitivity of filter properties to small component variability.

In this section we present several circuits for lowpass, highpass, and bandpass active filters. We begin with the popular VCVS, or controlled-source type, then show the state-variable designs available as ICs from several manufacturers, and finally mention the twin-T sharp rejection filter.

Most of the new active-filter ICs being introduced are of the switched-capacitor type, owing to their ease of use, small size, low cost, excellent stability, and (in some cases) complete absence of required external components. We conclude the chapter with a discussion of them.

### 6.3.1 VCVS circuits

The voltage-controlled voltage-source (VCVS) filter, also known simply as a controlled-source filter, was devised by Sallen and Key (and introduced in simplified form in §6.2.4E). It's a variation of the simpler unity-gain circuit shown earlier (Figure 6.16), in which the unity-gain follower is replaced with a noninverting amplifier of gain greater than unity. Figure 6.28 shows the circuits for lowpass, highpass, and bandpass realizations. The resistors at the outputs of the op-amps create a noninverting voltage amplifier of voltage gain $K$, with the remaining $R$ 's and $C$ 's contributing the frequency response properties for the filter. These are 2 -pole filters, and they can be Butterworth, Bessel, etc., by suitable choice of component values, as we show later. Any number of VCVS 2-pole sections may be cascaded to generate higher-order filters. When that is done, the individual filter sections are, in general, not identical. In fact, each section represents a quadratic polynomial factor of the $n$ th-order polynomial describing the overall filter.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-007.jpg?height=1126&width=777&top_left_y=223&top_left_x=1119)

Figure 6.28. VCVS active-filter circuits.

There are design equations and tables in most standard filter handbooks for all the standard filter responses, usually including separate tables for each of a number of ripple amplitudes for Chebyshev filters. In the next section we present an easy-to-use design table for VCVS filters of Butterworth, Bessel, and Chebyshev responses ( 0.5 dB and 2 dB passband ripple for Chebyshev filters) for use as lowpass or highpass filters. Bandpass and band-reject filters can be made from combinations of these.

### 6.3.2 VCVS filter design using our simplified table

To use Table 6.2 to make a lowpass or a highpass filter, begin by deciding which filter response you need. As we mentioned earlier, the Butterworth may be attractive if maximum flatness of passband is desired, the Chebyshev gives the fastest rolloff from passband to stopband (at the expense of some ripple in the passband), and the Bessel provides the best phase characteristics, i.e., constant signal delay in the passband, with correspondingly good step
response. The frequency responses for all types are shown in the accompanying graphs (Figure 6.30).

#### Table 6.2 VCVS Lowpass Filters

| $\frac{\mathscr{0}}{\circ}$ | Butterworth K | Bessel |  | Chebyshev ( 0.5 dB ) |  | Chebyshev (2dB) |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  | $c$ | K | $c$ | K | $c$ | K |
| 2 | 1.586 | 1.272 | 1.268 | 1.231 | 1.842 | 0.907 | 2.114 |
| 4 | 1.152 | 1.432 | 1.084 | 0.597 | 1.582 | 0.471 | 1.924 |
|  | 2.235 | 1.606 | 1.759 | 1.031 | 2.660 | 0.964 | 2.782 |
| 6 | 1.068 | 1.607 | 1.040 | 0.396 | 1.537 | 0.316 | 1.891 |
|  | 1.586 | 1.692 | 1.364 | 0.768 | 2.448 | 0.730 | 2.648 |
|  | 2.483 | 1.908 | 2.023 | 1.011 | 2.846 | 0.983 | 2.904 |
| 8 | 1.038 | 1.781 | 1.024 | 0.297 | 1.522 | 0.238 | 1.879 |
|  | 1.337 | 1.835 | 1.213 | 0.599 | 2.379 | 0.572 | 2.605 |
|  | 1.889 | 1.956 | 1.593 | 0.861 | 2.711 | 0.842 | 2.821 |
|  | 2.610 | 2.192 | 2.184 | 1.006 | 2.913 | 0.990 | 2.946 |

To construct an $n$-pole filter (for $n$ an even integer), you will need to cascade $n / 2$ VCVS sections. Within each section, $R_{1}=R_{2}=R$, and $C_{1}=C_{2}=C$. As is usual in op-amp circuits, $R$ will typically be chosen in the range 10 k to 100 k . (It is best to avoid small resistor values, because the rising open-loop output impedance of the op-amp at high frequencies adds to the resistor values and upsets calculations.) Then all you need to do is set the gain, $K$, of each stage according to the table entries. For an $n$-pole filter there are $n / 2$ entries, one for each section.

#### A. Butterworth lowpass filters

If the filter is a Butterworth, all sections have the same values of $R$ and $C$, given simply by $R C=1 / 2 \pi f_{\mathrm{c}}$, where $f_{\mathrm{c}}$ is the desired -3 dB frequency of the entire filter. To make a 6-pole lowpass Butterworth filter, for example, you cascade three of the lowpass sections shown previously, with gains of $1.07,1.59$, and 2.48 (preferably in that order, to avoid dynamic range problems), and with identical $R$ 's and $C$ 's to set the 3 dB point.

#### B. Bessel and Chebyshev lowpass filters

To make a Bessel or Chebyshev filter with the VCVS, the situation is only slightly more complicated. Again we cascade several 2-pole VCVS filters, with prescribed gains for each section. Within each section we again use $R_{1}=R_{2}=R$ and $C_{1}=C_{2}=C$. However, unlike the situation with the Butterworth, the $R C$ products for the different sections are different and must be scaled by the normalizing factor $c_{\mathrm{n}}$ (given for each section in Table 6.2 on this page) according
to $R C=1 / 2 \pi c_{\mathrm{n}} f_{\mathrm{c}}$. Here $f_{\mathrm{c}}$ is again the -3 dB point for the Bessel filter, whereas for the Chebyshev filter it defines the end of the passband, i.e., it is the frequency at which the amplitude response falls out of the ripple band on its way into the stopband. For example, the response of a Chebyshev lowpass filter with 0.5 dB ripple and $f_{\mathrm{c}}=100 \mathrm{~Hz}$ will be flat within +0 dB to -0.5 dB from dc to 100 Hz , with 0.5 dB attenuation at 100 Hz and a rapid falloff for frequencies greater than 100 Hz . Values are given for Chebyshev filters with 0.5 dB and 2.0 dB passband ripple; the latter have a somewhat steeper transition into the stopband (Figure 6.30).
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-008.jpg?height=598&width=955&top_left_y=747&top_left_x=959)

Figure 6.29. VCVS lowpass filter example. Resistor values shown are the nearest standard 1\% values (known as "E96").

#### An example

As an illustration, Figure 6.29 shows a VCVS implementation of a 4-pole lowpass filter with $f_{\mathrm{c}}=100 \mathrm{~Hz}$; resistor values for three filter characteristics are listed, calculated as just described. We used a similar filter (6-pole Butterworth, $f_{\mathrm{c}}=90 \mathrm{~Hz}$ ) to create a precision $50-70 \mathrm{~Hz}$ sinewave from a digital square wave that was referenced to a crystal oscillator; the output was amplified and used to drive an astronomical telescope. ${ }^{26}$

#### C. Highpass filters

To make a highpass filter, use the highpass configuration shown previously, i.e., with the $R$ 's and $C$ 's interchanged. For Butterworth filters, everything else remains unchanged (use the same values for $R, C$, and $K$ ). For the Bessel and Chebyshev filters, the $K$ values remain the same, but the

[^5]![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-009.jpg?height=1202&width=1455&top_left_y=205&top_left_x=318)

Figure 6.30. Normalized frequency response graphs for the 2-, 4-, 6-, and 8-pole filters in Table 6.2. The Butterworth and Bessel filters are normalized to 3 dB attenuation at unit frequency, whereas the Chebyshev filters are normalized to 0.5 dB and 2 dB attenuations. As explained earlier, the top of the ripple band in the Chebyshev plots has been set to unity.
normalizing factors $c_{\mathrm{n}}$ must be inverted, i.e., for each section the new $c_{\mathrm{n}}$ equals $1 /\left(c_{\mathrm{n}}\right.$ listed in Table 6.2 on the preceding page).

A bandpass filter can be made by cascading overlapping lowpass and highpass filters. A band-reject filter can be made by summing the outputs of nonoverlapping lowpass and highpass filters. However, such cascaded filters won't work well for high- $Q$ filters (extremely sharp bandpass filters) because there is great sensitivity to the component values in the individual (uncoupled) filter sections. In such cases a high- $Q$ single-stage bandpass circuit (e.g., the VCVS bandpass circuit illustrated previously, or the state-variable and biquad filters in the next section) should be used instead. Even a single-stage 2-pole filter can produce a response with an extremely sharp peak. Information on such filter design is available in the standard references.

#### D. Generalizing the Sallen-and-Key filter

A design simplification in these Sallen-and-Key (or VCVS) filter circuits was the use of identical resistor and capacitor values within each 2-pole filter stage; but with that simplification came a set of oddball amplifier gains, as seen in the "Gain" column in Figure 6.29.

Often you want to set the filter's gain, for example to prevent saturation, or so that you can change the filter characteristics (by a change of component value) without altering the gain. When you constrain the gain, however, you have to relax the component ratio constraint. You can learn all about this in a pair of nice Application Notes by James Karki from TI. ${ }^{27}$ The bottom line is that (just as with the preceding VCVS circuits) you can create any filter

[^6]characteristic, using amplifier stages with your choice of gain, providing you are willing to adjust the resistor and capacitor ratios.

Following Karki's analysis, we can write down summary formulas for the transition frequency $f_{\mathrm{c}}$ and $Q$ of a 2-pole Sallen-Key section in which the component ratios can take on arbitrary values. Following the naming convention $^{28}$ of Figure 6.28A, we define parameters $m, n$, and $\tau$ (which will make the final results prettier):

$$
m=R_{1} / R_{2}, n=C_{1} / C_{2}, \text { and } \tau=R_{2} C_{2}
$$

With these definitions, a 2-pole filter section has a transition frequency

$$
\begin{equation*}
f_{c}=\frac{1}{2 \pi \tau \sqrt{m n}} \tag{6.5}
\end{equation*}
$$

and a $Q$ (sharpness of transition, or peakiness) of

$$
\begin{equation*}
Q=\frac{\sqrt{m n}}{1+m+m n(1-K)} \tag{6.6}
\end{equation*}
$$

These results alone are not enough for you to design higher-order filter cascades with canonical filter shapes (Chebyshev, etc.); for that you can consult the tables in Karki's App Note SLOA049B, or (for more fun) use a filter-design program. But these expressions demonstrate the point that you can trade off one set of constraints for another. Note particularly the attractive case of unity gain ( $K=1$ ), for which the gain elements can be wideband unitygain buffer ICs, or simple discrete-transistor followers. ${ }^{29}$

Revisiting the earlier constraint we used with the VCVS table (i.e., $R_{1}=R_{2}=R, C_{1}=C_{2}=C$ ), these formulas reduce to the simple forms

$$
\begin{equation*}
f_{c}=\frac{1}{2 \pi R C}, \quad Q=\frac{1}{3-K} \tag{6.7}
\end{equation*}
$$

for which the circuit goes unstable $(Q \rightarrow \infty)$ when $K=3$. Note that such a circuit, with the gain $K$ further constrained to unity (i.e., a follower, as we illustrated in Figure 6.16 to introduce the idea of an active filter) produces a pretty anemic filter, with a $Q$ of just one half.

#### E. Summary

VCVS filters minimize the number of components needed (two poles per op-amp) and offer the additional advantages of noninverting gain, low output impedance, small

[^7]spread of component values, easy adjustability of gain, and the ability to operate at high gain or high $Q$. They suffer from sensitivity to component values and amplifier gain, and they don't lend themselves well to applications where a tunable filter of stable characteristics is needed. And they require op-amps whose bandwidth ( $f_{\mathrm{T}}$, or GBW) is much higher than $f_{\mathrm{c}}$ of the filter. ${ }^{30}$ Some of these drawbacks are nicely remedied in the state-variable and biquad filters.

Exercise 6.3. Design a 6-pole Chebyshev lowpass VCVS filter with a 0.5 dB passband ripple and 100 Hz cutoff frequency $f_{\mathrm{c}}$. What is the attenuation at $1.5 f_{\mathrm{c}}$ ?

### 6.3.3 State-variable filters

The 2-pole filter shown in Figure 6.31 is far more complex than the VCVS circuits, but it is popular because of its improved stability and ease of adjustment. It is called a state-variable filter and was originally available as an IC from National (the AF100 and AF150, now discontinued); you can get it from Burr-Brown/TI (the UAF42), and a closely similar part is made by Maxim (MAX274-5). Because it is a manufactured module, all components except $R_{\mathrm{G}}, R_{\mathrm{Q}}$, and the two $R_{\mathrm{F}}$ 's are built in. Among its nice properties is the availability of highpass, lowpass, and bandpass outputs from the same circuit; also, its frequency can be tuned while maintaining constant $Q$ (or, alternatively, constant bandwidth) in the bandpass characteristic. As with the VCVS realizations, multiple stages can be cascaded to generate higher-order filters. The frequency can be made adjustable with a dual pot for the $R_{\mathrm{F}}$ pair. But, given the inverse $(1 / R)$ frequency tuning, you may prefer a linear scheme like that shown in Figure 6.34, where you could use either a dual pot or a dual multiplying DAC (see §6.3.3C).

Extensive design formulas and tables are provided by the manufacturers for the use of these convenient ICs. They show how to choose the external resistor values to make Butterworth, Bessel, and Chebyshev filters for a wide range of filter orders, with lowpass, highpass, bandpass, or bandreject responses. Among the nice features of these hybrid ICs is integration of the capacitors into the module, ${ }^{31}$ so that only external resistors need be added.

[^8]![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-011.jpg?height=682&width=894&top_left_y=210&top_left_x=145)

Figure 6.31. State-variable active filter.

#### A. Bandpass filters

The state-variable circuit, in spite of its large number of components, is a good choice for sharp (high- $Q$ ) bandpass filters. It has low component sensitivities, does not make great demands on op-amp bandwidth, and is easy to tune. For example, in the circuit of Figure 6.31 used as a bandpass filter, the two resistors $R_{\mathrm{F}}$ set the center frequency, and $R_{\mathrm{Q}}$ and $R_{\mathrm{G}}$ together determine the $Q$ and band-center gain:

$$
\begin{align*}
& R_{\mathrm{F}}=5.03 \times 10^{7} / f_{0} \quad \text { ohms }  \tag{6.8}\\
& R_{\mathrm{Q}}=10^{5} /(3.48 Q+G-1) \quad \text { ohms }  \tag{6.9}\\
& R_{\mathrm{G}}=3.16 \times 10^{4} Q / G \quad \text { ohms } \tag{6.10}
\end{align*}
$$

So you could make a tunable-frequency, constant- $Q$ filter by using a 2 -section variable resistor (pot) for $R_{\mathrm{F}}$. Alternatively, you could make $R_{\mathrm{Q}}$ adjustable, producing a fixedfrequency, variable- $Q$ (and, unfortunately, variable-gain) filter.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-011.jpg?height=544&width=957&top_left_y=1728&top_left_x=144)

Figure 6.32. A filter with independently settable gain and $Q$.

Exercise 6.4. Calculate resistor values in Figure 6.32 to make a bandpass filter with $f_{0}=1 \mathrm{kHz}, Q=50$, and $G=10$.

Figure 6.32 shows a useful variant of the state-variable bandpass filter. The bad news is that it uses four op-amps; the good news is that you can adjust the bandwidth (i.e., $Q$ ) without affecting the midband gain. In fact, both $Q$ and gain are set with a single resistor each. The $Q$, gain, and center frequency are completely independent and are given by these simple equations:

$$
\begin{align*}
f_{0} & =1 / 2 \pi R_{\mathrm{F}} C  \tag{6.11}\\
Q & =R_{1} / R_{\mathrm{Q}}  \tag{6.12}\\
G & =R_{1} / R_{\mathrm{G}}  \tag{6.13}\\
R & \approx 10 \mathrm{k} \quad \text { (noncritical, matched) } . \tag{6.14}
\end{align*}
$$

Biquad filter
A close relative of the state-variable filter is the so-called biquad filter, shown in Figure 6.33. This circuit also uses three op-amps and can be constructed from the statevariable ICs mentioned earlier. It has the interesting property that you can tune its frequency ( via $R_{\mathrm{F}}$ ) while maintaining constant bandwidth (rather than constant $Q$ ). Here are the design equations:

$$
\begin{align*}
f_{0} & =1 / 2 \pi R_{\mathrm{F}} C,  \tag{6.15}\\
\mathrm{BW} & =1 / 2 \pi R_{\mathrm{B}} C,  \tag{6.16}\\
G & =R_{\mathrm{B}} / R_{\mathrm{G}} . \tag{6.17}
\end{align*}
$$

The $Q$ is given by $f_{0} / \mathrm{BW}$ and equals $R_{\mathrm{B}} / R_{\mathrm{F}}$. As the center frequency is varied (via $R_{\mathrm{F}}$ ), the $Q$ varies proportionately, keeping the bandwidth $f_{0} / Q$ constant.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-011.jpg?height=542&width=794&top_left_y=1568&top_left_x=1067)

Figure 6.33. Biquad active filter.
When you design a biquad filter from scratch (rather than with an active-filter IC that already contains most of the parts), the general procedure goes something like this.
(1) Choose an op-amp whose bandwidth $f_{\mathrm{T}}$ is at least 10 to 20 times $G f_{0}$.
(2) Pick a round-number capacitor value in the vicinity of $C=10 / f_{0} \mu \mathrm{~F}$, where $f_{0}$ is in Hz .
(3) Use the desired center frequency to calculate the corresponding $R_{\mathrm{F}}$ from eq'n 6.15 .
(4) Use the desired bandwidth to calculate $R_{\mathrm{B}}$ from eq'n 6.16.
(5) Use the desired band-center gain to calculate $R_{\mathrm{G}}$ from eq'n 6.17.

You may have to adjust the capacitor value if the resistor values become awkwardly large or small. For instance, in a high- $Q$ filter you may need to increase $C$ somewhat to keep $R_{\mathrm{B}}$ from becoming too large (or you can use the T-network trick described in $\S 4.5 .5$ ). Note that $R_{\mathrm{F}}, R_{\mathrm{B}}$, and $R_{\mathrm{G}}$ each act as op-amp loads, and so they ought not to become less than, say, 5k. When juggling component values, you may find it easier to satisfy requirement (1) by decreasing integrator gain (increase $R_{\mathrm{F}}$ ) and simultaneously increasing the inverter-stage gain (increase the 10k feedback resistor).

As an example, suppose we want to make a filter with the same characteristics as in Exercise 6.4 on page 411. We would begin by provisionally choosing $C=0.01 \mu \mathrm{~F}$. Then we find $R_{\mathrm{F}}=15.9 \mathrm{k}\left(f_{0}=1 \mathrm{kHz}\right)$ and $R_{\mathrm{B}}=796 \mathrm{k}(Q=50$; $\mathrm{BW}=20 \mathrm{~Hz})$. Finally, $R_{\mathrm{G}}=79.6 \mathrm{k}(G=10)$.

Exercise 6.5. Design a biquad bandpass filter with $f_{0}=60 \mathrm{~Hz}$, $\mathrm{BW}=1 \mathrm{~Hz}$, and $G=100$.

#### B. Higher-order bandpass filters

As with our earlier lowpass and highpass filters, it is possible to build higher-order bandpass filters with approximately flat bandpass and steep transition to the stopband.

You do this by cascading several lower-order bandpass filters, the combination tailored to realize the desired filter type (Butterworth, Chebyshev, or whatever). As before, the Butterworth is "maximally flat," whereas the Chebyshev sacrifices passband flatness for steepness of skirts. Both the VCVS and state-variable/biquad bandpass filters just considered are second-order (two pole). As you increase the filter sharpness by adding sections, you generally degrade the transient response and phase characteristics. The "bandwidth" of a bandpass filter is defined as the width between -3 dB points, except for equiripple filters, for which it is the width between frequencies at which the response falls out of the passband ripple channel.

You can find tables and design procedures for constructing complex filters in standard books on active filters, or in the datasheets for active-filter ICs. There are also some very nice filter-design programs, including shareware and
freeware versions that run on standard PCs and workstations.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-012.jpg?height=305&width=748&top_left_y=322&top_left_x=1006)

Figure 6.34. Tuning the frequency of the state-variable active filter. The op-amp buffer can be omitted if strict linearity with pot rotation is not needed.

#### C. Electronic tunability

Sometimes you want electrical tunability (or switchability) so you can change filter characteristics under control of a signal (rather than having to turn the shaft on a variable resistor). An example might be an anti-alias lowpass filter that precedes a digitizer, in which the digitizing rate $f_{\text {samp }}$ can be varied over some range. In that case the filter's $f_{\mathrm{c}}$ must be set to follow the Nyquist frequency, $f_{\mathrm{c}} \approx f_{\text {samp }} / 2$ (see $\S \S 6.2 .3 \mathrm{C}, 6.3 .7 \mathrm{~A}$, and 13.5.1B). In active-filter circuits like the VCVS you can do this, to a limited extent, by using analog switches to select among a small set of fixed resistors, each of which substitutes for one of the resistors in the filter. But the state variable filters provide a particularly convenient way to accomplish both switchability and continuous tuning, in one of several ways.
Digital potentiometer As we discussed in §3.4.3E, you can get convenient ICs that contain a long string of matched resistors, with MOSFET switches to select the voltage-divider tap (by means of digital control ${ }^{32}$ ). So you can effectively alter the value of a programming resistor (e.g., $R_{\mathrm{F}}$ in Figure 6.31) by preceding it with such a digital voltage divider (with a unity-gain follower, if needed to drive a low-value $R_{\mathrm{F}}$ ); see Figure 6.34. By using a dual digital pot ${ }^{33}$ you could adjust the pair of $R_{\mathrm{F}}$ 's simultaneously, as would be needed to tune $f_{0}$ in that bandpass circuit. Digital pots come with as many as 1024 taps, and they come in both linear and log spacing, so you can achieve pretty accurate electronic control. Digital pots do not provide particularly accurate overall resistance values (typically $\pm 20 \%$ ), but they do guarantee accurate and stable control of divider ratio ( $1 \%$ or

[^9]better); i.e., the resistors that make up the string are well matched. That is why they work well in this application, in which only the ratio is important.
Multiplying DAC Another way to effectively vary $R_{\mathrm{F}}$ in the state-variable filter is to use a multiplying DAC (digital-to-analog converter), rather than a programmable divider, to scale the op-amp's voltage output. The MDAC outputs a voltage (or a current, in some models) that is proportional to the product of an analog input voltage and a digital input quantity. Compared with the digital pot, the MDAC method provides higher resolution (finer step size), faster response, and (often) wider voltage range.
Analog switch If only a discrete set of filter parameters is desired, you can just use a set of MOSFET analog multiplexers to select among a preselected group of programming resistors. Don't forget to consider the effects of finite $R_{\mathrm{ON}}$.
Integrated switchability There are a few active-filter ICs that provide for programmable cutoff frequency, by a digital code you apply to a set of programming pins. You don't get continuous control, but you sure save a lot of work (and a lot of parts). In this class are the LTC1564 (8-pole elliptic lowpass), which lets you select the cutoff frequency from 10 kHz to 150 kHz in 10 kHz steps, and the MAX270 (dual 2-pole lowpass), which lets you select the cutoff frequency among 128 steps going from 1 kHz to 25 kHz .

#### Electronic tuning alternatives: switched-capacitor filters and DSP

The above techniques achieve electronic tunability by presenting the continuous-time filter with an effectively variable set of programming resistors. When thinking about electronic tuning, it's wise to consider switched-capacitor filters and digital signal processing (DSP), in both of which electronic tunability is inherent. These are discussed later in this chapter (§6.3.6 and 6.3.7).

#### D. Multiple-feedback active filter

In addition to the VCVS (Sallen-and-Key) and statevariable (or biquad) active-filter circuit configurations, there's another active-filter circuit that's commonly used. It's called the "multiple-feedback" (MFB) active filter (also known as the "infinite-gain multiple-feedback"), and is shown in Figure 6.35. Here the op-amp is configured as an integrator, rather than as a voltage amplifier (or follower). Designing an MFB filter is no more difficult than designing a VCVS, and you can find nice filter software that supports both configurations, for example at the very fine website of

Uwe Beis (see §6.3.8). You can get nice MFB filter ICs, for example the LTC1563, an inexpensive (\$2.30) linearfilter IC using the MFB configuration, convenient for making anti-alias filters, etc. The ' $1563-2$ version makes 4 - and 5-pole Butterworth filters, from 256 Hz to 360 kHz , and the -3 version makes Bessel filters. The ICs use internal 27 pF to 54 pF capacitors trimmed to $3 \%$, combined with your external 7 k to $10 \mathrm{M} 1 \%$ resistors. The datasheet is especially instructive.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-013.jpg?height=333&width=529&top_left_y=632&top_left_x=1205)

$$
\left.\begin{array}{l}
R=20 \mathrm{k} \\
C=5.6 \mathrm{nF}
\end{array}\right\} f_{\mathrm{C}}=1 \mathrm{kHz}
$$

Figure 6.35. Multiple-feedback (MFB) active filter, here shown in a 2-pole lowpass configuration.

This configuration has an interesting advantage compared with the VCVS: as you go to high frequencies, approaching the bandwidth $f_{\mathrm{T}}$ of the op-amp, the degrading effects of rising op-amp output impedance are less severe. We ran SPICE simulations of VCVS and MFB 2pole Butterworth lowpass filters (Figures 6.36 and 6.37), which show this effect nicely. We set the cutoff frequency at 4 kHz , well below the LF411's unity-gain frequency $\left(f_{\mathrm{T}}\right)$ of 4 MHz . In the VCVS configuration the op-amp's rising $Z_{\text {out }}$ allows input signal to couple to the output through the first capacitor, a path that is absent in the MFB configuration. ${ }^{34}$ In many applications, however, this is not a serious worry. And the effect is reduced as the resistor values of the filter are increased, as shown in Figure 6.36. The VCVS configuration is alive and well, and remains popular. ${ }^{35}$

[^10]![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-014.jpg?height=598&width=799&top_left_y=221&top_left_x=121)

Figure 6.36. The rising closed-loop output impedance of the opamp degrades the high-frequency attenuation in the VCVS (Sallen-and-Key) configuration, by allowing some input signal to couple to the output through the input resistor and feedback capacitor ( $R_{1}$ and $C_{1}$ in Figure 6.28). Larger resistor values reduce the effect. See also Figure 6.37.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-014.jpg?height=608&width=805&top_left_y=1122&top_left_x=118)

Figure 6.37. The stopband attenuation of the MFB configuration is not much affected by rising op-amp output impedance (e.g., as seen in Figure 4.53), compared with that of the VCVS. However, you can mitigate the effect in the VCVS by using a second opamp to create a buffered output from the signal at the op-amp's noninverting input.

### 6.3.4 Twin-T notch filters

The passive $R C$ network shown in Figure 6.38 has infinite attenuation at a frequency $f_{c}=1 / 2 \pi R C$. Infinite attenuation is uncharacteristic of $R C$ filters in general; this one works by effectively adding two signals that have been shifted $180^{\circ}$ out of phase at the cutoff frequency. It requires
good matching of components to obtain a good null at $f_{\mathrm{c}}$. It is called a twin-T, and it can be used to remove an interfering signal, such as 60 Hz powerline pickup. The problem is that it has the same "soft" cutoff characteristics as all passive $R C$ networks, except, of course, near $f_{\mathrm{c}}$, where its response drops like a rock. For example, a twin-T driven by a perfect voltage source is down 10 dB at twice (or half) the notch frequency and 3 dB at four times (or one-fourth) the notch frequency. One trick to improve its notch characteristic is to "activate" it in the manner of a Sallen-and-Key filter (Figure 6.39). This technique looks good in principle, but it is generally disappointing in practice, owing to the impossibility of maintaining a good filter null. As the filter notch becomes sharper (more gain in the bootstrap), its null becomes less deep.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-014.jpg?height=346&width=475&top_left_y=860&top_left_x=1140)

Figure 6.38. Passive twin-T notch filter.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-014.jpg?height=407&width=659&top_left_y=1322&top_left_x=1058)

Figure 6.39. Bootstrapped twin-T.
Twin-T filters are available as prefab modules, going from 1 Hz to 50 kHz , with notch depths of about 60 dB (with some deterioration at high and low temperatures). They are easy to make from components, but resistors and capacitors of good stability and low temperature coefficient should be used to get a deep and stable notch. One of the components should be made trimmable.

The twin-T filter works fine as a fixed-frequency notch, but it is a horror to make tunable, because three resistors must be simultaneously adjusted while maintaining constant ratio. However, the remarkably simple $R C$ circuit of Figure 6.40A, which behaves just like the twin-T, can be
adjusted over a significant range of frequency (at least two octaves) with a single potentiometer. Like the twin-T (and most active filters) it requires some matching of components; in this case, the three capacitors must be identical, and the fixed resistor must be exactly six times the bottom (adjustable) resistor. The notch frequency is then given by

$$
f_{\text {notch }}=1 / 2 \pi C \sqrt{3 R_{1} R_{2}} .
$$

Figure 6.40B shows an implementation that is tunable from 25 Hz to 100 Hz . The 50 k trimmer is adjusted (once) for maximum depth of notch.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-015.jpg?height=812&width=641&top_left_y=691&top_left_x=302)

Figure 6.40. Bridged differentiator tunable-notch filter. The implementation in (B) tunes from 25 Hz to 100 Hz .

As with the passive twin-T, this filter (known as a bridged differentiator) has a gently sloping attenuation away from the notch and infinite attenuation (assuming perfect matching of component values) at the notch frequency. It, too, can be "activated" by bootstrapping the wiper of the pot with a voltage gain somewhat less than unity (as in Figure 6.39). Increasing the bootstrap gain toward unity narrows the notch, but also leads to an undesirable response peak on the high-frequency side of the notch, along with a reduction in ultimate attenuation.

### 6.3.5 Allpass filters

Allpass? Allpass?! Whatever can that be? And why would you want such a thing, when a piece of wire does as well (and probably better)?

Allpass filters, also known as delay equalizers or phase equalizers, are filters with flat amplitude response, but with a phase shift that varies with frequency. They are used to compensate for phase shifts (or time delays) in some signal path.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-015.jpg?height=720&width=790&top_left_y=441&top_left_x=1059)

Figure 6.41. Allpass filter, also known as a delay equalizer, or phase equalizer.

Figure 6.41 shows the basic circuit configuration. Intuitively, it's easy to see that the circuit behaves like an inverter at low frequencies (where no signal is coupled to the noninverting input) and a follower at high frequencies (recall the optional inverter of §4.3.1A). By writing a few equations you can convince yourself that the circuit behaves as described in the figure. Interchanging $R$ and $C$ produces a similar characteristic, but with lagging (rather than leading) phase shifts between the extremes of inverting and following. The phase shift can be tuned by making $R$ variable; but note that a small value of $R$ makes the circuit's input impedance small at high frequencies (where the reactance of $C$ goes to zero).

Figure 6.42 shows a variant that extends the range of phase shift to a full $360^{\circ}$. The downside is that you have to adjust two components simultaneously (e.g., the pair of equal-value resistors) to change its tuning. This can be done nicely, though, by using a digital dual potentiometer (an "EEpot") of the sort described in §3.4.3E.

### 6.3.6 Switched-capacitor filters

One drawback to these state-variable or biquad filters is the need for accurately matched capacitors. If you build the
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-016.jpg?height=720&width=802&top_left_y=209&top_left_x=102)

Figure 6.42. Allpass filter with a full $360^{\circ}$ phase shifting range. (Genin, R., Proc. IEEE, 56, 1746 (1968).)
circuit from op-amps, you've got to get pairs of stable capacitors (not electrolytic, tantalum, or high- $\kappa$ ceramic), perhaps matched better than $1 \%$ for optimum performance. You also have to make a lot of connections, since the circuits use at least three op-amps and six resistors for each 2-pole section. Alternatively, you can buy a filter IC, letting the manufacturer figure out how to integrate matched 1000 pF ( $\pm 0.5 \%$ ) capacitors into an IC. Semiconductor manufacturers have solved those problems, but at a price: the UAF42 and MAX274 "Universal Active Filter" ICs (mentioned earlier), implemented with hybrid or laser-trim technology, cost about \$8-\$16 apiece. These "continuoustime" filters also do not lend themselves to easy tunability.

#### A. Switched-capacitor integrator

There's another way to implement the integrators that are needed in the state-variable or biquad filter configurations. The basic idea is to use MOSFET analog switches, clocked from an externally applied square wave at some high frequency (typically 100 times faster than the analog signals of interest), as shown in Figure 6.43. In the figure, the funny triangular object is a digital inverter, which turns the square wave upside down so that the two MOS switches are closed on opposite halves of the square wave.

The circuit is easy to analyze: when $S_{1}$ is closed, $C_{1}$ charges to $V_{\text {in }}$, i.e., holding charge $C_{1} V_{\text {in }}$. On the alternate half of the cycle, $C_{1}$ discharges into the virtual ground, transferring its charge to $C_{2}$. The voltage across $C_{2}$ therefore changes by an amount $\Delta V=\Delta Q / C_{2}=V_{\mathrm{in}} C_{1} / C_{2}$. Note
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-016.jpg?height=853&width=799&top_left_y=206&top_left_x=973)

Figure 6.43. A. Switched-capacitor integrator. B. conventional integrator.
that the output-voltage change during each cycle of the fast square wave is proportional to $V_{\text {in }}$ (which we assume changes only a small amount during one cycle of square wave), i.e., the circuit is an integrator! It is easy to show that the integrators obey the equations in the figure.

Exercise 6.6. Derive the equations in Figure 6.43.
Exercise 6.7. Here's another way to understand the switchedcapacitor integrator: calculate the average current that flows through $S_{2}$ into the virtual ground. You should find that it is proportional to $V_{\text {in }}$. Therefore, the combination of $S_{1}, C_{1}$, and $S_{2}$ behaves like a resistor, forming a classic integrator. What is the value of that equivalent resistance, in terms of $f_{0}$ and $C_{1}$ ? Use that to arrive at the equation in the figure, $V_{\text {out }}=f_{0}\left(C_{1} / C_{2}\right) \int V_{\text {in }} d t$.

#### B. Advantages of switched-capacitor filters

There are two important advantages to using switched capacitors instead of conventional integrators. First, as hinted earlier, it can be less expensive to implement on silicon: the integrator gain depends only on the ratio of two capacitors, not on their individual values. In general, it is easy to make a matched pair of anything on silicon, but very hard to make a similar component (resistor or capacitor) of precise value and high stability. As a result, monolithic switched-capacitor filter ICs are inexpensive - TI's universal switched-capacitor filter (the MF10) costs \$3.50
(compared with $\$ 16$ for the conventional UAF42), and furthermore it gives you two filters in one package.

The second advantage of switched-capacitor filters is the ability to tune the filter's characteristic frequency (e.g., the center frequency of a bandpass filter, or the -3 dB point of a lowpass filter) by merely changing the frequency of the square-wave ("clock") input. ${ }^{36}$ This is because the characteristic frequency of a state-variable or biquad filter is proportional to (and depends only on) the integrator gain.

#### C. Switched-capacitor filter configurations

Switched-capacitor filters are available in both dedicated and "universal" configurations. The former are prewired with on-chip components to form lowpass filters of the desired type (Butterworth, Bessel, Elliptic), whereas the latter have various intermediate inputs and outputs brought out so you can connect external components to make anything you want. The price you pay for universality is a larger IC package and the need for external resistors. For example, LTC's self-contained LTC1069-6 8-pole elliptic lowpass filter comes in an 8-pin package (about \$9), compared with their LTC1164 quad 2-pole universal filter which requires 12 external resistors to implement a comparable filter and comes in a 24-pin package (about \$15). Figure 6.44 shows just how easy it is to use the dedicated type. Look ahead to $\S 7.1 .5 \mathrm{~A}$ to see an elegant and simple sinewave generator that uses a tracking switched-capacitor filter acting on a square wave at a fraction of the clock frequency (Figures 7.18 and 7.19).
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-017.jpg?height=335&width=716&top_left_y=1450&top_left_x=262)

Figure 6.44. Switched capacitor dedicated lowpass filter, requiring no external components. The 8th-order elliptic response has $\pm 0.1 \mathrm{~dB}$ passband ripple, and is more than 40 dB down at $1.3 f_{3 \mathrm{~dB}}$.

Both dedicated and universal switched-capacitor filters use as the basic building block the 2-pole statevariable configuration, with switched-capacitor integrators replacing the resistor-fed op-amp integrators of the classic continuous-time state-variable active filter; see Fig-

[^11]ure 6.45. The universal filter ICs come with one to four such sections, which can be cascaded to form a higherorder filter (with each section implementing a quadratic term in the factored filter equation), or they can be used independently for multiple simultaneous channels (which must, however, share the common clocking input). The manufacturer's datasheets (or software or both) make filter design easy with these universal filter ICs. ${ }^{37}$ And no design is needed at all for the dedicated filter - you just connect it up, and off you go.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-017.jpg?height=335&width=792&top_left_y=659&top_left_x=1073)

Figure 6.45. "Universal" second-order switched-capacitor building block. It can provide lowpass, highpass, bandpass, allpass, and notch, as determined by external connections. With its on-chip capacitors, the only external components required are a few resistors.

#### D. Drawbacks of switched-capacitor filters

Now for the bad news: switched-capacitor filters have three annoying characteristics, all related and caused by the presence of the periodic clocking signal. First, there is clock feedthrough, the presence of some output signal (typically about 10 mV to 25 mV ) at the clock frequency, independent of the input signal. Usually this doesn't matter, because it is far removed from the signal band of interest. If clock feedthrough is a problem, a simple $R C$ filter at the output usually gets rid of it.

The second problem is more subtle: if the input signal has any frequency components near the clock frequency, they will be "aliased" down into the passband. To state it precisely, any input signal energy at a frequency that differs from the clock frequency by an amount corresponding to a frequency in the passband will appear (unattenuated!) in the passband. For example, if you use a MAX7400 (dedicated 8-pole elliptic lowpass) as a 1 kHz lowpass filter (i.e., set $f_{\text {clock }}=100 \mathrm{kHz}$ ), any input signal energy in the

[^12]range of $99-101 \mathrm{kHz}$ will appear in the output band of dc1 kHz . No filter at the output can remove it! You must make sure the input signal doesn't have energy near the clock frequency. If this isn't naturally the case, you can usually use a simple $R C$ filter, because the clock frequency is typically quite far removed from the passband. The use of filter ICs with a high clock-to-corner frequency ratio (e.g., 100:1 instead of $25: 1$ or $50: 1$ ) simplifies input anti-alias filter design. You can get some nice filter ICs with 1000:1 clock ration from Mixed Signal Integration, for example their MSHN series. ${ }^{38}$ A high clock ratio also reduces the "staircase" output waveform from these filters.

The third undesirable effect in switched-capacitor filters is a general reduction in signal dynamic range (an increase in the "noise floor") that is due to incomplete cancellation of MOSFET switch charge injection (see §3.4.2E). This manifests itself as a raised noise floor within the bandpass. Typical filter ICs have claimed dynamic ranges of $80-90 \mathrm{~dB}$. In addition to reduced dynamic range (compared with continuous-time filters), switched-capacitor filters tend to have more distortion than you would expect, especially for output signals near the supply rails.

Like any linear circuit, switched-capacitor filters (and their op-amp analogs) suffer from amplifier errors such as input offset voltage and $1 / f$ low-frequency noise. These can be a problem if, for example, you wish to lowpass filter some low-level signal without introducing errors or fluctuations in its average dc value. A nice solution is provided by the clever folks at Linear Technology, who dreamed up the LTC1062 "DC accurate lowpass filter" (or the MAX280, with improved offset voltage). Figure 6.46 shows how you use it. The basic idea is to put the filter outside the dc path, letting the low-frequency signal components couple passively to the output; the filter grabs onto the signal line only at higher frequencies, where it rolls off the response by shunting the signal to ground. The result is zero dc error, and switched-capacitor-type noise only in the vicinity of the rolloff ${ }^{39}$ (Figure 6.47). You can cascade a pair of these filters to make higher-order filters, or a tunable sharp bandpass filter. The datasheet also shows you how to make a tunable notch filter.

Switched-capacitor filter ICs are widely available from manufacturers such as Linear Technology, TI, and Maxim. Typically you can put the cutoff (or band center) anywhere in the range of dc to a few tens of kilohertz, as set by the clock frequency. The characteristic frequency

[^13]![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-018.jpg?height=404&width=774&top_left_y=211&top_left_x=985)

Figure 6.46. LTC1062 "dc-accurate" lowpass filter. The external clock input must swing rail-to-rail (add a small series resistor to protect the input); alternatively you can enable the internal oscillator by connecting a capacitor from CLK to ground.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-018.jpg?height=529&width=670&top_left_y=853&top_left_x=1040)

Figure 6.47. LTC1062 output noise spectra (see the datasheet).
is a fixed multiple of the clock, usually $50 f_{\text {clk }}$ or $100 f_{\text {clk }}$. Most switched-capacitor filter ICs are intended for lowpass, bandpass, or notch (band-stop) use, though you can configure the universal type as highpass filters. Note that clock feedthrough and discrete (clock-frequency) output waveform quantization effects are particularly bothersome in the latter case, since they're both in-band.

### 6.3.7 Digital signal processing

Our discussion of electronic filters in this chapter would be seriously incomplete without an introduction to the widespread technique of digital signal processing (DSP), also known as discrete-time signal processing. Contemporary systems that include microprocessors favor digitalfiltering methods for their flexibility and performance. Digital signal processing is the manipulation of signals in the digital domain, in which a signal (for example, a speech waveform) has been converted to a sequence of
numbers representing its sampled amplitude values at equally spaced intervals of time. The "manipulations" can be any of the things we've seen in the purely analog domain - filtering, combining, attenuation or amplification, nonlinear compression and clipping, and so on; but they can include also additional sophisticated operations made possible by the power of computation, such as coding, error correction, encryption, spectral analysis, speech synthesis and analysis, image processing, adaptive filtering, and lossless compression and storage.

We'll have much to say about digitizing and processing in Chapters 13 ("Digital meets analog") and 15 ("Microcontrollers"), when we'll have, respectively, the electronic tools for conversion between analog voltages and their digital representation, and the means to process those digital quantities. Here we would like simply to introduce the application of DSP to filtering and give a glimpse of its capabilities, particularly when compared with the analog filters we've seen. We'll stick to one-dimensional filters; that is, the filtering of "one-dimensional" signals such as speech (as contrasted with two-dimensional images), which are characterized by some voltage waveform $V(t)$ evolving in time.

#### A. Sampling

We mentioned earlier that a digitized representation of a continuous waveform involves sampling at a discrete set of (nearly always) uniformly spaced times, with a discrete set of (usually) uniformly spaced quantized amplitudes. These determine the fidelity of the quantization - in frequency (from the sampling rate, obeying the Nyquist sampling criterion, see Figure 13.60) and in dynamic range and noise (from the quantization precision); see §13.5.1. There's a lot to say about these; but at the most basic level you've got to sample at least twice the rate of the highest-frequency component that's in the input, and you've got to have enough precision in the $n$-bit amplitude quantization to preserve the dynamic range you want. Put compactly,

$$
\begin{aligned}
f_{\text {samp }} & \geq 2 f_{\text {sig }}(\max ), \\
\text { dynamic range } & =6 n \mathrm{~dB} .
\end{aligned}
$$

Assuming you're beginning with an analog waveform, the sampling is done with an analog-to-digital converter (ADC), preceded by an anti-alias lowpass filter (LPF), if needed, to ensure that the waveform being digitized contains no signals of significance above the Nyquist frequency $f_{\text {samp }} / 2$.

#### B. Filtering

The sequence of adequately sampled amplitudes (call it $x_{n}$, for the $n$th sample) represents the input signal. We
want to do a filtering operation on the sequence, for example a lowpass filter. There are two broad classes of DSP filters: finite-impulse-response (FIR) and infinite-impulseresponse (IIR). The FIR is easiest to understand - each output sample is simply a weighted sum of some number of input samples (see Figure 6.48):

$$
y_{i}=\sum_{k=-\infty}^{\infty} a_{k} x_{i-k}
$$

where the $x_{i}$ are the input signal amplitudes, the $a_{k}$ are the weights, and the $y_{i}$ are the output of the filter. In real life there will be only a finite number of weights, and so the sum will run only over a finite set of input values, as in the figure. Speaking crudely, the set of coefficients is an approximation to the inverse Fourier transform of the desired filter function.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-019.jpg?height=481&width=807&top_left_y=905&top_left_x=1063)

Figure 6.48. Finite impulse response (nonrecursive) digital filter.

Note an interesting - and important - feature of such a filter: its output is formed of samples both past and $f u$ ture. That is, it can generate an output that would appear to violate causality (effect must follow cause), but which is permitted here because the output signal has an overall delay with respect to the input. This ability to see into the future (a boast that no analog filter can make) allows digital filters to implement frequency- and phase-response characteristics that cannot be achieved with the (causal) analog filters we've seen up to this point.

The IIR filter differs in allowing the output to be included, with some weighting factor, along with the inputs in the weighted sum; this is sometimes called a recursive filter. The simplest example might be

$$
y_{i}=b y_{i-1}+(1-b) x_{i}
$$

which happens to be the discrete approximation to a continuous-time $R C$ lowpass filter, in which the weighting factor $b$ is given by $b=e^{-t_{\mathrm{s}} / R C}$, where $t_{\mathrm{s}}$ is the sampling interval. Of course, the situation is not identical to an analog
lowpass filter operating on an analog waveform because of the discrete nature of the sampled waveform.

Both FIR and IIR implementations have their pros and cons. FIR filters are generally preferred because they are simple to understand, easy to implement, unconditionally stable (no feedback), and they can be (and usually are) designed as linear-phase filters (i.e., the time delay is constant, independent of frequency). IIR filters are more economical, however, requiring fewer coefficients and therefore less memory and calculation. They also are easily derived from the corresponding classic analog filter; and they are particularly well suited to applications requiring high selectivity, for example, notch filters. However, they require more bits of arithmetic precision to prevent instabilities and "idle tones," and they are more difficult to code.

#### C. An example: IIR lowpass

As a simple numerical example, suppose you want to filter a set of numbers representing a signal, with a lowpass 3 dB point at $f_{3 \mathrm{~dB}}=1 / 20 t_{\mathrm{s}}$, equivalent to a single-section $R C$ lowpass filter of the same breakpoint. Here the time constant equals the time for 20 successive samples. Then $A=0.95123$, and so the output is given by

$$
y_{i}=0.95123 y_{i-1}+0.04877 x_{i}
$$

The approximation to a real lowpass filter becomes better as the time constant becomes long compared with the time between samples, $t_{\mathrm{s}}$.

You would probably use a filter like this to process data that are already in the form of discrete samples, e.g., an array of data in a computer. In that case the recursive filter becomes a trivial arithmetic pass once through the data.

#### D. An example: FIR lowpass

An ideal lowpass filter has unit response up to its cutoff frequency $f_{\mathrm{c}}$ and zero response for higher frequencies. That is, the response curve is rectangular, a "brick-wall" filter. To first order, the FIR coefficients $a_{k}$ are the rectangle's Fourier transform, namely a $(\sin x) / x$ function (or sinc function), in which the scaling of the argument depends on the ratio of the cutoff frequency to the sampling frequency, namely,

$$
\begin{equation*}
a_{k} \propto \frac{\sin \left(2 \pi k f_{\mathrm{n}}\right)}{2 \pi k f_{\mathrm{n}}} \tag{6.18}
\end{equation*}
$$

where the integers $k$ go from $-\infty$ to $\infty$, and $f_{\mathrm{n}}$ is the normalized cutoff frequency, defined as $f_{\mathrm{n}}=f_{\mathrm{c}} / f_{\mathrm{s}}$.

In a real-world implementation, of course, you get only a finite number of $k$ 's, say $N$ of them. So the question: what set of truncated filter coefficients $a_{k}$, where $k$ goes only from $-N / 2$ to $N / 2$, best approximates the ideal lowpass filter? This turns out to be more complicated than you
might at first imagine. Among other things, it depends on what you mean by "best."

If you simply truncate the $a_{k}$ series, discarding coefficients beyond the length of your FIR sample string, the resulting filter's frequency response will exhibit large bumps in the stopband attenuation; that is, degraded rejection around those frequencies. This is exactly analogous to the problem of "spectral leakage" in digital spectrum analysis, or of diffraction sidelobes in optics, and the fix is the same: here you taper the coefficients $a_{k}$ by multiplying them by a "window function" that goes smoothly toward zero at the ends (in spectrum analysis you multiply the incoming digitized signal amplitudes by an analogous windowing function, and in optics you "apodize" the aperture with a mask whose opacity increases toward the edges). The effect is to reduce greatly the stopband ripple, at the expense of a more gradual transition from passband to stopband (in spectral analysis the effect is greatly reduced spectral leakage into adjacent frequency bins, at the expense of broader bin width; in optics the sidelobes are attenuated, at the expense of decreased resolution in the form of a broader "point-spread function"). Typical window functions have names like Hamming, Hanning, and Blackman-Harris. There's no "best" window - it's always a tradeoff between the steepness of transition to the stopband versus the worst-case attenuation in the stopband. But most of the time it doesn't really matter a whole lot which of the standard windows you use. ${ }^{40}$

A second aspect of "best" is to choose a cutoff frequency $f_{\mathrm{n}}$ for which at least some of the coefficients are exactly zero; that way you can omit the multiply and add operations corresponding to those taps. This occurs, for example, with the choice $f_{\mathrm{n}}=0.25$ (a sampling rate four times the cutoff frequency), for which the coefficients in eq'n 6.18 become

$$
\begin{equation*}
a_{k} \propto \frac{\sin (\pi k / 2)}{\pi k / 2} \tag{6.19}
\end{equation*}
$$

and therefore all the coefficients with even $k$ (except $a_{0}$ ) are zero. You get a small bonus, also, by using a filter length $N$ that is a multiple of 4 ; that makes the end coefficients (at $k= \pm N / 2$ ) vanish, because their index $k$ is then even.

Because a cutoff frequency of half the sampling frequency (i.e., $f_{\mathrm{n}}=0.5$ ) is the maximum allowed by the Nyquist sampling theorem, a filter whose cutoff is at $f_{\mathrm{n}}=0.25$ is known as a "half-band" filter. Figures 6.49 and 6.50 show the response of half-band filters with $N=8,16$, 32 , and 64 , where the coefficients have been calculated

[^14]![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-021.jpg?height=443&width=789&top_left_y=207&top_left_x=228)

Figure 6.49. Half-band FIR digital filter response, plotted on a linear scale. A filter of order $N$ requires $N / 2+1$ coefficients.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-021.jpg?height=450&width=799&top_left_y=813&top_left_x=223)

Figure 6.50. The half-band filters of Figure 6.49, plotted on a loglog scale to reveal the stopband response.
according to eq'n 6.19 , weighted by a Hamming window. The latter is a raised cosine, given approximately by

$$
\begin{equation*}
w(k)=0.54+0.46 \cos (2 \pi k / N) \tag{6.20}
\end{equation*}
$$

A final step is to normalize the coefficients (by multiplying each by the same factor) so that their sum is 1 , giving the filter unit gain at dc. The recipe, then, is to choose an $N$ (preferably a multiple of 4 ); then, for each positive odd $k$ up to $N / 2$, calculate the sinc function of equation (6.19) and multiply it by the Hamming coefficient of eq'n 6.20 to get the (not yet normalized) $a_{k}$. Note that the coefficients are symmetric $\left(a_{-k}=a_{k}\right)$, and that the $a_{0}$ term will be 1.0 (because both $\operatorname{sinc}(0)$ and $w(0)$ have value unity). The final step is to normalize these coefficients by dividing each by their sum.

Because the even coefficients are zero, the resultant filters, though requiring $N$ stages of memory, need approximately half that number of coefficients (those with odd subscripts, plus $a_{0}$ ), namely $5,9,17$, and 33 , respectively. You can check our recipe by calculating the coefficients for
the lowest-order filter in the figures ( $N=8$ ); you should get

$$
\begin{aligned}
a_{0} & =+0.497374 \\
a_{1}=a_{-1} & =+0.273977 \\
a_{2}=a_{-2} & =0 \\
a_{3}=a_{-3} & =-0.022664 \\
a_{4}=a_{-4} & =0
\end{aligned}
$$

#### An aside: window tradeoffs

We used a Hamming window as the coefficient multiplier for the filters of Figures 6.49 and 6.50, partly out of laziness (it's easy to calculate), and partly because it's a reasonably good window in terms of stopband attenuation ( $\sim 60 \mathrm{~dB}$ ). But, as we remarked above, you can produce better stopband attenuation at the expense of transition-region steepness. This is nicely illustrated in Figure 6.51, where we've redone the $N=32$ half-band lowpass FIR filter using three different window functions. The Blackman-Harris windows are a sum of two or three sinusoidal terms, weighted to produce the minimum sidelobe level. The exact form is

$$
w(k)=a_{0}+a_{1} \cos (2 \pi k / N)+a_{2} \cos (4 \pi k / N)+a_{3} \cos (6 \pi k / N)
$$

where the $a$ 's are given by $\left[a_{0}, a_{1}, a_{2}, a_{3}\right]=[0.42323$, $0.49755,0.07922,0]$ (3-term) and [0.35875, 0.48829, $0.14128,0.01168]$ (4-term). These windows produce impressive stopband attenuation ( $\sim 85 \mathrm{~dB}$ and $\sim 105 \mathrm{~dB}$ ), as compared with the Hamming's $\sim 55 \mathrm{~dB}$, but with correspondingly softer transition regions. It's worth noting that these are calculated responses, and will be realized in practice only if the FIR multiply and add operations are done with adequate arithmetic precision, and if the upstream ADC has correspondingly accurate linearity.
![](https://cdn.mathpix.com/cropped/2024_11_07_fcfbaeb41b4683641406g-021.jpg?height=439&width=802&top_left_y=1709&top_left_x=1073)

Figure 6.51. Half-band FIR lowpass filters of order $N=32$, with three choices of coefficient window function. Note the change of vertical scale compared with those of Figures 6.49 and 6.50.

#### E. Implementation

You could set up a DSP filter with discrete hardware - shift registers, multipliers, accumulators, and the like - the stuff of Chapters 10 and 11. But any such attempt would seem quaint by current standards, where general-purpose processors (microprocessors and microcontrollers) let you do the same tasks, and with greater flexibility. Even better, there is a class of digital signal processor chips, optimized for the sort of multiply-accumulate operations you need to do, and generally arranged for efficient flow of lots of data in and out. An example is the TMS320 series from TI, which includes (at time of writing) chips like the TMS320C64xx, which can do a 1k-point fast Fourier transform (FFT) in about $1 \mu \mathrm{~s}$ (!), or a 32 -coefficient FIR on a 10,000 -point data set in $108 \mu \mathrm{~s}$. At the other end of the performance scale, the tiny QF1D512 from Quickfilter Technology is an inexpensive stand-alone chip that performs up to a 512-tap FIR filter on 12- to 24-bit serial data (at audio rates), with 32-bit programmable coefficients. It costs less than $\$ 2$ in small quantities and comes with free design software; you can also get a variety of evaluation kits.

### 6.3.8 Filter miscellany

#### A. Linearity

In some filtering applications it is essential to maintain a high degree of amplitude linearity, even as the filter attenuates some frequencies more than others. This is necessary, for example, in high-quality audio reproduction. For such applications you should use op-amps designed for low distortion (which will be prominently featured on the datasheet), with adequate bandwidth, slew rate, and loop gain; some examples are the LT1115, OPA627, and AD8599; see Table 5.4 on page 310 and the discussion of high-speed op-amps and design issues in $\S 5.8$, and further discussion in Chapter $4 x$. Perhaps less obvious, it's important to choose passive components of good linearity. The primary hazards lying in wait here are the "high- $\kappa$ " ceramic capacitors (which can exhibit astonishing variations of capacitance with applied voltage), and electrolytic capacitors (with their memory effect caused by dielectric absorption - see the discussion in Chapter $l x$. Use film capacitors (ideally polypropylene) or NPO/C0G ceramic.

And for $L C$ (passive) filters it's essential to choose inductors wound on magnetic material of good linearity (a problem that is absent for air-core inductors; the latter are available in reasonable sizes for inductances up to $\sim 1 \mathrm{mH}$ or so).

#### B. Filter-design software

It used to be hard to design filters - but no more! There's plenty of software out there, and it's easy to use. You can set up your passband and stopband requirements for a continuous-time filter (cutoff frequency, stopband frequency, ripple and attenuation, etc.), and the software obliges with a recitation of how many sections will be required, according to the circuit configuration (Sallen-and-Key, state variable, biquad, or MFB) and filter function (Bessel, Butterworth, Chebyshev, elliptic). Then it will draw the circuit, and give you plots of amplitude, phase, and time delay as functions of frequency. And similarly for switched-capacitor filters or digital filters.

Here are some filter design resources we've found useful. Most of these are free (but you have to pay for MMICAD, and for Filter Solutions and Filter Light).

- LC filters:
- http://www-users.cs.york.ac.uk/ fisher/lcfilter/
- MMICAD (Optotek)
- Analog active filters
- FilterPro (TI)
- FilterCAD (LTC)
- ADI Analog Filter Wizard
- http://www.beis.de/Elektronik/Filter/Filter.html
- Digital filters:
- http://www-users.cs.york.ac.uk/ fisher/mkfilter/
- All types
- Filter Solutions, Filter Light, and Filter Free (http://www.nuhertz.com/filter/)

## Review of Chapter 6

An A-to-J summary of what we have learned in Chapter 6. This summary reviews basic principles and facts in Chapter 6, but it does not cover application circuit diagrams and practical engineering advice presented there.

### ๆA. Filter Overview.

This chapter deals with signals in the frequency domain: by filter we mean a circuit with some deliberate passband and attenuation characteristics (both amplitude and phase) versus frequency. For some applications the filter's timedomain behavior is important also, i.e., the filter's transient response (overshoot and settling time) to a voltage-step input, and its in-band fidelity to an input waveform.

### IB. Filter Characteristics.

There are the basic shapes - lowpass, highpass, bandpass, and band-stop (notch). There's also the all-pass (or delay equalizer), which has a flat amplitude response, but a varying phase; and there are comb filters that pass (or block) an array of equally spaced frequencies. Important frequencydomain parameters include flatness of response in the passband, depth of attenuation in the stopband, and steepness of falling response in the transition region between. In the time-domain you care about overshoot, settling time, and linearity of phase across the passband (i.e., constancy of time delay).

### qC. Filter Implementations.

Filters can be built (a) entirely with passive components ( $R$, $L$, and $C$ ); (b) with $R$ 's and $C$ 's, assisted with op-amps; (c) with $C$ 's alone, combined with periodically-clocked analog switches; or (d) with digital processing of the ADCsampled input waveform. These are called passive filters, active filters, switched-capacitor filters, and digital filters, respectively. The term continuous-time filter is sometimes applied to filters of type (a) and (b), and discrete-time filter to (c) and (d). The order of a filter is equal to the number of $C$ 's plus the number of $L$ 's (or equivalent, if implemented digitally). An $n$th order lowpass filter has an ultimate rolloff of $6 n \mathrm{~dB} /$ octave ( $20 n \mathrm{~dB} /$ decade $)$.

### ID. Passive RC Filters.

Passive $R C$ filters ( $\S 6.2 .1$ ) are the simplest, and good enough for applications such as blocking dc, suppressing high-frequency power-supply noise, or removing signals far from the band of interest. But $R C$ filters, regardless of order, have a soft transition region (Figure 6.2) and are unsuited to separating signals that are nearby in frequency.

Their transfer function is far from the ideal "brick-wall" filter response (see for example Figure 6.11).

### ПE. Passive LC Filters.

Perhaps surprisingly, combining inductors with capacitors allows you to make all manner of very sharp filters ( $\S 6.2 .2$; see for example Figure 6.5). The classic filter shapes, all implementable with $L C$ filters, are the Butterworth (maximally flat passband), the Chebyshev (sharpest transition region, at the cost of amplitude ripple in the passband), and the Bessel (maximally flat time-delay in the passband). The performance characteristics of these filter types are compared in Table 6.1 and Figures 6.20, 6.21, 6.25-6.27, and 6.30 .

### IF. Active Filters.

Inductors are non-ideal in several respects (size, linearity, electrical losses; see Chapter $1 x$; but the combination of a capacitor and an op-amp (plus several resistors), in a configuration known as a gyrator ( 86.2 .4 C ), creates an electrical equivalent of an inductor. So you can make an inductorless filter that mimics any $L C$ filter, by simply substituting gyrators for the inductors. More generally, you can make such active filters (\$6.3) with various configurations of opamps, capacitors, and resistors that need not incorporate explicit gyrators.

### IIG. Active Filter Circuits.

In §6.3.1 we showed how to design the simple and popular VCVS active filter, with tabulated data (Table 6.2) for 2nd-order to 8th-order lowpass or highpass filters, with Butterworth, Chebyshev, or Bessel response. Better performance and tunability is gotten with the state-variable and biquad active filters (\$6.3.3), which require three op-amps for each 2nd-order section. These latter filter topologies are well suited for bandpass filters; see §6.3.3A, where explicit design equations are given. You can get nice state-variable ICs that include the op-amps and capacitors, and can be configured as lowpass, highpass, band-pass, or band-reject, requiring only a few external resistors to set the characteristic cutoff frequencies; examples are the UAF42 and the MAX274. The world is awash with active-filter implementations; some others seen in Chapter 6 include the Sallen-and-Key filter (Figure 6.16), a state-variable variant with independently settable gain and $Q$-factor (Figure 6.32), and the multiple-feedback filter (Figure 6.35).

### IH. Notch Filters.

In contrast to their generally "soft" frequency characteristics, the $R C$ filter known as a twin-T (\$6.3.4) produces a
deep notch (limited only by component imperfection and mismatching). The twin-T is hard to tune (it requires three tracking adjustable resistors). But a similar $R C$ notch filter (the bridged-differentiator, Figure 6.40) allows a modest range of tunability ( $5: 1$ or so) with a single pot.

### |ll. Switched-capacitor Filters.

An op-amp combined with a pair of capacitors and a pair of analog switches forms a discrete approximation to a continuous-time integrator (Figure 6.43). This is the building block of the switched-capacitor filter (§6.3.6), easily incorporated into an IC, and conveniently tuned by varying the externally-applied switching frequency. The downside is the production of artifacts related to the switching operation: clock feedthrough, aliasing, and limited dynamic range.

### ПJ. Digital Filters and DSP.

With ubiquitous embedded microcontrollers and accompanying ADCs, it's natural to implement filtering operations with the machinery of digital signal processing (DSP, §6.3.7). If the signals to be filtered are in the form of ana-
log voltages, they first must be digitized (sampled at regular intervals and converted to a stream of numbers), taking care to sample at a high enough rate (at least twice the highest frequency present in the signal, $\left.f_{\mathrm{samp}} \geq 2 f_{\operatorname{sig}(\max )}\right)$ and with sufficient amplitude accuracy ( $n$-bit quantization yields $6 n \mathrm{~dB}$ dynamic range) to retain adequate fidelity. (If the input signal is already digitized, no sampling is needed, and digital filtering is particularly convenient.)

The stream of numbers representing the successive sampled and digitized signal voltages (call them $x_{i}$ ) is then subjected to a digital filtering operation. Easiest to understand is the finite-impulse-response (FIR) filter, where each output signal amplitude $y_{i}$ is formed from a weighted sum of a finite number $N$ of input samples; i.e., $y_{i}=\sum a_{k} x_{i-k}$, with $k$ going from $-N / 2$ to $N / 2$. If the sum is permitted to include output samples, you've got a recursive filter, also known as an infinite-impulse-response filter. See Figure 6.49 for an example of an FIR lowpass filter. There's plenty of complexity, and plenty of math, in the business of digital filtering; this specialty appeals to EEs who are really applied mathematicians in disguise (you know who you are!).
