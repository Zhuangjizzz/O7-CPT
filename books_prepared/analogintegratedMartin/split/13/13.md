# 13 Discrete-Time Signals

A basic understanding of discrete-time signal processing is essential in the design of most modern analog systems. For example, discrete-time signal processing is heavily used in the design and analysis of oversampling analog-todigital (A/D) and digital-to-analog (D/A) converters used in digital audio, wireless communication, and instrumentation applications. Also, a discrete-time filtering technique known as switched-capacitor filtering is a popular approach for realizing fully integrated analog filters. Switched-capacitor filters are in the class of analog filters since voltage levels in these filters remain continuous. In other words, switched-capacitor filters operate and are analyzed using discrete time-steps but involve no $\mathrm{A} / \mathrm{D}$ or $\mathrm{D} / \mathrm{A}$ converters; hence, they are quantized in time but not in amplitude. This chapter presents some basic concepts of discrete-time signals and filters.

## 13.1 OVERVIEW OF SOME SIGNAL SPECTRA

Consider the spectra of sampled and continuous-time signals in the block diagram systems shown in Fig. 13.1, where it is assumed that the continu-ous-time signal, $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$, is band limited through the use of an anti-aliasing filter (not shown). DSP refers to Discrete-time signal processing, which may be accomplished using fully digital processing or discrete-time analog circuits such as switched-capacitor filters. Some example time signals and frequency spectra for this system are shown in Fig. 13.2. Here, $\mathbf{s}(\mathrm{t})$ is a periodic impulse train in time with a period of T , where T equals the inverse of the sampling frequency, $\mathrm{f}_{\mathrm{s}}$. Some relationships for the signals in

Key Point: Discrete-time signals may be processed either digitally, in which case they are quantized both in time and amplitude, or using discrete-time analog circuits such as switched-capacitor circuits, in which case the signal amplitude is continuously variable.

Figs. 13.1 and 13.2 are as follows:

1. $x_{s}(t)$ has the same frequency spectrum as $x_{c}(t)$, but the baseband spectrum repeats every $f_{s}$ (assuming that no aliasing occurs and hence, an anti-aliasing filter is needed).
2. $x(n)$ has the same frequency spectrum as $x_{s}(t)$, but the sampling frequency is normalized to 1 .
3. The frequency spectrum for $x_{s h}(t)$ equals that of $x_{s}(t)$ multiplied by a response of $(\sin x) / x($ in effect, multiplying $X_{s}(f)$ by this response helps to remove high-frequency images).
The remainder of this chapter confirms these spectral relationships and introduces other basic discrete-time concepts.

## 13.2 LAPLACE TRANSFORMS OF DISCRETE-TIME SIGNALS

Consider the sampled signal, $\mathbf{x}_{\mathrm{s}}(\mathrm{t})$, related to the continuous-time signal, $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$, as shown in Fig. 13.3. The signal $\mathrm{x}_{\mathrm{s}}(\mathrm{t})$ is fictitious; it does not arise anywhere in a practical physical realization, such as the one depicted in Fig. 13.1(b). However, it is a useful tool to aid our understanding and modeling of practical discrete-time signals.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-038.jpg?height=529&width=1178&top_left_y=176&top_left_x=301)

Fig. 13.1 Performing DSP on ana log signals. (a) Conceptual realization, and (b) typical physical realization.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-038.jpg?height=985&width=1383&top_left_y=827&top_left_x=208)

Fig. 13.2 Some time signals and frequency spectra.

Compared to $\mathrm{x}_{\mathrm{c}}(\mathrm{t}), \mathrm{x}_{\mathrm{s}}(\mathrm{t})$ has been scaled by $\tau$ such that the area under the pulse at nT equals the value of $x_{c}(n T)$. In other words, at $t=n T$, we have

$$
\begin{equation*}
\mathrm{x}_{\mathrm{s}}(\mathrm{nT})=\frac{\mathrm{x}_{\mathrm{c}}(\mathrm{nT})}{\tau} \tag{13.1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-039.jpg?height=400&width=1063&top_left_y=179&top_left_x=359)

Fig. 13.3 Sampled and continuous-time signals.
such that the area under the pulse, $\tau \mathrm{x}_{\mathrm{s}}(\mathrm{nT})$, equals $\mathrm{x}_{\mathrm{c}}(\mathrm{nT})$. Thus, as $\tau \rightarrow 0$, the height of $\mathrm{x}_{\mathrm{s}}(t)$ at time $n T$ goes to $\infty$, and so we plot $\tau \mathrm{X}_{\mathrm{s}}(\mathrm{t})$ instead of $\mathrm{X}_{\mathrm{s}}(\mathrm{t})$.

We define $\vartheta(\mathrm{t})$ to be the step function given by

$$
\vartheta(t) \equiv \begin{cases}1 & (t \geq 0)  \tag{13.2}\\ 0 & (t<0)\end{cases}
$$

Then $x_{s}(t)$ can be represented as a linear combination of a series of pulses, $x_{s n}(t)$, where $x_{s n}(t)$ is zero everywhere except for a single pulse at nT . The single-pulse signal, $\mathrm{x}_{\mathrm{sn}}(\mathrm{t})$, can be written as

$$
\begin{equation*}
\mathrm{x}_{\mathrm{sn}}(\mathrm{t})=\frac{\mathrm{x}_{\mathrm{c}}(\mathrm{nT})}{\tau}[\vartheta(\mathrm{t}-\mathrm{nT})-\vartheta(\mathrm{t}-\mathrm{nT}-\tau)] \tag{13.3}
\end{equation*}
$$

so that we can now write $\mathrm{x}_{\mathrm{s}}(\mathrm{t})$ as

$$
\begin{equation*}
\mathrm{x}_{\mathrm{s}}(\mathrm{t})=\sum_{\mathrm{n}=-\infty}^{\infty} \mathrm{x}_{\mathrm{sn}}(\mathrm{t}) \tag{18.4}
\end{equation*}
$$

Note that these signals are defined for all time, so we can find the Laplace transform of $\mathrm{x}_{\mathrm{s}}(\mathrm{t})$ in terms of $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$. Using the notation that $X_{s}(s)$ is the Laplace transform of $x_{s}(t)$, we find the Laplace transform $X_{s n}(s)$ for $x_{s n}(t)$ to be given by

$$
\begin{equation*}
\mathrm{X}_{\mathrm{sn}}(\mathrm{~s})=\frac{1}{\tau}\left(\frac{1-\mathrm{e}^{-\mathrm{s} \tau}}{\mathrm{~s}}\right) \mathrm{x}_{\mathrm{c}}(\mathrm{nT}) \mathrm{e}^{-\mathrm{snT}} \tag{13.5}
\end{equation*}
$$

Since $x_{s}(t)$ is merely a linear combination of $x_{s n}(t)$, we also have (for $\tau \neq 0$ )

$$
\begin{equation*}
X_{s}(s)=\frac{1}{\tau}\left(\frac{1-e^{-s t}}{s}\right) \sum_{n=-\infty}^{\infty} x_{c}(n T) e^{-s n T} \tag{13.6}
\end{equation*}
$$

Using the expansion $\mathrm{e}^{\mathrm{x}}=1+\mathrm{x}+\left(\mathrm{x}^{2} / 2\right.$ ! $)+\cdots$, when $\tau \rightarrow 0$, the term before the summation in (13.6) goes to unity. Therefore, in the limiting case as $\tau \rightarrow 0$, we have

$$
\begin{equation*}
X_{s}(s)=\sum_{n=-\infty}^{\infty} x_{c}(n T) e^{-s n T} \tag{13.7}
\end{equation*}
$$

### 13.2.1 Spectra of Discrete-Time Signals

The spectrum of the sampled signal, $x_{s}(t)$, can be found by replacing $s$ by $j \omega$ in (13.7). However, a more intuitive approach to find the spectrum of $x_{s}(t)$ is to recall that multiplication in the time domain is equivalent to convolution in the frequency domain. To use this fact, note that, for $\tau \rightarrow 0, \mathrm{x}_{\mathrm{s}}(\mathrm{t})$ can be written as the product

$$
\begin{equation*}
\mathrm{x}_{\mathrm{s}}(\mathrm{t})=\mathrm{x}_{\mathrm{c}}(\mathrm{t}) \mathrm{s}(\mathrm{t}) \tag{13.8}
\end{equation*}
$$

where $\mathrm{s}(\mathrm{t})$ is a periodic pulse train, or mathematically,

$$
\begin{equation*}
s(t)=\sum_{n=-\infty}^{\infty} \delta(t-n T) \tag{13.9}
\end{equation*}
$$

where $\delta(\mathrm{t})$ is the unit impulse function, also called the Dirac delta function. It is well known that the Fourier transform of a periodic impulse train is another periodic impulse train. Specifically, the spectrum of $s(t), S(j \omega)$, is given by

$$
\begin{equation*}
\mathrm{S}(\mathrm{j} \omega)=\frac{2 \pi}{\mathrm{~T}} \sum_{\mathrm{k}=-\infty}^{\infty} \delta\left(\omega-\mathrm{k} \frac{2 \pi}{\mathrm{~T}}\right) \tag{13.10}
\end{equation*}
$$

Now writing (13.8) in the frequency domain, we have

$$
\begin{equation*}
X_{s}(j \omega)=\frac{1}{2 \pi} X_{c}(j \omega) \otimes S(j \omega) \tag{13.11}
\end{equation*}
$$

where $\otimes$ denotes convolution. Finally, by performing this convolution either mathematically or graphically, the spectrum of $X_{s}(j \omega)$ is seen to be given by

$$
\begin{equation*}
X_{s}(j \omega)=\frac{1}{T} \sum_{k=-\infty}^{\infty} X_{c}\left(j \omega-\frac{j k 2 \pi}{T}\right) \tag{13.12}
\end{equation*}
$$

or, equivalently,

$$
\begin{equation*}
X_{s}(f)=\frac{1}{T} \sum_{k=-\infty}^{\infty} X_{c}\left(j 2 \pi f-j k 2 \pi f_{s}\right) \tag{13.13}
\end{equation*}
$$

Key Point: The spectrum of a sampled signal is a sum of shifted copies of the original continuous-time spectrum so that no aliasing occurs if the original waveform is bandlimited to one-half the sampling rate. The minimum sampling frequency required to avoid aliasing is called the Nyquist rate, and is equal to two times the signal bandwidth.

Equations (13.12) and (13.13) show that the spectrum of the sampled signal, $x_{s}(t)$, equals a sum of shifted spectra of $x_{c}(t)$, and therefore no aliasing occurs if $X_{c}(j \omega)$ is band limited to $f_{s} / 2$. The minimum sampling frequency required to avoid aliasing is called the Nyquist rate, and is equal to two times the signal bandwidth. The relation in (13.13) also confirms the example spectrum for $\mathrm{X}_{\mathrm{s}}(\mathrm{f})$, shown in Fig. 13.2. Each copy of the dirac-delta-sampled spectrum is identical: $X_{s}(f)=X_{s}\left(f \pm k f_{s}\right)$, where $k$ is an arbitrary integer as seen by substitution in (13.13). ${ }^{1}$

Finally, note that the signal $\mathbf{x}_{s}(t)$ cannot exist in practice when $\tau \rightarrow 0$ since an infinite amount of power would be required to create it. This is evident when one considers the integral of $X_{s}(f)$ over all frequencies.

## 13.3 z-TRANSFORM

For our purposes, the z-transform is merely a shorthand notation for (13.7). Specifically, defining

$$
\begin{equation*}
z \equiv e^{s T} \tag{13.14}
\end{equation*}
$$

we can write

$$
\begin{equation*}
X(z) \equiv \sum_{n=-\infty}^{\infty} x_{c}(n T) z^{-n} \tag{13.15}
\end{equation*}
$$

where $X(z)$ is called the $z$-transform of the samples $x_{c}(n T)$.
Two properties of the $\mathbf{z}$-transform that can be deduced from Laplace transform properties are as follows:

1. If $x(n) \leftrightarrow X(z)$, then $x(n-k) \leftrightarrow z^{-k} X(z)$
2. Convolution in the time domain is equivalent to multiplication in the frequency domain. Specifically, if $y(n)=h(n) \otimes x(n)$, where $\otimes$ denotes convolution, then $Y(z)=H(z) X(z)$. Similarly, multiplication in the time domain is equivalent to convolution in the frequency domain.

Note that $X(z)$ is not a function of the sampling rate but is related only to the numbers $x_{c}(n T)$, whereas $X_{s}(s)$ is the Laplace transform of the signal $x_{s}(t)$ as $\tau \rightarrow 0$. In other words, the signal $x(n)$ is simply a series of numbers that may (or may not) have been obtained by sampling a continuous-time signal. One way of thinking about this series of numbers as they relate to the samples of a possible continuous-time signal is that the original sample time, $T$, has been effectively normalized to one (i.e., $f_{s}^{\prime}=1 \mathrm{~Hz}$ ). Such a normalization of the sample time, $T$, in both time and frequency, justifies the spectral relation between $X_{s}(f)$ and $X(\omega)$ shown in Fig. 13.2. Specifically, the relationship between $X_{s}(f)$ and $X(\omega)$ is given by

$$
\begin{equation*}
\mathrm{X}_{\mathrm{s}}(\mathrm{f})=\mathrm{X}\left(\frac{2 \pi \mathrm{f}}{\mathrm{f}_{\mathrm{s}}}\right) \tag{13.16}
\end{equation*}
$$

or, equivalently, the following frequency scaling has been applied:

$$
\begin{equation*}
\omega=\frac{2 \pi f}{f_{s}} \tag{13.17}
\end{equation*}
$$

This normalization results in discrete-time signals having $\omega$ in units of radians/sample, whereas the original continuous-time signals have frequency units of cycles/second (hertz) or radians/second. For example, a continuous-time sinusoidal signal of 1 kHz when sampled at 4 kHz will change by $\pi / 2$ radians between each sample. Therefore, such a discrete-time signal is defined to have a frequency of $\pi / 2 \mathrm{rad} / \mathrm{sample}$. Other examples of discrete-time sinusoidal signals

Key Point: Discrete-time signal spectra are equal to the corresponding sampled signal spectra with the sample time normalized to 1 Hz . Hence, their spectra repeat every $2 \pi$.
are shown in Fig. 13.4. The spectra of discrete-time signals are always invariant under shifts of $2 \pi$ radians/sample. For example, a discrete-time signal that has a frequency of $\pi / 4 \mathrm{rad} / \mathrm{sample}$ is identical to that of $9 \pi / 4 \mathrm{rad} / \mathrm{sample}$. Thus, normally discrete-time signals are completely specified by considering their spectra only between $-\pi$ and $\pi \mathrm{rad} / \mathrm{sample}$. For a more detailed discussion of this topic, see [Proakis, 1992].

### EXAMPLE 13.1

Consider the spectra of $X_{c}(f)$ and $X_{s}(f)$, shown in Fig. 13.2, where $f_{0}$ is 1 Hz and $f_{s}$ is 4 Hz . Compare the time and spectrum plots of $X_{s}(f)$ and $X_{s 2}(f)$, where $X_{s 2}(f)$ is sampled at 12 Hz . How do the spectra differ between the two sampling rates?

### Solution

By sampling at 12 Hz , the spectrum of $\mathrm{X}_{\mathrm{c}}(\mathrm{f})$ repeats every 12 Hz , resulting in the signals shown in Fig. 13.5.
Note that, for $X(\omega), 4 \mathrm{~Hz}$ is normalized to $2 \pi \mathrm{rad} / \mathrm{sample}$, whereas for $X_{2}(\omega), 12 \mathrm{~Hz}$ is normalized to $2 \pi \mathrm{rad} / \mathrm{sample}$.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-042.jpg?height=855&width=1311&top_left_y=497&top_left_x=203)

Fig. 13.4 Some discrete-time sinusoidal signals.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-042.jpg?height=610&width=1329&top_left_y=1453&top_left_x=226)

Fig. 13.5 Comparing time and frequency of two sampling rates.

## 13.4 DOWNSAMPLING AND UPSAMPLING

Two important operations in discrete-time signal processing are downsampling and upsampling. Downsampling is used to reduce the sample rate, and hence the amount of information that must be processed and/or stored, hopefully without information loss. Upsampling is used to increase the sample rate. Although noninteger downsampling and upsampling rates can be achieved, here we consider only the case in which $L$ is an integer value.

Downsampling is achieved by keeping every Lth sample and discarding the others. As Fig. 13.6 shows, the result of downsampling is to expand the original spectra by L. Thus, to avoid digital aliasing, the spectrum of the original signal must be band limited to $\pi / \mathrm{L}$ before downsampling is done. In other words, the signal must be sampled $L$ times above its minimum sampling

Key Point: To avoid aliasing when downsampling by a factor L, the original signal must be sampled at L times the Nyquist rate.
rate so that no information is lost during downsampling.

Upsampling is accomplished by inserting $L-1$ zero values between each pair of consecutive samples, as shown in Fig. 13.7. In this case, one can show that the spectrum of the resulting upsampled signal is identical to that of the original signal but with a renormalization along the frequency axis. Specifically, when a signal is upsampled by $L$, the frequency axis is scaled by $L$ such that $2 \pi$ now occurs where $L 2 \pi$ occurred in the original signal and $L$ identical copies of the original spectrum are now squeezed within the range 0 to $2 \pi$. This operation

Key Point: Upsampling by $L$ results in a renormalization along the frequency axis so that $L$ copies of the original signal spectrum are now squeezed in the range 0 to $2 \pi$.
is useful when one wishes to increase the effective sampling rate of a signal, particularly if postfiltering is then applied.

Follow the next two examples carefully-they help explain the spectral changes due to downsampling and upsampling.

### EXAMPLE 13.2

The signal $\mathrm{x}_{2}(n)$ in Example 13.1 is to be downsampled by $L=3$. Find the new spectrum, $X_{3}(\omega)$, when every third sample is kept and the others are discarded. In other words, if the original series of numbers is $\mathrm{x}_{1}, \mathrm{x}_{2}, \mathrm{x}_{3}, \mathrm{x}_{4}, \ldots$, the new series is $\mathrm{x}_{1}, \mathrm{x}_{4}, \mathrm{x}_{7}, \mathrm{x}_{10}, \ldots$
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-043.jpg?height=517&width=1302&top_left_y=1538&top_left_x=253)

Fig. 13.6 Downsampling by 4: (a) time domain, and (b) frequency domain.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-044.jpg?height=505&width=1384&top_left_y=170&top_left_x=210)

Fig. 13.7 Upsampling by 4: (a) time domain, and (b) frequency domain.

### Solution

Clearly the solution here is that the new sequence is equivalent to $x(n)$ in Example 13.1, and thus its spectrum is simply $X_{3}(\omega)=X(\omega)$.

Note that no information was lost in this example because the initial images of the signal $x_{2}(n)$ were far enough apart. However, if the downsampling operation results in the spectra overlapping one another, then an aliasing phenomenon occurs that is similar to that which occurs when sampling an analog signal lower than the Nyquist rate. In fact, it can be shown that, to avoid any aliasing during downsampling by the factor $L$, the original signal should be band limited to $\pi / \mathrm{L}$.

### EXAMPLE 13.3

As an example of upsampling of the signal $x(n)$ in Example 13.1, find the new spectrum, $X_{4}(\omega)$, if two zeros are inserted between each sample (i.e., if we upsample by $L=3$ ). In other words, if the original series of numbers was $\mathrm{x}(\mathrm{n})=\mathrm{x}_{1}, \mathrm{x}_{2}, \mathrm{x}_{3}, \ldots$ and had a spectrum $X(\omega)$, then the new series of numbers is now $x_{4}(n)=\left(x_{1}, 0,0, x_{2}, 0,0, x_{3}, \ldots\right)$ and has a spectrum $X_{4}(\omega)$.

### Solution

Perhaps the simplest way to conceptualize the insertion of these extra 0 samples in a series is to look at $X_{s 4}(\mathrm{f})$ in time and frequency when we let $f_{s 4}=12 \mathrm{~Hz}$. Recall that $x_{s 4}(t)$ is defined for all time, where it is zero between its impulses, and the Laplace transform is used to observe its frequency response. With such a sampling frequency, we note that $x_{s 4}(t)$ is equal to the signal $x_{s}(t)$, and thus $X_{s 4}(f)=X_{s}(f)$. To find $X_{4}(\omega)$, recall that it is simply a frequency normalization of $X_{s 4}(f)$, where the sampling frequency is normalized to $2 \pi$. In other words, the series $\mathbf{x}(\mathrm{n})$ is simply a normalization of the time between impulses to 1 . However, by inserting extra zeros between samples, the normalization is effectively being done for a time period smaller than that between nonzero impulses. Thus, the images remain the same while the normalization along the frequency axis is different.

In this example, since two zeros are inserted, the effective sampling rate might be thought of as 12 Hz , but now the images at 4 Hz and 8 Hz remain in contrast to $\mathrm{X}_{2}(\omega)$ in Example 13.1. The resulting signals are shown in Fig. 13.8.

Finally, note that if signal processing is used on the samples $x_{4}(n)$ to eliminate the two images at $(2 \pi) / 3$ and $(4 \pi) / 3$, then the resulting signal will equal $\mathrm{x}_{2}(\mathrm{n})$. In other words, as long as an analog signal is originally sampled higher than the Nyquist rate, we can use upsampling and digital-signal processing to derive signals that are the same as if the analog signal were sampled at a much higher rate.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-045.jpg?height=622&width=1289&top_left_y=179&top_left_x=221)

Fig. 13.8 Spectrum of a discrete-time signal upsampled by 3.

## 13.5 DISCRETE-TIME FILTERS

Thus far, we have seen the relationship between continuous-time and discrete-time signals in the time and frequency domain. However, often one wishes to perform filtering on a discrete-time signal to produce another discrete-time signal. In other words, an input series of numbers is applied to a discrete-time filter to create an output series of numbers. This filtering of discrete-time signals is most easily visualized with the shorthand notation of z-transforms.

Consider the system shown in Fig. 13.9, where the output signal is defined to be the impulse response, $h(\mathrm{n})$, when the input, $u(n)$, is an impulse (i.e., 1 for $\mathrm{n}=0$ and 0 otherwise). The transfer function of the filter is said to be given by $\mathrm{H}(\mathrm{z})$, which is the $z$-transform of the impulse response, $h(n)$.

### 13.5.1 Frequency Response of Discrete-Time Filters

The transfer functions for discrete-time filters appear similar to those for continuous-time filters; practical integrated circuit discrete-time transfer functions are represented by rational transfer functions except that, instead of polynomials in s , polynomials in $\mathbf{z}$ are obtained. For example, the transfer function of a low-pass, continuoustime filter, $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$, might appear as

$$
\begin{equation*}
H_{c}(s)=\frac{4}{s^{2}+2 s+4} \tag{13.18}
\end{equation*}
$$

The poles for this filter are determined by finding the roots of the denominator polynomial, which are $-1.0 \pm 1.7321 \mathrm{j}$ for this example. This continuous-time filter is also defined to have two zeros at $\infty$ since the
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-045.jpg?height=141&width=565&top_left_y=1884&top_left_x=327)
(Discrete-time filter)
( $y(n)$ equals $h(n)$ if $u(n)$ is an impulse)
Fig. 13.9 Discrete-time filter system.
![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-046.jpg?height=456&width=1163&top_left_y=176&top_left_x=348)

Fig. 13.10 Transfer function response. (a) Continuous-time, and (b) discrete-time.
denominator polynomial is two orders higher than the numerator polynomial. To find the frequency response of $H_{c}(s)$, it is evaluated along the $j \omega$ axis by substituting $s=j \omega$. The poles and zeros are plotted on the $s$-plane in Fig. 13.10(a), and the magnitude and phase response $\mathrm{H}_{\mathrm{c}}(\mathrm{j} \omega)$ can be found in terms of the magnitude and phase of vectors from all poles (and finite zeros) to the point $s=j \omega$ along the frequency-axis.

$$
\begin{gather*}
\left.\mid \mathrm{H}_{\mathrm{c}} \mathrm{j} \omega\right) \left\lvert\,=\frac{4}{|\mathrm{j} \omega+1.0+1.7321 \mathrm{j}||\mathrm{j} \omega+1.0-1.7321 \mathrm{j}|}\right.  \tag{13.19}\\
\angle \mathrm{H}_{\mathrm{c}}(\mathrm{j} \omega)=-\angle(\mathrm{j} \omega+1.0+1.7321 \mathrm{j})-\angle(\mathrm{j} \omega+1.0-1.7321 \mathrm{j}) \tag{13.20}
\end{gather*}
$$

An example of a discrete-time, low-pass transfer function is given by the following equation:

$$
\begin{equation*}
H(z)=\frac{0.05}{z^{2}-1.6 z+0.65} \tag{13.21}
\end{equation*}
$$

Key Point: The frequency response of a discrete-time filter $H(z)$ is found by evaluating its magnitude and phase on the unit circle, or graphically by considering the magnitude and phase of vectors connecting its poles and zeros to points around the unit circle.

The poles of $H(z)$ occur at $0.8 \pm 0.1 \mathrm{j}$ in the $z$-plane, and two zeros are again at $\infty$. To find the frequency response of $\mathrm{H}(\mathrm{z})$, we evaluate it around the unit circle contour $\mathbf{Z}=\mathrm{e}^{\mathrm{j} \omega}$ as shown in Fig. 13.10(b), instead of going along the vertical $\mathrm{j} \omega$ axis as in the s-plane. Note that substituting $z=\mathrm{e}^{\mathrm{j} \omega}$ in the z domain transfer function, $H(z)$, is simply a result of substituting $s=j \omega$ into (13.14), where T has been normalized to 1, as discussed in Section 13.3. The discrete-time frequency response can be found graphically by considering the magnitude and phase of vectors from each pole and zero of $\mathrm{H}(\mathrm{z})$ as shown in Fig. $13.10(b)$ to the corresponding frequency on the unit circle $z=e^{j \omega}$.

Poles or zeros occurring at $z=0$ do not affect the magnitude response $\mathrm{H}(\mathrm{z})$ since a vector from the origin to the unit circle always has a length of unity. However, they do affect the phase response.

In discrete time, $\mathrm{H}(\mathrm{z}=1)$ corresponds to the frequency response at

Key Point: In discrete-time, the point $z=1$ corresponds both to dc and to signals at the sampling frequency. The frequency response is periodic, and for rational transfer functions with real-valued coefficients exhibits conjugate symmetry around dc. Hence, discrete-time frequency responses need only be plotted from dc to half the sample rate, $\pi$.
both dc (i.e., $\omega=0$ ) and at $\omega=2 \pi$. Also, the time normalization of setting T to unity implies that $\omega=2 \pi$ is equivalent to the samplingrate speed (i.e., $f=f_{s}$ ) for $X_{s}(f)$. In addition, note that the frequency response of a filter need be plotted only for $0 \leq \omega \leq \pi$ (i.e., $0 \leq \omega \leq f_{s} / 2$ ) since, for filters with real coefficients, the poles and zeros always occur in complex-conjugate pairs (or on the real axis), so the magnitude response of the filter is equal to that for $\pi \leq \omega \leq 2 \pi$ (the filter's phase is antisymmetric). Going around the circle again gives the same result as the first time, implying that the frequency response repeats every $2 \pi$.

Before we leave this section, a word of caution is in order. To simplify notation, the same variables, $f$ and $\omega$, are used in both the continuous-time and discrete-time domains in Fig. 13.10. However, these variables are not equal in the two domains, and care should be taken not to confuse values from the two domains. The continuous-time domain is used here for illustrative reasons only since the reader should already be quite familiar with transfer function analysis in the s -domain. In summary, the unit circle, $\mathrm{e}^{\mathrm{j} \omega}$, is used to determine the frequency response of a system that has its input and output as a series of numbers, whereas the $\mathrm{j} \omega$-axis is used for a system that has continuous-time inputs and outputs. However, $\omega$ is different for the two domains.

#### EXAMPLE 13.4

Assuming a sample rate of $f_{s}=100 \mathrm{kHz}$, find the magnitude of the transfer function in (13.21) for 0 Hz , $100 \mathrm{~Hz}, 1 \mathrm{kHz}, 10 \mathrm{kHz}, 50 \mathrm{kHz}, 90 \mathrm{kHz}$, and 100 kHz .

#### Solution

To find the magnitude of $\mathrm{H}(\mathrm{z})$ at these frequencies, first we find their equivalent $\mathbf{z}$-domain locations by normalizing $f_{s}$ to $2 \pi$. Next, we find the gain of $H(z)$ by putting these $z$-domain values into (13.21) and finding the magnitude of the resulting complex value. Table 13.1 summarizes the results.

Note that the gain of $\mathrm{H}(\mathrm{z})$ is the same at both 0 Hz and 100 kHz , as expected, since their z-plane locations are the same. Also, the gain is the same at both 10 kHz and 90 kHz since their z-plane locations are complex conjugates of each other. Finally, note that the minimum gain for this transfer function occurs at $\mathbf{z}=-1$, or equivalently, $\mathrm{f}_{\mathrm{s}} / 2=50 \mathrm{kHz}$.

#### EXAMPLE 13.5

Consider a first-order $\mathrm{H}(\mathrm{z})$ having its zero at $\infty$ and its pole on the real axis, where $0<\mathrm{a}<1$. Mathematically, the transfer function is represented by $H(z)=b /(z-a)$. Find the value of $\omega$, where the magnitude of $H(z)$ is $3 d B$ lower than its dc value. What is the $3-\mathrm{dB}$ value of $\omega$ for a real pole at 0.8 ? What fraction of the sampling rate, $\mathrm{f}_{\mathrm{s}}$, does it correspond to?

Table 13.1 Finding the gain of $\mathrm{H}(\mathrm{z})$ at some example frequencies.

|  | $\mathbf{z - p l a n e}$ locations |  |  |
| :---: | :--- | :---: | :--- |
| Frequency <br> $(\mathbf{k H z})$ | $\mathbf{e}^{\mathrm{j} \omega}$ | $\mathbf{z}=\mathbf{x}+\mathbf{j} \mathbf{y}$ |  |
| 0 | $\mathrm{e}^{\mathrm{j} 0}$ | $1.0+\mathrm{j} 0.0$ | 1.0 |
| 0.1 | $\mathrm{e}^{\mathrm{j} 0.002 \pi}$ | $0.9999803+\mathrm{z} 0.00628314$ | 0.9997 |
| 1 | $\mathrm{e}^{\mathrm{j} 0.02 i}$ | $0.9980267+\mathrm{j} 0.06279052$ | 0.968 |
| 10 | $\mathrm{e}^{\mathrm{j} 0.2 \pi}$ | $0.809+\mathrm{j} 0.5878$ | 0.149 |
| 50 | $\mathrm{e}^{\mathrm{j} \pi}$ | $-1.0+\mathrm{j} 0.0$ | 0.0154 |
| 90 | $\mathrm{e}^{\mathrm{j} 1.8 \pi}$ | $0.809-\mathrm{j} 0.5878$ | 0.149 |
| 100 | $\mathrm{e}^{\mathrm{j} 2 \pi}$ | $1.0+\mathrm{j} 0.0$ | 1.0 |

![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-048.jpg?height=476&width=873&top_left_y=180&top_left_x=454)

Fig. 13.11 Pole-zero plot used to determine the 3-dB frequency of a first-order, discrete-time filter.

#### Solution

Consider the pole-zero plot shown in Fig. 13.11, where the zero is not shown since it is at $\infty$. Since the zero is at $\infty$, we need be concerned only with the magnitude of the denominator of $H(z)$ and when it becomes $\sqrt{2}$ larger than its dc value. The magnitude of the denominator of $\mathrm{H}(\mathrm{z})$ for $\mathrm{Z}=1$ (i.e., dc) is shown as the vector $\mathrm{I}_{1}$ in Fig. 13.11. This vector changes in size as $z$ goes around the unit circle and is shown as $I_{2}$ when it becomes $\sqrt{2}$ larger than $I_{1}$. Thus we can write

$$
\begin{equation*}
\mathrm{I}_{2}=\left|\mathrm{e}^{\mathrm{j} \omega}-\mathrm{a}\right| \equiv \sqrt{2}(1-\mathrm{a}) \tag{13.22}
\end{equation*}
$$

Writing $\mathrm{e}^{\mathrm{j} \omega}=\cos (\omega)+\mathrm{j} \sin (\omega)$, we have

$$
\begin{gather*}
|(\cos (\omega)-a)+j \sin (\omega)|^{2}=2(1-a)^{2}  \tag{13.23}\\
\cos ^{2}(\omega)-(2 a) \cos (\omega)+a^{2}+\sin ^{2}(\omega)=2(1-a)^{2}  \tag{13.24}\\
1-(2 a) \cos (\omega)+a^{2}=2\left(1-2 a+a^{2}\right) \tag{13.25}
\end{gather*}
$$

which is rearranged to give the final result.

$$
\begin{equation*}
\omega=\cos ^{-1}\left(2-\frac{\mathrm{a}}{2}-\frac{1}{2 \mathrm{a}}\right) \tag{13.26}
\end{equation*}
$$

For $\mathrm{a}=0.8, \omega=0.2241 \mathrm{rad}$, or 12.84 degrees. Such a location on the unit circle corresponds to $0.2241 /(2 \pi)$ times $\mathrm{f}_{\mathrm{s}}$ or, equivalently, $\mathrm{f}_{\mathrm{s}} / 28.04$.

### 13.5.2 Stability of Discrete-Time Filters

To realize rational polynomials in $\mathbf{z}$, discrete-time filters use delay elements (i.e., $z^{-1}$ building blocks) much the same way that analog filters can be formed using integrators (i.e., $\mathrm{s}^{-1}$ building blocks). The result is that finite difference equations represent discrete-time filters rather than the differential equations used to describe continuoustime filters.

Consider the signal flow graph block diagram of a first-order, discrete-time filter shown in Fig. 13.12. A finite difference equation describing this block diagram can be written as

$$
\begin{equation*}
y(n+1)=b x(n)+a y(n) \tag{13.27}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-049.jpg?height=191&width=739&top_left_y=192&top_left_x=521)

Fig. 13.12 A first-order, discrete-time filter.

In the Z -domain, this equation is written as

$$
\begin{equation*}
z \mathrm{y}(\mathrm{z})=\mathrm{bX}(\mathrm{z})+\mathrm{a} \mathrm{Y}(\mathrm{z}) \tag{13.28}
\end{equation*}
$$

where the z -domain property of delayed signals is used. We define the transfer function of this system to be $\mathrm{H}(\mathrm{z})$ given by

$$
\begin{equation*}
H(z) \equiv \frac{Y(z)}{X(z)}=\frac{b}{z-a} \tag{13.29}
\end{equation*}
$$

which has a pole on the real axis at $\mathbf{z}=\mathrm{a}$.
To test for stability, we let the input, $\mathbf{x}(\mathrm{n})$, be an impulse signal (i.e., 1 for $\mathrm{n}=0$ and 0 otherwise), which gives the following output signal, according to (13.27),

$$
y(0)=k
$$

where k is some arbitrary initial state value for y .

$$
\begin{gathered}
y(1)=b+a k \\
y(2)=a b+a^{2} k \\
y(3)=a^{2} b+a^{3} k \\
y(4)=a^{3} b+a^{4} k
\end{gathered}
$$

More concisely, the response, $h(n)$, is given by

$$
h(n)=\left\{\begin{array}{cc}
k & (n<1)  \tag{13.30}\\
\left(a^{n-1} b+a^{n} k\right) & (n \geq 1)
\end{array}\right.
$$

Clearly, this response remains bounded only when $|\mathrm{a}| \leq 1$ for this first-order filter and is unbounded otherwise.
Although this stability result is shown only for first-order systems, in general, an arbitrary, linear, time-invariant, discrete-time filter, $H(z)$, is stable if and only if all its poles are located within the unit circle. In other words, if $\mathbf{z}_{\mathrm{pi}}$ are the poles, then $\left|z_{\mathrm{pi}}\right|<1$ for all i . Locating some poles on the unit circle is similar to poles being on the imaginary $\mathrm{j} \omega$-axis for continuous-time systems. For example, in the preceding firstorder example, if $\mathrm{a}=1$, the pole is at $\mathbf{z}=1$, and the system is marginally stable (in

Key Point: A discretetime filter is stable if and only if all its poles are located within the unit circle.
fact, it is a discrete-time integrator). If we let $\mathrm{a}=-1$, the pole is at $\mathbf{z}=-1$, and one can show that the system oscillates at $f_{s} / 2$, as expected.

### 13.5.3 IIR and FIR Filters

Key Point: An infinite impulse response (IIR) filter has an impulse response that remains nonzero forever. A finite impulse response (FIR) filter has an impulse response that is finite in duration, eventually becoming preciselyzero.

Infinite impulse $r$ esponse (IIR) filters are discrete-time filters that, when excited by an impulse, have nonzero outputs indefinitely, assuming infinite precision arithmetic. ${ }^{2}$ For example, the filter given in (13.29) is an IIR filter (for a not equal to zero) since, although its impulse response decays towards zero (as all stable filters should), it remains nonzero forever, seen by letting $\mathrm{n} \rightarrow \infty$ in (13.30).

Finite impulse response (FIR) filters are discrete-time filters that, when excited by an impulse, their outputs go precisely to zero (and remain zero) after a finite value of $n$. As an example of an FIR filter, consider the following filter:

$$
\begin{equation*}
y(n)=\frac{1}{3}[x(n)+x(n-1)+x(n-2)] \tag{13.31}
\end{equation*}
$$

The transfer function for this filter, $H(z)$, is

$$
\begin{equation*}
H(z)=\frac{1}{3} \sum_{i=0}^{2} z^{-i} \tag{13.32}
\end{equation*}
$$

This filter is essentially a running average filter since its output is equal to the average value of its input over the last three samples. Applying an impulse signal to this filter results in an output that is nonzero for only three samples and, therefore, this is an FIR filter. Note that this FIR filter has poles, but they all occur at $\mathbf{z}=0$.

Some advantages of FIR filters are that stability is never an issue (they are always stable) and exact linear phase filters can be realized (a topic beyond the scope of this chapter). However, for many specifications, an IIR filter can meet the same specifications as an FIR filter, but with a much lower order, particularly in narrowband filters in which the poles of an IIR filter are placed close to the unit circle (i.e., has a slowly decaying impulse response).

### 13.5.4 Bilinear Transform

One method for obtaining a discrete-time transfer functions that meets a set of specifications is to use a bilinear transform to convert the specifications into a set of fictitious continuous-time filter specifications, design a filter in continuous-time to meet those specifications, and then convert the resulting filter back to discrete-time, again using a bilinear transform. Assuming that $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$ is a continuous-time transfer function (where s is the complex variable equal to $\left.\sigma_{s}+j \Omega\right)$, the bilinear transform is defined to be given by ${ }^{3}$

$$
\begin{equation*}
s=\frac{z-1}{z+1} \tag{13.33}
\end{equation*}
$$

The inverse transformation is given by

$$
\begin{equation*}
\mathrm{z}=\frac{1+\mathrm{s}}{1-\mathrm{s}} \tag{13.34}
\end{equation*}
$$

[^0]A couple of points of interest about this bilinear transform are that the z-plane locations of 1 and -1 (i.e., dc and $f_{s} / 2$ ) are mapped to s-plane locations of 0 and $\infty$, respectively. However, with a little analysis, we will see that this bilinear transformation also maps the unit circle, $z=\mathrm{e}^{\mathrm{j} \omega}$, in the z-plane to the entire $\mathrm{j} \Omega$-axis in the s-plane. To see this mapping, we substitute $\mathrm{Z}=\mathrm{e}^{\mathrm{j} \omega}$ into (13.33),

$$
\begin{align*}
s & =\frac{e^{j \omega}-1}{e^{j \omega}+1}=\frac{e^{j(\omega / 2)}\left(e^{j(\omega / 2)}-e^{-j(\omega / 2)}\right)}{e^{j(\omega / 2)}\left(e^{j(\omega / 2)}+e^{-j(\omega / 2)}\right)}  \tag{13.35}\\
& =\frac{2 j \sin (\omega / 2)}{2 \cos (\omega / 2)}=j \tan (\omega / 2)
\end{align*}
$$

Thus, we see that points on the unit circle in the z-plane are mapped to locations on the j $\Omega$-axis in the s-plane, and we have

$$
\begin{equation*}
\Omega=\tan (\omega / 2) \tag{13.36}
\end{equation*}
$$

As a check, note that the z-plane locations of 1 and -1 , which correspond to $\omega$ equal to 0 and $\pi$, respectively, map to $\Omega$ equal to 0 and $\infty$.

One way to use this transform is to design a continuous-time transfer function, $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$, and choose the discrete-time transfer function, $\mathrm{H}(\mathrm{z})$, such that

$$
\begin{equation*}
H(z) \equiv H_{c}[(z-1) /(z+1)] \tag{13.37}
\end{equation*}
$$

With such an arrangement, one can show that,

$$
\begin{equation*}
\mathrm{H}\left(\mathrm{e}^{\mathrm{j} \omega}\right)=\mathrm{H}_{\mathrm{c}}[\mathrm{j} \tan (\omega / 2)] \tag{13.38}
\end{equation*}
$$

and so the response of $\mathrm{H}(\mathrm{z})$ is shown to be equal to the response of $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$, except with a frequency warping according to (13.36). Note that the order of $\mathrm{H}(\mathrm{z})$ equals that of $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$ since, according to (13.37), each s term is replaced by another first-order function.

Key Point: The bilinear transform provides a mapping betweendiscreteand continuous-time transfer functions whereby $z=-1$ maps to infinite frequency and $z=1$ maps to dc.

#### EXAMPLE 13.7

Using the bilinear transform, find a first-order $H(z)$ that has a $3-d B$ frequency at $f_{s} / 20$, a zero at -1 , and a dc gain of 1 .

#### Solution

Using (13.36), the frequency value, $\mathrm{f}_{\mathrm{s}} / 20$, or equivalently, $\omega=(2 \pi) / 20=0.314159$ is mapped to $\Omega=0.1584 \mathrm{rad} / \mathrm{s}$. Thus, $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$ should have a $3-\mathrm{dB}$ frequency value of $0.1584 \mathrm{rad} / \mathrm{s}$. Such a $3-\mathrm{dB}$ frequency value is obtained by having a s-plane zero equal to $\infty$ and a pole equal to -0.1584 . Transforming these continuous-time pole and zero back into the $\mathbf{z}$-plane using (13.34) results in a $\mathbf{Z}$-plane zero at -1 and a pole at 0.7265 . Therefore, $H(z)$ appears as

$$
H(z)=\frac{k(z+1)}{z-0.7265}
$$

The constant $k$ can be determined by setting the dc gain to 1 , or equivalently, $|H(1)|=1$, which results in $\mathrm{k}=0.1368$.

## 13.6 SAMPLE-AND-HOLD RESPONSE

In this section, we look at the frequency response that occurs when we change a discrete-time signal back into an analog signal with the use of a sample-and-hold circuit. Note that here we plot a frequency response for all frequencies (as opposed to only up to $f_{s} / 2$ ) since the output signal is a continuous-time signal rather than a discrete-time one.

A sample-and-hold signal, $\mathrm{x}_{\mathrm{sh}}(\mathrm{t})$, is related to its sampled signal by the mathematical relationship

$$
\begin{equation*}
\mathrm{x}_{\mathrm{sh}}(\mathrm{t})=\sum_{n=-\infty}^{\infty} \mathrm{x}_{\mathrm{c}}(\mathrm{nT})[\vartheta(\mathrm{t}-\mathrm{nT})-\vartheta(\mathrm{t}-\mathrm{nT}-\mathrm{T})] \tag{13.39}
\end{equation*}
$$

Note that, once again, $\mathrm{x}_{\mathrm{sh}}(\mathrm{t})$ is well defined for all time, and thus the Laplace transform can be found to be equal to

$$
\begin{align*}
X_{s h}(s) & =\frac{1-e^{-s T}}{s} \sum_{n=-\infty}^{\infty} x_{c}(n T) e^{-s n T}  \tag{13.40}\\
& =\frac{1-e^{s T}}{s} X_{s}(s)
\end{align*}
$$

This result implies that the hold transfer function, $\mathrm{H}_{\mathrm{sh}}(\mathrm{s})$, is equal to

$$
\begin{equation*}
\mathrm{H}_{\mathrm{sh}}(\mathrm{~s})=\frac{1-\mathrm{e}^{-\mathrm{sT}}}{\mathrm{~s}} \tag{13.41}
\end{equation*}
$$

It should be mentioned here that this transfer function is usually referred to as the sample-and-hold response although, in fact, it only accounts for the hold portion.

The spectrum for $H_{s h}(s)$ is found by substituting $s=j \omega$ into (13.41), resulting in

$$
\begin{equation*}
H_{s h}(j \omega)=\frac{1-e^{-j \omega T}}{j \omega}=T \times e^{-j \omega T / 2} \times \frac{\sin (\omega T / 2)}{(\omega T / 2)} \tag{13.42}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_20b049a9b1012d1b244fg-053.jpg?height=286&width=1017&top_left_y=181&top_left_x=355)

Fig. 13.13 Sample-and-hold response (also called the sinc response).
The magnitude of this response is given by

$$
\left|\mathrm{H}_{\mathrm{sh}}(\mathrm{j} \omega)\right|=\mathrm{T} \frac{|\sin (\omega \mathrm{~T} / 2)|}{|\omega \mathrm{T} / 2|}
$$

or

$$
\begin{equation*}
\left|\mathrm{H}_{\mathrm{sh}}(\mathrm{f})\right|=\mathrm{T} \frac{\left|\sin \left(\pi \mathrm{f} / \mathrm{f}_{\mathrm{s}}\right)\right|}{\left|(\pi \mathrm{f}) / \mathrm{f}_{\mathrm{s}}\right|} \tag{13.43}
\end{equation*}
$$

and is often referred to as the $(\sin \mathbf{x}) / \mathrm{x}$ or sinc response. This magnitude response is illustrated in Fig. 13.13.
Multiplying this sinc response by $\mathrm{X}_{\mathrm{s}}(\mathrm{f})$ in Fig. 13.2 confirms the spectral relationship for $\mathrm{X}_{\text {sh }}(\mathrm{f})$. It should be noted here that this frequency shaping of a sample and hold occurs only for a continuous-time signal. Specifically, although the sample and hold before the A/D converter shown in Fig. 13.1(b) would result in $\mathrm{x}_{\mathrm{sh}}(\mathrm{t})$ having smaller images at higher frequencies (due to the sinc response), the images of $x(n)$ are all of the same height (i.e., they are not multiplied by the sinc response) since it is a discrete-time signal. This is because, when converted to a discrete-time signal, the smaller images located at and above $f_{s}$ are aliased in a manner that pre-

Key Point: The frequencyresponse of a sample-and-held signal is that of the original discrete-time sequence, repeated every $f_{s}$, and then shaped by a sinc frequency response.
cisely reconstructs the original spectrum, so long as it was sampled above the Nyquist rate. In other words, a sample and hold before an A/D converter simply allows the converter to have a constant input value during one conversion and does not aid in any anti-aliasing requirement.

### EXAMPLE 13.8

Consider the discrete-time signal processing system shown in Fig. 13.1(b), where a sample (and clock rate) of 50 kHz is used and the digital filter has the response

$$
H(z)=\frac{0.2}{z-0.8}
$$

For a $10-\mathrm{kHz}$ input sinusoidal signal of 1 V rms , find the magnitude of the output signal, $\mathrm{y}_{\mathrm{sn}}(\mathrm{t})$, at 10 kHz , and at the images 40 kHz and 60 kHz . Assume the quantization effects of the $\mathrm{A} / \mathrm{D}$ and $\mathrm{D} / \mathrm{A}$ converters are so small that they can be ignored. Also assume the converters complement each other such that a 1-V dc signal into the $\mathrm{A} / \mathrm{D}$ converter results in a $1-\mathrm{V}$ dc signal from the $\mathrm{D} / \mathrm{A}$ converter if the converters are directly connected together.

### Solution

First, the magnitude of $\mathrm{H}(\mathrm{z})$ is found for a $10-\mathrm{kHz}$ signal when the sampling rate is 50 kHz by noting that

$$
\begin{aligned}
\mathrm{e}^{\mathrm{j}(2 \pi \times 10 \mathrm{kHz} / 50 \mathrm{kHz})} & =\mathrm{e}^{\mathrm{j} 0.4 \pi}=\cos (0.4 \pi)+\mathrm{j} \sin (0.4 \pi) \\
& =0.309017+\mathrm{j} 0.951057
\end{aligned}
$$

and therefore the gain of $\mathrm{H}(\mathrm{z})$ for a $10-\mathrm{kHz}$ signal is found to be given by

$$
\left|\mathrm{H}\left(\mathrm{e}^{\mathrm{j} 0.4 \pi}\right)\right|=\frac{0.2}{|(0.309017-0.8)+\mathrm{j} 0.951057|}=0.186864
$$

To determine the magnitude of $\mathrm{y}_{\mathrm{sh}}(\mathrm{t})$ at various frequencies, we need only multiply the filter's gain by the sinc response shown in Fig. 13.13. Specifically, the magnitude of the sample-and-hold response for a $10-\mathrm{kHz}$ signal when using a $50-\mathrm{kHz}$ clock is equal to

$$
\left|\mathrm{H}_{\mathrm{sh}}(10 \mathrm{kHz})\right|=\mathrm{T} \frac{\sin (\pi 10 / 50)}{(\pi 10 / 50)}=0.9355 \mathrm{~T}
$$

and therefore the magnitude of $\mathrm{y}_{\mathrm{sh}}(\mathrm{t})$ at 10 kHz is equal to $0.18686 \times 0.9355=175 \mathrm{mV}_{\mathrm{rms}}$ (note that the T term cancels with a similar T term due to the creation of a discrete-time signal-see (13.13) in Section 13.2). Similarly, the magnitude of $\mathrm{H}_{\mathrm{sh}}(\mathrm{f})$ at 40 kHz and 60 kHz is 0.2399 and 0.1559 , respectively, resulting in the magnitude of $\mathrm{y}_{\mathrm{sh}}(\mathrm{t})$ at 40 kHz and 60 kHz to be 43.7 and $29.1 \mathrm{mV}_{\mathrm{rms}}$, respectively.

## 13.7 KEY POINTS

- Discrete-time signals may be processed either digitally, in which case they are quantized both in time and amplitude, or using discrete-time analog circuits such as switched-capacitor circuits, in which case the signal amplitude is continuously variable. [p. 537]
- The spectrum of a sampled signal is a sum of shifted copies of the original continuous-time spectrum so that no aliasing occurs if the original waveform is bandlimited to one-half the sampling rate. The minimum sampling frequency required to avoid aliasing is called the Nyquist rate, and is equal to two times the signal bandwidth. [p. 540]
- Discrete-time signal spectra are equal to the corresponding sampled signal spectra with the sample time normalized to 1 Hz . Hence, their spectra repeat every $2 \pi$. [p. 541]
- To avoid aliasing when downsampling by a factor L , the original signal must be sampled at L times the Nyquist rate. [p. 543]
- Upsampling by L results in a renormalization along the frequency axis so that L copies of the original signal spectrum are now squeezed in the range 0 to $2 \pi$. [p. 543]
- The frequency response of a discrete-time filter $\mathrm{H}(\mathrm{z})$ is found by evaluating its magnitude and phase on the unit circle, or graphically by considering the magnitude and phase of vectors connecting its poles and zeros to points around the unit circle. [p. 546]
- In discrete-time, the point $\mathrm{z}=1$ corresponds both to dc and to signals at the sampling frequency. The frequency response is periodic, and for rational transfer functions with real-valued coefficients exhibits conjugate symmetry around dc. Hence, discrete-time frequency responses need only be plotted from dc to half the sample rate, p. [p. 546]
- A discrete-time filter is stable if and only if all its poles are located within the unit circle. [p. 549]
- An infinite impulse response (IIR) filter has an impulse response that remains nonzero forever. A finite impulse response (FIR) filter has an impulse response that is finite in duration, eventually becoming precisely zero. [p. 550]
- The bilinear transform provides a mapping between discrete- and continuous-time transfer functions whereby $\mathrm{z}=-1$ maps to infinite frequency and $\mathrm{z}=1$ maps to dc. [p. 551]
- Using the bilinear transform, discrete-time transfer functions can be designed by mapping the specifications to fictitious continuous-time equivalents and finding a suitable $\mathrm{H}_{\mathrm{c}}(\mathrm{s})$. The inverse mapping $\mathrm{H}(\mathrm{z})=\mathrm{H}_{\mathrm{c}}((\mathrm{z}-1) /(\mathrm{z}+1))$ results in the desired discrete-time transfer function. [p. 551]
- The frequency-response of a sample-and-held signal is that of the original discrete-time sequence, repeated every $f_{s}$, and then shaped by a sinc frequency response. [p. 553]
