# 18 Oversampling Converters

Key Point: Oversampling converters relax the requirements placed on the analog circuitry at the expense of more complicated digital circuitry.

Oversampling $\mathrm{A} / \mathrm{D}$ and $\mathrm{D} / \mathrm{A}$ converters are popular for high-resolution medium-to-low-speed applications such as high-quality digital audio and baseband signal processing in some wireless systems. A major reason for their popularity is that oversampling converters relax the requirements placed on the analog circuitry at the expense of more complicated digital circuitry. This tradeoff became desirable with the advent of deep submicron CMOS technologies as complicated high-speed digital circuitry became more easily realized in less area, but the realization of high-resolution analog circuitry was complicated by the low power-supply voltages and poor transistor output impedance caused by short-channel effects. With oversampling data converters, the analog components have reduced requirements on matching tolerances and amplifier gains. Oversampling converters also simplify the requirements placed on the analog anti-aliasing filters for $\mathrm{A} / \mathrm{D}$ converters and smoothing filters for D/A converters. For example, usually only a first- or second-order anti-aliasing filter is required for A/D converters, which can often be realized very inexpensively. Furthermore, a sample-and-hold is usually not required at the input of an oversampling $A / D$ converter.

In this chapter, the basics of oversampling converters are discussed first. We shall see that extra bits of resolution can be extracted from converters that sample much faster than the Nyquist rate. Furthermore, this extra resolution can be obtained with lower oversampling rates by spectrally shaping the quantization noise through the use of feedback. The use of shaped quantization noise applied to oversampling signals is commonly referred to as delta-sigma $(\Delta \Sigma)$ modulation. ${ }^{1}$ Simple first- and second-order $\Delta \Sigma$ modulators are discussed, followed by a discussion of typical system architectures for $\Delta \Sigma$ data converters. Next, two popular approaches for realizing decimation filters are described. Descriptions of some modern approaches are then described along with some practical considerations. The chapter concludes with an example design of a third-order $\Delta \Sigma$ A/D converter.

## 18.1 OVERSAMPLING WITHOUT NOISE SHAPING

In this section, the advantage of sampling at higher than the Nyquist rate is discussed. Here, we shall see that extra dynamic range can be obtained by spreading the quantization noise power over a larger frequency range. However, we shall see that the increase in dynamic range is only 3 dB for every doubling of the sample rate. To obtain much higher dynamic-range improvements as the sampling rate is increased, noise shaping through the use of feedback can be used and is discussed in the next section.

[^2]![](https://cdn.mathpix.com/cropped/2024_11_07_e169e965a17846596f50g-097.jpg?height=419&width=1150&top_left_y=179&top_left_x=311)

Fig. 18.1 Quantizer and its linear model.
![](https://cdn.mathpix.com/cropped/2024_11_07_e169e965a17846596f50g-097.jpg?height=337&width=1001&top_left_y=745&top_left_x=381)

Fig. 18.2 Assumed spectral density of quantization noise.

### 18.1.1 Quantization Noise Modelling

We begin by modelling a quantizer as adding quantization error $\mathrm{e}(\mathrm{n})$, as shown in Fig. 18.1. The output signal, $y(n)$, is equal to the closest quantized value of $\mathbf{x}(\mathrm{n})$. The quantization error is the difference between the input and output values. This model is exact if one recognizes that the quantization error is not an independent signal but may be strongly related to the input signal, $\mathbf{x}(\mathrm{n})$. This linear model becomes approximate when assumptions are made about the statistical properties of $e(n)$, such as $e(n)$ being an independent white-noise signal. However, even though approximate, it has been found that this model leads to a much simpler understanding of $\Delta \Sigma$ and with some exceptions is usually reasonably accurate.

### 18.1.2 White Noise Assumption

If $x(n)$ is very active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\pm \Delta / 2$, where $\Delta$ equals the difference between two adjacent quantization levels. Thus, the quantization noise power equals $\Delta^{2} / 12$ (from Section 15.3) and is independent of the sampling frequency, $f_{s}$. Also, the spectral density of $\mathrm{e}(\mathrm{n}), \mathrm{S}_{\mathrm{e}}(\mathrm{f})$, is white (i.e., a constant over frequency) and all its power is within $\pm \mathrm{f}_{\mathrm{s}} / 2$ (a two-sided definition of power).

Assuming white quantization noise, the spectral density of the quantization noise, $\mathrm{S}_{\mathrm{e}}(\mathrm{f})$ appears as shown in Fig. 18.2.

Key Point: Quantization with a step size "LSB" can be modeled as an additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$ with a white power spectrum and total power of $\operatorname{LSB}^{2} / 12$.

The spectral density height is calculated by noting that the total noise power is $\Delta^{2} / 12$ and, with a two-sided definition of power, equals the area under $S_{e}(f)$ within $\pm f_{s} / 2$, or mathematically,

$$
\begin{equation*}
\int_{-\mathrm{s}_{\mathrm{s}} / 2}^{\mathrm{f}_{\mathrm{s}} / 2} \mathrm{~S}_{\mathrm{e}}^{2}(\mathrm{f}) \mathrm{df}=\int_{-\mathrm{f}_{\mathrm{s}} / 2}^{\mathrm{f}_{\mathrm{s}} / 2} \mathrm{k}_{\mathrm{x}}^{2} \mathrm{df}=\mathrm{k}_{\mathrm{x}}^{2} \mathrm{f}_{\mathrm{s}}=\frac{\Delta^{2}}{12} \tag{18.1}
\end{equation*}
$$

Solving this relation gives

$$
\begin{equation*}
\mathrm{k}_{\mathrm{x}}=\left(\frac{\Delta}{\sqrt{12}}\right) \sqrt{\frac{1}{\mathrm{f}_{\mathrm{s}}}} \tag{18.2}
\end{equation*}
$$

#### EXAMPLE 18.1

Find the output and quantization errors for two different quantizers, as shown in Fig. 18.3, when the input values are

$$
\begin{equation*}
x(n)=\{0.01,0.31,-0.11,0.80,0.52,-0.70\} \tag{18.3}
\end{equation*}
$$

Also find the expected power and the power density height, $S_{e}^{2}(\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \pi \mathrm{rad} /$ sample.

#### Solution

The output and quantization noise values for this example are given in Table 18.1. Note that although the output signals, $y(n)$, are well-defined values, the quantization error values can be approximated as uniformly distributed random numbers since the input signal is quite active.

Recalling that the quantization noise power is given by

$$
\begin{equation*}
\mathrm{P}_{\mathrm{e}}=\frac{\Delta^{2}}{12} \tag{18.4}
\end{equation*}
$$

then the expected noise powers of the two quantizers are

$$
\begin{equation*}
\mathrm{P}_{\mathrm{I}}=\frac{0.5^{2}}{12}=0.0208 \mathrm{~W} \tag{18.5}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_e169e965a17846596f50g-098.jpg?height=551&width=1229&top_left_y=1496&top_left_x=267)

Fig. 18.3 Two example quantizers.

#### Table 18.1 Example signal values and quantization noise for two quantizers.

|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |
| ---: | ---: | ---: | ---: | ---: | ---: |
| $\mathbf{x}(\mathbf{n})$ | $\mathbf{y ( n )}$ | $\mathbf{e ( n )}$ |  | $\mathbf{y ( n )}$ | $\mathbf{e ( n )}$ |
| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |
| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |
| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |
| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |
| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |
| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |

$$
\begin{equation*}
\mathrm{P}_{\mathrm{II}}=\frac{2^{2}}{12}=0.333 \mathrm{~W} \tag{18.6}
\end{equation*}
$$

where we note that these values are not affected by normalizing the sampling frequency. Also note that the two power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577 , respectively.

For the power density, we note that the power is spread evenly between $\pm f_{s} / 2$, resulting in a density of

$$
\begin{equation*}
S_{e}^{2}(f)=\frac{P_{e}}{f_{s}} \tag{18.7}
\end{equation*}
$$

which results in

$$
\begin{align*}
& S_{\mathrm{el}}^{2}(\mathrm{f})=\left(\frac{0.0208}{2 \pi}\right)=0.00331 \frac{\mathrm{~W}}{\mathrm{rad} / \mathrm{sample}}  \tag{18.8}\\
& \mathrm{~S}_{\mathrm{elI}}^{2}(\mathrm{f})=\left(\frac{0.333}{2 \pi}\right)=0.053 \frac{\mathrm{~W}}{\mathrm{rad} / \mathrm{sample}} \tag{18.9}
\end{align*}
$$

### 18.1.3 Oversampling Advantage

Oversampling occurs when the signals of interest are bandlimited to $f_{0}$ yet the sample rate is at $f_{s}$, where $f_{s}>2 f_{0}$ ( $2 f_{0}$ being the Nyquist rate or, equivalently, the minimum sampling rate for signals bandlimited to $f_{0}$ ). We define the oversampling ratio, OSR, as

$$
\begin{equation*}
\mathrm{OSR} \equiv \frac{\mathrm{f}_{\mathrm{s}}}{2 \mathrm{f}_{0}} \tag{18.10}
\end{equation*}
$$

After quantization, since the signals of interest are all below $f_{0}, y_{1}(n)$ is filtered by $H(f)$ to create the signal $y_{2}(n)$, as shown in Fig. 18.4. This filter eliminates quantization noise (together with any other signals) greater than $\mathrm{f}_{0}$.

Assuming the input signal is a sinusoidal wave, its maximum peak value without clipping is $2^{\mathrm{N}}(\Delta / 2)$. For this maximum sinusoidal wave, the signal power, $P_{s}$, has a power equal to

$$
\begin{equation*}
P_{s}=\left(\frac{\Delta 2^{N}}{2 \sqrt{2}}\right)^{2}=\frac{\Delta^{2} 2^{2 N}}{8} \tag{18.11}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_e169e965a17846596f50g-100.jpg?height=611&width=937&top_left_y=167&top_left_x=420)

Fig. 18.4 (a) A possible oversampling system without noise shaping. (b) The brick-wall response of the filter to remove much of the quantization noise.

The power of the input signal within $\mathrm{y}_{2}(\mathrm{n})$ remains the same as before since we assumed the signal's frequency content is below $f_{0}$. However, the quantization noise power is reduced to

$$
\begin{equation*}
P_{e}=\int_{-f_{s} / 2}^{f_{\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\frac{2 f_{0}}{f_{s}} \frac{\Delta^{2}}{12}=\frac{\Delta^{2}}{12}\left(\frac{1}{\mathrm{OSR}}\right) \tag{18.12}
\end{equation*}
$$

Therefore, doubling OSR (i.e., sampling at twice the rate) decreases the quantization noise power by one-half or, equivalently, 3 dB (or, equivalently, 0.5 bits).

We can also calculate the maximum SQNR (in dB ) to be the ratio of the maximum sinusoidal power to the quantization noise power in the signal $\mathrm{y}_{2}(\mathrm{n})$. Mathematically, we have through the use of (18.11) and (18.12)

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=10 \log \left(\frac{\mathrm{P}_{\mathrm{s}}}{\mathrm{P}_{\mathrm{e}}}\right)=10 \log \left(\frac{3}{2} 2^{2 \mathrm{~N}}\right)+10 \log (\mathrm{OSR}) \tag{18.13}
\end{equation*}
$$

which is also equal to

Key Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \log (O S R) d B$.

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=6.02 \mathrm{~N}+1.76+10 \log (\mathrm{OSR}) \tag{18.14}
\end{equation*}
$$

The first term is the SQNR due to the N -bit quantizer while the OSR term is the SQNR enhancement obtained from oversampling. Here we see that straight oversampling gives a SQNR improvement of $3 \mathrm{~dB} /$ octave or, equivalently, 0.5 bits/octave. The reason for this SQNR improvement through the use of oversampling is that when quantized samples are averaged together, the signal portion adds linearly, whereas the noise portion adds as the square root of the sum of the squares. Note that this enhancement also takes place with respect to other types of noise, such as thermal noise in circuits. Hence, oversampling generally improves overall signal to noise ratio (SNR) by $10 \log (\mathrm{OSR})$.

[^0]:    1. In fact, the resistor-string $D / A$ was used to realize an $A / D$ converter in the reference.
[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes $(00,01$, or 11$)$, they are actually $\log _{2}(3)=1.585$-bit stages, but in practice they are always referred to simply as 1.5 -bit stages.
[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.

#### EXAMPLE 18.2

Consider a sampled dc signal, $\mathrm{V}_{\mathrm{s}}$, of value 1 V where the measured voltage, $\mathrm{V}_{\text {meas }}$, is $\mathrm{V}_{\mathrm{s}}$ plus a noise signal, $\mathrm{V}_{\text {noise }}$. Assume $\mathrm{V}_{\text {noise }}$ is a random signal uniformly distributed between $\pm \sqrt{3}$. What is the SNR for $\mathrm{V}_{\text {meas }}$ when looking at individual values? If eight samples of $\mathrm{V}_{\text {meas }}$ are averaged together, roughly what is the new SNR? To illustrate the results, use eight typical samples for $\mathrm{V}_{\text {meas }}$ of $\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\}$.

#### Solution

Referencing signals to $1 \Omega$, we calculate the power of $V_{s}$ and $V_{\text {noise }}$ to both be 1 watt. Thus the SNR for $V_{\text {meas }}$ is 0 dB when looking at individual $\mathrm{V}_{\text {meas }}$ values. Note that it is difficult to see the signal value of 1 V in the example $V_{\text {meas }}$ samples since the SNR is so poor.

If eight samples are averaged, we are realizing a modest low-pass filter, resulting in the oversampling ratio being approximately equal to 8 (this is a rough estimate since a brick-wall filter is not being used). Since each octave of oversampling results in a $3-\mathrm{dB}$ SNR improvement, the averaged value should have a SNR of around 9 dB . Note that averaging the eight given $\mathrm{V}_{\text {meas }}$ samples results in 0.8875 , which more closely represents the signal value of 1 V .

The reason oversampling improves the SNR here is that by summing eight measured values, the eight signal values add linearly to $8 \mathrm{~V}_{\mathrm{rms}}$ (or 64 watts) while the eight noise values add to $\sqrt{8} \mathrm{~V}_{\mathrm{rms}}$ (or 8 watts), since the noise values are assumed to be independent.

#### EXAMPLE 18.3

Given that a 1-bit A/D converter has a $6-\mathrm{dB}$ SQNR, what sample rate is required using oversampling (no noise shaping) to obtain a $96-\mathrm{dB}$ SQNR (i.e., 16 bits) if $\mathrm{f}_{0}=25 \mathrm{kHz}$ ? (Note that the input into the $\mathrm{A} / \mathrm{D}$ converter has to be very active for the white-noise quantization model to be valid-a difficult arrangement when using a 1 bit quantizer with oversampling without noise shaping.)

#### Solution

Oversampling (without noise shaping) gives 3 dB /octave where 1 octave implies doubling the sampling rate. We require 90 dB divided by 3 dB /octave, or 30 octaves. Thus, the required sampling rate, $\mathrm{f}_{\mathrm{s}}$, is

$$
f_{s}=2^{30} \times 2 f_{0} \cong 54,000 \mathrm{GHz}!
$$

This example shows why noise shaping is needed to improve the SQNR faster than $3 \mathrm{~dB} /$ octave, since $54,000 \mathrm{GHz}$ is highly impractical.

### 18.1.4 The Advantage of 1-Bit D/A Converters

While oversampling improves the signal-to-noise ratio, it does not improve linearity. For example, if a 16-bit linear converter is desired while using a 12 -bit converter with oversampling, the 12 -bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (here, LSB refers to that for a 12-bit converter). In other words, the component accuracy would have to match better than 16-bit accuracy (i.e., $100 \times\left(1 / 2^{16}\right)=0.0015$ percent

Key Point: One-bit D/A converters are inherently linear. Hence, when combined with a high oversampling ratio, they can provide a good signal to quantization noise and distortion ratio.
accuracy). Thus, some sort of auto calibration or laser trimming must be used to obtain the required linearity. However, as we saw in Example 18.3, with a high enough sampling rate, the output from a 1-bit converter can be filtered to obtain the equivalent of a 16-bit converter. The advantage of a 1 -bit $D / A$ is that it is inherently linear. ${ }^{2}$ This linearity is a result of a 1-bit D/A converter having only two output values and, since two points define a straight line, no trimming or calibration is required. This inherent linearity is one of the major motivations for making use of oversampling techniques with 1-bit converters. In fact, the reader may be aware that many audio converters use 1-bit converters for realizing 16- to 18-bit linear converters (with noise shaping). In fact, 20-bit linearity has been reported without the need for any trimming [Leopold, 1991]. Finally, it should be mentioned that there are other advantages when using oversampling techniques, such as a reduced requirement for analog anti-aliasing and smoothing filters.

## 18.2 OVERSAMPLING WITH NOISE SHAPING

In this section, the advantage of noise shaping the quantization noise through the use of feedback is discussed. Here, we shall see a much more dramatic improvement in dynamic range when the input signal is oversampled as compared to oversampling the input signal with no noise shaping. Although this section illustrates the basic principles with reference to $\mathrm{A} / \mathrm{D}$ converters, much of it applies directly to $\Delta \Sigma \mathrm{D} / \mathrm{A}$ converters as well.

The system architecture of a $\Delta \Sigma$ oversampling $\mathrm{A} / \mathrm{D}$ converter is shown in Fig. 18.5. The first stage is a con-tinuous-time anti-aliasing filter and is required to band-limit the input signal to frequencies less than one-half the oversampling frequency, $\mathrm{f}_{\mathrm{s}}$. When the oversampling ratio is large, the anti-aliasing filter can often be quite simple, such as a simple RC low-pass filter. Following the anti-aliasing filter, the continuous-time signal, $\mathbf{x}_{\mathrm{c}}(\mathrm{t})$, is sampled by a sample and hold. This signal is then processed by the $\Delta \Sigma$ modulator, which converts the analog signal into a noise-shaped low-resolution digital signal. The third block in the system is a decimator. It converts the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate usually equal to twice the frequency of the desired bandwidth of the input signal. The decimation filter can be conceptually thought of as a low-pass filter followed by a down sampler, although in many systems the decimation is performed in a number of stages. It should be mentioned that in many realizations where the $\Delta \Sigma$ modulator is realized using switched-capacitor circuitry, a separate sample-and-hold is not required, as the continuous-time signal
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-02.jpg?height=335&width=1273&top_left_y=1579&top_left_x=254)

Fig. 18.5 Block diagram of an oversampling A/D converter.
2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, or reference voltages, or memory in the $\mathrm{D} / \mathrm{A}$ converter are not present.
is inherently sampled by the switches and input capacitors of the SC $\Delta \Sigma$. In the next few sections the operation of the various building blocks will be described in greater detail.

### 18.2.1 Noise-Shaped Delta-Sigma Modulator

A general noise-shaped delta-sigma ( $\Delta \Sigma$ ) modulator and its linear model are shown in Fig. 18.6. This arrangement is known as an interpolative structure and is analogous to an amplifier realized using an opamp and feedback. In this analogy, the feedback reduces the effect of the noise of the output stage of the opamp in the closedloop amplifier's output signal at low frequencies when the opamp gain is high. At high frequencies, when the opamp's gain is low, the noise is not reduced. Note that the quantizer here is shown for the general case where many output levels occur. While many oversampling converters make use of 1-bit quantizers (i.e., only two output levels) due to reasons already discussed, there is certainly no reason to restrict ourselves to such implementations. Multibit oversampling converters are discussed in detail in Section 18.8.

Treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\mathrm{S}_{\mathrm{TF}}(\mathrm{Z})$, and a noise transfer function, $\mathrm{N}_{T F}(\mathrm{Z})$.

$$
\begin{align*}
& S_{T F}(z) \equiv \frac{Y(z)}{U(z)}=\frac{H(z)}{1+H(z)}  \tag{18.15}\\
& N_{T F}(z) \equiv \frac{Y(z)}{E(z)}=\frac{1}{1+H(z)} \tag{18.16}
\end{align*}
$$

Note that the zeros of the noise transfer function, $N_{T F}(z)$, will be equal to the poles of $\mathrm{H}(\mathrm{z})$. In other words, when $H(z)$ goes to infinity, we see by (18.16) that $\mathrm{N}_{T F}(\mathrm{z})$ will go to zero. We can also write the output signal as the combination of the input signal and the noise signal, with each being filtered by the corresponding transfer function. In the frequency domain, we have

$$
\begin{equation*}
Y(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \tag{18.17}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-03.jpg?height=231&width=834&top_left_y=1405&top_left_x=460)
(a)
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-03.jpg?height=250&width=830&top_left_y=1711&top_left_x=471)
(b)

Fig. 18.6 A modulator and its linear model: (a) a general $\Delta \Sigma$ modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.

Key Point: To shape the spectrum of a quantization noise source, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest.

To noise-shape the quantization noise in a useful manner, we choose $H(z)$ such that its magnitude is large from 0 to $f_{0}$ (i.e., over the frequency band of interest). With such a choice, the signal transfer function, $\mathrm{S}_{\mathrm{TF}}(\mathrm{Z})$, will approximate unity over the frequency band of interest very similarly to an opamp in a unity-gain feedback configuration. Furthermore, the noise transfer function, $\mathrm{N}_{\mathrm{TF}}(\mathbf{z})$, will approximate zero over the same band. Thus, the quantization noise is reduced over the frequency band of interest while the signal itself is largely unaffected. The high-frequency noise is not reduced by the feedback as there is little loop gain at high frequencies. However, additional post filtering can remove the out-of-band quantization noise with little effect on the desired signal.

Before choosing specific functions for $\mathrm{H}(\mathrm{z})$, note that the maximum level of the in-band input signal, $\mathrm{u}(\mathrm{n})$, must remain within the maximum levels of the feedback signal, $\mathrm{y}(\mathrm{n})$; otherwise the large gain in $\mathrm{H}(\mathrm{z})$ will cause the signal $x(n)$ to saturate. For example, if a 1-bit quantizer having output levels of $\pm 1$ is used, the input signal must also remain within $\pm 1$ for frequencies where the gain of $H(z)$ is large. In fact, for many modulators the input signal needs to be significantly smaller than the bounds of the quantizer output levels to keep the modulator stable. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is small will not necessarily cause the signal $x(n)$ to saturate. In other words, the maximum level of the out-ofband input signal can be quite a bit larger than the feedback levels (see Problem 18.6).

### 18.2.2 First-Order Noise Shaping

Key Point: Using a single integrator inside a $\Delta \Sigma$ modulator feedback loop places a zero at dc in the noise transfer function providing firstorder noise shaping for low-pass signals.

To realize first-order noise shaping, the noise transfer function, $\mathrm{N}_{\mathrm{TF}}(\mathbf{z})$, should have a zero at dc (i.e., $\mathbf{z}=1$ ) so that the quantization noise is high-pass filtered. Since the zeros of $N_{T F}(z)$ are equal to the poles of $H(z)$, we can obtain first-order noise shaping by letting $H(z)$ be a discrete-time integrator (i.e., have a pole at z = 1). ${ }^{4}$ Specifically,

$$
\begin{equation*}
H(z)=\frac{1}{z-1} \tag{18.18}
\end{equation*}
$$

A block diagram for such a choice is shown in Fig. 18.7.
Time Domain View From a time domain point of view, if the feedback is operating correctly and the system is stable, then the signal $x(n)$ is bounded (i.e., $\neq \infty$ ). Since the integrator has infinite dc gain, the average value of the discrete-time integrator's input must exactly equal zero (i.e., average value of $u(n)-y(n)$ equals zero). This result implies that the average value (i.e., dc value) of $u(n)$ must equal the average value (i.e., dc value) of $y(n)$.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-04.jpg?height=231&width=839&top_left_y=1661&top_left_x=471)

Fig. 18.7 A first-order noise-shaped interpolative modulator.
3. A modulator is defined to be stable if the input to the quantizer does not become so large as to cause the quantizer error to become greater than $\pm \Delta / 2$ (which is referred to as overloading the quantizer). See Section 18.7.
4. A continuous-time integrator can also be used, but discrete-time integrators are more popular in integrated realizations as they are less sensitive to sampling jitter and have better distortion characteristics.

Again, the similarity of this configuration and an opamp having unity-gain feedback is emphasized. The open-loop transfer function of an opamp is closely approximated by a first-order integrator having very large gain at low frequencies.

#### EXAMPLE 18.4

Find the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when a two-level quantizer of $\pm 1.0$ is used (threshold at zero) and the initial state for $\mathrm{x}(\mathrm{n})$ is 0.1 .

#### Solution

The output sequence and state values are given in Table 18.2.
Note that the average of $y(n)$ exactly equals $1 / 3$ as expected. However, also note that the output pattern is periodic, which implies that the quantization noise is not random in this example. (However, the result is much more satisfying than applying $1 / 3$ directly into a 1-bit quantizer using straight oversampling, which would give all 1 s as its output.)

Frequency Domain View From a frequency domain view, the signal transfer function, $\mathrm{S}_{\mathrm{TF}}(\mathrm{z})$, is given by

$$
\begin{equation*}
S_{T F}(z)=\frac{Y(Z)}{U(Z)}=\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \tag{18.19}
\end{equation*}
$$

and the noise transfer function, $\mathrm{N}_{\mathrm{TF}}(\mathrm{Z})$, is given by

$$
\begin{equation*}
N_{T F}(z)=\frac{Y(z)}{E(z)}=\frac{1}{1+1 /(z-1)}=\left(1-z^{-1}\right) \tag{18.20}
\end{equation*}
$$

We see here that the signal transfer function is simply a delay, while the noise transfer function is a discrete-time differentiator (i.e., a high-pass filter).

To find the magnitude of the noise transfer function, $\left|N_{T F}(f)\right|$, we let $Z=e^{j \omega T}=e^{j 2 \pi t / f_{s}}$ and write the following:

$$
\begin{align*}
N_{T F}(f) & =1-e^{-j 2 \pi \tau / f_{s}}=\frac{e^{j \pi f / f_{s}}-e^{-j \pi t / f_{s}}}{2 j} \times 2 j \times e^{-j \pi t / f_{s}}  \tag{18.21}\\
& =\sin \left(\frac{\pi f}{f_{s}}\right) \times 2 j \times e^{-j \pi f / f_{s}}
\end{align*}
$$

Table 18.2 First-order modulator example.

| $\mathbf{n}$ | $\mathbf{x}(\mathbf{n})$ | $\mathbf{x}(\mathbf{n}+\mathbf{1})$ | $\mathbf{y ( n )}$ | $\mathbf{e ( n )}$ |
| :---: | :---: | :---: | :---: | :---: |
| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |
| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |
| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |
| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |
| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |
| 5 | $\ldots$ | $\cdots$ | $\cdots$ | $\cdots$ |

Taking the magnitude of both sides, we have the high-pass function

$$
\begin{equation*}
\left|N_{T F}(f)\right|=2 \sin \left(\frac{\pi f}{f_{s}}\right) \tag{18.22}
\end{equation*}
$$

Now the quantization noise power over the frequency band from 0 to $f_{0}$ is given by

$$
\begin{equation*}
P_{e}=\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\left|N_{T F}(f)\right|^{2} d f=\int_{-f_{0}}^{f_{0}}\left(\frac{\Delta^{2}}{12}\right) \frac{1}{f_{s}}\left[2 \sin \left(\frac{\pi f}{f_{s}}\right)\right]^{2} d f \tag{18.23}
\end{equation*}
$$

and making the approximation that $f_{0}<<f_{s}$ (i.e., OSR $>>1$ ), so that we can approximate $\sin \left((\pi f) / f_{s}\right)$ to be $(\pi f) / f_{s}$, we have

$$
\begin{equation*}
\mathrm{P}_{\mathrm{e}} \cong\left(\frac{\Delta^{2}}{12}\right)\left(\frac{\pi^{2}}{3}\right)\left(\frac{2 \mathrm{f}_{0}}{\mathrm{f}_{\mathrm{s}}}\right)^{3}=\frac{\Delta^{2} \pi^{2}}{36}\left(\frac{1}{\mathrm{OSR}}\right)^{3} \tag{18.24}
\end{equation*}
$$

Assuming the maximum signal power is the same as that obtained before in (18.11), the maximum SNR for this case is given by

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=10 \log \left(\frac{\mathrm{P}_{\mathrm{s}}}{\mathrm{P}_{\mathrm{e}}}\right)=10 \log \left(\frac{3}{2} 2^{2 \mathrm{~N}}\right)+10 \log \left[\frac{3}{\pi^{2}}(\mathrm{OSR})^{3}\right] \tag{18.25}
\end{equation*}
$$

or, equivalently,

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=6.02 \mathrm{~N}+1.76-5.17+30 \log (\mathrm{OSR}) \tag{18.26}
\end{equation*}
$$

Key Point: First-order noise shaping permits SQNR to increase by 1.5 bits/octave with respect to oversampling ratio, or 9 dB for every doubling of OSR.

We see here that doubling the OSR gives an SQNR improvement for a first-order modulator of 9 dB or, equivalently, a gain of 1.5 bits/octave. This result should be compared to the 0.5 bits/octave when oversampling with no noise shaping.

### 18.2.3 Switched-Capacitor Realization of a First-Order A/D Converter

It is possible to realize a first-order modulator using switched-capacitor (SC) techniques. An example of a firstorder modulator where a 1-bit quantizer is used in the feedback loop is shown in Fig. 18.8. Here, the $\Delta \Sigma$ modulator consists of both analog and digital circuitry. It should be mentioned that the two input capacitances to the discrete-time integrator in Fig. 18.8 can be combined to one capacitance, as shown in Fig. 18.9 [Boser, 1988]. However, such an approach does not easily allow scaling of the feedback signal relative to the input signal.

### 18.2.4 Second-Order Noise Shaping

The modulator shown in Fig. 18.10 realizes second-order noise shaping (i.e., the noise transfer function, $\mathrm{N}_{T F}(\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is given by

$$
\begin{equation*}
S_{T F}(f)=z^{-1} \tag{18.27}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-07.jpg?height=307&width=832&top_left_y=180&top_left_x=472)
(a)
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-07.jpg?height=403&width=970&top_left_y=579&top_left_x=394)
(b)

Fig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-07.jpg?height=412&width=930&top_left_y=1242&top_left_x=416)

Fig. 18.9 First-order A/D modulator using only one input capacitance to the discrete-time integrator.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-07.jpg?height=220&width=1122&top_left_y=1819&top_left_x=339)

Fig. 18.10 Second-order $\Delta \Sigma$ modulator.
and the noise transfer function is given by

$$
\begin{equation*}
N_{T F}(f)=\left(1-z^{-1}\right)^{2} \tag{18.28}
\end{equation*}
$$

Additionally, the magnitude of the noise transfer function can be shown to be given by

$$
\begin{equation*}
\left|N_{T F}(f)\right|=\left[2 \sin \left(\frac{\pi f}{f_{s}}\right)\right]^{2} \tag{18.29}
\end{equation*}
$$

resulting in the quantization noise power over the frequency band of interest being given by

$$
\begin{equation*}
\mathrm{P}_{\mathrm{e}} \cong \frac{\Delta^{2} \pi^{4}}{60}\left(\frac{1}{\mathrm{OSR}}\right)^{5} \tag{18.30}
\end{equation*}
$$

Again, assuming the maximum signal power is that obtained in (18.11), the maximum SQNR for this case is given by

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=10 \log \left(\frac{\mathrm{P}_{\mathrm{s}}}{\mathrm{P}_{\mathrm{e}}}\right)=10 \log \left(\frac{3}{2} 2^{2 \mathrm{~N}}\right)+10 \log \left[\frac{5}{\pi^{4}}(\mathrm{OSR})^{5}\right] \tag{18.31}
\end{equation*}
$$

or, equivalently,

$$
\begin{equation*}
\mathrm{SQNR}_{\max }=6.02 \mathrm{~N}+1.76-12.9+50 \log (\mathrm{OSR}) \tag{18.32}
\end{equation*}
$$

Key Point: Second-order noise shaping increases SQNR by 15 dB for each doubling of OSR, or equivalently by 1.5 bits/octave.

We see here that doubling the OSR improves the SQNR for a second-order modulator by 15 dB or, equivalently, a gain of 2.5 bits/octave.

The realization of the second-order modulator using switched-capacitor techniques is left as an exercise for the interested reader.

### 18.2.5 Noise Transfer-Function Curves

The general shape of zero-, first-, and second-order noise-shaping curves are shown in Fig. 18.11. Note that over the band of interest (i.e., from 0 to $f_{0}$ ), the noise power decreases as the noise-shaping order increases. However, the out-of-band noise increases for the higher-order modulators.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-08.jpg?height=428&width=1323&top_left_y=1622&top_left_x=224)

Fig. 18.11 Some different noise-shaping transfer functions.

#### EXAMPLE 18.5

Given that a 1-bit A/D converter has a $6-\mathrm{dB}$ SQNR, what sample rate is required to obtain a $96-\mathrm{dB}$ SNR (or 16 bits) if $\mathrm{f}_{0}=25 \mathrm{kHz}$ for straight oversampling as well as first- and second-order noise shaping?

#### Solution

Oversampling with No Noise Shaping From Example 18.3, straight oversampling requires a sampling rate of 54,000 GHz.

First-Order Noise Shaping First-order noise shaping gives $9 \mathrm{~dB} /$ octave where 1 octave is doubling the OSR. Since we lose 5 dB , we require 95 dB divided by $9 \mathrm{~dB} /$ octave, or 10.56 octaves. Thus, the required sampling rate, $f_{s}$, is

$$
f_{s}=2^{10.56} \times 2 f_{0} \cong 75 \mathrm{MHz}
$$

This compares very favorably with straight oversampling, though it is still quite high.
Second-Order Noise Shaping Second-order noise shaping gives $15 \mathrm{~dB} /$ octave, but loses 13 dB . Thus we required 103 dB divided by $15 \mathrm{~dB} /$ octave, resulting in a required sampling rate of only 5.8 MHz . However, this simple calculation does not take into account the reduced input range for a second-order modulator needed for stability.

### 18.2.6 Quantization Noise Power of 1-Bit Modulators

Assuming the output of a 1 -bit modulator is $\pm 1$, then one can immediately determine the total power of the output signal, $y(n)$, to be a normalized power of 1 watt. Since $y(n)$ consists of both signal and quantization noise, it is clear that the signal power can never be greater than 1 watt. In fact, as alluded to earlier, the signal level is often limited to well below the $\pm 1$ level in higher-order modulators to maintain stability. For example, assuming that the maximum peak signal level is

Key Point: The input signal power is often limited to well below the maximum quantizerswing to ensure stability, resulting in reduced SQNR.
only $\pm 0.25$, then the maximum signal power is 62.5 mW (referenced to a $1 \Omega$ load). This would imply a signal power approximately 12 dB less than is predicted by (18.11) and a corresponding reduction in the SQNR estimates that follow from (18.11). Since the signal power plus quantization noise power equals 1 W , in this example the maximum signal power is about 12 dB below the total quantization noise power. Fortunately, as we saw above, the quantization noise power is mostly in a different frequency region than the signal power and can therefore be filtered out. Note, however, that the filter must have a dynamic range capable of accommodating the full power of $y(n)$ at its input. For a $\Delta \Sigma A / D$ converter, the filtering would be done by digital filters following the quantizer.

### 18.2.7 Error-Feedback Structure

Before leaving this section, it is of interest to look at another structure for realizing a delta-sigma modulator-an error-feedback structure, as shown in Fig. 18.12 [Anastassiou, 1989]. Using a linear model for the quantizer, it is not difficult to show that this error-feedback structure has a signal transfer function, $\mathrm{S}_{\mathrm{TF}}(\mathrm{z})$, equal to unity while
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-10.jpg?height=330&width=775&top_left_y=189&top_left_x=503)

Fig. 18.12 The error-feedback structure of a general $\Delta \Sigma$ modulator.
the noise transfer function, $N_{T F}(z)$, equals $G(z)$. Thus for a first-order modulator, $G(z)=1-z^{-1}$, or in other words, the block $(G(z)-1)$ is simply $-z^{-1}$.

Unfortunately, a slight coefficient error can cause significant noise-shaping degradation with this errorfeedback structure. For example, in a first-order case, if the delayed signal becomes $-0.99 z^{-1}$ (rather than $-z^{-1}$ ), then $G(z)=1-0.99 z^{-1}$, and the zero is moved off dc. Such a shift of the zero will result in the quantization noise not being fully nulled at dc and therefore would not be suitable for high oversampling ratios. Thus, this structure is not well suited to analog implementations where coefficient mismatch occurs. In contrast, an interpolative structure has the advantage that the zeros of the noise transfer function remain at dc as long as $\mathrm{H}(\mathrm{z})$ has infinite gain at dc. This high gain at dc can usually be obtained in analog implementations by using opamps with large open-loop gains and does not rely on component matching. The error feedback structure is discussed here because it is useful for analysis purposes and can work well for fully digital implementations (such as in D/A converters) where no coefficient mismatches occur.

A second-order modulator based on the error-feedback structure is shown in Fig. 18.13. For this case we have

$$
\begin{equation*}
G(z)-1=z^{-1}\left(z^{-1}-2\right) \tag{18.33}
\end{equation*}
$$

implying that

$$
\begin{align*}
\mathrm{G}(\mathrm{z}) & =1-2 \mathrm{z}^{-1}+\mathrm{z}^{-2} \\
& =\left(1-\mathrm{z}^{-1}\right)^{2} \tag{18.34}
\end{align*}
$$

which is identical to (18.28), and we see that second-order noise shaping is obtained. In practical realizations, one might have to take into account additional details such as preventing overflow and reducing complexity. For these more advanced topics, the reader is referred to [Temes, 1996].
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-10.jpg?height=334&width=871&top_left_y=1712&top_left_x=450)

Fig. 18.13 The error-feedback structure of a second-order $\Delta \Sigma$ modulator.

## 18.3 SYSTEM ARCHITECTURES

In this section, we look at typical system architectures for oversampled $A / D$ and $D / A$ converters.

### 18.3.1 System Architecture of Delta-Sigma A/D Converters

The system architecture for a typical $\Delta \Sigma$ oversampling A/D converter is shown in Fig. 18.14, and some example signal spectra are shown in Fig. 18.15. In the case of digital audio, various sampling frequencies might be $f_{s}=5.6448 \mathrm{MHz}, f_{0}=44.1 \mathrm{kHz}$, which represent an oversampling ratio of 128 . Here, the input signal, $x_{c}(t)$, is sampled and held, ${ }^{5}$ resulting in the signal $x_{\text {sh }}(t)$. This sampled-and-held signal is then applied to an $A / D \Delta \Sigma$ modulator, which has as its output a 1-bit digital signal $\mathrm{x}_{\mathrm{dsm}}(\mathrm{n})$. This 1-bit digital signal is assumed to be linearly related to the input signal $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$ (accurate to many bits of resolution), although it includes a large amount of out-of-band quantization noise. To remove this out-of-band quantization noise, a digital decimation filter is used as shown. Conceptually, one can think of the decimation process as first reducing the quantization noise through the use of a digital low-pass filter, resulting in the multi-bit signal $x_{1 p}(n)$. Note that this low-pass filter will also remove any higher-frequency signal content that was originally on the input signal, $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$, and thus also acts as an anti-aliasing filter to limit signals to one-half the final output sampling rate, $2 \mathrm{f}_{0}$, as opposed to the anti-aliasing filter at the input, which needed to only limit signals to frequencies less than $f_{s} / 2$. By contrast, in a Nyquist-rate $A / D$ converter, where $f_{s}$ is only slightly greater than $2 f_{0}$, the analog anti-aliasing filter must have a very sharp cutoff to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Hence, oversampling A/D converters require additional digital lowpass filtering, but less analog antialiasing filtering-often an desirable trade-off in integrated circuits.

Next, $x_{1 p}(n)$ is resampled at $2 f_{0}$ to obtain $x_{s}(n)$ by simply keeping samples at a submultiple of the oversampling rate and throwing away the rest. In Fig. 18.15 an oversampling rate of only 6 is shown for clarity as opposed to the more typical values of 64 or 128 that are used in many commercial applications. This decimation process does not result in any loss of information, since the bandwidth of the original signal was assumed to be $f_{0}$. In other words, the signal $x_{10}(n)$ has redundant information since it is an oversampled signal where all of its spectral information

Key Point: Oversampling A/D converters require additional digital low-pass filtering, but less analog anti-aliasing filteringoften andesirable trade-off in integrated circuits.
lies well below $\pi$, and by throwing away samples, the spectral information is spread over 0 to $\pi$. Finally, it should be noted that there is no need to actually create the signal $x_{1 p}(n)$, and much digital circuit complexity can be saved by combining the digital low-pass filter with the resampling block to directly
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-11.jpg?height=339&width=1266&top_left_y=1575&top_left_x=253)

Fig. 18.14 Block diagram of an oversampling A/D converter.
5. This sample-and-hold block is often inherent in the switched-capacitor modulator. Thus, the signal $X_{s h}(t)$ may never physically exist in many realizations.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-12.jpg?height=1232&width=1392&top_left_y=165&top_left_x=167)

Fig. 18.15 Signals and spectra in an oversampling A/D converter.
produce the downsampled signal $\mathrm{x}_{\mathrm{s}}(\mathrm{n})$, as discussed in Section 18.4. The final signal, $\mathrm{x}_{\mathrm{s}}(\mathrm{n})$, would typically have 16-bit resolution in digital audio applications.

Key Point: The linearity of oversampled A/D converters depends more strongly on the linearity of its internal $D / A$ converter than on its internal quantizer.

It is of interest to look at what element most strongly affects the linearity of this oversampling $\mathrm{A} / \mathrm{D}$ system. Returning to the $\Delta \Sigma$ modulator, note that an internal 1-bit D/A converter is used whose output signal is combined with the input signal such that, over the frequency band of interest, these two signals are nearly the same. As a result, the overall linearity of this $\Delta \Sigma$ modulator converter depends strongly on the linearity of its internal D/A converter. For example, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would essentially equal that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to account for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is most strongly dependent on realizing a linear $\mathrm{D} / \mathrm{A}$ converter inside the $\Delta \Sigma$ modulator. In fact, nonlinearities in the internal A/D converter (if it was multi-bit) have only a small effect on the linearity of the overall converter, since the high gain in the feedback loop compensates for that nonlinearity.

### 18.3.2 System Architecture of Delta-Sigma D/A Converters

Most of the discussion so far has focused on $\Delta \Sigma \mathrm{A} / \mathrm{D}$ converters, but much of it also applies to $\Delta \Sigma \mathrm{D} / \mathrm{A}$ converters, with a few qualifications. A high-resolution oversampling D/A converter using a 1-bit converter can be realized as shown in the block diagram in Fig. 18.16. Some illustrative signals that might occur in this system are shown in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal and has an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly greater than the highest input signal frequency. For example, in a compact disc audio application, a 16-bit input signal is used with a frequency band of interest from 0 to 20 kHz while the sample rate, $2 \mathrm{f}_{0}$, is 44.1 kHz . Note, however, that $\mathrm{X}_{\mathrm{s}}(\mathrm{n})$ is actually just a series of numbers and thus its shown frequency spectrum has normalized the sample rate to $2 \pi$. Next, the input signal is upsampled to an equivalent higher sampling rate, $\mathrm{f}_{\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example shown, the oversampling rate is only six (i.e., $f_{s}=6 \times 2 f_{0}$ ), while in typical audio applications, $f_{s}$ is often near a $5-\mathrm{MHz}$ rate (i.e., oversampling rate of 128). However, $x_{s 2}(n)$ has large images left in its signal so an interpolation filter is used to create the multi-bit digital signal, $\mathrm{x}_{\mathrm{lp}}(\mathrm{n})$, by digitally filtering out the images. This interpolation filter is effectively a digital brick-wall-type filter that passes 0 to $\left(2 \pi f_{0}\right) / f_{s}$ and rejects all other signals. The resulting signal, $\mathrm{x}_{1 \mathrm{p}}(\mathrm{n})$, is then applied to a fully digital $\Delta \Sigma$ modulator that produces a 1-bit output signal, $x_{d s m}(n)$, which has a large amount of shaped quantization noise. As discussed earlier, the main reason for going to a 1-bit digital signal is so that a 1-bit $\mathrm{D} / \mathrm{A}$ converter can now be used to create $\mathrm{x}_{\mathrm{da}}(\mathrm{t})$, which has excellent linearity properties but still a large amount of out-of-band quantization noise. Finally, the desired output signal, $\mathrm{x}_{\mathrm{c}}(\mathrm{t})$, can be obtained by using an analog filter to filter out this out-of-band quantization noise. The analog filter may be a combination of switched-capacitor and continuous-time filtering.

Some points to note here are that while oversampling allows the use of a 1-bit D/A converter, which can have excellent linearity, the use of oversampling also relaxes some of the analog-smoothing filter specifications. For example, if a 16 -bit converter was used at the Nyquist rate, $2 \mathrm{f}_{0}$, the analog-smoothing filter would have to remove the images in the signal instead of a precise digital interpolation filter removing these images. This specification can be very demanding, as in a digital-audio application, where a near $96-\mathrm{dB}$ attenuation is required at 24 kHz , while up to 20 kHz should pass with unity gain. With the use of an oversampling approach, the digital interpolation filter is faced with this strict specification rather than an analog smoothing filter. In fact, oversampling is often used in audio applications with multi-bit D/A converters just to reduce this analog-smoothing filter's complexity.

Another point to note is that the order of the analog lowpass filter should be at least one order higher than that of the $\Delta \Sigma$ modulator. The reason for this choice is that if the analog filter's order is equal to that of the modulator, the slope of the rising quantization noise will match the filter's falling attenuation, and thus the resulting quantization noise will be approximately a constant spectral density up to one-half the sampling rate (i.e., $f_{s} / 2$ ). By having a higher-order analog filter, the

Key Point: Oversampling D/A converters require a very linear but low-resolution internal D/A converter, and an analog smoothing filter whose order should be at least one greater than that of the noise shaping andmust have sufficient dynamicrange to accommodate both signal and large quantization noise power at its input.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-13.jpg?height=346&width=1300&top_left_y=1704&top_left_x=245)

Fig. 18.16 Block diagram of a 1-bit oversampling D/A converter.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-14.jpg?height=1218&width=1373&top_left_y=176&top_left_x=204)

Fig. 18.17 Signals and spectra in an oversampling D/A converter.
spectral density of the output signal's quantization noise will have a bandwidth similar to the analog filter's bandwidth, which is around $f_{0}$.

Finally, note that the analog filter must be able to strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$, and this analog filter should be linear so it does not modulate the noise back to the frequency band of interest. In many applications, the realization of these filters, especially if they are integrated, is nontrivial.

## 18.4 DIGITAL DECIMATION FILTERS

There are many techniques for realizing digital decimation filters in oversampling $\mathrm{A} / \mathrm{D}$ converters. In this section, we discuss two popular approaches - multi-stage and single-stage.

### 18.4.1 Multi-Stage

One method for realizing decimation filters is to use a multi-stage approach, as shown in Fig. 18.18. Here, the first-stage FIR filter, $\mathrm{T}_{\text {sinc }}(\mathrm{z})$, removes much of the quantization noise such that its output can be downsampled to four times the Nyquist rate (i.e., $8 \mathrm{f}_{0}$ ). This lower-rate output is applied to the second-stage filter, which may be either an IIR filter, as shown in Fig. 18.18(a), or a cascade of FIR filters, as shown in Fig. 18.18(b).

The sinc ${ }^{L+1}$ FIR filter is a cascade of $L+1$ averaging filters where the transfer function of a single averaging filter, $T_{\text {avg }}(z)$, is given by

$$
\begin{equation*}
T_{\mathrm{avg}}(z)=\frac{Y(z)}{U(z)}=\frac{1}{M} \sum_{i=0}^{M-1} z^{-i} \tag{18.35}
\end{equation*}
$$

and $M$ is the integer ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$ ). Note that the impulse response of this filter is finite, implying it is an FIR-type filter. In addition, all of its impulse response coefficients are symmetric (in fact, they are all equal), and thus it is also a linear-phase filter. ${ }^{6}$ Finally, note that the $1 / \mathrm{M}$ multiplication term is easily realized by changing the location of the fractional bits when M is chosen to be a power of two.

As an illustration of a series of averaging filters reducing quantization noise, consider an average-of-four filter (i.e., $M=4$ ) operating on the output of the 1-bit signal in Example 18.4. Since the output 1-bit sequence is $\{1,1,-1,1,1,-1,1,1,-1, \ldots\}$, the first averaged output, $\mathrm{x}_{\mathrm{lp} 1}(\mathrm{n})$, would be given by

$$
\mathrm{x}_{\mathrm{lp} \mathrm{l}}(\mathrm{n})=\{0.5,0.5,0.0,0.5,0.5,0.0, \ldots\}
$$

To obtain more attenuation of the quantization noise, the signal $\mathrm{x}_{\mathrm{pl} 1}(\mathrm{n})$ can also be applied to a running-average-of-four filter, giving $\mathrm{x}_{\mathrm{lp} 2}(\mathrm{n})$ as

$$
x_{\mathrm{lp} 2}(n)=\{0.375,0.375,0.25,0.375,0.375,0.25, \ldots\}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-15.jpg?height=199&width=1200&top_left_y=1266&top_left_x=336)
(a)
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-15.jpg?height=312&width=1262&top_left_y=1568&top_left_x=305)
(b)

Fig. 18.18 Multi-stage decimation filters: (a) sinc followed by an IIR filter; (b) sinc followed by halfband filters.
6. A linear-phase filter results in all frequency components being delayed by the same amount and is therefore desirable in applications where phase distortion is unwanted (such as hi-fi audio).
and repeating this process to get $x_{1 p 3}(n)$ would give

$$
x_{1 \mathrm{p} 3}(\mathrm{n})=\{0.344,0.344,0.313,0.344,0.344,0.313, \ldots\}
$$

Note the convergence of these sequences to a series of all samples equalling $1 / 3$ as expected.
To show that the frequency response of an averaging filter, $\mathrm{T}_{\text {avg }}(z)$, has a sinc-type behavior, it is useful to rewrite (18.35) as

$$
\begin{equation*}
M Y(z)=\left(\sum_{i=0}^{M-1} z^{-i}\right) U(z)=\left(1+z^{-1}+z^{-2}+\cdots+z^{-(M-1)}\right) U(z) \tag{18.36}
\end{equation*}
$$

which can also be rewritten as

$$
\begin{align*}
M Y(z) & =\left(z^{-1}+z^{-2}+\cdots+z^{-M}\right) U(z)+\left(1-z^{-M}\right) U(z)  \tag{18.37}\\
& =M z^{-1} Y(z)+\left(1-z^{-M}\right) U(z)
\end{align*}
$$

Finally, we group together $Y(z)$ terms and find the transfer function of this averaging filter can also be written in the recursive form as

$$
\begin{equation*}
\mathrm{T}_{\mathrm{avg}}(\mathrm{z})=\frac{\mathrm{Y}(\mathrm{z})}{\mathrm{U}(\mathrm{z})}=\frac{1}{\mathrm{M}}\left(\frac{1-\mathrm{z}^{-\mathrm{M}}}{1-\mathrm{z}^{-1}}\right) \tag{18.38}
\end{equation*}
$$

The frequency response for this filter is found by substituting $z=e^{j \omega}$, which results in

$$
\begin{equation*}
\mathrm{T}_{\mathrm{avg}}\left(\mathrm{e}^{\mathrm{j} \omega}\right)=\frac{\operatorname{sinc}\left(\frac{\omega \mathrm{M}}{2}\right)}{\operatorname{sinc}\left(\frac{\omega}{2}\right)} \tag{18.39}
\end{equation*}
$$

where $\operatorname{sinc}(\mathrm{x}) \equiv \sin (\mathrm{x}) / \mathrm{x}$.
A cascade of $L+1$ averaging filters has the response $T_{\text {sinc }}(z)$ given by

$$
\begin{equation*}
\mathrm{T}_{\text {sinc }}(\mathrm{z})=\frac{1}{\mathrm{M}^{\mathrm{L}+1}}\left(\frac{1-\mathrm{z}^{-\mathrm{M}}}{1-\mathrm{Z}^{-1}}\right)^{\mathrm{L}+1} \tag{18.40}
\end{equation*}
$$

The reason for choosing to use $L+1$ of these averaging filters in cascade is similar to the argument that the order of the analog low-pass filter in an oversampling $\mathrm{D} / \mathrm{A}$ converter should be higher than the order of the $\Delta \Sigma$ modulator. Specifically, the slope of the attenuation for this low-pass filter should be greater than the rising quantization noise, so that the resulting noise falls off at a relatively low frequency. Otherwise, the noise would be integrated over a very large bandwidth, usually causing excessive total noise.

An efficient way to realize this cascade-of-averaging filters is to write (18.40) as

$$
\begin{equation*}
\mathrm{T}_{\text {sinc }}(\mathrm{z})=\left(\frac{1}{1-\mathrm{z}^{-1}}\right)^{\mathrm{L}+1}\left(1-\mathrm{z}^{\mathrm{M}}\right)^{\mathrm{L}+1} \frac{1}{\mathrm{M}^{\mathrm{L}+1}} \tag{18.41}
\end{equation*}
$$

and thus realize it as shown in Fig. 18.19 [Candy, 1992]. A point to note here is that at first glance it appears as though this circuit will not operate properly due to a dc input causing saturation of the discrete-time integrators.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-17.jpg?height=616&width=1339&top_left_y=176&top_left_x=223)

Fig. 18.19 Realizing $\mathrm{T}_{\text {sinc }}(z)$ as a cascade of integrators and differentiators: (a) downsampling performed after all the filtering; (b) a more efficient method where downsampling is done before the differentiators.

Fortunately, such a result does not occur when 2's-complement arithmetic is used due to its wrap-around characteristic. Specifically, although the dc levels at the integrator outputs may be incorrect, the differentiators compare the present sample with that of M samples past while rejecting the dc component. Thus, as long as this difference is properly maintained (as it would be using 2 's-complement arithmetic) the correct calculation is performed.

Referring once again to Fig. 18.18, the purpose of the filters following the $\mathrm{T}_{\text {sinc }}(z)$ filter is twofold. One reason for their use is to remove any higher-frequency input signals (in effect, a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \mathrm{f}_{0}$ ). In other words, while the $T_{\text {sinc }}(z)$ filter is good at filtering out the quantization noise, it is not sharp enough to act as a reasonable anti-aliasing filter for input signals slightly higher than $f_{0}$. A second reason is to compensate for the frequency drop in the passband caused by the $T_{\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter might be realized using a single IIR filter, as shown in Fig. 18.18(a). Alternatively, a few halfband FIR filters might be used together with a separate sinc-compensation FIR filter, as shown in Fig. 18.18(b). A halfband FIR filter has a passband from 0 to $\pi / 2$, while its stopband is from $\pi / 2$ to $\pi$ with every second coefficient being zero [Vaidyanathan, 1993]. Thus, with a high enough filter order, its output can be downsampled by a factor of two. It has also been shown that in some applications, these halfband and sinc-compensation filters can be realized using no general multi-bit multipliers [Saramaki, 1990].

### 18.4.2 Single Stage

Another approach for realizing decimation filters is to use a relatively highorder FIR filter. For example, in [Dattorro, 1989], a 2048 tap FIR filter was used to decimate 1 -bit stereo outputs from two $\Delta \Sigma$ modulators, each having an oversampling ratio of 64 . While this FIR order seems high, note that no multi-bit multiplications are needed, since the input signal is simply 1-bit, so all multiplications are trivial. In addition, the output need only be calculated at the Nyquist rate (intermediate samples would be discarded anyway) such

Key Point: In single-stage decimation, one filter operates on alow-resolution noise-shaped signal providing the decimated output. Because of the high filter order, several time-interleaved filters may be used in parallel.
that 2048 additions are required during one clock cycle at the Nyquist rate. However, if only one accumulator is used to perform all 2048 additions, the clock rate of that accumulator would
be 2048 times the Nyquist rate. For example, if the Nyquist rate is 48 kHz , the single accumulator would have to be clocked at 98.3 MHz . To overcome this high clock rate, 32 separate FIR filters are realized (with shared coefficients) in a time-interleaved fashion, with each FIR having 2048 coefficients and each producing an output at a clock rate of 1.5 kHz . In this way, each of the 32 FIR filters uses a single accumulator operating at 3 MHz (i.e., 2048 times 1.5 kHz ). The coefficient ROM values were shared between the FIR filters (as well as in the two stereo channels), and the ROM size can also be halved if coefficients are duplicated, as in the case of linear-phase FIR filtering.

Finally, it is also possible to reduce the number of additions by grouping together input bits. For example, if four input bits are grouped together, then a 16 -word ROM lookup table can be used rather than using three additions. With such a grouping of input bits, each of the 32 FIR filters would require only 512 additions.

## 18.5 HIGHER-ORDER MODULATORS

Key Point: Noise shaping with order $L>2$ offers the potential for further improvements in SQNR of $6 L+3 \mathrm{~dB}$ /octave or $L+0.5$ bits/octave with respect to oversampling ratio.

In general, it can be shown that an Lth-order noise-shaping modulator improves the SQNR by $6 \mathrm{~L}+3 \mathrm{~dB} /$ octave, or equivalently, $L+0.5$ bits/octave. In this section, we look at two approaches for realizing higher-order modulators-interpolative and MASH. The first approach is typically a single high-order structure with feedback from the quantized signal. The second approach consists of a cascade of lowerorder modulators, where the latter modulators are used to cancel the noise errors introduced by the earlier modulators.

### 18.5.1 Interpolative Architecture

Key Point: Interpolative higherorder modulators permit the arbitrary placement of noise transfer function zeros, offering improved SQNR performance compared to the placement of all zeros at dc, especially for relatively low OSR. However, it is nontrivial to guarantee stability for such structures, and they are therefore often combined with multi-bit internal quantizers.

As discussed earlier, when compared to the error-feedback structure, the interpolative structure of Fig. 18.6(a) is much better suited to analog implementations of modulators due to its reduced sensitivity. One of the first approaches for realizing higher-order interpolative modulators was presented in [Chao, 1990]. It used a filtering structure very similar to a direct-form filter structure; however, a direct-form-type structure made it sensitive to component variations, which can cause the zeros of the noise transfer function to move off the unit circle. To improve component sensitivity, resonators can be used together with a modified interpolative structure, as shown in Fig. 18.20 [Ferguson, 1991]. Note here that a single 1-bit D/A signal is still used for feedback, and therefore its linearity will
u(n)
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-18.jpg?height=307&width=1293&top_left_y=1767&top_left_x=242)

Fig. 18.20 A block diagram of a fifth-order modulator.
be excellent. The resonators in this structure are due to the feedback signals associated with $f_{1}$ and $f_{2}$, resulting in the placement of zeros in the noise transfer function spread over the frequency-of-interest band. Such an arrangement gives better dynamic range performance than placing all the zeros at dc as we have been assuming thus far.

Unfortunately, it is possible for modulators of order two or more to go unstable, especially when large input signals are present. When they go unstable, they may never return to stability even when the large input signals go away. Guaranteeing stability for an interpolative modulator is nontrivial and is discussed further in Section 18.7. In particular, the use of multi-bit internal quantizers improves stability and is therefore often used in combination with higher-order interpolative architectures.

### 18.5.2 Multi-Stage Noise Shaping (MASH) Architecture

Another approach for realizing modulators is to use a cascade-type structure where the overall higher-order modulator is constructed using lower-order ones. The advantage of this approach is that since the lower-order modulators are more stable, the overall system should remain stable. Such an arrangement has been called MASH (Multi-stAge noise SHaping) [Matsuya, 1987].

The arrangement for realizing a second-order modulator using two first-order modulators is shown in Fig. 18.21. The basic approach is to pass along the first section's quantization error, $\mathrm{e}_{1}(\mathrm{n})$, to another modulator and combine the outputs of both modulators in such a way that the first section's quantization noise is removed completely. The output is then left with only the second section's quantization noise, which has been filtered twice - once by the second modulator and once by the post digital circuitry. Assuming linear models for the quantizers, straightforward linear analysis for the first stage gives

$$
\begin{align*}
\mathrm{X}_{1}(\mathrm{z}) & =\mathrm{S}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{U}(\mathrm{z})+\mathrm{N}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{E}_{1}(\mathrm{z}) \\
& =\mathrm{z}^{-1} \mathrm{U}(\mathrm{z})+\left(1-\mathrm{z}^{-1}\right) \mathrm{E}_{1}(\mathrm{z}) \tag{18.42}
\end{align*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-19.jpg?height=773&width=1202&top_left_y=1262&top_left_x=305)

Fig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.
and for the second stage

$$
\begin{align*}
\mathrm{X}_{2}(\mathrm{z}) & =\mathrm{S}_{\mathrm{TF} 2}(\mathrm{z}) \mathrm{E}_{1}(\mathrm{z})+\mathrm{N}_{\mathrm{TF} 2}(\mathrm{z}) \mathrm{E}_{2}(\mathrm{z}) \\
& =\mathrm{z}^{-1} \mathrm{E}_{1}(\mathrm{z})+\left(1-\mathrm{z}^{-1}\right) \mathrm{E}_{2}(\mathrm{z}) \tag{18.43}
\end{align*}
$$

The MASH output is then formed by passing the two digital outputs $x_{1}$ and $x_{2}$ through digital filters intended to match $S_{T F 2}$ and $N_{T F 1}$ respectively.

$$
\begin{align*}
\mathrm{Y}(\mathrm{Z})= & \hat{\mathrm{S}}_{\mathrm{TF} 2}(\mathrm{Z}) \mathrm{X}_{1}(\mathrm{z})+\hat{\mathrm{N}}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{X}_{2}(\mathrm{z}) \\
= & \hat{\mathrm{S}}_{\mathrm{TF} 2}(\mathrm{Z}) \mathrm{S}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{U}(\mathrm{z})+\left[\hat{\mathrm{S}}_{\mathrm{TF} 2}(\mathrm{z}) \mathrm{N}_{\mathrm{TF} 1}(\mathrm{z})+\hat{\mathrm{N}}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{S}_{\mathrm{TF} 2}(\mathrm{Z})\right] \mathrm{E}_{1}(\mathrm{z})  \tag{18.44}\\
& +\hat{\mathrm{N}}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{N}_{\mathrm{TF} 2}(\mathrm{z}) \mathrm{E}_{2}(\mathrm{z})
\end{align*}
$$

If $\hat{N}_{\mathrm{TF}_{1} 1}(\mathrm{Z})=\mathrm{N}_{\mathrm{TF}_{1}}(\mathrm{Z})$ and $\hat{\mathrm{S}}_{\mathrm{TF} 2}(\mathrm{Z})=\mathrm{S}_{\mathrm{TF}_{2}}(\mathrm{Z})$ then the entire second term disappears resulting in

$$
\begin{equation*}
\mathrm{Y}(\mathrm{z})=\hat{\mathrm{S}}_{\mathrm{TF} 2}(\mathrm{Z}) \mathrm{S}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{U}(\mathrm{z})+\hat{\mathrm{N}}_{\mathrm{TF} 1}(\mathrm{z}) \mathrm{N}_{\mathrm{TF} 2}(\mathrm{z}) \mathrm{E}_{2}(\mathrm{z}) \tag{18.45}
\end{equation*}
$$

so that the only quantization noise remaining is $\mathrm{E}_{2}$ shaped by both $\mathrm{N}_{T F_{1}}$ and $\mathrm{N}_{\mathrm{TF} 2}$. In the case of Fig. 18.21, this implies second-order noise shaping using two first-order modulators.

$$
\begin{equation*}
Y(z)=z^{-2} U(z)-\left(1-z^{-1}\right)^{2} E_{2}(z) \tag{18.46}
\end{equation*}
$$

Key Point: Multi-stage noise shaping (MASH) oversampling converters cascade lower order modulators to realize high-order noise shaping. Since the constituent stages are each first- or second-order, it is easy to ensure stability. However, MASH converters require digital filtering whose coefficients are matched to those of analog circuitry.

The approach can be generalized and extended to accommodate cascading more than two modulators. Thus, a MASH approach has the advantage that higher-order noise filtering can be achieved using lower-order modulators. The lower-order modulators are much less susceptible to instability as compared to an interpolator structure having a high order with a single feedback. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth and mismatches causing gain errors. Such errors cause the analog integrators to have finite gain and pole frequencies (see Section 18.7.5), making it difficult to ensure $N_{T F_{1}}(\mathrm{Z})=N_{T F_{1}}(\mathrm{z})$ and $\hat{S}_{T F_{2}}(\mathrm{Z})=\mathrm{S}_{\mathrm{TF} 2}(\mathrm{Z})$ precisely as required for cancellation of the quantization noise $\mathrm{E}_{1}(\mathrm{z})$ in (18.44). In the above example, this would cause firstorder noise to leak through from the first modulator and hence reduce dynamic range performance.

In order to mitigate the mismatch problem, the first stage may be chosen to be a higher-order modulator such that any leak-through of its noise has less effect than if this first modulator was first-order. For example, a third-order modulator would be realized using a second-order modulator for the first stage and a first-order modulator for the second stage.

Another approach to combat errors in MASH architectures is to cancel these errors digitally by appropriately modifying the digital filters $\hat{\mathrm{N}}_{\mathrm{TF} 1}$ and $\hat{\mathrm{S}}_{\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals may be injected and later cancelled digitally while using them to precisely identify $\mathrm{N}_{\mathrm{TF} 1}$ and $\mathrm{S}_{\mathrm{TF} 2}$ and match them with $\hat{\mathrm{N}}_{\mathrm{TF} 1}$ and $\hat{S}_{\mathrm{TF} 2}$ [Kiss, 2000]. Also, it is very important to minimize errors due to input-offset voltages that might occur because of clock feedthrough or opamp input-offset voltages. Typically, in practical realizations additional circuit design techniques will be employed to minimize these effects.

Finally, note that the use of this MASH approach results in the digital output signal, $y(n)$, being a four-level signal (rather than two-level) due to the combination of the original two-level signals. Such a four-level signal would require a linear four-level D/A converter in a D/A application. For A/D applications, it makes the FIR decimation filter slightly more complex.

## 18.6 BANDPASS OVERSAMPLING CONVERTERS

As we have seen, oversampling converters have the advantage of high linearity through the use of 1-bit conversion and reduced anti-aliasing and smoothing-filter requirements. However, at first glance some signals do not appear to easily lend themselves to oversampling approaches such as modulated radio signals. Such signals have information in only a small amount of bandwidth, say 10 kHz , but have been modulated by some higher-frequency carrier signal, say 1 MHz . For such applications, one can make use of bandpass oversampling converters.

In low-pass oversampling converters, the transfer function $\mathrm{H}(\mathrm{z})$ in Fig. 18.6 is chosen such that it has a high gain near dc , and thus quantization noise is small around dc. In a similar way, bandpass oversampling converters are realized by choosing $\mathrm{H}(\mathrm{z})$ such that it has a high gain near some frequency value, $\mathrm{f}_{\mathrm{c}}$, [Schreier, 1989]. With such an approach, the quantization noise is small around $f_{c}$, and thus most of the quantization noise can be removed through the use of a narrow bandpass filter of total width $\mathrm{f}_{\Delta}$ following the modulator. Thus, in the case of a bandpass $A / D$ converter intended for digital radio, post narrowband digital filtering would remove quantization noise as well as adjacent radio channels. In addition, further digital circuitry would also perform the necessary demodulation of the signal.

An important point here is that the oversampling ratio for a bandpass converter is equal to the ratio of the sampling rate, $f_{s}$, to two times the width of the narrow-band filter, $2 f_{\Delta}$, and it does not depend on the value of $f_{c}$. For example, consider a bandpass oversampling converter with a sampling rate of $f_{s}=4 \mathrm{MHz}$, which is intended to convert a $10-\mathrm{kHz}$ signal bandwidth centered around 1 MHz ( or $\mathrm{f}_{\mathrm{c}}=\mathrm{f}_{\mathrm{s}} / 4$ ). In this case, $\mathrm{f}_{\Delta}=10 \mathrm{kHz}$, resulting in the oversampling ratio being equal to

$$
\begin{equation*}
\mathrm{OSR}=\frac{\mathrm{f}_{\mathrm{s}}}{2 \mathrm{f}_{\Delta}}=200 \tag{18.47}
\end{equation*}
$$

To obtain a high gain in $H(z)$ near $f_{c}$, a similar approach to the low-pass case is taken. In a first-order lowpass oversampling converter, $\mathrm{H}(\mathrm{z})$ is chosen such that it has a pole at dc (i.e., $\mathrm{z}=1$ ) and such that the noise transfer function, $N_{T F}(z)$, has a zero at dc. In a second-order bandpass oversampling converter with $f_{c}=f_{s} / 4, H(z)$ is chosen such that it has poles at $\mathrm{e}^{ \pm \mathrm{ji/2}}= \pm \mathrm{j}$. In other words, $\mathrm{H}(\mathrm{z})$ is a resonator that has an infinite gain at the frequency $f_{s} / 4$. The zeros of the noise transfer function for this type of second-order oversampling converter are shown in Fig. 18.22, together with a similar low-pass case.

A block diagram for the example bandpass modulator is shown in Fig. 18.23, where one can derive $H(z)$ to be given by

$$
\begin{equation*}
H(z)=\frac{z}{z^{2}+1} \tag{18.48}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-21.jpg?height=396&width=549&top_left_y=1555&top_left_x=276)
(a) $\mathrm{OSR}=\frac{\mathrm{f}_{\mathrm{s}}}{2 \mathrm{f}_{0}}=200$
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-21.jpg?height=400&width=520&top_left_y=1549&top_left_x=982)
(b) $\operatorname{OSR}=\frac{\mathrm{f}_{\mathrm{s}}}{2 \mathrm{f}_{\Delta}}=200$

Fig. 18.22 Noise-transfer-function zeros for oversampling converters: (a) first-order low-pass; (b) second-order bandpass.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-22.jpg?height=293&width=913&top_left_y=178&top_left_x=434)

Fig. 18.23 A second-order bandpass oversampling modulator that shapes the quantization noise away from $\mathrm{f}_{\mathrm{s}} / 4$.

Note that this second-order example has poles at $\pm \mathrm{j}$, and therefore the noise transfer function, $\mathrm{N}_{\mathrm{TF}}(\mathrm{z})$, has only one zero at $j$ and another zero at $-j$. For this reason, the dynamic range increase of a second-order bandpass converter equals that of a first-order low-pass converter that also has only one zero at dc. Specifically, the dynamic range increase of a second-order bandpass converter is 1.5 bits/octave or, equivalently, $9 \mathrm{~dB} /$ cctave. To obtain the equivalent dynamic range increase of a second-order low-pass converter (i.e., $15 \mathrm{~dB} /$ octave), a fourth-order bandpass converter would have to be used. The first design of an integrated bandpass oversampling A/D converter was presented in [Jantzi, 1993].

## 18.7 PRACTICAL CONSIDERATIONS

### 18.7.1 Stability

As with any feedback-type system, delta-sigma modulators have the potential to go unstable. A stable modulator is defined here as one in which the input (or inputs) to the quantizer (or quantizers) remains bounded such that the quantization does not become overloaded. An overloaded quantizer is one in which the input signal goes beyond the quantizer's normal range, resulting in the quantization error becoming greater than $\pm \Delta / 2$.

Unfortunately, the stability of higher-order 1-bit modulators is not well understood as they include a highly nonlinear element (a 1-bit quantizer), resulting in the system being stable for one input but unstable for another. As a general rule of thumb, keeping the peak frequency response gain of the noise-transfer function, $\mathrm{N}_{\mathrm{TF}}(\mathrm{z})$, less than 1.5 often results in a stable modulator [Chao, 1990]. ${ }^{7}$ In mathematical terms,

$$
\begin{equation*}
\left|\mathrm{N}_{\mathrm{TF}}\left(\mathrm{e}^{\mathrm{j} \omega}\right)\right| \leq 1.5 \quad \text { for } 0 \leq \omega \leq \pi \tag{18.49}
\end{equation*}
$$

Key Point: The stability of 1-bit modulators is not well understood, but as a rule of thumb keeping the peak magnitude response of the noise transfer function below 1.5 often results in a stable modulator.
should be satisfied for a 1-bit quantizer. It should be noted that this stability criterion has little rigorous justification and that there does not presently exist any necessary and sufficient stability criterion for $\Delta \Sigma$ modulators having arbitrary inputs. There is, however, a rigorous 1-norm stability test (which is sufficient but not necessary), but it is often too conservative, as it eliminates many "stable" modulators [Anastassiou, 1989]. Hence, extensive simulations are used to confirm the stability of integrated circuit modulators. For a summary of stability tests for $\Delta \Sigma$ modulators, the reader is referred to [Schreier, 1993].

It should be mentioned here that the stability of a modulator is also related to the maximum input signal level with respect to the 1-bit feedback as well as the poles of the noise transfer function. Specifically, a modulator can be made more stable by placing the poles of the system closer to the noise-transfer-function

[^0]zeros. Also, a more stable modulator allows a larger maximum input signal level. However, this stability comes at a dynamic-range penalty since less of the noise power will then occur at out-of-band frequencies, but instead the noise will be greater over the in-band frequencies.

Since the stability issues of higher-order modulators are not well understood (particularly for arbitrary inputs), additional circuitry for detecting instability is often included, such as looking for long strings of 1 s or 0 s occurring. Alternatively, the signal amplitude at the input of the comparator might be monitored. If predetermined amplitude thresholds are exceeded for a specified number of consecutive clock cycles, then it is assumed that the converter has gone (or is going) unstable. In this case, the circuit is changed to make it more stable. One possibility is to turn on switches across the integrating capacitors of all integrators for a short time. This resets all integrator outputs to zero. A second alternative is to change the modulator into a second- or even first-order modulator temporarily by using only the first one or two integrators and resetting other integrators. Another possibility is to eliminate the comparator temporarily and feed back the input signal to the comparator. This changes the modulator into a stable filter.

Modulators having multi-bit internal quantization exhibit improved stability over their 1-bit counterparts, and are therefore often used in higher order modulators and at low OSR. When used for A/D conversion, they require highlinearity DACs. Fortunately, a number of architectures have been proposed to lessen the linearity requirements on the DACs, as described in Section 18.8.

### 18.7.2 Linearity of Two-Level Converters

Key Point: Multi-bit internal quantization improves stability and therefore is often used in high order modulators with low OSR. In A/D converters, it is combined with linearity enhancement techniques for the feedback DAC.

It was stated earlier that 1-bit D/A converters are inherently linear since they need only produce two output values and two points define a straight line. However, as usual, practical issues limit the linearity of D/A converters-even those having only two output levels. It should be pointed out here that most of the linearity issues discussed below are also applicable to multi-level converters, but we restrict our attention to two-level converters for clarity.

One limitation is when the two output levels somehow become functions of the low-frequency signal they are being used to create. For example, if the two voltage levels are related to power supply voltages, then these powersupply voltages might slightly rise and fall as the circuit draws more or less power. Since typically the amount of power drawn is related to the low-frequency signal being created, distortion will occur. A mechanism whereby this occurs is if a different amount of charge is being taken from the voltage references when a 1 is being output from the 1-bit $\mathrm{D} / \mathrm{A}$ converter, as opposed to when a 0 is being output from the $\mathrm{D} / \mathrm{A}$ converter. A somewhat more subtle but similar mechanism can occur due to the clock feedthrough of the input switches. This feedthrough is dependent on the gate voltages driving the input switches and therefore on the power-supply voltages connected to the drivers of the input switches. It is possible that these voltages can change when more 1 s than 0 s are being output by the D/A converter, having well-regulated power-supply voltages on the drivers for the input switches is very important. A similar argument can be made about any clock jitter in the converter. Thus, for high linearity it is important that the two output levels and associated clock jitter not be a function of the low-frequency input signal.

A more severe linearity limitation occurs if there is memory between output levels. For example, consider the ideal and typical output signals for a two-level D/A converter, shown in Fig. 18.24. The area for each symbol is defined to be the integral of the waveform over that symbol's time period. Notice that for the typical output signal, the area is dependent on the past symbol and that difference is depicted using $\delta_{i}$. As an illustrative example, consider the average voltage for three periodic patterns corresponding to average voltages of $0,1 / 3$, and $-1 / 3$ when $V_{1}$ and $V_{2}$ are $\pm 1$ volt.

In the ideal case, both $\delta_{1}$ and $\delta_{2}$ are zero as the waveform is memoryless. Thus, the three periodic patterns 0 , $1 / 3$, and $-1 / 3$ result in the following averages:
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-24.jpg?height=389&width=1358&top_left_y=180&top_left_x=200)

Fig. 18.24 A nonreturn-to-zero (NRZ) 1-bit D/A converter typical output.

$$
\begin{aligned}
0: & \{1,-1,1,-1,1,-1,1,-1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{a}}(\mathrm{t})}=\frac{\mathrm{A}_{1}+\mathrm{A}_{0}}{2} \\
1 / 3: & \{1,1,-1,1,1,-1,1,1,-1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{b}}(\mathrm{t})}=\frac{2 \mathrm{~A}_{1}+\mathrm{A}_{0}}{3} \\
-1 / 3: & \{-1,-1,1,-1,-1,1,-1,-1,1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{c}}(\mathrm{t})}=\frac{\mathrm{A}_{1}+2 \mathrm{~A}_{0}}{3}
\end{aligned}
$$

By calculating the differences, $\overline{\mathrm{v}_{\mathrm{b}}(\mathrm{t})}-\overline{\mathrm{v}_{\mathrm{a}}(\mathrm{t})}$ and $\overline{\mathrm{V}_{\mathrm{a}}(\mathrm{t})}-\overline{\mathrm{v}_{\mathrm{c}}(\mathrm{t})}$, and noting that they are identical, we conclude that $\overline{\mathrm{v}_{\mathrm{a}}(\mathrm{t})}, \overline{\mathrm{v}_{\mathrm{b}}(\mathrm{t})}$, and $\overline{\mathrm{v}_{\mathrm{c}}(\mathrm{t})}$ lie along a straight line and therefore this memoryless $\mathrm{D} / \mathrm{A}$ converter is perfectly linear.

In the typical waveform case, the three periodic patterns result in the following averages:

$$
\begin{aligned}
& 0: \quad\{1,-1,1,-1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{d}}(\mathrm{t})}=\frac{\mathrm{A}_{1}+\mathrm{A}_{0}+\delta_{1}+\delta_{2}}{2}=\overline{\mathrm{v}_{\mathrm{a}}(\mathrm{t})}+\frac{\delta_{1}+\delta_{2}}{2} \\
& 1 / 3: \quad\{1,1,-1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{e}}(\mathrm{t})}=\frac{2 \mathrm{~A}_{1}+\mathrm{A}_{0}+\delta_{1}+\delta_{2}}{3}=\overline{\mathrm{v}_{\mathrm{b}}(\mathrm{t})}+\frac{\delta_{1}+\delta_{2}}{3} \\
& -1 / 3: \quad\{-1,-1,1, \ldots\} \rightarrow \overline{\mathrm{v}_{\mathrm{f}}(\mathrm{t})}=\frac{\mathrm{A}_{1}+2 \mathrm{~A}_{0}+\delta_{1}+\delta_{2}}{3}=\overline{\mathrm{v}_{\mathrm{c}}(\mathrm{t})}+\frac{\delta_{1}+\delta_{2}}{3}
\end{aligned}
$$

Now, these three averages do not lie on a straight line except when $\delta_{1}=-\delta_{2}$. Thus, one way to obtain high linearity is to match falling and rising signals - a very difficult task since they are typically realized with different types of devices.

A better way to obtain linearity without matching rising and falling signals of the $\mathrm{D} / \mathrm{A}$ converter is to use some sort of memoryless coding sc heme. For example, consider the return-to-zero coding scheme shown in Fig. 18.25. It is not difficult to see here that since the area of one output bit does not depend on any previous bits, the coding scheme is memoryless and the output signal will remain linear. Naturally, other memoryless schemes can also be used, such as using two levels of opposite signs but ensuring that the signal settles to ground between samples.

It is of interest to see how this memoryless coding is applied in oversampling A/D converters. Presently, most oversampling $\mathrm{A} / \mathrm{D}$ converters are realized using a switched-capacitor technology for linearity reasons. Switched capacitor circuits naturally realize memoryless levels as long as enough time is left for settling on each clock phase. In other words, switched-capacitor circuits implement memoryless coding since capacitors are charged on one clock phase and discharged on the next. For the same reason, the first stage of filtering in oversampling D/A
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-25.jpg?height=391&width=1344&top_left_y=179&top_left_x=214)

Fig. 18.25 A return-to-zero (RZ) coding scheme, which is one example of a memoryless coding scheme.
converters is often realized using switched-capacitor filters, which is followed by continuous-time filtering. However, some type of memoryless coding should be used when high linearity is desired from a 1-bit D/A output either fed directly to a continuous-time filter in an oversampling $\mathrm{D} / \mathrm{A}$ or used in the internal operation of a contin-uous-time oversampling A/D converter.

### 18.7.3 Idle Tones

Consider the case of applying a dc level of $1 / 3$ to a first-order $\Delta \Sigma$ modulator having a 1 -bit quantizer with output levels of $\pm 1$ (as in Example 18.4). With such an input, the output of the modulator will be a periodic sequence of two 1 s and one -1 . In other words,

$$
\begin{equation*}
\mathrm{y}(\mathrm{n})=\{1,1,-1,1,1,-1,1,1, \ldots\} \tag{18.50}
\end{equation*}
$$

This output periodic pattern is three cycles long and its power is concentrated at dc and $f_{s} / 3$. Although the output pattern is periodic, the post low-pass filter will eliminate the high-frequency content such that only the dc level of $1 / 3$ remains.

Now consider applying a dc level of $(1 / 3+1 / 24)=3 / 8$ to the same modulator. For this case, the output sequence becomes

$$
\begin{equation*}
y(n)=\{1,1,-1,1,1,-1,1,1,-1,1,1,-1,1,1,1,-1,1,1,-1, \ldots\} \tag{18.51}
\end{equation*}
$$

The period of this output pattern is now 16 cycles long and has some power at $f_{s} / 16$. With an oversampling ratio of eight (i.e., $f_{0}=f_{s} / 16$ ), the post low-pass filter will not attenuate the signal power at $f_{s} / 16$ since that frequency is just within the frequency band of interest. In other words, a dc level of $3 / 8$ into this modulator will produce the correct dc output signal but have a superimposed $f_{s} / 16$ signal on it even when using a brick-wall type low-pass filter.

While the preceding example shows a tone occurring at $f_{s} / 16$, it is not difficult to find other cases that would produce frequency tones at much lower frequencies, say $\mathrm{f}_{\mathrm{s}} / 256$. Such low-frequency tones will not be filtered out by the next stage low-pass filter and can lead to annoying tones in the audible range. ${ }^{8}$ In addition, although a firstorder modulator was used in the above example, it has been shown that annoying audible tones exist even in higher-order modulators [Norsworthy, 1993]. Finally, it should be mentioned that these tones might not lie at a single frequency but instead be short-term periodic patterns. In other words, a tone appearing near 1 kHz might actually be a signal varying between 900 Hz and 1.1 kHz in a random-like fashion.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-26.jpg?height=311&width=937&top_left_y=180&top_left_x=388)

Fig. 18.26 Adding dithering to a delta-sigma modulator. Note that the dithered signal is also noise shaped.

### 18.7.4 Dithering

One way to reduce the amount of idle tones in modulators is through the use of dithering. The term dithering here refers to the act of introducing some random (or pseudo-random) signal into a modulator.

Key Point: The nonlinear dynamics of 1-bit oversampling modulators can result in idle tones within the signal band when applying dc or slowlyvarying inputs. An additive pseudo-random dither signal can break up the tones but raises the noise floor.

Assuming the random signal to be introduced has a white-noise type spectrum, then the most suitable place to add the dithering signal is just before the quantizer, as shown in Fig. 18.26. The reason for adding it at this location is so that the dithering signal becomes noise shaped in the same manner as the quantization noise, and thus a large amount of dithering can be added. Typically, the dithering signal is realized using some sort of pseudo-random number generator with only a few bits of resolution, but its total noise power is comparable to the quantization noise power. Thus, the use of dithering in a $\mathrm{D} / \mathrm{A}$ converter would require a small additional digital adder, while a small $\mathrm{D} / \mathrm{A}$ converter would be needed in an oversampling A/D converter.

It should be noted that the use of dither to reduce idle tones is not an attempt to add noise to mask out the tones but instead breaks up the tones so that they never occur. However, since the noise power of the dithering signal is similar to the quantization noise power, the use of dithering adds about 3 dB extra in-band noise and often requires rechecking the modulator's stability.

### 18.7.5 Opamp Gain

A switched-capacitor integrator with a finite opamp gain, $A$, results in the integrator having a transfer function (see Problem 14.6) of

$$
\begin{equation*}
\frac{V_{0}(z)}{V_{i}(z)}=-\left(\frac{C_{1}}{C_{2}}\right)\left(\frac{1}{z\left(1+\frac{C_{1}}{C_{2} A}\right)-1}\right) \tag{18.52}
\end{equation*}
$$

Assuming $\mathrm{C}_{2} \approx \mathrm{C}_{1}$ as is typical in oversampled converters, the pole has moved to the left of $\mathbf{z}=1$ by an amount $1 / A$. With this knowledge, we can determine the new NTF zeros due to finite opamp gain by substituting $\mathbf{z}-1$ with $\mathbf{Z}-(1-1 / A)$. In other words, we substitute all ideal integrators with damped integrators and recalculate the transfer functions. Such an approach results in the NTF zeros, which were located at $\mathbf{Z}=1$ for a low-pass design, to be moved to $\mathbf{Z}=(1-1 / A)$. Thus, the shaped quantization noise does not drop to zero at dc but instead levels off near dc. Such a zero near $Z=1$ results in the $3-\mathrm{dB}$ break frequency being approximately equal to $1 / \mathrm{A} \mathrm{rad} /$ sample. Now, we note that the frequency band of interest, $f_{0}$, should be greater than $1 / A \mathrm{rad} / \mathrm{sample}$ since the shaped quantization noise is flat below that level. In other words, if $f_{0}$ is below where the quantization noise flattens
out, then we are not obtaining any further noise-shaping benefits. Thus, any further doubling of the oversampling ratio will only improve the SNR by $3 \mathrm{~dB} /$ octave. Finally, we can write the following requirement:

$$
\begin{equation*}
\frac{f_{0}}{f_{s}}>\frac{1 / A}{2 \pi} \tag{18.53}
\end{equation*}
$$

and recalling that $O S R=f_{s} /\left(2 f_{0}\right)$, we can rearrange this to

$$
\begin{equation*}
\mathrm{A}>\frac{\mathrm{OSR}}{\pi} \tag{18.54}
\end{equation*}
$$

Of course, some approximations have been made here, such as having the two capacitors of the integrator equal (that is $\mathrm{C}_{2} \approx \mathrm{C}_{1}$ ) and having the $3-\mathrm{dB}$ break point being sharp, as well as allowing noise to be flat from dc to $f_{0}$ (rather than shaped). In summary, designers will typically ensure that the opamp gain is at least twice the oversampling ratio, which is not usually a difficult requirement.

In addition, the above analysis only applies to modulators having a single D/A feedback and does not apply to MASH or cascade modula-

Key Point: Opamps in analog oversampling modulators should have a dc gain at least twice the oversampling ratio, which is not usually a difficult requirement. An exception is MASH modulators where higher gains may be required to ensure digital and analog transfer functions are matched.
tors, where larger opamp gains are often required to aid matching between digital and analog signal paths.

## 18.8 MULTI-BIT OVERSAMPLING CONVERTERS

Although 1-bit oversampling converters have the advantage that they can realize highly linear data conversion, they also have some disadvantages. For example, 1-bit oversampling modulators are prone to instability due to the high degree of nonlinearity in the feedback. Another disadvantage is the existence of idle tones, as previously discussed. Additionally, in oversampling D/A converters, the use of a 1-bit D/A converter results in a large amount of out-of-band quantization noise, which must be significantly attenuated using analog circuitry. Such a task often requires relatively high-order analog filtering (recall that the low-pass filter should be at least one order higher than the modulator order). Also, the dynamic range of the analog filter may have to be significantly higher than the converter's dynamic range since the filter's input must cope with power of both the quantization noise and signal itself. Since the quantization noise may be up to 15 dB larger in level than the signal level, such an extension in the dynamic range makes the realization of analog filters for oversampling D/A converters nontrivial. The use of a multi-bit $\mathrm{D} / \mathrm{A}$ converter can significantly reduce this large amount of quantization noise, but care must be taken to ensure that the multi-bit converter remains linear. Typically, a multi-bit oversampling system would be similar to that shown in Fig. 18.16, except that an M-bit quantizer would be used in the digital modulator, and its output would drive an M-bit D/A converter. This section will briefly discuss some multi-bit oversampling converter architectures that employ methods so that the overall system remains highly linear.

### 18.8.1 Dynamic Element Matching

One approach for realizing a multi-bit D/A converter intended for oversampling systems is that of dynamic element matching [Carley, 1989]. With this approach, a thermometer-code D/A converter is realized, and randomization is used to effectively spread the nonlinearity over the whole frequency range. For example, a 3-bit D/A converter using dynamic element matching is shown in Fig. 18.27. Here, the 8 -line randomizer makes use of

Key Point: Dynamic element matching randomizes the use of analog elements in a D/A to eliminate the tones that would otherwise result from mismatches, making instead spec-trally-shaped noise. It enables the use of multi-bit D/As in highly linear oversampling converters.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-28.jpg?height=661&width=1085&top_left_y=181&top_left_x=398)

Fig. 18.27 Dynamic element matching 3-bit D/A converter.
a pseudo-random code to distribute the thermometer lines equally to each of the unit capacitances, C. Using the simplest randomization approaches, the mismatch "noise" from this multi-bit converter is not shaped by any feedback loop and therefore appears more white than high-pass filtered [Carley, 1989].

Dynamic element matching has been extended to include noise shaping the nonlinearity introduced by the D/A [Leung, 1992; Galton, 1997]. These approaches enable much lower oversampling ratios and can be used while maintaining high linearity with a reasonably coarse DAC mismatch. They are currently the most popular approach to mitigating D/A nonlinearity errors in oversampling converters. Some examples are [Chen, 1995; Adams, 1995; Baird, 1995].

### 18.8.2 Dynamically Matched Current Source D/A Converters

Another method of maintaining high linearity in an oversampling D/A system is through the use of a highly linear $\mathrm{D} / \mathrm{A}$ converter operating at the fast oversampling rate. Such high linearity has been achieved using dynamically matched current sources similar to those described in Section 16.3.3 [Schouwenaars, 1991].

### 18.8.3 Digital Calibration A/D Converter

One way to make use of a multi-bit $\mathrm{D} / \mathrm{A}$ converter in an oversampling $\mathrm{A} / \mathrm{D}$ modulator is to have a calibration cycle where digital circuitry is used to model the static nonlinearity of the D/A converter, as shown in Fig. 18.28 [Larson, 1988]. With this approach, the multi-bit digital signal $\mathrm{x}_{2}(\mathrm{n})$ creates $2^{N}$ output levels at $\mathrm{x}_{1}(\mathrm{n})$, which are consistent in time but not necessarily linearly related to $x_{2}(n)$. However, the feedback loop of the modulator forces the in-band frequency of $x_{1}(n)$ to very closely equal $u(n)$, and thus $x_{1}(n)$ is still linearly related to $u(n)$. Through the use of the digital correction circuitry, the signal $y(n)$ also equals $x_{1}(n)$ if its nonlinearity equals that of the D/A converter. To realize this digital correction circuitry, a $2^{\mathrm{N}}$ word look-up RAM is used where the size of each RAM word is at least equal to the desired linearity. For example, if a 4 -bit D/A converter is used and 18 bits of linearity is desired, then the digital correction circuitry consists of a 16-word RAM, each of length 18 bits or greater (or equivalently, a 288bit RAM). Furthermore, this RAM size can be reduced by digitizing only the difference between the desired linearity and the expected linearity of the D/A converter [Sarhang-Nejad, 1993]. For example, if the D/A converter is
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-29.jpg?height=378&width=1083&top_left_y=181&top_left_x=381)

Fig. 18.28 Digitally corrected multi-bit A/D modulator.
expected to have a linearity of at least 9 bits, then the RAM need only have a word length of 10 bits for 18 -bit overall linearity.

The calibration of the digital correction circuitry can be accomplished by reconfiguring the $\Delta \Sigma \mathrm{A} / \mathrm{D}$ modulator to a single-bit system. Next, the input to this 1-bit converter is one of the 4 -bit $\mathrm{D} / \mathrm{A}$ converter levels to be calibrated. In other words, the multi-bit converter's input is held constant while its output is applied to the 1-bit A/D modulator for many clock cycles. The resulting 1-bit signal is digitally low-pass filtered and gives the desired digital equivalent value of that particular dc level for the D/A converter. This procedure is repeated 16 times to find all the 16 words of RAM.

Finally, it should be mentioned that a similar approach can be used to improve the linearity of a multi-bit oversampling D/A converter, except in this case the digital correction circuit would be in the feedback portion of the digital modulator.

### 18.8.4 A/D with Both Multi-Bit and Single-Bit Feedback

Another very interesting alternative architecture uses both multi-bit feedback and single-bit feedback [Hairapetian, 1994]. A third-order example of this $\mathrm{A} / \mathrm{D}$ is shown in Fig. 18.29. If one assumes that the errors due to the quantization of the 1-bit $\mathrm{A} / \mathrm{D}$ and 5-bit $\mathrm{A} / \mathrm{D}$ are $\mathrm{Q}_{1}$, and $\mathrm{Q}_{5}$, respectively, and also that the 5-bit $\mathrm{D} / \mathrm{A}$ injects errors due to its nonlinearity given by $Q_{d}$, then by applying a linear analysis to the system of Fig. 18.29 it can be shown that

$$
\begin{align*}
U_{s}(z)= & U(z) z^{-1}+Q_{1}(z) \frac{\left(1-z^{-1}\right)^{2}}{1-0.5 z^{-1}}-Q_{5}(z) \frac{z^{-1}\left(1-z^{-1}\right)^{-2}}{1-0.5 z^{-1}} \\
& -Q_{d}(z) \frac{z^{-1}\left(1-z^{-1}\right)^{-2}}{1-0.5 z^{-1}} \tag{18.55}
\end{align*}
$$

After digital signal processing, the digital output signal, $Y(z)$, is given by

$$
\begin{equation*}
Y(z)=U(z) z^{-1}+2 Q_{5}(z)\left(1-z^{-1}\right)^{3}-2 Q_{d}(z) z^{-1}\left(1-z^{-1}\right)^{2} \tag{18.56}
\end{equation*}
$$

It is seen that, based on the assumption of perfect integrators, the quantization noise due to the 1-bit $\mathrm{A} / \mathrm{D}$ is cancelled exactly, the quantization noise due to the 5-bit A/D undergoes third-order noise shaping, and the noise due to the nonlinearity of the 5 -bit $\mathrm{D} / \mathrm{A}$ converter undergoes second-order shaping. Of course, if the integrators are not perfect, then the cancellation of the quantization noise of the 1-bit $\mathrm{A} / \mathrm{D}$ will not be perfect, but any errors in the cancellation still undergo second-order noise shaping. It can be shown that the stability characteristics of this system are very similar to those of a second-order $\Delta \Sigma \mathrm{A} / \mathrm{D}$ converter. It should also be noted that the digital signal processing required does not require any multiplications, but that multi-bit signals must be processed by the following decimator, which complicates its realization.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-30.jpg?height=720&width=1378&top_left_y=170&top_left_x=192)

Fig. 18.29 An A/D architecture that uses both multi-bit and single-bit feedback.

## 18.9 THIRD-ORDER A/D DESIGN EXAMPLE

In this section, a design example is presented for a third-order oversampled switched-capacitor $\mathrm{A} / \mathrm{D}$ converter. In this example, all the zeros of the noise transfer function (NTF) are placed at $\mathbf{z}=1$ (i.e., dc) so that the converter could be used for various oversampling ratios. In other words, the zeros are not spread over the frequency band of interest, as that would restrict the converter's usefulness to a particular oversampling ratio.

Since all the zeros are assumed to be at $\mathbf{z}=1$, the NTF has the following form:

$$
\begin{equation*}
\operatorname{NTF}(z)=\frac{(z-1)^{3}}{D(z)} \tag{18.57}
\end{equation*}
$$

To find the poles of the system, given by the roots of $D(z)$, we need to ensure modulator stability while shaping as much quantization noise away from dc as possible. To ensure modulator stability, recall that a heuristic approach is to restrict the peak NTF magnitude response to less than 1.5 . However, to shape the quantization noise away from dc, we wish to make the NTF as large as possible outside the frequency band of interest. Thus, the best NTF choice would be one which has a flat gain of 1.4 at high frequencies. Such a high-pass filter is obtained (i.e., no peaking in the NTF) when the poles are placed in a Butterworth configuration, as shown in Fig. 18.30. Thus, the

Fig. 18.30 Pole and zero locations for the third-order NTF.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-30.jpg?height=351&width=712&top_left_y=1788&top_left_x=822)
denominator is found using digital filter software to design a third-order high-pass digital filter where the passband is adjusted until the peak NTF is less than 1.4 (i.e., $\left|\operatorname{NTF}\left(\mathrm{e}^{\mathrm{j} \omega}\right)\right|<1.4$ ). Specifically, with a passband edge at $\mathrm{f}_{\mathrm{s}} / 20$, a third-order Butterworth high-pass filter has a peak gain equal to 1.37 , and thus the $\operatorname{NTF}(z)$ is given by

$$
\begin{equation*}
\operatorname{NTF}(z)=\frac{(z-1)^{3}}{z^{3}-2.3741 z^{2}+1.9294 z-0.5321} \tag{18.58}
\end{equation*}
$$

By rearranging (18.16), we can find $H(z)$ in term of $\operatorname{NTF}(z)$, resulting in

$$
\begin{equation*}
\mathrm{H}(\mathrm{z})=\frac{1-\operatorname{NTF}(z)}{\operatorname{NTF}(z)} \tag{18.59}
\end{equation*}
$$

which, for the function given in (18.58), results in

$$
\begin{equation*}
H(z)=\frac{0.6259 z^{2}-1.0706 z+0.4679}{(z-1)^{3}} \tag{18.60}
\end{equation*}
$$

Next, a suitable implementation structure is chosen. In this case, a cascade-of-integrators structure was used, as shown in Fig. 18.31. The $\alpha_{\mathrm{i}}$ coefficients are included for dynamic-range scaling and are initially set to $\alpha_{2}=\alpha_{3}=1$, while the last term, $\alpha_{1}$, is initially set equal to $\beta_{1}$. By initially setting $\alpha_{1}=\beta_{1}$, we are allowing the input signal to have a power level similar to that of the feedback signal, $y(n)$. In other words, if $\alpha_{1}$ were initially set equal to one and $\beta_{1}$ were quite small, then the circuit would initially be stable for only small input-signal levels.

Coefficient values for $\beta_{i}$ are then found by deriving the transfer function from the 1-bit $\mathrm{D} / \mathrm{A}$ output to $\mathrm{V}_{3}$ and equating that function to $-H(z)$ in (18.60). Specifically, assuming $\alpha_{2}=\alpha_{3}=1$, we find the following $H(z)$ :

$$
\begin{equation*}
H(z)=\frac{z^{2}\left(\beta_{1}+\beta_{2}+\beta_{3}\right)-z\left(\beta_{2}+2 \beta_{3}\right)+\beta_{3}}{(z-1)^{3}} \tag{18.61}
\end{equation*}
$$

Equating (18.61) with (18.60), we find an initial set of coefficients to be

$$
\begin{array}{rrl}
\alpha_{1}=0.0232, & \alpha_{2}=1.0, & \alpha_{3}=1.0 \\
\beta_{1}=0.0232, & \beta_{2}=0.1348, & \beta_{3}=0.4679 \tag{18.62}
\end{array}
$$

It is then necessary to perform dynamic-range scaling. Dynamic scaling is necessary to ensure that all nodes have approximately the same power level, so that all nodes will clip near the same level, and there will be no unnecessarily large noise gains from nodes with small signal levels. Here, dynamic-range scaling was accomplished by simulating the system in Fig. 18.31 with the coefficients just given and an input sinusoidal wave with a peak value of 0.7 at a frequency of $\pi / 256 \mathrm{rad} / \mathrm{sample}$. Following the simulation, the maximum values at nodes $\mathrm{V}_{1}, \mathrm{~V}_{2}, \mathrm{~V}_{3}$ were found to be $0.1256,0.5108$, and 1.004 , respectively. To increase the output level of a node by a
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-31.jpg?height=366&width=1380&top_left_y=1696&top_left_x=162)

Fig. 18.31 The cascade-of-integrators structure used to realize the third-order modulator. Note that $\alpha_{i}$ coefficients are used for dynamic-range scaling and are initially set to $\alpha_{1}=\beta_{1}$ and $\alpha_{2}=\alpha_{3}=1$.
![](https://cdn.mathpix.com/cropped/2024_11_07_4038aaf14c2d86a2487fg-32.jpg?height=1149&width=1378&top_left_y=188&top_left_x=197)

Fig. 18.32 A switched-capacitor realization of the third-order modulator example.
factor k, the input branches should be multiplied by k, while the output branches should be divided by k. For example, the maximum value of node $\mathrm{V}_{1}$ is increased to unity by multiplying both $\alpha_{1}$ and $\beta_{1}$ by $1 / 0.1256$ and dividing $\alpha_{2}$ by $1 / 0.1256$. Similarly, node $V_{2}$ is scaled by dividing $0.1256 \alpha_{2}$ and $\beta_{2}$ by 0.5108 and multiplying $\alpha_{3}$ by 0.5108 . Node $V_{3}$ was left unchanged, as its maximum value was already near unity. Such a procedure results in the following final values for the coefficients.

$$
\begin{array}{lll}
\alpha^{\prime}{ }_{1}=0.1847, & \alpha^{\prime}{ }_{2}=0.2459, & \alpha^{\prime}=0.5108 \\
\beta^{\prime}=0.1847, & \beta^{\prime}{ }_{2}=0.2639, & \beta_{3}^{\prime}=0.4679 \tag{18.63}
\end{array}
$$

Finally, the block diagram of Fig. 18.31 can be realized by the switched-capacitor circuit shown in Fig. 18.32 to obtain the final oversampled A/D converter.

## 18.10 KEY POINTS

- Oversampling converters relax the requirements placed on the analog circuitry at the expense of more complicated digital circuitry. [p. 696]
- Quantization with a step size "LSB" can be modeled as an additive quantization noise uniformly distributed between $-\mathrm{LSB} / 2$ and $+\mathrm{LSB} / 2$ with a white power spectrum and total power of LSB2/12. [p. 697]
- Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \log (\mathrm{OSR}) \mathrm{dB}$. [p. 700]
- One-bit D/A converters are inherently linear. Hence, when combined with a high oversampling ratio, they can provide a good signal to quantization noise and distortion ratio. [p. 702]
- To shape the spectrum of a quantization noise source, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest. [p. 704]
- Using a single integrator inside a DS modulator feedback loop places a zero at dc in the noise transfer function providing first-order noise shaping for low-pass signals. [p. 704]
- First-order noise shaping permits SQNR to increase by 1.5 bits/octave with respect to oversampling ratio, or 9 dB for every doubling of OSR. [p. 706]
- Second-order noise shaping increases SQNR by 15 dB for each doubling of OSR, or equivalently by 1.5 bits/ octave. [p. 708]
- The input signal power is often limited to well below the maximum quantizer swing to ensure stability, resulting in reduced SQNR. [p. 709]
- Oversampling A/D converters require additional digital low-pass filtering, but less analog anti-aliasing filtering-often an desirable trade-off in integrated circuits. [p. 711]
- The linearity of oversampled $\mathrm{A} / \mathrm{D}$ converters depends more strongly on the linearity of its internal $\mathrm{D} / \mathrm{A}$ converter than on its internal quantizer. [p. 712]
- Oversampling D/A converters require a very linear but low-resolution internal D/A converter, and an analog smoothing filter whose order should be at least one greater than that of the noise shaping and must have sufficient dynamic range to accommodate both signal and large quantization noise power at its input. [p. 713]
- In a multi-stage decimation filter, an initial lowpass filter removes much of the quantization noise. Its output is then downsampled so that the remaining filtering can be performed at a lower clock frequency. [p. 715]
- In single-stage decimation, one filter operates on a low-resolution noise-shaped signal providing the decimated output. Because of the high filter order, several time-interleaved filters may be used in parallel. [p. 717]
- Noise shaping with order $\mathrm{L}>2$ offers the potential for further improvements in SQNR of $6 \mathrm{~L}+3 \mathrm{~dB} /$ octave or $\mathrm{L}+0.5$ bits/octave with respect to oversampling ratio. [p. 718]
- Interpolative higher-order modulators permit the arbitrary placement of noise transfer function zeros, offering improved SQNR performance compared to the placement of all zeros at dc, especially for relatively low OSR. However, it is nontrivial to guarantee stability for such structures, and they are therefore often combined with multi-bit internal quantizers. [p. 718]
- Multi-stage noise shaping (MASH) oversampling converters cascade lower order modulators to realize highorder noise shaping. Since the constituent stages are each first- or second-order, it is easy to ensure stability. However, MASH converters require digital filtering whose coefficients are matched to those of analog circuitry. [p. 720]
- The stability of 1-bit modulators is not well understood, but as a rule of thumb keeping the peak magnitude response of the noise transfer function below 1.5 often results in a stable modulator. [p. 722]
- Multi-bit internal quantization improves stability and therefore is often used in high order modulators with low OSR. In A/D converters, it is combined with linearity enhancement techniques for the feedback DAC. [p. 723]
- The nonlinear dynamics of 1-bit oversampling modulators can result in idle tones within the signal band when applying dc or slowly-varying inputs. An additive pseudo-random dither signal can break up the tones but raises the noise floor. [p. 726]
- Opamps in analog oversampling modulators should have a dc gain at least twice the oversampling ratio, which is not usually a difficult requirement. An exception is MASH modulators where higher gains may be required to ensure digital and analog transfer functions are matched. [p. 727]
- Dynamic element matching randomizes the use of analog elements in a $\mathrm{D} / \mathrm{A}$ to eliminate the tones that would otherwise result from mismatches, making instead spectrally-shaped noise. It enables the use of multi-bit D/As in highly linear oversampling converters. [p. 727]
