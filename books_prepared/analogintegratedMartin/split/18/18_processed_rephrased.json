[

{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by increasing the complexity of digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems from the fact that these converters reduce the stringent requirements on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became advantageous with the emergence of deep submicron CMOS technologies, which facilitated the implementation of complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. With oversampling data converters, the analog components face less stringent demands regarding matching tolerances and amplifier gains. Additionally, these converters simplify the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in $\\mathrm{D} / \\mathrm{A}$ converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for $\\mathrm{A} / \\mathrm{D}$ converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $\\mathrm{A} / \\mathrm{D}$ converter.\n\nThis chapter begins by covering the fundamentals of oversampling converters. We will explore how additional bits of resolution can be achieved from converters that sample at rates significantly higher than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by shaping the quantization noise spectrally through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter discusses simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are outlined. The chapter also describes some contemporary approaches and practical considerations. It concludes with an example design of a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by requiring more complex digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems largely from the fact that these converters reduce the demands on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became advantageous with the introduction of deep submicron CMOS technologies, which made it easier to implement complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. In oversampling data converters, the analog components face less stringent requirements regarding matching tolerances and amplifier gains. Additionally, these converters streamline the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in $\\mathrm{D} / \\mathrm{A}$ converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for $\\mathrm{A} / \\mathrm{D}$ converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is usually not necessary at the input of an oversampling $\\mathrm{A} / \\mathrm{D}$ converter.\n\nThis chapter begins by discussing the fundamentals of oversampling converters. We will explore how additional bits of resolution can be achieved from converters that sample significantly faster than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by shaping the quantization noise spectrally through feedback. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter covers simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are detailed. Modern approaches and practical considerations are also discussed. The chapter concludes with a design example of a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by increasing the complexity of digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems from the fact that these converters reduce the stringent requirements on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became advantageous with the emergence of deep submicron CMOS technologies, which facilitated the implementation of complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. In oversampling data converters, the analog components face less stringent demands regarding matching tolerances and amplifier gains. Additionally, these converters ease the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in D/A converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for A/D converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $A / D$ converter.\n\nThis chapter begins by exploring the fundamentals of oversampling converters. It will illustrate how additional bits of resolution can be achieved from converters that sample significantly faster than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by shaping the quantization noise spectrally through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter discusses simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are outlined. Modern approaches and practical considerations are then described, and the chapter concludes with a design example of a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by requiring more complex digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems largely from the fact that these converters reduce the demands on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became attractive with the emergence of deep submicron CMOS technologies, which facilitated the creation of complex high-speed digital circuits in smaller areas, while the fabrication of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. With oversampling data converters, the analog components face less stringent requirements regarding matching tolerances and amplifier gains. Additionally, these converters simplify the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in D/A converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for A/D converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $A / D$ converter.\n\nIn this chapter, we initially explore the fundamentals of oversampling converters. We will demonstrate that additional bits of resolution can be achieved from converters that sample significantly faster than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by spectrally shaping the quantization noise through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ We discuss simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, we describe two prevalent methods for implementing decimation filters. We then outline some modern approaches and address practical considerations. The chapter concludes with a case study of designing a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by introducing more complex digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their widespread adoption is largely due to the fact that these converters reduce the stringent requirements on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became advantageous with the emergence of deep submicron CMOS technologies, which facilitated the implementation of complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance resulting from short-channel effects. In oversampling data converters, the analog components face less stringent demands regarding matching tolerances and amplifier gains. Additionally, these converters streamline the requirements for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in D/A converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for A/D converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $A / D$ converter.\n\nThis chapter begins by exploring the fundamentals of oversampling converters. It will be demonstrated that additional bits of resolution can be achieved from converters that sample at rates significantly higher than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by shaping the quantization noise spectrally through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter discusses simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are outlined. The chapter also describes some contemporary approaches and practical considerations. It concludes with a case study of designing a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by increasing the complexity of the digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems from the fact that these converters reduce the stringent requirements on analog circuitry, albeit at the cost of more intricate digital circuitry. This balance became favorable with the emergence of deep submicron CMOS technologies, which facilitated the implementation of complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. With oversampling data converters, the analog components face less stringent demands regarding matching tolerances and amplifier gains. Additionally, these converters streamline the requirements for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in $\\mathrm{D} / \\mathrm{A}$ converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for $\\mathrm{A} / \\mathrm{D}$ converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $\\mathrm{A} / \\mathrm{D}$ converter.\n\nThis chapter begins by exploring the fundamentals of oversampling converters. It will illustrate how additional bits of resolution can be derived from converters that sample at rates significantly higher than the Nyquist rate. Moreover, this enhanced resolution can be achieved at lower oversampling rates by shaping the quantization noise spectrally through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter discusses simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are outlined. The chapter also covers descriptions of some contemporary approaches and practical considerations. It concludes with a case study of designing a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by requiring more complex digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications such as high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems largely from the fact that these converters reduce the stringent requirements on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became attractive with the emergence of deep submicron CMOS technologies, which facilitated the implementation of complex high-speed digital circuits in smaller areas. Conversely, the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. In oversampling data converters, the analog components face less stringent demands regarding matching tolerances and amplifier gains. Additionally, these converters ease the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in $\\mathrm{D} / \\mathrm{A}$ converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for $\\mathrm{A} / \\mathrm{D}$ converters, which can be implemented cost-effectively. Moreover, a sample-and-hold circuit is generally not necessary at the input of an oversampling $\\mathrm{A} / \\mathrm{D}$ converter.\n\nThis chapter begins by exploring the fundamentals of oversampling converters. It will illustrate how additional bits of resolution can be derived from converters that sample at rates significantly higher than the Nyquist rate. Moreover, this enhanced resolution can be achieved at lower oversampling rates by spectrally shaping the quantization noise using feedback. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ The chapter discusses simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two prevalent methods for implementing decimation filters are outlined. The chapter then describes some contemporary approaches and practical considerations. It concludes with an example design of a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "Key Point: Oversampling converters ease the demands on analog circuitry by requiring more complex digital circuitry.\n\nOversampling $\\mathrm{A} / \\mathrm{D}$ and $\\mathrm{D} / \\mathrm{A}$ converters are widely used in high-resolution, medium-to-low-speed applications like high-fidelity digital audio and baseband signal processing in certain wireless systems. Their popularity stems from the fact that they reduce the demands on analog circuitry, albeit at the cost of more intricate digital circuitry. This trade-off became advantageous with the introduction of deep submicron CMOS technologies, which made it easier to implement complex high-speed digital circuits in smaller areas, while the creation of high-resolution analog circuits was hindered by low power-supply voltages and poor transistor output impedance due to short-channel effects. With oversampling data converters, the analog components face less stringent requirements regarding matching tolerances and amplifier gains. Additionally, these converters simplify the specifications for analog anti-aliasing filters in $\\mathrm{A} / \\mathrm{D}$ converters and smoothing filters in D/A converters. For instance, typically only a first- or second-order anti-aliasing filter is needed for A/D converters, which can be implemented very cost-effectively. Moreover, a sample-and-hold circuit is usually not necessary at the input of an oversampling $A / D$ converter.\n\nIn this chapter, we begin by discussing the fundamentals of oversampling converters. We will explore how additional bits of resolution can be achieved from converters that sample significantly faster than the Nyquist rate. Moreover, this enhanced resolution can be attained at lower oversampling rates by spectrally shaping the quantization noise through feedback mechanisms. The application of shaped quantization noise to oversampling signals is commonly known as delta-sigma $(\\Delta \\Sigma)$ modulation. ${ }^{1}$ We will cover simple first- and second-order $\\Delta \\Sigma$ modulators, followed by an examination of typical system architectures for $\\Delta \\Sigma$ data converters. Subsequently, two widely-used methods for implementing decimation filters are detailed. Modern approaches and practical considerations are also discussed. The chapter concludes with a design example of a third-order $\\Delta \\Sigma$ A/D converter."
},
{
    "text": "In this section, the benefits of sampling at a rate higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the enhancement in dynamic range is merely 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate increases, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented in a linear fashion. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to illustrate that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to reconstruct the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point labeled with \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical expression of the quantization error.\n\n4. **Overall System Function:**\n- The primary purpose of this diagram is to depict the quantization process and its linear representation. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and comprehending the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:The graph in Fig. 18.2 illustrates the assumed spectral density of quantization noise. This is a frequency-domain plot with the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This is a spectral density plot, depicting the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with significant points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph features a constant level of spectral density across the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the magnitude of the noise power density.\n- The plot is essentially rectangular, indicating a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is explicitly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at rates higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the enhancement in dynamic range is limited to 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate increases, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented linearly. The input \\( x(n) \\) is shown as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to illustrate that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then modeled linearly by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to recreate the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly labeled with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point marked with \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical expression of the quantization error.\n\n4. **Overall System Function:**\n- The main purpose of this diagram is to depict the quantization process and its linear representation. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and comprehending the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:Fig. 18.2 presents a graph representing the assumed spectral density of quantization noise. This frequency-domain plot features a horizontal axis labeled as frequency \\( f \\) and a vertical axis labeled as \\( S_e(f) \\), indicating the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This is a spectral density plot, illustrating the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with significant points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph exhibits a constant level of spectral density throughout the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\). This suggests that the quantization noise is uniformly distributed within this frequency band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented as \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the magnitude of the noise power density.\n- The plot is essentially rectangular, indicating a flat noise spectrum, characteristic of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is clearly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this segment, the benefits of sampling at a rate higher than the Nyquist frequency are explored. Here, we will demonstrate that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will be evident that the enhancement in dynamic range is merely 3 dB for each doubling of the sampling rate. To achieve significantly greater improvements in dynamic range as the sampling rate increases, the application of noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Key Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented in a linear fashion. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to illustrate that the error is the difference between the quantized output and the original input.\n\n2. **Information or Control Flow:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to reconstruct the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point indicated by \\( + \\), showing the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical expression of the quantization error.\n\n4. **System Function Overview:**\n- The main purpose of this diagram is to depict the quantization process and its modeling. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and comprehending the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:The graph in Fig. 18.2 illustrates the assumed spectral density of quantization noise. This is a frequency-domain plot with the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Graph Type and Function:**\n- This is a spectral density plot, depicting the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with key points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **General Behavior and Trends:**\n- The graph features a consistent level of spectral density throughout the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\). This suggests that the quantization noise is uniformly spread over this frequency band.\n\n4. **Notable Features and Technical Aspects:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula indicates the magnitude of the noise power density.\n- The plot essentially forms a rectangular shape, signifying a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is clearly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at a rate higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the enhancement in dynamic range is limited to just 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate increases, the application of noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Key Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented linearly. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to show that the error is the difference between the quantized output and the original input.\n\n2. **Information or Control Flow:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to reconstruct the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point labeled \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to offer a mathematical expression of the quantization error.\n\n4. **System Function Overview:**\n- The main purpose of this diagram is to depict the quantization process and its modeling. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and comprehending the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:The graph in Fig. 18.2 illustrates the assumed spectral density of quantization noise. This is a frequency-domain plot with the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Graph Type and Function:**\n- This is a spectral density plot, depicting the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with significant points at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **General Behavior and Trends:**\n- The graph features a consistent level of spectral density across the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the noise power density magnitude.\n- The plot is essentially rectangular, indicating a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is explicitly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at a rate higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the dynamic range only increases by 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate rises, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented in a linear fashion. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to illustrate that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to recreate the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point labeled \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical representation of the quantization error.\n\n4. **Overall System Function:**\n- The primary purpose of this diagram is to illustrate the quantization process and its modeling. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and understanding the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:Fig. 18.2 presents a graph depicting the assumed spectral density of quantization noise. This frequency-domain plot features a horizontal axis labeled frequency \\( f \\) and a vertical axis labeled \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This is a spectral density plot, illustrating the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with significant points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph exhibits a constant level of spectral density across the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the magnitude of the noise power density.\n- The plot is essentially rectangular, indicating a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is explicitly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at rates higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the dynamic range increases by only 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate rises, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented linearly. The input \\( x(n) \\) is shown as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to indicate that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to recreate the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly labeled with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point marked with \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical representation of the quantization error.\n\n4. **Overall System Function:**\n- The main purpose of this diagram is to illustrate the quantization process and its modeling. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and understanding the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:The graph in Fig. 18.2 depicts the assumed spectral density of quantization noise. This is a frequency-domain plot with the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This is a spectral density plot, illustrating the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\), with significant points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph features a constant level of spectral density across the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this frequency band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, denoted as \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula represents the magnitude of the noise power density.\n- The plot is essentially rectangular, signifying a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is explicitly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at rates higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the enhancement in dynamic range is limited to 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range as the sampling rate increases, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented linearly. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to show that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to recreate the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point labeled with \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical representation of the quantization error.\n\n4. **Overall System Function:**\n- The main purpose of this diagram is to illustrate the quantization process and its linear representation. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model depicts this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and understanding the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:Fig. 18.2 presents a graph depicting the assumed spectral density of quantization noise. This frequency-domain plot features the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This is a spectral density plot, illustrating the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with notable points at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph shows a constant level of spectral density throughout the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the noise power density magnitude.\n- The plot forms a rectangular shape, indicating a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the spectral density height, providing the formula for \\( k_x \\).\n- The frequency range is clearly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "In this section, the benefits of sampling at a rate higher than the Nyquist rate are explored. Here, it will be demonstrated that additional dynamic range can be achieved by distributing the quantization noise power across a broader frequency spectrum. However, it will also be shown that the enhancement in dynamic range is limited to 3 dB for each doubling of the sample rate. To achieve significantly greater improvements in dynamic range with increasing sampling rates, noise shaping via feedback can be employed, a topic covered in the subsequent section.\n\n[^2]image_name:Fig. 18.1 Quantizer and its linear model\ndescription:The system block diagram titled \"Fig. 18.1 Quantizer and its linear model\" comprises two primary components: the quantizer and its associated linear model.\n\n1. **Main Components:**\n- **Quantizer Block:** Located on the left side of the diagram, this block accepts an input signal \\( x(n) \\) and produces an output signal \\( y(n) \\). Within the quantizer block, a staircase-like graph depicts the quantization process, where continuous input values are mapped to discrete output levels.\n- **Linear Model:** On the right side, the quantizer is represented in a linear fashion. The input \\( x(n) \\) is depicted as an arrow leading to a summation point, where it is combined with a quantization error \\( e(n) \\) to generate the output \\( y(n) \\). The equation \\( e(n) = y(n) - x(n) \\) is provided to illustrate that the error is the difference between the quantized output and the original input.\n\n2. **Flow of Information or Control:**\n- The input signal \\( x(n) \\) enters the quantizer block, undergoes quantization, and results in the output \\( y(n) \\). This output is then linearly modeled by adding the quantization error \\( e(n) \\) to the input \\( x(n) \\) to reconstruct the output \\( y(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The quantizer block is clearly marked with input \\( x(n) \\) and output \\( y(n) \\) signals.\n- The linear model includes a summation point labeled with \\( + \\), indicating the addition of quantization error \\( e(n) \\).\n- The equation \\( e(n) = y(n) - x(n) \\) is annotated to provide a mathematical expression of the quantization error.\n\n4. **Overall System Function:**\n- The main purpose of this diagram is to depict the quantization process and its linear representation. The quantizer transforms the input signal into a quantized output by mapping it to discrete levels, introducing a quantization error. The linear model represents this process by adding the quantization error to the input to produce the quantized output. This model aids in analyzing and comprehending the impact of quantization in digital signal processing systems.\n\nFig. 18.1 Quantizer and its linear model.\nimage_name:Fig. 18.2 Assumed spectral density of quantization noise\ndescription:Fig. 18.2 displays a graph representing the assumed spectral density of quantization noise. This is a frequency-domain plot with the horizontal axis labeled as frequency \\( f \\) and the vertical axis labeled as \\( S_e(f) \\), representing the spectral density of the quantization error.\n\n1. **Type of Graph and Function:**\n- This plot illustrates the spectral density, showing the distribution of quantization noise power across various frequencies.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), with key points marked at \\(-\\frac{f_s}{2}\\), 0, and \\(\\frac{f_s}{2}\\), where \\( f_s \\) is the sampling frequency.\n- The vertical axis represents the spectral density \\( S_e(f) \\).\n\n3. **Overall Behavior and Trends:**\n- The graph features a constant level of spectral density throughout the frequency range from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), indicating uniform distribution of quantization noise over this band.\n\n4. **Key Features and Technical Details:**\n- The spectral density maintains a constant height, represented by \\( k_x = \\left( \\frac{\\Delta}{\\sqrt{12}} \\right) \\sqrt{\\frac{1}{f_s}} \\), where \\( \\Delta \\) is the quantization step size. This formula signifies the magnitude of the noise power density.\n- The plot is essentially rectangular, indicating a flat noise spectrum, typical of white noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes an annotation for the height of the spectral density, providing the formula for \\( k_x \\).\n- The frequency range is clearly marked from \\(-\\frac{f_s}{2}\\) to \\(\\frac{f_s}{2}\\), highlighting the Nyquist frequency range for digital signals.\n\nFig. 18.2 Assumed spectral density of quantization noise."
},
{
    "text": "When $x(n)$ is highly active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between two neighboring quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and is independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequency) with all its power contained within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nUnder the assumption of white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, featuring a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe spectral density height is determined by recognizing that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, or mathematically,\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relation yields\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, given the input values:\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, calculate the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the active nature of the input signal.\n\nRecalling that the quantization noise power is given by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" illustrates a step function used in signal processing to convert continuous signal values into discrete levels. This piecewise constant function maps an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph is a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), representing the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph exhibits a staircase pattern with five levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function is constant within intervals of \\( x(n) \\), specifically from \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), \\(0.25\\) to \\(0.75\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for fewer bits needed for signal representation.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), representing the input signal values, while the vertical axis is labeled \\(y(n)\\), representing the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting a two-level quantizer's behavior.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also with no specific units.\n\nOverall Behavior and Trends:\n- The graph shows that the quantizer outputs 1.0 for all \\(x(n)\\) values greater than or equal to 0, and -1.0 for all \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the quantization threshold.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapping to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- No specific annotations or data points are marked beyond the axes labels and quantization levels.\n- The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping any positive or zero input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ exhibits high activity, $e(n)$ can be regarded as an independent random variable uniformly distributed within $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between consecutive quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (refer to Section 15.3) and remains independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is flat (constant across frequencies) with all its power confined to $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nUnder the assumption of white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, characterized by a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe height of the spectral density is determined by recognizing that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, or mathematically,\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relationship yields\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, given the input values\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, compute the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the high activity of the input signal.\n\nRecalling that the quantization noise power is given by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" depicts a step function used in signal processing to convert continuous signal values into discrete levels. This piecewise constant function maps an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph represents a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), indicating the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five distinct levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function remains constant within specific intervals of \\( x(n) \\), such as \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), \\(0.25\\) to \\(0.75\\), and so on.\n- Each step corresponds to a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces the precision of signal representation, introducing quantization noise as a trade-off for using fewer bits to represent the signal.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), representing the input signal values, while the vertical axis is labeled \\(y(n)\\), indicating the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, illustrating the behavior of a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input values of the signal, with no specific units provided.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also with no specific units.\n\nOverall Behavior and Trends:\n- The graph indicates that the quantizer outputs 1.0 for all input values \\(x(n)\\) greater than or equal to 0, and -1.0 for all input values \\(x(n)\\) less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), which is the threshold for quantization.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values that map to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- There are no specific annotations or data points marked on the graph beyond the axes labels and quantization levels. The graph effectively illustrates the simple binary decision-making process of the two-level quantizer, mapping any positive or zero input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the two power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ exhibits high activity, $e(n)$ can be regarded as an independent random number uniformly distributed within $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between successive quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and remains independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequencies) with all its power confined within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nGiven the assumption of white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, characterized by a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe height of the spectral density is determined by recognizing that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, mathematically expressed as:\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relation yields:\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, given the input values:\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, compute the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are listed in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the high activity of the input signal.\n\nRecalling that the quantization noise power is given by:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" illustrates a step function used in signal processing to convert continuous signal values into discrete levels. This function is piecewise constant, mapping the input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph represents a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), indicating the input signal values.\n- The vertical axis is labeled \\( y(n) \\), showing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five discrete levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function remains constant within specific intervals of \\( x(n) \\), such as \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), and so on.\n- Each step corresponds to a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for using fewer bits to represent the signal.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), representing the input signal values, while the vertical axis is labeled \\(y(n)\\), indicating the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting the behavior of a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units provided.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also without specific units.\n\nOverall Behavior and Trends:\n- The graph shows that the quantizer outputs 1.0 for all \\(x(n)\\) values greater than or equal to 0, and -1.0 for all \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), serving as the threshold for quantization.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values that map to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- There are no specific annotations or data points on the graph beyond the axes labels and quantization levels. The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping any non-negative input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of:\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to:\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ is highly active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ is the difference between two adjacent quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and is independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequency) with all its power within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nGiven white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, featuring a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe spectral density height is determined by noting that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, mathematically expressed as:\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this yields:\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, given the input values:\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, compute the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the active nature of the input signal.\n\nRecalling that the quantization noise power is given by:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" illustrates a step function used in signal processing to convert continuous signal values into discrete levels. This piecewise constant function maps an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph is a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), representing the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function is constant within specific intervals of \\( x(n) \\), such as \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for fewer bits required for signal representation.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), indicating the input signal values, while the vertical axis is labeled \\(y(n)\\), representing the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also without specific units.\n\nOverall Behavior and Trends:\n- The graph shows that the quantizer outputs 1.0 for \\(x(n)\\) values greater than or equal to 0, and -1.0 for \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the quantization threshold.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapping to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- No specific annotations or data points are marked beyond the axes labels and quantization levels. The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping any non-negative input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of:\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to:\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ exhibits high activity, $e(n)$ can be regarded as an independent random variable uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between consecutive quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as derived in Section 15.3) and remains independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is flat (constant across frequencies) with all its power confined within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nUnder the assumption of white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as adding quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, characterized by a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe height of the spectral density is determined by noting that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, or mathematically,\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relation yields\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, given the input values\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, compute the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the high activity of the input signal.\n\nRecalling that the quantization noise power is given by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" depicts a step function used in signal processing to convert continuous signal values into discrete levels. This piecewise constant function maps an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nGraph Type and Function:\n- The graph is a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), representing the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are equally spaced with a step size \\( \\Delta = 0.5 \\).\n- The function is constant within intervals of \\( x(n) \\), specifically from \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), \\(0.25\\) to \\(0.75\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for fewer bits required for signal representation.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), indicating the input signal values, while the vertical axis is labeled \\(y(n)\\), representing the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nGraph Type and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also without specific units.\n\nOverall Behavior and Trends:\n- The graph indicates that the quantizer outputs 1.0 for all \\(x(n)\\) values greater than or equal to 0, and -1.0 for all \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the threshold for quantization.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapping to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- No specific annotations or data points are marked on the graph beyond the axes labels and quantization levels. The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping any non-negative input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the two power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ is highly active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between two adjacent quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and is independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequency) with all its power within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nGiven white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, featuring a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe spectral density height is determined by noting that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, mathematically expressed as:\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relation yields:\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two distinct quantizers, as illustrated in Fig. 18.3, when the input values are:\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, compute the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are listed in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the active nature of the input signal.\n\nRecalling that the quantization noise power is given by:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are:\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:This graph, titled \"Quantizer I (Five-level quantizer),\" depicts a step function used in signal processing to map continuous signal values to discrete levels. It is a piecewise constant function that translates an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nGraph Type and Function:\n- The graph represents a step function for quantization, a process in signal processing where continuous amplitude values are converted to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), indicating the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) shifts to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function remains constant within specific intervals of \\( x(n) \\), such as \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for using fewer bits to represent the signal.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis, labeled \\(x(n)\\), represents the input signal values, while the vertical axis, labeled \\(y(n)\\), shows the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nGraph Type and Function:\n- This is a piecewise constant function graph, specifically a step function, illustrating a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also without specific units.\n\nOverall Behavior and Trends:\n- The graph indicates that the quantizer outputs 1.0 for \\(x(n)\\) values of 0 or higher, and -1.0 for \\(x(n)\\) values below 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the quantization threshold.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapped to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- No specific annotations or data points are marked beyond the axes labels and quantization levels.\n- The graph effectively demonstrates the binary decision-making process of the two-level quantizer, mapping positive or zero inputs to 1.0 and negative inputs to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of:\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to:\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ is highly active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ represents the difference between two adjacent quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and is independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequency) with all its power contained within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nGiven the assumption of white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, featuring a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe height of the spectral density is determined by recognizing that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, or mathematically,\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this relation yields\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two different quantizers, as illustrated in Fig. 18.3, given the input values\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, calculate the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the active nature of the input signal.\n\nRecalling that the quantization noise power is given by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:The graph titled \"Quantizer I (Five-level quantizer)\" illustrates a step function used in signal processing to convert continuous signal values into discrete levels. This piecewise constant function maps an input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph is a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), representing the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) jumps to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are equally spaced with a step size \\( \\Delta = 0.5 \\).\n- The function is constant within intervals of \\( x(n) \\), specifically from \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), \\(0.25\\) to \\(0.75\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for fewer bits needed for signal representation.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), indicating the input signal values, while the vertical axis is labeled \\(y(n)\\), representing the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also with no specific units.\n\nOverall Behavior and Trends:\n- The graph shows that the quantizer outputs 1.0 for all \\(x(n)\\) values greater than or equal to 0, and -1.0 for all \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the quantization threshold.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapping to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- There are no specific annotations or data points beyond the axes labels and quantization levels.\n- The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping positive or zero inputs to 1.0 and negative inputs to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "When $x(n)$ is highly active, $e(n)$ can be approximated as an independent random number uniformly distributed between $\\pm \\Delta / 2$, where $\\Delta$ is the difference between two adjacent quantization levels. Consequently, the quantization noise power is $\\Delta^{2} / 12$ (as per Section 15.3) and is independent of the sampling frequency, $f_{s}$. Additionally, the spectral density of $\\mathrm{e}(\\mathrm{n}), \\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, is white (constant across frequency) with all its power contained within $\\pm \\mathrm{f}_{\\mathrm{s}} / 2$ (using a two-sided power definition).\n\nGiven white quantization noise, the spectral density of the quantization noise, $\\mathrm{S}_{\\mathrm{e}}(\\mathrm{f})$, appears as depicted in Fig. 18.2.\n\nKey Point: Quantization with a step size \"LSB\" can be modeled as additive quantization noise uniformly distributed between $-L S B / 2$ and $+L S B / 2$, characterized by a white power spectrum and a total power of $\\operatorname{LSB}^{2} / 12$.\n\nThe spectral density height is determined by recognizing that the total noise power is $\\Delta^{2} / 12$ and, with a two-sided power definition, equals the area under $S_{e}(f)$ within $\\pm f_{s} / 2$, mathematically expressed as:\n\n$$\n\\begin{equation*}\n\\int_{-\\mathrm{s}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{~S}_{\\mathrm{e}}^{2}(\\mathrm{f}) \\mathrm{df}=\\int_{-\\mathrm{f}_{\\mathrm{s}} / 2}^{\\mathrm{f}_{\\mathrm{s}} / 2} \\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{df}=\\mathrm{k}_{\\mathrm{x}}^{2} \\mathrm{f}_{\\mathrm{s}}=\\frac{\\Delta^{2}}{12} \\tag{18.1}\n\\end{equation*}\n$$\n\nSolving this yields:\n\n$$\n\\begin{equation*}\n\\mathrm{k}_{\\mathrm{x}}=\\left(\\frac{\\Delta}{\\sqrt{12}}\\right) \\sqrt{\\frac{1}{\\mathrm{f}_{\\mathrm{s}}}} \\tag{18.2}\n\\end{equation*}\n$$\n\n#### EXAMPLE 18.1\n\nDetermine the output and quantization errors for two different quantizers, as illustrated in Fig. 18.3, given the input values:\n\n$$\n\\begin{equation*}\nx(n)=\\{0.01,0.31,-0.11,0.80,0.52,-0.70\\} \\tag{18.3}\n\\end{equation*}\n$$\n\nAlso, calculate the expected power and the power density height, $S_{e}^{2}(\\mathrm{f})$, of the quantization noise when the sampling frequency is normalized to $2 \\pi \\mathrm{rad} /$ sample.\n\n#### Solution\n\nThe output and quantization noise values for this example are presented in Table 18.1. Note that while the output signals, $y(n)$, are well-defined, the quantization error values can be approximated as uniformly distributed random numbers due to the active nature of the input signal.\n\nRecalling that the quantization noise power is given by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}}=\\frac{\\Delta^{2}}{12} \\tag{18.4}\n\\end{equation*}\n$$\n\nthe expected noise powers for the two quantizers are\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{I}}=\\frac{0.5^{2}}{12}=0.0208 \\mathrm{~W} \\tag{18.5}\n\\end{equation*}\n$$\n\nimage_name:Quantizer I (Five-level quantizer)\ndescription:This graph, titled \"Quantizer I (Five-level quantizer),\" illustrates a step function used in signal processing to convert continuous signal values into discrete levels. It is a piecewise constant function that maps input signal \\( x(n) \\) to a quantized output \\( y(n) \\) using five discrete levels.\n\nType of Graph and Function:\n- The graph represents a step function for quantization, a process in signal processing where continuous amplitude values are mapped to discrete levels.\n\nAxes Labels and Units:\n- The horizontal axis is labeled \\( x(n) \\), indicating the input signal values.\n- The vertical axis is labeled \\( y(n) \\), representing the quantized output levels.\n- The quantization step size \\( \\Delta \\) is 0.5.\n\nOverall Behavior and Trends:\n- The graph displays a staircase pattern with five distinct levels.\n- As \\( x(n) \\) increases, \\( y(n) \\) shifts to the nearest quantization level.\n- The levels are centered around 0, with steps at -1.0, -0.5, 0.0, 0.5, and 1.0.\n\nKey Features and Technical Details:\n- The quantization levels are evenly spaced with a step size \\( \\Delta = 0.5 \\).\n- The function remains constant within specific intervals of \\( x(n) \\), such as \\(-0.75\\) to \\(-0.25\\), \\(-0.25\\) to \\(0.25\\), and so on.\n- Each step represents a range of input values mapped to a single output level.\n\nAnnotations and Specific Data Points:\n- The graph marks critical transition points at \\( x(n) = -0.75, -0.25, 0.25, 0.75 \\) where the output level changes.\n- Each step is labeled with its corresponding output value \\( y(n) \\).\n\nThis quantizer reduces signal precision, introducing quantization noise as a trade-off for reduced bit requirements for signal representation.\nimage_name:Quantizer II (Two-level quantizer)\ndescription:The graph for \"Quantizer II (Two-level quantizer)\" shows a step function representing a two-level quantizer. The horizontal axis is labeled \\(x(n)\\), representing the input signal values, while the vertical axis is labeled \\(y(n)\\), indicating the quantized output values. The quantization step size \\(\\Delta\\) is 2.0.\n\nType of Graph and Function:\n- This is a piecewise constant function graph, specifically a step function, depicting the behavior of a two-level quantizer.\n\nAxes Labels and Units:\n- **Horizontal Axis (x(n))**: Represents the input signal values, with no specific units provided.\n- **Vertical Axis (y(n))**: Represents the quantized output values, ranging from -1.0 to 1.0, also with no specific units.\n\nOverall Behavior and Trends:\n- The graph shows that the quantizer outputs 1.0 for all \\(x(n)\\) values greater than or equal to 0, and -1.0 for all \\(x(n)\\) values less than 0. This binary behavior is typical of a two-level quantizer, simplifying the input signal to two possible output levels.\n\nKey Features and Technical Details:\n- The transition between the two levels occurs at \\(x(n) = 0\\), the threshold for quantization.\n- The quantizer has a step size \\(\\Delta = 2.0\\), indicating the range of input values mapping to the same quantized output level.\n\nAnnotations and Specific Data Points:\n- No specific annotations or data points are marked on the graph beyond the axes labels and quantization levels.\n- The graph effectively illustrates the binary decision-making process of the two-level quantizer, mapping any non-negative input to 1.0 and any negative input to -1.0.\n\nFig. 18.3 Two example quantizers.\n\n#### Table 18.1 Example signal values and quantization noise for two quantizers.\n\n|  | Quantizer I <br> (Five Levels) |  |  | Quantizer II <br> (Two Levels) |  |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |  | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| 0.01 | 0.0 | -0.01 |  | 1 | 0.99 |\n| 0.31 | 0.5 | 0.19 |  | 1 | 0.69 |\n| -0.11 | 0.0 | 0.11 |  | -1 | -0.89 |\n| 0.80 | 1.0 | 0.2 |  | 1 | 0.20 |\n| 0.52 | 0.5 | -0.02 |  | 1 | 0.48 |\n| -0.70 | -0.5 | 0.2 |  | -1 | -0.30 |\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{II}}=\\frac{2^{2}}{12}=0.333 \\mathrm{~W} \\tag{18.6}\n\\end{equation*}\n$$\n\nNote that these values remain unaffected by normalizing the sampling frequency. Also, the power estimates for $P_{I}$ and $P_{I I}$ correspond to rms power levels of 0.144 and 0.577, respectively.\n\nFor the power density, note that the power is evenly distributed between $\\pm f_{s} / 2$, resulting in a density of\n\n$$\n\\begin{equation*}\nS_{e}^{2}(f)=\\frac{P_{e}}{f_{s}} \\tag{18.7}\n\\end{equation*}\n$$\n\nwhich leads to\n\n$$\n\\begin{align*}\n& S_{\\mathrm{el}}^{2}(\\mathrm{f})=\\left(\\frac{0.0208}{2 \\pi}\\right)=0.00331 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}}  \\tag{18.8}\\\\\n& \\mathrm{~S}_{\\mathrm{elI}}^{2}(\\mathrm{f})=\\left(\\frac{0.333}{2 \\pi}\\right)=0.053 \\frac{\\mathrm{~W}}{\\mathrm{rad} / \\mathrm{sample}} \\tag{18.9}\n\\end{align*}\n$$"
},
{
    "text": "Oversampling takes place when the signals of interest are bandlimited to $f_{0}$, yet the sampling rate is set at $f_{s}$, where $f_{s}$ exceeds $2 f_{0}$ (with $2 f_{0}$ being the Nyquist rate, or the minimum required sampling rate for signals bandlimited to $f_{0}$). The oversampling ratio, denoted as OSR, is defined by\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since all signals of interest lie below $f_{0}$, $y_{1}(n)$ is processed by $H(f)$ to produce $y_{2}(n)$, as depicted in Fig. 18.4. This filter removes quantization noise (along with any other signals) exceeding $\\mathrm{f}_{0}$.\n\nAssuming the input signal is a sinusoidal wave, its highest peak value without clipping is $2^{\\mathrm{N}}(\\Delta / 2)$. For this peak sinusoidal wave, the signal power, $P_{s}$, is calculated as\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter represented by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block accepts the input signal, u(n), and quantizes it into discrete levels, producing y(n), which includes quantization noise due to the conversion.\n- **Filter H(f):** This block processes the quantized signal y(n). The filter's frequency response, shown in part (b) of the figure, is a brick-wall type, allowing frequencies below f to pass while attenuating those above f.\n\n2. **Information and Control Flow:**\n- The input signal u(n) enters the N-bit quantizer. The resulting quantized output, y(n), is then fed into the filter H(f).\n- The filter removes quantization noise and any other signals with frequencies above f, yielding the output y(n).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The signals are labeled as u(n), y(n), and y(n).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of f, indicating a gain of 1 for frequencies between -f and f and zero outside this range.\n\n4. **System Function:**\n- The system's primary role is to process an input signal, quantize it, and filter out unwanted noise and signals above a specific frequency. The N-bit quantizer introduces quantization noise, which the filter H(f) then attenuates. The system is designed to retain signal components below the cutoff frequency f while reducing the quantization noise power in the output y(n).\nimage_name:(b)\ndescription:Fig. 18.4(b) presents a frequency response plot, specifically showing the magnitude response of a low-pass filter with a brick-wall characteristic.\n\n1. **Graph Type and Function:**\n- This is a magnitude frequency response graph.\n- The depicted function is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\), typically in hertz (Hz).\n- The vertical axis represents the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Behavior and Trends:**\n- The graph displays a rectangular shape, indicating a sharp cutoff at \\( f_0 \\).\n- The magnitude remains constant at 1 (unity gain) for frequencies between \\(-f_0\\) and \\( f_0\\), dropping to 0 outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is clearly marked at \\( f_0 \\) and \\(-f_0\\).\n- The filter allows all frequencies within \\(-f_0\\) to \\( f_0\\) to pass without attenuation, completely attenuating frequencies outside this range.\n- The transition from passband to stopband is instantaneous, typical of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin, indicating an even filter response.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented by the sampling frequency \\( f_s \\).\n\nFig. 18.4 (a) Illustrates a potential oversampling system without noise shaping. (b) Shows the brick-wall response of the filter to eliminate much of the quantization noise.\n\nThe power of the input signal within $\\mathrm{y}_{2}(\\mathrm{n})$ remains unchanged, assuming the signal's frequency content is below $f_{0}$. However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling the OSR (i.e., doubling the sampling rate) reduces the quantization noise power by half, or equivalently, by 3 dB (or 0.5 bits).\n\nWe can also compute the maximum SQNR (in dB) as the ratio of the maximum sinusoidal power to the quantization noise power in $\\mathrm{y}_{2}(\\mathrm{n})$. Using equations (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich can also be expressed as\n\nKey Point: Oversampling a signal by a factor of OSR relative to the Nyquist rate, without spectrally shaping the quantization noise, results in an SNR improvement of $10 \\log (O S R) d B$.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term signifies the SQNR enhancement from oversampling. Here, we observe that straightforward oversampling yields a SQNR improvement of 3 dB per octave, or 0.5 bits per octave. The reason for this SQNR enhancement via oversampling is that when quantized samples are averaged, the signal components add linearly, whereas the noise components add as the square root of the sum of the squares. This improvement also applies to other noise types, such as thermal noise in circuits, thereby generally enhancing the overall SNR by $10 \\log (\\mathrm{OSR})$.\n\n[^0]:    1. Indeed, the resistor-string $D / A$ was used to implement an $A / D$ converter in the reference.\n[^1]:    1. Strictly speaking, since each stage generates one of three digital output codes (00, 01, or 11), they are actually $\\log _{2}(3)=1.585$-bit stages, but in practice, they are always referred to as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is sometimes also known as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, $\\mathrm{V}_{\\mathrm{s}}$, with a value of 1 V, where the measured voltage, $\\mathrm{V}_{\\text {meas }}$, is $\\mathrm{V}_{\\mathrm{s}}$ plus a noise signal, $\\mathrm{V}_{\\text {noise }}$. Assume $\\mathrm{V}_{\\text {noise }}$ is a random signal uniformly distributed between $\\pm \\sqrt{3}$. What is the SNR for $\\mathrm{V}_{\\text {meas }}$ when examining individual values? If eight samples of $\\mathrm{V}_{\\text {meas }}$ are averaged, approximately what is the new SNR? To illustrate, use eight typical samples for $\\mathrm{V}_{\\text {meas }}$ of $\\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\\}$.\n\n#### Solution\n\nReferencing signals to $1 \\Omega$, we find the power of $V_{s}$ and $V_{\\text {noise }}$ to be 1 watt each. Thus, the SNR for $V_{\\text {meas }}$ is 0 dB when considering individual $\\mathrm{V}_{\\text {meas }}$ values. Note that it is challenging to discern the signal value of 1 V in the example $V_{\\text {meas }}$ samples due to the poor SNR.\n\nAveraging eight samples effectively implements a basic low-pass filter, approximating an oversampling ratio of about 8 (this is a rough estimate as a brick-wall filter is not used). Since each octave of oversampling improves the SNR by 3 dB, the averaged value should exhibit an SNR of around 9 dB. Note that averaging the given eight $\\mathrm{V}_{\\text {meas }}$ samples results in 0.8875, which more closely reflects the signal value of 1 V.\n\nThe rationale behind the SNR improvement through oversampling here is that summing eight measured values results in the eight signal values adding linearly to $8 \\mathrm{~V}_{\\mathrm{rms}}$ (or 64 watts), whereas the eight noise values sum to $\\sqrt{8} \\mathrm{~V}_{\\mathrm{rms}}$ (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary using oversampling (without noise shaping) to achieve a $96-\\mathrm{dB}$ SQNR (equivalent to 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$? (Note that the input to the $\\mathrm{A} / \\mathrm{D}$ converter must be highly active for the white-noise quantization model to be valid, a challenging condition when using a 1-bit quantizer with oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping yields a 3 dB improvement per octave, where one octave corresponds to doubling the sampling rate. We need 90 dB divided by 3 dB per octave, resulting in 30 octaves. Thus, the required sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\mathrm{GHz}!\n$$\n\nThis example demonstrates why noise shaping is essential to enhance the SQNR faster than 3 dB per octave, as 54,000 GHz is impractically high."
},
{
    "text": "Oversampling takes place when the signals of interest are bandlimited to \\( f_0 \\), yet the sampling rate is \\( f_s \\), where \\( f_s > 2f_0 \\) (with \\( 2f_0 \\) being the Nyquist rate or the minimum required sampling rate for signals bandlimited to \\( f_0 \\)). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, as the signals of interest are all below \\( f_0 \\), \\( y_1(n) \\) is filtered by \\( H(f) \\) to produce \\( y_2(n) \\), as depicted in Fig. 18.4. This filter removes quantization noise (and any other signals) above \\( f_0 \\).\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is \\( 2^{\\mathrm{N}}(\\Delta / 2) \\). For this peak sinusoidal wave, the signal power, \\( P_s \\), is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The system block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block accepts the input signal, \\( u(n) \\), and quantizes it to discrete levels, producing \\( y_1(n) \\) with inherent quantization noise.\n- **Filter H(f):** This block processes \\( y_1(n) \\). The filter's frequency response, shown in part (b), is a brick-wall type, allowing frequencies below \\( f_0 \\) to pass while attenuating those above \\( f_0 \\).\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the N-bit quantizer, producing \\( y_1(n) \\), which is then fed to the filter H(f).\n- The filter removes quantization noise and other signals above \\( f_0 \\), resulting in \\( y_2(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The signals are labeled \\( u(n) \\), \\( y_1(n) \\), and \\( y_2(n) \\).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff at \\( f_0 \\), indicating a gain of 1 for frequencies between -\\( f_0 \\) and \\( f_0 \\) and zero outside this range.\n\n4. **Overall System Function:**\n- The system quantizes the input signal and filters out unwanted noise and signals above a specific frequency. The N-bit quantizer introduces quantization noise, which the filter H(f) attenuates. The system retains signal components below \\( f_0 \\) while reducing the quantization noise power in \\( y_2(n) \\).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) presents a frequency response plot, specifically the magnitude response of a low-pass filter with a brick-wall characteristic.\n\n1. **Type of Graph and Function:**\n- This is a magnitude frequency response graph.\n- The function depicted is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\) in hertz (Hz).\n- The vertical axis shows the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Overall Behavior and Trends:**\n- The graph displays a rectangular shape, indicating a sharp cutoff at \\( f_0 \\).\n- The magnitude is constant at 1 for frequencies between -\\( f_0 \\) and \\( f_0 \\), dropping to 0 outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is clearly marked at \\( f_0 \\) and -\\( f_0 \\).\n- The filter passes frequencies from -\\( f_0 \\) to \\( f_0 \\) without attenuation, completely attenuating frequencies outside this range.\n- The transition from passband to stopband is instantaneous, typical of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin, indicating an even filter response.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented given \\( f_s \\).\n\nFig. 18.4 (a) shows an oversampling system without noise shaping. (b) illustrates the brick-wall filter response to remove much of the quantization noise.\n\nThe power of the input signal within \\( y_2(n) \\) remains unchanged, assuming the signal's frequency content is below \\( f_0 \\). However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling the OSR (i.e., doubling the sampling rate) halves the quantization noise power, or equivalently, reduces it by 3 dB (or 0.5 bits).\n\nWe can also compute the maximum SQNR (in dB) as the ratio of the maximum sinusoidal power to the quantization noise power in \\( y_2(n) \\). Mathematically, using (18.11) and (18.12), we have\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of \\( 10 \\log (OSR) \\) dB.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term represents the SQNR enhancement from oversampling. Straight oversampling yields a SQNR improvement of 3 dB per octave, or 0.5 bits per octave. This SQNR improvement arises because quantized samples, when averaged, have their signal portions add linearly, whereas the noise portions add as the square root of the sum of the squares. This enhancement applies to other noise types, such as thermal noise, thereby improving the overall SNR by \\( 10 \\log (OSR) \\).\n\n[^0]:    1. In fact, the resistor-string D/A was used to realize an A/D converter in the reference.\n[^1]:    1. Strictly speaking, each stage produces one of three digital output codes (00, 01, or 11), making them actually \\(\\log_2(3)=1.585\\)-bit stages, but they are typically referred to as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is sometimes also called sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, \\( V_s \\), of 1 V, where the measured voltage, \\( V_{\\text{meas}} \\), is \\( V_s \\) plus a noise signal, \\( V_{\\text{noise}} \\). Assume \\( V_{\\text{noise}} \\) is a random signal uniformly distributed between \\( \\pm \\sqrt{3} \\). What is the SNR for \\( V_{\\text{meas}} \\) when examining individual values? If eight samples of \\( V_{\\text{meas}} \\) are averaged, what is the approximate new SNR? To illustrate, use eight typical samples for \\( V_{\\text{meas}} \\) of \\( \\{0.94, -0.52, -0.73, 2.15, 1.91, 1.33, -0.31, 2.33\\} \\).\n\n#### Solution\n\nReferencing signals to 1 , the power of \\( V_s \\) and \\( V_{\\text{noise}} \\) is calculated as 1 watt each. Thus, the SNR for \\( V_{\\text{meas}} \\) is 0 dB when looking at individual values. Note that it is challenging to discern the 1 V signal in the example \\( V_{\\text{meas}} \\) samples due to the poor SNR.\n\nIf eight samples are averaged, this approximates a low-pass filter, with the oversampling ratio roughly equal to 8 (a rough estimate since a brick-wall filter isn't used). Since each octave of oversampling improves SNR by 3 dB, the averaged value should have an SNR around 9 dB. Averaging the given \\( V_{\\text{meas}} \\) samples results in 0.8875, closer to the signal value of 1 V.\n\nOversampling improves the SNR here because summing eight measured values results in the signal values adding linearly to \\( 8 V_{\\text{rms}} \\) (or 64 watts), while the noise values add to \\( \\sqrt{8} V_{\\text{rms}} \\) (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a 6-dB SQNR, what sample rate is needed using oversampling (without noise shaping) to achieve a 96-dB SQNR (i.e., 16 bits) if \\( f_0 = 25 \\text{kHz} \\)? (Note that the input to the A/D converter must be very active for the white-noise quantization model to be valida challenging condition with a 1-bit quantizer and oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping provides a 3 dB improvement per octave, where 1 octave corresponds to doubling the sampling rate. We need 90 dB divided by 3 dB per octave, or 30 octaves. Thus, the required sampling rate, \\( f_s \\), is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\text{GHz}!\n$$\n\nThis example illustrates why noise shaping is necessary to improve the SQNR faster than 3 dB per octave, as 54,000 GHz is highly impractical."
},
{
    "text": "Oversampling takes place when the signals of interest are bandlimited to \\( f_0 \\) but the sampling rate is set at \\( f_s \\), where \\( f_s > 2f_0 \\) (with \\( 2f_0 \\) being the Nyquist rate or the minimum sampling rate for signals bandlimited to \\( f_0 \\)). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since all signals of interest are below \\( f_0 \\), \\( y_1(n) \\) is filtered by \\( H(f) \\) to produce \\( y_2(n) \\), as depicted in Fig. 18.4. This filter removes quantization noise (and any other signals) exceeding \\( f_0 \\).\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is \\( 2^{\\mathrm{N}}(\\Delta / 2) \\). For this maximum sinusoidal wave, the signal power, \\( P_s \\), is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The system block diagram labeled as (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block receives the input signal, \\( u(n) \\), and quantizes it into discrete levels. The output, \\( y_1(n) \\), includes quantization noise due to the conversion.\n- **Filter H(f):** This block processes the quantized signal \\( y_1(n) \\). The filter's frequency response, shown in part (b) of the figure, is a brick-wall filter that allows frequencies below \\( f_0 \\) to pass while attenuating those above \\( f_0 \\).\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the N-bit quantizer. The quantized output, \\( y_1(n) \\), is then passed to the filter H(f).\n- The filter removes quantization noise and any other signals with frequencies greater than \\( f_0 \\), resulting in the output \\( y_2(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input and output signals are labeled as \\( u(n) \\), \\( y_1(n) \\), and \\( y_2(n) \\).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of \\( f_0 \\), indicating a gain of 1 for frequencies between -\\( f_0 \\) and \\( f_0 \\) and zero outside this range.\n\n4. **Overall System Function:**\n- The system processes an input signal, quantizes it, and filters out unwanted noise and signals above a certain frequency. The N-bit quantizer introduces quantization noise, which is then attenuated by the filter H(f). The system retains signal components below \\( f_0 \\) while reducing the power of quantization noise in the output \\( y_2(n) \\).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) shows a frequency response plot, specifically the magnitude response of a low-pass filter with a brick-wall characteristic.\n\n1. **Type of Graph and Function:**\n- This is a magnitude frequency response graph.\n- The function depicted is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\), typically in hertz (Hz).\n- The vertical axis represents the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Overall Behavior and Trends:**\n- The graph exhibits a rectangular shape, indicating a sharp cutoff at \\( f_0 \\).\n- The magnitude is constant and equal to 1 for frequencies between -\\( f_0 \\) and \\( f_0 \\), and drops to 0 outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is clearly marked at \\( f_0 \\) and -\\( f_0 \\).\n- The filter passes frequencies in the range -\\( f_0 \\) to \\( f_0 \\) without attenuation, while completely attenuating frequencies outside this range.\n- The transition from passband to stopband is instantaneous, characteristic of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin, indicating an even filter response.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented given the sampling frequency \\( f_s \\).\n\nFig. 18.4 (a) illustrates a potential oversampling system without noise shaping. (b) The brick-wall response of the filter to eliminate much of the quantization noise.\n\nThe power of the input signal within \\( y_2(n) \\) remains unchanged since we assumed the signal's frequency content is below \\( f_0 \\). However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling OSR (i.e., doubling the sampling rate) reduces the quantization noise power by half, or equivalently, 3 dB (or 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in \\( y_2(n) \\). Mathematically, using (18.11) and (18.12), we have\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of \\( 10 \\log (\\mathrm{OSR}) \\) dB.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term accounts for the SQNR enhancement from oversampling. Here, straight oversampling yields a SQNR improvement of 3 dB/octave or 0.5 bits/octave. The reason for this SQNR improvement via oversampling is that when quantized samples are averaged, the signal portion adds linearly, whereas the noise portion adds as the square root of the sum of the squares. This enhancement also applies to other types of noise, such as thermal noise in circuits, thereby generally improving the overall SNR by \\( 10 \\log (\\mathrm{OSR}) \\).\n\n[^0]:    1. In fact, the resistor-string D/A was used to realize an A/D converter in the reference.\n[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes (00, 01, or 11), they are actually \\(\\log_2(3)=1.585\\)-bit stages, but in practice they are always referred to simply as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, \\( V_s \\), of value 1 V where the measured voltage, \\( V_{\\text{meas}} \\), is \\( V_s \\) plus a noise signal, \\( V_{\\text{noise}} \\). Assume \\( V_{\\text{noise}} \\) is a random signal uniformly distributed between \\( \\pm \\sqrt{3} \\). What is the SNR for \\( V_{\\text{meas}} \\) when looking at individual values? If eight samples of \\( V_{\\text{meas}} \\) are averaged, what is the approximate new SNR? To illustrate, use eight typical samples for \\( V_{\\text{meas}} \\) of \\( \\{0.94, -0.52, -0.73, 2.15, 1.91, 1.33, -0.31, 2.33\\} \\).\n\n#### Solution\n\nReferencing signals to 1 , we calculate the power of \\( V_s \\) and \\( V_{\\text{noise}} \\) to both be 1 watt. Thus, the SNR for \\( V_{\\text{meas}} \\) is 0 dB when examining individual \\( V_{\\text{meas}} \\) values. Note that it is difficult to discern the signal value of 1 V in the example \\( V_{\\text{meas}} \\) samples due to the poor SNR.\n\nIf eight samples are averaged, it approximates a low-pass filter, resulting in an oversampling ratio of roughly 8 (this is a rough estimate since a brick-wall filter is not used). Since each octave of oversampling improves SNR by 3 dB, the averaged value should have an SNR of around 9 dB. Note that averaging the eight given \\( V_{\\text{meas}} \\) samples results in 0.8875, which more closely represents the signal value of 1 V.\n\nThe reason oversampling enhances SNR here is that summing eight measured values results in the eight signal values adding linearly to \\( 8 \\text{ V}_{\\text{rms}} \\) (or 64 watts), while the eight noise values add to \\( \\sqrt{8} \\text{ V}_{\\text{rms}} \\) (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a 6-dB SQNR, what sample rate is required using oversampling (without noise shaping) to achieve a 96-dB SQNR (i.e., 16 bits) if \\( f_0 = 25 \\text{ kHz} \\)? (Note that the input to the A/D converter must be very active for the white-noise quantization model to be valida challenging setup when using a 1-bit quantizer with oversampling without noise shaping.)\n\n#### Solution\n\nOversampling (without noise shaping) provides 3 dB/octave improvement, where 1 octave corresponds to doubling the sampling rate. We need 90 dB divided by 3 dB/octave, or 30 octaves. Thus, the required sampling rate, \\( f_s \\), is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\text{ GHz}!\n$$\n\nThis example demonstrates why noise shaping is necessary to enhance SQNR faster than 3 dB/octave, as 54,000 GHz is highly impractical."
},
{
    "text": "Oversampling arises when the signals of interest are bandlimited to $f_{0}$, yet the sampling rate is set at $f_{s}$, where $f_{s}$ exceeds $2 f_{0}$ (with $2 f_{0}$ being the Nyquist rate, or the minimum required sampling rate for signals bandlimited to $f_{0}$). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, as the signals of interest lie below $f_{0}$, $y_{1}(n)$ is processed by $H(f)$ to generate $y_{2}(n)$, as depicted in Fig. 18.4. This filter removes quantization noise (and any other signals) exceeding $\\mathrm{f}_{0}$.\n\nAssuming a sinusoidal input signal, its maximum peak value without clipping is $2^{\\mathrm{N}}(\\Delta / 2)$. For this peak sinusoidal wave, the signal power, $P_{s}$, is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block accepts the input signal, u(n), and quantizes it into discrete levels, producing y(n) with inherent quantization noise.\n- **Filter H(f):** This block processes y(n). The filter's frequency response, shown in part (b), is a brick-wall type, allowing frequencies below f while attenuating those above f.\n\n2. **Information Flow:**\n- The input signal u(n) enters the N-bit quantizer, producing y(n), which is then fed to the filter H(f).\n- The filter removes quantization noise and other signals above f, resulting in y(n).\n\n3. **Labels and Annotations:**\n- Signals are labeled u(n), y(n), and y(n).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff at f, indicating unity gain for frequencies within -f to f and zero outside.\n\n4. **System Function:**\n- The system quantizes the input signal and filters out noise and signals above f. The N-bit quantizer introduces noise, which the filter H(f) attenuates. The system retains signal components below f while reducing quantization noise in y(n).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) shows a frequency response plot of a low-pass filter with a brick-wall characteristic.\n\n1. **Graph Type and Function:**\n- This is a magnitude frequency response graph.\n- It depicts a brick-wall low-pass filter.\n\n2. **Axes and Units:**\n- The horizontal axis is frequency \\( f \\) (Hz).\n- The vertical axis is the magnitude \\(|H(f)|\\) (unitless).\n- Both axes are linear.\n\n3. **Behavior and Trends:**\n- The graph displays a sharp cutoff at \\( f_0 \\), forming a rectangular shape.\n- The magnitude is 1 for frequencies between \\(-f_0\\) and \\(f_0\\), and 0 outside.\n\n4. **Key Features:**\n- Cutoff frequencies are marked at \\( f_0 \\) and \\(-f_0\\).\n- The filter passes frequencies in \\(-f_0\\) to \\(f_0\\) without attenuation and completely attenuates others.\n- The transition is instantaneous, typical of an ideal filter.\n\n5. **Annotations:**\n- The graph is symmetric around the origin.\n- Passband gain is 1, and stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum representable frequency.\n\nFig. 18.4 (a) shows a possible oversampling system without noise shaping. (b) illustrates the brick-wall filter response for removing quantization noise.\n\nThe power of the input signal in $\\mathrm{y}_{2}(\\mathrm{n})$ remains unchanged, assuming its frequency content is below $f_{0}$. However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling OSR reduces quantization noise power by half, or 3 dB (equivalent to 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in $\\mathrm{y}_{2}(\\mathrm{n})$. Using (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \\log (O S R) d B$.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR from the N-bit quantizer, while the OSR term denotes the SQNR enhancement from oversampling. Straight oversampling yields a SQNR improvement of 3 dB/octave, or 0.5 bits/octave. This improvement arises because quantized samples, when averaged, add linearly for the signal but as the square root of the sum of squares for the noise. This enhancement applies to other noise types, such as thermal noise, thus generally improving the SNR by $10 \\log (\\mathrm{OSR})$.\n\n[^0]:    1. The resistor-string D/A was indeed used to realize an A/D converter in the reference.\n[^1]:    1. Technically, each stage produces one of three digital output codes (00, 01, or 11), making them $\\log _{2}(3)=1.585$-bit stages, but they are commonly referred to as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is also known as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, $\\mathrm{V}_{\\mathrm{s}}$, of 1 V, where the measured voltage, $\\mathrm{V}_{\\text {meas }}$, is $\\mathrm{V}_{\\mathrm{s}}$ plus noise, $\\mathrm{V}_{\\text {noise }}$. Assume $\\mathrm{V}_{\\text {noise }}$ is uniformly distributed between $\\pm \\sqrt{3}$. What is the SNR for $\\mathrm{V}_{\\text {meas }}$ when examining individual values? If eight samples of $\\mathrm{V}_{\\text {meas }}$ are averaged, what is the approximate new SNR? Use typical samples $\\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\\}$ to illustrate.\n\n#### Solution\n\nReferencing signals to $1 \\Omega$, both $V_{s}$ and $V_{\\text {noise }}$ have powers of 1 watt, resulting in a 0 dB SNR for individual $\\mathrm{V}_{\\text {meas }}$ values. The signal value of 1 V is hard to discern in the example samples due to the poor SNR.\n\nAveraging eight samples acts like a simple low-pass filter, roughly equivalent to an OSR of 8. Each octave of oversampling improves SNR by 3 dB, so the averaged value should have an SNR around 9 dB. Averaging the given samples results in 0.8875, closer to the true signal value of 1 V.\n\nOversampling enhances SNR because summing eight measured values linearly adds the signal to $8 \\mathrm{~V}_{\\mathrm{rms}}$ (64 watts), while the noise adds as $\\sqrt{8} \\mathrm{~V}_{\\mathrm{rms}}$ (8 watts), assuming independence.\n\n#### EXAMPLE 18.3\n\nFor a 1-bit A/D converter with a 6-dB SQNR, what sample rate is needed using oversampling (without noise shaping) to achieve a 96-dB SQNR (16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$? (Note: The input must be very active for the white-noise quantization model to apply, challenging with a 1-bit quantizer and oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping improves SQNR by 3 dB/octave. To achieve 90 dB improvement, we need 30 octaves. Thus, the required sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\mathrm{GHz}!\n$$\n\nThis example demonstrates the need for noise shaping to enhance SQNR faster than 3 dB/octave, as 54,000 GHz is impractical."
},
{
    "text": "Oversampling arises when the signals of interest are bandlimited to $f_{0}$, yet the sampling rate is set at $f_{s}$, where $f_{s} > 2f_{0}$ (with $2f_{0}$ representing the Nyquist rate or the minimum sampling rate for signals bandlimited to $f_{0}$). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since all signals of interest lie below $f_{0}$, $y_{1}(n)$ is filtered by $H(f)$ to produce $y_{2}(n)$, as depicted in Fig. 18.4. This filter removes quantization noise (along with any other signals) exceeding $\\mathrm{f}_{0}$.\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is $2^{\\mathrm{N}}(\\Delta / 2)$. For this maximum sinusoidal wave, the signal power, $P_{s}$, is given by\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The system block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block receives the input signal, u(n), and quantizes it into discrete levels. The output, y(n), includes quantization noise due to the conversion.\n- **Filter H(f):** This block processes y(n). The filter's frequency response, shown in part (b) of the figure, is a brick-wall filter that passes frequencies below f and attenuates those above f.\n\n2. **Flow of Information or Control:**\n- The input signal u(n) enters the N-bit quantizer, producing y(n), which is then passed to the filter H(f).\n- The filter removes quantization noise and other signals with frequencies greater than f, resulting in y(n).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The signals are labeled as u(n), y(n), and y(n).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of f, indicating a gain of 1 for frequencies between -f and f and zero outside this range.\n\n4. **Overall System Function:**\n- The system processes an input signal, quantizes it, and filters out unwanted noise and signals above a certain frequency. The N-bit quantizer introduces quantization noise, which is then reduced by the filter H(f). The system retains signal components below f while minimizing quantization noise in y(n).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) shows a frequency response plot of a low-pass filter with a brick-wall characteristic.\n\n1. **Type of Graph and Function:**\n- This is a magnitude frequency response graph.\n- The function depicted is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\) in hertz (Hz).\n- The vertical axis represents the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Overall Behavior and Trends:**\n- The graph displays a rectangular shape, indicating a sharp cutoff at \\( f_0 \\).\n- The magnitude is constant at 1 for frequencies between \\(-f_0\\) and \\( f_0\\), and drops to 0 outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is marked at \\( f_0 \\) and \\(-f_0\\).\n- The filter allows frequencies in the range \\(-f_0\\) to \\( f_0\\) without attenuation, while completely blocking frequencies outside this range.\n- The transition from passband to stopband is instantaneous, typical of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin, indicating an even filter response.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented given the sampling frequency \\( f_s \\).\n\nFig. 18.4 (a) An example of an oversampling system without noise shaping. (b) The brick-wall filter response for removing much of the quantization noise.\n\nThe power of the input signal within $\\mathrm{y}_{2}(\\mathrm{n})$ remains unchanged, assuming the signal's frequency content is below $f_{0}$. However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling the OSR (i.e., doubling the sampling rate) reduces the quantization noise power by half, or equivalently, 3 dB (or 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in $\\mathrm{y}_{2}(\\mathrm{n})$. Using equations (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equivalent to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \\log (O S R) d B$.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term reflects the SQNR enhancement from oversampling. Here, straight oversampling yields a SQNR improvement of 3 dB per octave, or 0.5 bits per octave. The SQNR improvement through oversampling occurs because quantized samples, when averaged, result in linear addition of the signal portion and square root of the sum of squares addition of the noise portion. This enhancement also applies to other noise types, such as thermal noise in circuits, thereby generally improving the overall SNR by $10 \\log (\\mathrm{OSR})$.\n\n[^0]:    1. In fact, the resistor-string $D / A$ was used to realize an $A / D$ converter in the reference.\n[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes (00, 01, or 11), they are actually $\\log _{2}(3)=1.585$-bit stages, but in practice they are always referred to simply as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, $\\mathrm{V}_{\\mathrm{s}}$, with a value of 1 V, where the measured voltage, $\\mathrm{V}_{\\text {meas }}$, is $\\mathrm{V}_{\\mathrm{s}}$ plus a noise signal, $\\mathrm{V}_{\\text {noise }}$. Assume $\\mathrm{V}_{\\text {noise }}$ is a random signal uniformly distributed between $\\pm \\sqrt{3}$. What is the SNR for $\\mathrm{V}_{\\text {meas }}$ when examining individual values? If eight samples of $\\mathrm{V}_{\\text {meas }}$ are averaged, what is the approximate new SNR? To illustrate, use eight typical $\\mathrm{V}_{\\text {meas }}$ samples: $\\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\\}$.\n\n#### Solution\n\nReferencing signals to $1 \\Omega$, the power of $V_{s}$ and $V_{\\text {noise }}$ is calculated to be 1 watt each. Thus, the SNR for $V_{\\text {meas }}$ is 0 dB when examining individual values. Note that the signal value of 1 V is difficult to discern in the example $V_{\\text {meas }}$ samples due to the poor SNR.\n\nAveraging eight samples acts as a simple low-pass filter, roughly equivalent to an oversampling ratio of 8 (this is an approximation since a brick-wall filter is not used). Given that each octave of oversampling improves SNR by 3 dB, the averaged value should have an SNR of approximately 9 dB. Averaging the given $\\mathrm{V}_{\\text {meas }}$ samples results in 0.8875, which more closely represents the signal value of 1 V.\n\nThe SNR improvement from oversampling here is due to the linear addition of the eight signal values to $8 \\mathrm{~V}_{\\mathrm{rms}}$ (or 64 watts), while the eight noise values sum to $\\sqrt{8} \\mathrm{~V}_{\\mathrm{rms}}$ (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a 6-dB SQNR, what sample rate is required using oversampling (without noise shaping) to achieve a 96-dB SQNR (i.e., 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$? (Note that the input to the A/D converter must be very active for the white-noise quantization model to be valid, a challenging condition when using a 1-bit quantizer with oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping provides a 3 dB improvement per octave, where one octave corresponds to doubling the sampling rate. To achieve a 90 dB increase (from 6 dB to 96 dB), we need 30 octaves. Thus, the required sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\mathrm{GHz}!\n$$\n\nThis example illustrates why noise shaping is necessary to enhance the SQNR faster than 3 dB per octave, as 54,000 GHz is impractically high."
},
{
    "text": "Oversampling arises when the signals of interest are bandlimited to $f_{0}$, yet the sampling rate is $f_{s}$, where $f_{s}>2 f_{0}$ (with $2 f_{0}$ being the Nyquist rate or the minimum required sampling rate for signals bandlimited to $f_{0}$). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since the signals of interest are all below $f_{0}$, $y_{1}(n)$ is filtered by $H(f)$ to produce $y_{2}(n)$, as depicted in Fig. 18.4. This filter removes quantization noise (and any other signals) exceeding $\\mathrm{f}_{0}$.\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is $2^{\\mathrm{N}}(\\Delta / 2)$. For this maximum sinusoidal wave, the signal power, $P_{s}$, is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The system block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter represented by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block accepts the input signal, u(n), and quantizes it into discrete levels. The output, y(n), includes quantization noise due to the conversion.\n- **Filter H(f):** This block processes y(n). The filter's frequency response, shown in part (b) of the figure, is a brick-wall filter that passes frequencies below f and attenuates those above f.\n\n2. **Information Flow:**\n- The input signal u(n) enters the N-bit quantizer. The quantized output, y(n), is then routed to the filter H(f).\n- The filter eliminates quantization noise and other signals with frequencies greater than f, producing y(n).\n\n3. **Labels and Annotations:**\n- The input and output signals are labeled u(n), y(n), and y(n).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of f, indicating a gain of 1 for frequencies between -f and f and zero outside this range.\n\n4. **System Function:**\n- This system processes an input signal, quantizes it, and filters out unwanted noise and signals above a specific frequency. The N-bit quantizer introduces quantization noise, which the filter H(f) attenuates. The system aims to retain signal components below f while reducing quantization noise in y(n).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) shows a frequency response plot of a low-pass filter with a brick-wall characteristic.\n\n1. **Graph Type and Function:**\n- This is a magnitude frequency response graph.\n- The function is a brick-wall low-pass filter.\n\n2. **Axes and Units:**\n- The horizontal axis is frequency \\( f \\), typically in hertz (Hz).\n- The vertical axis is the magnitude \\(|H(f)|\\) of the filter response, unitless.\n- Both axes are linear.\n\n3. **Behavior and Trends:**\n- The graph displays a rectangular shape with a sharp cutoff at \\( f_0 \\).\n- The magnitude is constant at 1 for frequencies between \\(-f_0\\) and \\(f_0\\), dropping to 0 outside this range.\n\n4. **Key Features:**\n- The cutoff frequency is marked at \\( f_0 \\) and \\(-f_0\\).\n- The filter passes frequencies from \\(-f_0\\) to \\(f_0\\) without attenuation and completely attenuates frequencies outside this range.\n- The transition from passband to stopband is instantaneous, typical of an ideal filter.\n\n5. **Annotations:**\n- The graph is symmetric around the origin.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is indicated on the axis.\n\nFig. 18.4 (a) depicts a potential oversampling system without noise shaping. (b) shows the brick-wall response of the filter to eliminate much of the quantization noise.\n\nThe power of the input signal within $\\mathrm{y}_{2}(\\mathrm{n})$ remains unchanged, assuming the signal's frequency content is below $f_{0}$. However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling OSR (i.e., doubling the sampling rate) reduces the quantization noise power by half, or equivalently, 3 dB (or 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in $\\mathrm{y}_{2}(\\mathrm{n})$. Using (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \\log (O S R) d B$.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term reflects the SQNR enhancement from oversampling. Here, straightforward oversampling yields a SQNR improvement of $3 \\mathrm{~dB} /$ octave or 0.5 bits/octave. The SQNR improvement through oversampling arises because quantized samples, when averaged, add linearly for the signal portion, whereas the noise portion adds as the square root of the sum of the squares. This enhancement applies to other noise types, such as thermal noise, thereby generally improving the overall SNR by $10 \\log (\\mathrm{OSR})$.\n\n[^0]:    1. In fact, the resistor-string $D / A$ was used to realize an $A / D$ converter in the reference.\n[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes $(00,01$, or 11$)$, they are actually $\\log _{2}(3)=1.585$-bit stages, but in practice they are always referred to simply as 1.5 -bit stages.\n[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, $\\mathrm{V}_{\\mathrm{s}}$, of 1 V where the measured voltage, $\\mathrm{V}_{\\text {meas }}$, is $\\mathrm{V}_{\\mathrm{s}}$ plus a noise signal, $\\mathrm{V}_{\\text {noise }}$. Assume $\\mathrm{V}_{\\text {noise }}$ is a random signal uniformly distributed between $\\pm \\sqrt{3}$. What is the SNR for $\\mathrm{V}_{\\text {meas }}$ when examining individual values? If eight samples of $\\mathrm{V}_{\\text {meas }}$ are averaged, what is the approximate new SNR? To illustrate, use eight typical samples for $\\mathrm{V}_{\\text {meas }}$ of $\\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\\}$.\n\n#### Solution\n\nReferencing signals to $1 \\Omega$, the power of $V_{s}$ and $V_{\\text {noise }}$ is calculated as 1 watt each. Thus, the SNR for $V_{\\text {meas }}$ is 0 dB when examining individual values. Note that in the given $V_{\\text {meas }}$ samples, it is challenging to discern the signal value of 1 V due to the poor SNR.\n\nAveraging eight samples effectively acts as a basic low-pass filter, approximating an oversampling ratio of 8 (a rough estimate since a brick-wall filter is not used). Since each octave of oversampling improves SNR by 3 dB, the averaged value should have an SNR of about 9 dB. Averaging the eight provided $\\mathrm{V}_{\\text {meas }}$ samples results in 0.8875, which more closely represents the signal value of 1 V.\n\nThe SNR improvement from oversampling here stems from the fact that summing eight measured values results in the signal values adding linearly to $8 \\mathrm{~V}_{\\mathrm{rms}}$ (or 64 watts), while the noise values add to $\\sqrt{8} \\mathrm{~V}_{\\mathrm{rms}}$ (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is needed using oversampling (without noise shaping) to achieve a $96-\\mathrm{dB}$ SQNR (i.e., 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$? (Note that for the white-noise quantization model to be valid, the input to the $\\mathrm{A} / \\mathrm{D}$ converter must be very active, a challenging condition with a 1-bit quantizer and oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping provides a 3 dB/octave improvement, where one octave corresponds to doubling the sampling rate. To achieve 90 dB improvement, we need 30 octaves. Thus, the required sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\mathrm{GHz}!\n$$\n\nThis example illustrates why noise shaping is necessary to enhance the SQNR faster than 3 dB/octave, as 54,000 GHz is impractically high."
},
{
    "text": "Oversampling occurs when the signals of interest are bandlimited to \\( f_0 \\), yet the sample rate is \\( f_s \\), where \\( f_s > 2f_0 \\) (with \\( 2f_0 \\) being the Nyquist rate or the minimum sampling rate for signals bandlimited to \\( f_0 \\)). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since the signals of interest are all below \\( f_0 \\), \\( y_1(n) \\) is filtered by \\( H(f) \\) to produce \\( y_2(n) \\), as depicted in Fig. 18.4. This filter removes quantization noise (and any other signals) above \\( f_0 \\).\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is \\( 2^{\\mathrm{N}}(\\Delta / 2) \\). For this maximum sinusoidal wave, the signal power, \\( P_s \\), is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The block diagram labeled (a) represents an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block takes the input signal \\( u(n) \\) and quantizes it into discrete levels, producing \\( y_1(n) \\) with inherent quantization noise.\n- **Filter H(f):** This block processes \\( y_1(n) \\). The filter's frequency response, shown in part (b) of the figure, is a brick-wall filter that passes frequencies below \\( f_0 \\) and attenuates those above \\( f_0 \\).\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the N-bit quantizer, producing \\( y_1(n) \\), which is then fed to the filter H(f).\n- The filter removes quantization noise and any signals above \\( f_0 \\), resulting in \\( y_2(n) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The signals are labeled as \\( u(n) \\), \\( y_1(n) \\), and \\( y_2(n) \\).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of \\( f_0 \\), indicating a gain of 1 for frequencies between -\\( f_0 \\) and \\( f_0 \\) and zero outside this range.\n\n4. **Overall System Function:**\n- The system quantizes the input signal and filters out unwanted noise and signals above a certain frequency. The N-bit quantizer introduces quantization noise, which is then reduced by the filter H(f). The system retains signal components below \\( f_0 \\) while decreasing the power of quantization noise in \\( y_2(n) \\).\nimage_name:(b)\ndescription:Fig. 18.4(b) shows a frequency response plot of a low-pass filter with a brick-wall characteristic.\n\n1. **Type of Graph and Function:**\n- This is a magnitude frequency response graph.\n- The function is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\) in hertz (Hz).\n- The vertical axis shows the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Overall Behavior and Trends:**\n- The graph features a rectangular shape, indicating a sharp cutoff at \\( f_0 \\).\n- The magnitude is unity for frequencies between \\(-f_0\\) and \\( f_0 \\), and drops to zero outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is clearly marked at \\( f_0 \\) and \\(-f_0 \\).\n- The filter passes frequencies in the range \\(-f_0\\) to \\( f_0 \\) without attenuation and completely attenuates frequencies outside this range.\n- The transition from passband to stopband is instantaneous, characteristic of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented given \\( f_s \\).\n\nFig. 18.4 (a) illustrates an oversampling system without noise shaping. (b) shows the brick-wall response of the filter, which removes much of the quantization noise.\n\nThe power of the input signal within \\( y_2(n) \\) remains unchanged, assuming the signal's frequency content is below \\( f_0 \\). However, the quantization noise power is reduced to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling OSR reduces the quantization noise power by half, or equivalently, 3 dB (or 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in \\( y_2(n) \\). Using equations (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of \\( 10 \\log (\\mathrm{OSR}) \\) dB.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term reflects the SQNR enhancement from oversampling. Straight oversampling yields a SQNR improvement of 3 dB/octave or 0.5 bits/octave. This improvement arises because, when quantized samples are averaged, the signal portion adds linearly, whereas the noise portion adds as the square root of the sum of the squares. This enhancement also applies to other noise types, such as thermal noise, thereby improving the overall SNR by \\( 10 \\log (\\mathrm{OSR}) \\).\n\n[^0]:    1. In fact, the resistor-string D/A was used to realize an A/D converter in the reference.\n[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes (00, 01, or 11), they are actually \\( \\log_2(3)=1.585 \\)-bit stages, but in practice, they are always referred to as 1.5-bit stages.\n[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, \\( V_s \\), of 1 V where the measured voltage, \\( V_{\\text{meas}} \\), is \\( V_s \\) plus a noise signal, \\( V_{\\text{noise}} \\). Assume \\( V_{\\text{noise}} \\) is a random signal uniformly distributed between \\( \\pm \\sqrt{3} \\). What is the SNR for \\( V_{\\text{meas}} \\) when examining individual values? If eight samples of \\( V_{\\text{meas}} \\) are averaged, what is the approximate new SNR? To illustrate, use eight typical \\( V_{\\text{meas}} \\) samples: \\( \\{0.94, -0.52, -0.73, 2.15, 1.91, 1.33, -0.31, 2.33\\} \\).\n\n#### Solution\n\nReferencing signals to 1 , the power of \\( V_s \\) and \\( V_{\\text{noise}} \\) is calculated as 1 watt each, resulting in an SNR of 0 dB for individual \\( V_{\\text{meas}} \\) values. The signal value of 1 V is difficult to discern in the given \\( V_{\\text{meas}} \\) samples due to the poor SNR.\n\nAveraging eight samples approximates a low-pass filter, with the oversampling ratio being roughly 8. Each octave of oversampling improves the SNR by 3 dB, so the averaged value should have an SNR of around 9 dB. Averaging the provided \\( V_{\\text{meas}} \\) samples results in 0.8875, closer to the signal value of 1 V.\n\nOversampling enhances the SNR here because summing eight measured values results in \\( 8 V_{\\text{rms}} \\) (or 64 watts) for the signal, while the noise sums to \\( \\sqrt{8} V_{\\text{rms}} \\) (or 8 watts), assuming independent noise values.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a 6-dB SQNR, what sample rate is required using oversampling (without noise shaping) to achieve a 96-dB SQNR (equivalent to 16 bits) if \\( f_0 = 25 \\text{kHz} \\)? (Note: The input to the A/D converter must be very active for the white-noise quantization model to be valid, a challenging condition with a 1-bit quantizer and oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping yields a 3 dB/octave improvement. To achieve 90 dB improvement, we need 30 octaves. Thus, the required sampling rate, \\( f_s \\), is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\text{GHz}!\n$$\n\nThis example demonstrates the necessity of noise shaping to improve the SQNR faster than 3 dB/octave, as 54,000 GHz is impractically high."
},
{
    "text": "Oversampling happens when the signals of interest are bandlimited to $f_{0}$, but the sampling rate is $f_{s}$, where $f_{s}$ exceeds $2 f_{0}$ (with $2 f_{0}$ being the Nyquist rate, or the minimum required sampling rate for signals bandlimited to $f_{0}$). The oversampling ratio, OSR, is defined as\n\n$$\n\\begin{equation*}\n\\mathrm{OSR} \\equiv \\frac{\\mathrm{f}_{\\mathrm{s}}}{2 \\mathrm{f}_{0}} \\tag{18.10}\n\\end{equation*}\n$$\n\nPost-quantization, since the signals of interest are all below $f_{0}$, $y_{1}(n)$ is filtered by $H(f)$ to produce $y_{2}(n)$, as depicted in Fig. 18.4. This filter removes quantization noise (along with any other signals) above $\\mathrm{f}_{0}$.\n\nAssuming the input signal is a sinusoidal wave, its maximum peak value without clipping is $2^{\\mathrm{N}}(\\Delta / 2)$. For this maximum sinusoidal wave, the signal power, $P_{s}$, is\n\n$$\n\\begin{equation*}\nP_{s}=\\left(\\frac{\\Delta 2^{N}}{2 \\sqrt{2}}\\right)^{2}=\\frac{\\Delta^{2} 2^{2 N}}{8} \\tag{18.11}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The system block diagram labeled (a) illustrates an oversampling system without noise shaping, comprising two main components: an N-bit quantizer and a filter denoted by H(f).\n\n1. **Main Components:**\n- **N-bit Quantizer:** This block takes the input signal, u(n), and quantizes it into discrete levels, producing y(n), which includes quantization noise from the conversion.\n- **Filter H(f):** This block processes the quantized signal y(n). The filter's frequency response, shown in part (b) of the figure, is a brick-wall filter that allows frequencies below f to pass while attenuating those above f.\n\n2. **Flow of Information or Control:**\n- The input signal u(n) enters the N-bit quantizer, producing the quantized output y(n), which is then fed to the filter H(f).\n- The filter removes quantization noise and any other signals with frequencies greater than f, resulting in the output y(n).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The signals are labeled as u(n), y(n), and y(n).\n- The filter's frequency response in part (b) shows a rectangular shape with a cutoff frequency of f, indicating a gain of 1 for frequencies between -f and f and zero outside this range.\n\n4. **Overall System Function:**\n- The system's primary role is to process an input signal, quantize it, and filter out unwanted noise and signals above a specific frequency. The N-bit quantizer introduces quantization noise, which the filter H(f) then attenuates. The system is designed to retain signal components below the cutoff frequency f while reducing the quantization noise power in the output signal y(n).\n\nimage_name:(b)\ndescription:Fig. 18.4(b) presents a frequency response plot, specifically showing the magnitude response of a low-pass filter with a brick-wall characteristic.\n\n1. **Type of Graph and Function:**\n- This is a magnitude frequency response graph.\n- The depicted function is a brick-wall low-pass filter.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency \\( f \\), typically in hertz (Hz).\n- The vertical axis represents the magnitude \\(|H(f)|\\) of the filter response, which is unitless.\n- Both axes are linear.\n\n3. **Overall Behavior and Trends:**\n- The graph displays a rectangular shape, indicating a sharp cutoff at frequency \\( f_0 \\).\n- The magnitude remains constant at 1 (unity gain) for frequencies between \\(-f_0\\) and \\(f_0\\), dropping to 0 outside this range.\n\n4. **Key Features and Technical Details:**\n- The cutoff frequency is clearly marked at \\( f_0 \\) and \\(-f_0\\).\n- The filter passes all frequencies in the range \\(-f_0\\) to \\(f_0\\) without attenuation, completely attenuating frequencies outside this range.\n- The transition from passband to stopband is instantaneous, characteristic of an ideal filter.\n\n5. **Annotations and Specific Data Points:**\n- The graph is symmetric around the origin, indicating an even filter response.\n- The passband gain is 1, and the stopband gain is 0.\n- The Nyquist frequency \\( \\frac{f_s}{2} \\) is marked, indicating the maximum frequency accurately represented given the sampling frequency \\( f_s \\).\n\nFig. 18.4 (a) illustrates a possible oversampling system without noise shaping. (b) shows the brick-wall response of the filter to remove much of the quantization noise.\n\nThe power of the input signal within $\\mathrm{y}_{2}(\\mathrm{n})$ remains unchanged, assuming the signal's frequency content is below $f_{0}$. However, the quantization noise power decreases to\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{s} / 2}^{f_{\\mathrm{s}} / 2} S_{e}^{2}(f)|H(f)|^{2} d f=\\int_{-f_{0}}^{f_{0}} k_{x}^{2} d f=\\frac{2 f_{0}}{f_{s}} \\frac{\\Delta^{2}}{12}=\\frac{\\Delta^{2}}{12}\\left(\\frac{1}{\\mathrm{OSR}}\\right) \\tag{18.12}\n\\end{equation*}\n$$\n\nThus, doubling the OSR (i.e., doubling the sampling rate) reduces the quantization noise power by half, or equivalently, by 3 dB (or 0.5 bits).\n\nThe maximum SQNR (in dB) can be calculated as the ratio of the maximum sinusoidal power to the quantization noise power in $\\mathrm{y}_{2}(\\mathrm{n})$. Using equations (18.11) and (18.12), we get\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log (\\mathrm{OSR}) \\tag{18.13}\n\\end{equation*}\n$$\n\nwhich is also equal to\n\nKey Point: Oversampling a signal at OSR times the Nyquist rate, without spectrally shaping the quantization noise, results in a SNR enhancement of $10 \\log (O S R) d B$.\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76+10 \\log (\\mathrm{OSR}) \\tag{18.14}\n\\end{equation*}\n$$\n\nThe first term represents the SQNR due to the N-bit quantizer, while the OSR term signifies the SQNR enhancement from oversampling. Here, straight oversampling yields a SQNR improvement of 3 dB per octave, or 0.5 bits per octave. The reason for this SQNR improvement through oversampling is that when quantized samples are averaged, the signal portion adds linearly, whereas the noise portion adds as the square root of the sum of the squares. This enhancement also applies to other noise types, such as thermal noise in circuits, thereby generally improving the overall SNR by $10 \\log (\\mathrm{OSR})$.\n\n[^0]:    1. In fact, the resistor-string $D / A$ was used to realize an $A / D$ converter in the reference.\n[^1]:    1. Strictly speaking, because each stage produces one of three digital output codes $(00,01$, or 11$)$, they are actually $\\log _{2}(3)=1.585$-bit stages, but in practice they are always referred to simply as 1.5 -bit stages.\n[^2]:    1. Delta-sigma modulation is also sometimes referred to as sigma-delta modulation.\n\n#### EXAMPLE 18.2\n\nConsider a sampled dc signal, $\\mathrm{V}_{\\mathrm{s}}$, with a value of 1 V, where the measured voltage, $\\mathrm{V}_{\\text {meas }}$, is $\\mathrm{V}_{\\mathrm{s}}$ plus a noise signal, $\\mathrm{V}_{\\text {noise }}$. Assume $\\mathrm{V}_{\\text {noise }}$ is a random signal uniformly distributed between $\\pm \\sqrt{3}$. What is the SNR for $\\mathrm{V}_{\\text {meas }}$ when examining individual values? If eight samples of $\\mathrm{V}_{\\text {meas }}$ are averaged, what is the approximate new SNR? To illustrate, use eight typical samples for $\\mathrm{V}_{\\text {meas }}$ of $\\{0.94,-0.52,-0.73,2.15,1.91,1.33,-0.31,2.33\\}$.\n\n#### Solution\n\nReferencing signals to $1 \\Omega$, the power of $V_{s}$ and $V_{\\text {noise }}$ is calculated to be 1 watt each. Thus, the SNR for $V_{\\text {meas }}$ is 0 dB when looking at individual $\\mathrm{V}_{\\text {meas }}$ values. Note that it is challenging to discern the signal value of 1 V in the example $V_{\\text {meas }}$ samples due to the poor SNR.\n\nAveraging eight samples effectively acts as a simple low-pass filter, approximating an oversampling ratio of about 8 (this is a rough estimate since a brick-wall filter is not used). Since each octave of oversampling improves SNR by 3 dB, the averaged value should have an SNR around 9 dB. Averaging the given $\\mathrm{V}_{\\text {meas }}$ samples results in 0.8875, which more closely reflects the signal value of 1 V.\n\nThe reason oversampling enhances SNR here is that summing eight measured values causes the eight signal values to add linearly to $8 \\mathrm{~V}_{\\mathrm{rms}}$ (or 64 watts), while the eight noise values add to $\\sqrt{8} \\mathrm{~V}_{\\mathrm{rms}}$ (or 8 watts), assuming the noise values are independent.\n\n#### EXAMPLE 18.3\n\nGiven a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is needed using oversampling (without noise shaping) to achieve a $96-\\mathrm{dB}$ SQNR (i.e., 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$? (Note that the input to the $\\mathrm{A} / \\mathrm{D}$ converter must be very active for the white-noise quantization model to be valida challenging condition when using a 1-bit quantizer with oversampling without noise shaping.)\n\n#### Solution\n\nOversampling without noise shaping provides a 3 dB improvement per octave, where one octave corresponds to doubling the sampling rate. To achieve a 90 dB improvement, we need 30 octaves. Thus, the required sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, is\n\n$$\nf_{s}=2^{30} \\times 2 f_{0} \\cong 54,000 \\mathrm{GHz}!\n$$\n\nThis example demonstrates why noise shaping is necessary to enhance the SQNR faster than 3 dB per octave, as 54,000 GHz is highly impractical."
},
{
    "text": "While oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). In essence, the component accuracy must exceed 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can deliver a favorable signal to quantization noise and distortion ratio. To achieve the necessary linearity, some form of auto calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to match that of a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity, stemming from its two output values; since two points form a straight line, no trimming or calibration is needed. This intrinsic linearity is a key reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Notably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "Oversampling enhances the signal-to-noise ratio but does not affect linearity. For instance, to achieve a 16-bit linear converter using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error below $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). Essentially, the component's accuracy needs to surpass 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. When paired with a high oversampling ratio, they can deliver an excellent signal to quantization noise and distortion ratio. To achieve the necessary linearity, some form of auto calibration or laser trimming is essential. However, as demonstrated in Example 18.3, a sufficiently high sampling rate allows the output from a 1-bit converter to be filtered, effectively matching a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity, stemming from its two output values, which define a straight line and eliminate the need for trimming or calibration. This inherent linearity is a significant reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Reports even indicate 20-bit linearity without any trimming [Leopold, 1991]. Additionally, oversampling techniques offer other benefits, such as reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "While oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed but a 12-bit converter with oversampling is used, the 12-bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). In essence, the component's accuracy must surpass 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can deliver an excellent signal to quantization noise and distortion ratio. To achieve the necessary linearity, some form of auto-calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to match the performance of a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity, which stems from having only two output values. Since two points define a straight line, no trimming or calibration is needed. This inherent linearity is a significant reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Notably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of using oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "While oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error below $1 / 2^{4}$ LSB (where LSB pertains to the 12-bit converter). In essence, the component accuracy must surpass 16-bit accuracy (i.e., $100 \\times (1 / 2^{16}) = 0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can achieve a favorable signal to quantization noise and distortion ratio.\n\nTo achieve the necessary linearity, some form of auto-calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to emulate a 16-bit converter. The primary advantage of a 1-bit D/A converter is its inherent linearity. This linearity stems from the 1-bit D/A converter having only two output values, and since two points define a straight line, no trimming or calibration is needed. This inherent linearity is a significant reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). In fact, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of using oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "While oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). In essence, the component accuracy must surpass 16-bit accuracy (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can achieve a favorable signal to quantization noise and distortion ratio.\n\nTo achieve the necessary linearity, some form of auto calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to match that of a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity, which stems from having only two output values. Since two points define a straight line, no trimming or calibration is needed. This inherent linearity is a key reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Remarkably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "Oversampling enhances the signal-to-noise ratio but does not affect linearity. For instance, to achieve a 16-bit linear converter using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error below $1 / 2^{4}$ LSB (where LSB pertains to the 12-bit converter). In essence, the component's accuracy must surpass 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can deliver an excellent signal to quantization noise and distortion ratio. To achieve the necessary linearity, some form of auto-calibration or laser trimming is essential. However, as demonstrated in Example 18.3, a sufficiently high sampling rate can enable the output from a 1-bit converter to be filtered, achieving equivalence to a 16-bit converter. The primary advantage of a 1-bit D/A converter is its inherent linearity, stemming from its two output values, which define a straight line, eliminating the need for trimming or calibration. This inherent linearity is a significant reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to realize 16- to 18-bit linear converters (with noise shaping). Notably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, oversampling techniques offer other benefits, such as reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "Although oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed using a 12-bit converter with oversampling, the 12-bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). In essence, the component accuracy must surpass 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can deliver an excellent signal to quantization noise and distortion ratio.\n\nTo achieve the necessary linearity, some form of auto-calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to emulate a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity. ${ }^{2}$ This linearity stems from the 1-bit D/A converter having only two output values; since two points define a straight line, no trimming or calibration is needed. This intrinsic linearity is a key reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Notably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of using oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "While oversampling enhances the signal-to-noise ratio, it does not enhance linearity. For instance, if a 16-bit linear converter is needed and a 12-bit converter with oversampling is used, the 12-bit converter must have an integral nonlinearity error less than $1 / 2^{4}$ LSB (where LSB pertains to a 12-bit converter). In essence, the component's accuracy must surpass 16-bit precision (i.e., $100 \\times\\left(1 / 2^{16}\\right)=0.0015$ percent).\n\nKey Point: One-bit D/A converters are inherently linear. Therefore, when paired with a high oversampling ratio, they can achieve a favorable signal to quantization noise and distortion ratio. To attain the necessary linearity, some form of auto-calibration or laser trimming is essential. However, as demonstrated in Example 18.3, with a sufficiently high sampling rate, the output from a 1-bit converter can be filtered to match the performance of a 16-bit converter. The primary advantage of a 1-bit $D / A$ converter is its inherent linearity. ${ }^{2}$ This linearity stems from the 1-bit D/A converter having only two output values; since two points define a straight line, no trimming or calibration is needed. This intrinsic linearity is a key reason for employing oversampling techniques with 1-bit converters. Indeed, many audio converters utilize 1-bit converters to achieve 16- to 18-bit linear performance (with noise shaping). Notably, 20-bit linearity has been achieved without any trimming [Leopold, 1991]. Additionally, other benefits of using oversampling techniques include reduced demands for analog anti-aliasing and smoothing filters."
},
{
    "text": "In this section, the benefits of shaping quantization noise using feedback are explored. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, in contrast to oversampling without noise shaping. While this section primarily demonstrates the fundamental principles in the context of $\\mathrm{A} / \\mathrm{D}$ converters, much of the discussion is also pertinent to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage comprises a continuous-time anti-aliasing filter, which is essential to restrict the input signal's frequencies to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, the anti-aliasing filter can be relatively simple, such as a basic RC low-pass filter. Following this filter, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample and hold circuit. This sampled signal is then processed by the $\\Delta \\Sigma$ modulator, transforming it into a noise-shaped low-resolution digital signal. The third component is a decimator, which converts the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the frequency of the desired input signal bandwidth. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, though in many systems, decimation occurs in multiple stages. It is worth noting that in implementations where the $\\Delta \\Sigma$ modulator is realized using switched-capacitor circuitry, a separate sample-and-hold circuit is often unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will delve into the detailed operation of these various components.\n\n**Block Diagram Description:**\nThe block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components that collaborate in this conversion process.\n\n1. **Key Components:**\n   - **Anti-aliasing Filter:** This initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n   - **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then processed by this circuit, which samples it at a rate \\(f_s\\) and holds it, producing a discrete-time signal \\(x_{sh}(t)\\).\n   - **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\), performs noise shaping and quantization, and outputs a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n   - **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) is processed to remove quantization noise outside the signal band, resulting in \\(x_{lp}(n)\\).\n   - **Decimation Filter:** This involves a downsampling operation (denoted by OSR, Oversampling Ratio) that reduces the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Information Flow:**\n   - The process starts with the continuous analog signal \\(x_{in}(t)\\), which passes through the anti-aliasing filter to become \\(x_{c}(t)\\).\n   - The sample and hold circuit then samples this filtered signal, creating a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n   - The discrete-time signal is modulated by the Delta-Sigma modulator, resulting in a quantized digital signal \\(x_{dsm}(n)\\).\n   - The digital low-pass filter processes \\(x_{dsm}(n)\\) to eliminate out-of-band noise, yielding \\(x_{lp}(n)\\).\n   - Finally, the decimation filter reduces the sampling rate of \\(x_{lp}(n)\\) to produce the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels and Annotations:**\n   - The diagram is clearly marked with the function of each block and the signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n   - The sampling frequency \\(f_s\\) is indicated at relevant stages.\n   - The decimation filter is highlighted with a dashed line, signifying its combined function of filtering and downsampling.\n\n4. **System Function:**\n   - The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present."
},
{
    "text": "In this section, the benefits of shaping quantization noise using feedback are explored. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily illustrates the fundamental principles in the context of $\\mathrm{A} / \\mathrm{D}$ converters, much of the discussion is also applicable to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage is a continuous-time anti-aliasing filter, essential for limiting the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be relatively simple, such as a basic RC low-pass filter. Following this, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample-and-hold circuit. This signal is then processed by the $\\Delta \\Sigma$ modulator, which transforms the analog signal into a low-resolution digital signal with noise shaping. The third component is a decimator, which converts the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the desired bandwidth frequency of the input signal. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will delve into the detailed operation of these various components.\n\nThe block diagram in Fig. 18.5 illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components working together in this conversion process.\n\n1. **Main Components:**\n   - **Anti-aliasing Filter:** This initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n   - **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then sampled by this circuit at a rate \\(f_s\\), producing a discrete-time signal \\(x_{sh}(t)\\).\n   - **Delta-Sigma Modulator ( mod):** This block processes the sampled signal \\(x_{sh}(t)\\), performing noise shaping and quantization, resulting in a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n   - **Digital Low-Pass Filter:** This filter removes quantization noise outside the signal band from \\(x_{dsm}(n)\\), yielding \\(x_{lp}(n)\\).\n   - **Decimation Filter:** This component downsamples the signal \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n   - The process starts with the continuous analog signal \\(x_{in}(t)\\), which is filtered to become \\(x_{c}(t)\\).\n   - The sample and hold block converts this filtered signal into a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n   - The Delta-Sigma modulator then modulates this discrete-time signal, creating a quantized digital signal \\(x_{dsm}(n)\\).\n   - The digital low-pass filter refines \\(x_{dsm}(n)\\) by removing out-of-band noise, resulting in \\(x_{lp}(n)\\).\n   - Finally, the decimation filter reduces the sampling rate of \\(x_{lp}(n)\\) to produce the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n   - The diagram is clearly marked with each block's function and the signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n   - The sampling frequency \\(f_s\\) is indicated at relevant stages.\n   - The decimation filter is highlighted with a dashed line, signifying its combined role of filtering and downsampling.\n\n4. **Overall System Function:**\n   - The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process further refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present. In the following sections, the operation of these various components will be described in more detail."
},
{
    "text": "In this section, we explore the benefits of shaping quantization noise using feedback. Here, we'll observe a significantly enhanced dynamic range when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily references $\\mathrm{A} / \\mathrm{D}$ converters, many principles also directly apply to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage is a continuous-time anti-aliasing filter, essential for restricting the input signal's frequencies to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be relatively simple, such as a basic RC low-pass filter. Following this, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample-and-hold mechanism. This signal then undergoes processing by the $\\Delta \\Sigma$ modulator, which transforms the analog signal into a noise-shaped, low-resolution digital signal. The third component is a decimator, which converts the oversampled, low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the desired bandwidth frequency of the input signal. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The following sections will delve deeper into the operation of these various components.\n\n---\n\nThe block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components working together in this conversion process.\n\n1. **Main Components:**\n- **Anti-aliasing Filter:** This initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n- **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then sampled by this circuit at a rate \\(f_s\\), producing a discrete-time signal \\(x_{sh}(t)\\).\n- **Delta-Sigma Modulator ( mod):** This block processes the sampled signal \\(x_{sh}(t)\\), performing noise shaping and quantization, resulting in a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n- **Digital Low-Pass Filter:** This filter removes quantization noise outside the signal band from \\(x_{dsm}(n)\\), yielding \\(x_{lp}(n)\\).\n- **Decimation Filter:** This involves a downsampling operation (denoted by OSR, Oversampling Ratio) that reduces the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n- The process starts with the continuous analog signal \\(x_{in}(t)\\), which is filtered to become \\(x_{c}(t)\\).\n- The sample and hold block converts this filtered signal into a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n- The discrete-time signal is then modulated by the Delta-Sigma modulator, generating a quantized digital signal \\(x_{dsm}(n)\\).\n- The digital low-pass filter refines \\(x_{dsm}(n)\\) to remove out-of-band noise, resulting in \\(x_{lp}(n)\\).\n- Finally, the decimation filter lowers the sampling rate of \\(x_{lp}(n)\\) to produce the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram clearly labels each block's function and the signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n- The sampling frequency \\(f_s\\) is indicated at relevant stages.\n- The decimation filter is outlined with a dashed line, highlighting its combined function of filtering and downsampling.\n\n4. **Overall System Function:**\n- The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process further refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present."
},
{
    "text": "In this section, the benefits of shaping quantization noise via feedback are explored. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily illustrates the fundamental principles in the context of $\\mathrm{A} / \\mathrm{D}$ converters, much of the content is also applicable to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage is a continuous-time anti-aliasing filter, necessary to restrict the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be relatively simple, such as a basic RC low-pass filter. Following this, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample-and-hold circuit. This signal is then processed by the $\\Delta \\Sigma$ modulator, transforming it into a noise-shaped, low-resolution digital signal. The third component is a decimator, which converts the oversampled, low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the desired bandwidth of the input signal. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a down sampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal\nimage_name:Fig. 18.5 Block diagram of an oversampling A/D converter\ndescription:The block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components working together in this conversion process.\n\n1. **Main Components:**\n- **Anti-aliasing Filter:** This initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n- **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then processed by the sample-and-hold circuit, which samples it at a rate \\(f_s\\) to produce a discrete-time signal \\(x_{sh}(t)\\).\n- **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\), performs noise shaping and quantization, and outputs a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n- **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) is processed by a digital low-pass filter to remove out-of-band quantization noise, resulting in \\(x_{lp}(n)\\).\n- **Decimation Filter:** This involves a downsampling operation (denoted by OSR, Oversampling Ratio) that reduces the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n- The process starts with the continuous analog signal \\(x_{in}(t)\\), which is filtered to become \\(x_{c}(t)\\).\n- The sample and hold block converts this filtered signal into a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n- The discrete-time signal is then modulated by the Delta-Sigma modulator, generating a quantized digital signal \\(x_{dsm}(n)\\).\n- The digital low-pass filter refines \\(x_{dsm}(n)\\) by removing out-of-band noise, resulting in \\(x_{lp}(n)\\).\n- Finally, the decimation filter lowers the sampling rate of \\(x_{lp}(n)\\) to yield the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram is clearly marked with the functions of each block and the signals at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n- The sampling frequency \\(f_s\\) is indicated at relevant points.\n- The decimation filter is highlighted with a dashed line, signifying its combined function of filtering and downsampling.\n\n4. **Overall System Function:**\n- The primary purpose of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process further refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are absent.\nis inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. In the following sections, the operation of these various components will be described in more detail."
},
{
    "text": "In this section, we explore the benefits of shaping quantization noise using feedback. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, in contrast to oversampling without noise shaping. While this section primarily illustrates the fundamental principles with respect to $\\mathrm{A} / \\mathrm{D}$ converters, much of the content is also directly applicable to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage comprises a continuous-time anti-aliasing filter, essential for restricting the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be quite rudimentary, such as a basic RC low-pass filter. Following this filter, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample and hold circuit. This signal then undergoes processing by the $\\Delta \\Sigma$ modulator, which transforms the analog signal into a low-resolution digital signal with noise shaping. The third component is a decimator, which converts the oversampled low-resolution digital signal into a high-resolution digital signal at a reduced sampling rate, typically twice the desired bandwidth frequency of the input signal. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will delve into the detailed operation of these various components.\n\nimage_name: Fig. 18.5 Block diagram of an oversampling A/D converter\ndescription: This block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to transform an analog input signal into a digital output. The system comprises several key components that collaborate in this conversion process.\n\n1. **Main Components:**\n- **Anti-aliasing Filter:** The initial block, receiving the continuous-time input signal \\(x_{in}(t)\\), functions to eliminate high-frequency components, preventing aliasing during sampling.\n- **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then fed to the sample and hold circuit, which samples it at a rate \\(f_s\\) and holds it, producing a discrete-time signal \\(x_{sh}(t)\\).\n- **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\), performs noise shaping and quantization, and outputs a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n- **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) is processed by this filter to remove out-of-band quantization noise, resulting in \\(x_{lp}(n)\\).\n- **Decimation Filter:** This involves a downsampling operation (denoted by OSR, Oversampling Ratio) that lowers the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n- The process initiates with the continuous analog signal \\(x_{in}(t)\\), which passes through the anti-aliasing filter to become \\(x_{c}(t)\\).\n- The sample and hold block then samples this filtered signal, creating a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n- The discrete-time signal is modulated by the Delta-Sigma modulator, generating a quantized digital signal \\(x_{dsm}(n)\\).\n- The digital low-pass filter processes \\(x_{dsm}(n)\\) to eliminate out-of-band noise, yielding \\(x_{lp}(n)\\).\n- Finally, the decimation filter reduces the sampling rate of \\(x_{lp}(n)\\) to produce the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram is clearly marked with the function of each block and the corresponding signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n- The sampling frequency \\(f_s\\) is indicated at pertinent stages.\n- The decimation filter is delineated with a dashed line, highlighting its combined nature of filtering and downsampling.\n\n4. **Overall System Function:**\n- The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process further refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present."
},
{
    "text": "In this section, we explore the benefits of shaping quantization noise using feedback. Here, a significant enhancement in dynamic range is observed when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily focuses on $\\mathrm{A} / \\mathrm{D}$ converters, many principles also apply to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage is a continuous-time anti-aliasing filter, necessary to limit the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be simple, such as a basic RC low-pass filter. Following this, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample-and-hold circuit. This signal then undergoes processing by the $\\Delta \\Sigma$ modulator, converting it into a low-resolution digital signal with noise shaping. The third component is a decimator, which transforms the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the desired bandwidth frequency of the input signal. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will delve deeper into the functioning of these various components.\n\nimage_name: Fig. 18.5 Block diagram of an oversampling A/D converter\ndescription: This block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components that collaborate in this conversion process.\n\n1. **Main Components:**\n- **Anti-aliasing Filter:** The initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n- **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then sampled by this circuit at a rate \\(f_s\\), producing a discrete-time signal \\(x_{sh}(t)\\).\n- **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\), performs noise shaping and quantization, and outputs a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n- **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) is processed to remove out-of-band quantization noise, resulting in \\(x_{lp}(n)\\).\n- **Decimation Filter:** This involves a downsampling operation (denoted by OSR, Oversampling Ratio) that reduces the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n- The process starts with the continuous analog signal \\(x_{in}(t)\\), which passes through the anti-aliasing filter to become \\(x_{c}(t)\\).\n- The sample and hold block converts this filtered signal into a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n- The discrete-time signal is then modulated by the Delta-Sigma modulator, resulting in a quantized digital signal \\(x_{dsm}(n)\\).\n- The digital low-pass filter refines \\(x_{dsm}(n)\\) by removing out-of-band noise, yielding \\(x_{lp}(n)\\).\n- Finally, the decimation filter lowers the sampling rate of \\(x_{lp}(n)\\) to obtain the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram is clearly marked with each block's function and the signals at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n- The sampling frequency \\(f_s\\) is indicated at relevant points.\n- The decimation filter is highlighted with a dashed line, signifying its combined function of filtering and downsampling.\n\n4. **Overall System Function:**\n- The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process further refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present.\nThe inherent sampling by the switches and input capacitors of the SC $\\Delta \\Sigma$ negates the need for a separate sample-and-hold. The following sections will provide a more detailed description of the operation of these various components."
},
{
    "text": "In this section, the benefits of shaping quantization noise using feedback are explored. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily illustrates the fundamental principles with reference to $\\mathrm{A} / \\mathrm{D}$ converters, much of the content is also directly applicable to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage comprises a continuous-time anti-aliasing filter, necessary to restrict the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. When the oversampling ratio is substantial, the anti-aliasing filter can be relatively simple, such as a basic RC low-pass filter. Following this filter, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample-and-hold circuit. This signal is then processed by the $\\Delta \\Sigma$ modulator, which transforms the analog signal into a low-resolution digital signal with noise shaping. The third component is a decimator, which converts the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the frequency of the desired input signal bandwidth. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a downsampler, although in many systems, decimation is executed in multiple stages. It is worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold circuit is often unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will provide a more detailed description of the various building blocks.\n\n**Block Diagram Description:**\nThe block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components that collaborate in this conversion process.\n\n1. **Key Components:**\n   - **Anti-aliasing Filter:** This initial block receives the continuous-time input signal \\(x_{in}(t)\\) and removes high-frequency components to prevent aliasing during sampling.\n   - **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then processed by the sample-and-hold circuit, which samples it at a rate \\(f_s\\) to produce a discrete-time signal \\(x_{sh}(t)\\).\n   - **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\) and performs noise shaping and quantization, outputting a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n   - **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) is processed by this filter to remove out-of-band quantization noise, resulting in \\(x_{lp}(n)\\).\n   - **Decimation Filter:** This component includes a downsampling operation (denoted by OSR, Oversampling Ratio) that reduces the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Information and Control Flow:**\n   - The process initiates with the continuous analog signal \\(x_{in}(t)\\), which passes through the anti-aliasing filter to become \\(x_{c}(t)\\).\n   - The sample-and-hold circuit then samples this filtered signal, converting it to a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n   - The discrete-time signal is modulated by the Delta-Sigma modulator, generating a quantized digital signal \\(x_{dsm}(n)\\).\n   - The digital low-pass filter processes \\(x_{dsm}(n)\\) to eliminate out-of-band noise, resulting in \\(x_{lp}(n)\\).\n   - Finally, the decimation filter reduces the sampling rate of \\(x_{lp}(n)\\) to yield the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels and Annotations:**\n   - The diagram is clearly labeled with each block's function and the signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n   - The sampling frequency \\(f_s\\) is indicated at relevant stages.\n   - The decimation filter is highlighted with a dashed line, signifying its composite nature of filtering and downsampling.\n\n4. **System Function:**\n   - The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample-and-hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present."
},
{
    "text": "In this section, the benefits of shaping quantization noise using feedback are explored. Here, we will observe a significantly enhanced dynamic range when the input signal is oversampled, compared to oversampling without noise shaping. While this section primarily demonstrates the fundamental principles with reference to $\\mathrm{A} / \\mathrm{D}$ converters, much of the content is also applicable to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters.\n\nThe architecture of a $\\Delta \\Sigma$ oversampling $\\mathrm{A} / \\mathrm{D}$ converter is depicted in Fig. 18.5. The initial stage is a continuous-time anti-aliasing filter, necessary to restrict the input signal's frequency to less than half the oversampling frequency, $\\mathrm{f}_{\\mathrm{s}}$. With a high oversampling ratio, this filter can be quite rudimentary, such as a basic RC low-pass filter. Following this filter, the continuous-time signal, $\\mathbf{x}_{\\mathrm{c}}(\\mathrm{t})$, is sampled by a sample and hold circuit. This signal is then processed by the $\\Delta \\Sigma$ modulator, which transforms the analog signal into a low-resolution digital signal with noise shaping. The third component is a decimator, which converts the oversampled low-resolution digital signal into a high-resolution digital signal at a lower sampling rate, typically twice the frequency of the desired input signal bandwidth. Conceptually, the decimation filter can be viewed as a low-pass filter followed by a down sampler, though in many systems, decimation occurs in multiple stages. It's worth noting that in implementations where the $\\Delta \\Sigma$ modulator uses switched-capacitor circuitry, a separate sample-and-hold is unnecessary, as the continuous-time signal is inherently sampled by the switches and input capacitors of the SC $\\Delta \\Sigma$. The subsequent sections will delve deeper into the operation of these various components.\n\nimage_name: Fig. 18.5 Block diagram of an oversampling A/D converter\ndescription: This block diagram illustrates an oversampling analog-to-digital (A/D) converter designed to convert an analog input signal into a digital output. The system comprises several key components that collaborate in this conversion process.\n\n1. **Main Components:**\n- **Anti-aliasing Filter:** The initial block, receiving the continuous-time input signal \\(x_{in}(t)\\), functions to eliminate high-frequency components, thereby preventing aliasing during sampling.\n- **Sample and Hold:** The filtered signal \\(x_{c}(t)\\) is then directed to the sample and hold circuit, which samples the signal at a rate \\(f_s\\) and holds it, producing a discrete-time signal \\(x_{sh}(t)\\).\n- **Delta-Sigma Modulator ( mod):** This block takes the sampled signal \\(x_{sh}(t)\\), performs noise shaping and quantization, and outputs a digital signal \\(x_{dsm}(n)\\) at the same sampling rate \\(f_s\\).\n- **Digital Low-Pass Filter:** The digital signal \\(x_{dsm}(n)\\) undergoes processing by a digital low-pass filter to remove quantization noise outside the signal band, resulting in \\(x_{lp}(n)\\).\n- **Decimation Filter:** This involves a downsampling operation (represented by OSR, Oversampling Ratio) that decreases the sampling rate of \\(x_{lp}(n)\\) to twice the desired bandwidth frequency \\(2f_0\\), producing the final digital signal \\(x_s(n)\\).\n\n2. **Flow of Information or Control:**\n- The process initiates with the continuous analog signal \\(x_{in}(t)\\), which passes through the anti-aliasing filter to become \\(x_{c}(t)\\).\n- The sample and hold block then samples this filtered signal, converting it to a discrete-time signal \\(x_{sh}(t)\\) at the sampling frequency \\(f_s\\).\n- The discrete-time signal is modulated by the Delta-Sigma modulator, generating a quantized digital signal \\(x_{dsm}(n)\\).\n- The digital low-pass filter processes \\(x_{dsm}(n)\\) to eliminate out-of-band noise, resulting in \\(x_{lp}(n)\\).\n- Finally, the decimation filter reduces the sampling rate of \\(x_{lp}(n)\\) to yield the output signal \\(x_s(n)\\) at \\(2f_0\\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram is clearly marked with the function of each block and the signal at each stage (e.g., \\(x_{in}(t)\\), \\(x_{c}(t)\\), \\(x_{sh}(t)\\), \\(x_{dsm}(n)\\), \\(x_{lp}(n)\\), \\(x_s(n)\\)).\n- The sampling frequency \\(f_s\\) is indicated at pertinent stages.\n- The decimation filter is delineated with a dashed line, signifying its composite nature of filtering and downsampling.\n\n4. **Overall System Function:**\n- The primary role of this oversampling A/D converter is to accurately convert an analog signal into a digital signal while minimizing noise and distortion. The anti-aliasing filter, sample and hold, and Delta-Sigma modulator ensure high-quality sampling and noise shaping. The digital low-pass filter and decimation process refine the signal, ensuring the final output \\(x_s(n)\\) is a high-fidelity digital representation of the original analog input \\(x_{in}(t)\\).\n\nFig. 18.5 Block diagram of an oversampling A/D converter.\n2. This assumes that second-order errors due to imperfections such as signal-dependent power supply, reference voltages, or memory in the $\\mathrm{D} / \\mathrm{A}$ converter are not present.\nIn the following sections, the operation of these various components will be described in more detail."
},
{
    "text": "A generic noise-shaped delta-sigma () modulator and its corresponding linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and parallels an amplifier constructed with an opamp and feedback. In this comparison, the feedback diminishes the impact of the opamp's output stage noise on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. Conversely, at high frequencies where the opamp's gain is minimal, the noise remains unaffected. It is important to note that the quantizer illustrated here is for a general scenario involving multiple output levels. While numerous oversampling converters employ 1-bit quantizers (i.e., just two output levels) for reasons previously discussed, there is no inherent necessity to limit ourselves to such implementations. Multibit oversampling converters are extensively covered in Section 18.8.\n\nBy treating the linear model in Fig. 18.6(b) as having two separate inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nIt should be noted that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, equation (18.16) indicates that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. Additionally, the output signal can be expressed as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled (a) depicts a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block accepts the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing their subtraction.\n- **Transfer Function Block \\( H(z) \\):** This block processes the output from the adder, representing the filter with transfer function \\( H(z) \\), essential for noise shaping.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to discrete levels, introducing quantization noise.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The subtraction result is processed by the filter \\( H(z) \\), generating the signal \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized, producing the output \\( y(n) \\).\n- The output \\( y(n) \\) is looped back to the adder, forming a feedback loop crucial for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is marked \\( u(n) \\), the intermediate signal after \\( H(z) \\) is \\( x(n) \\), and the output is \\( y(n) \\).\n- The feedback path is clearly shown, indicating the subtraction at the adder.\n\n4. **Overall System Function:**\n- The primary role of this  modulator is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is designed to reduce quantization noise within a specific frequency band, thereby improving the signal-to-noise ratio in the desired band. This is effectively managed by the feedback mechanism, which continuously adjusts the quantizer's input based on the output, controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The illustration represents a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the quantization noise spectrum. This modulator enhances the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through feedback.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the modulator's driving error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation in the desired band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, creating a closed-loop system that continuously minimizes quantization noise.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) enters the system, combining with the feedback signal \\( y(n) \\) in the first adder/subtractor. The result is processed by \\( H(z) \\), shaping the signal.\n- The output \\( x(n) \\) from \\( H(z) \\) is combined with quantization noise \\( e(n) \\) in the second adder, resulting in the output \\( y(n) \\).\n- The feedback loop ensures continuous subtraction of \\( y(n) \\) from \\( u(n) \\), dynamically adjusting and controlling noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal post \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The  modulator's primary function is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is tailored to attenuate noise in the desired frequency band, enhancing the signal-to-noise ratio. This is achieved through a feedback mechanism that continuously adjusts the quantizer's input based on the output, effectively managing noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general  modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the quantization noise spectrum, it is placed within a feedback loop whose response is designed to attenuate noise in the band of interest.\n\nTo effectively shape the quantization noise, we select \\( H(z) \\) such that its magnitude is significant from 0 to \\( f_{0} \\) (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will closely approximate unity over the band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, quantization noise is reduced within the frequency band of interest while the signal remains largely unaffected. High-frequency noise is not reduced by the feedback due to minimal loop gain at high frequencies. However, subsequent post-filtering can eliminate out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore determining specific functions for $\\mathrm{H}(\\mathrm{z})$, it is essential to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where $H(z)$ has high gain. In fact, for many modulators, the input signal must be significantly smaller than the quantizer's output level bounds to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where $H(z)$ has low gain will not necessarily lead to saturation of the signal $x(n)$. In other words, the maximum level of the out-of-band input signal can be substantially higher than the feedback levels (see Problem 18.6)."
},
{
    "text": "A generic noise-shaped delta-sigma () modulator and its corresponding linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and is comparable to an amplifier implemented using an operational amplifier (opamp) with feedback. In this comparison, the feedback diminishes the impact of the opamp's output stage noise on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. Conversely, at high frequencies where the opamp's gain is minimal, the noise is not mitigated. It is important to note that the quantizer depicted here is for a general scenario involving multiple output levels. While many oversampling converters employ 1-bit quantizers (i.e., only two output levels) for reasons previously discussed, there is no inherent necessity to limit ourselves to such implementations. Multibit oversampling converters are explored in depth in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, equation (18.16) indicates that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. Additionally, the output signal can be expressed as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled as (a) illustrates a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing subtraction to generate an error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal, shaping the noise spectrum through its transfer function \\( H(z) \\).\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it into discrete levels, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is combined with the feedback signal \\( y(n) \\) in the adder, producing an error signal.\n- This error signal is then processed by the filter \\( H(z) \\), resulting in the signal \\( x(n) \\).\n- The signal \\( x(n) \\) is quantized, generating the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop crucial for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is labeled \\( x(n) \\), and the output is labeled \\( y(n) \\).\n- The feedback path is clearly marked, indicating the subtraction operation at the adder.\n\n4. **Overall System Function:**\n- The primary role of this  modulator is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, thereby improving the signal-to-noise ratio in the desired band. This is achieved through a feedback mechanism that continuously adjusts the input to the quantizer based on the output, effectively controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram illustrates a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the spectrum of quantization noise, thereby enhancing the signal-to-noise ratio through feedback mechanisms.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal that drives the modulator.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation within the desired frequency band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously adjusts to minimize quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is combined with the feedback signal \\( y(n) \\) in the first adder/subtractor, producing an error signal.\n- This error signal is processed by \\( H(z) \\), resulting in \\( x(n) \\).\n- The signal \\( x(n) \\) is then combined with the quantization noise \\( e(n) \\) in the second adder to produce \\( y(n) \\).\n- The feedback loop ensures continuous adjustment by subtracting \\( y(n) \\) from \\( u(n) \\), controlling noise characteristics dynamically.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added to the signal.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The  modulator's primary function is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is tailored to attenuate noise in the desired frequency band, enhancing the signal-to-noise ratio. This is achieved through a feedback mechanism that allows continuous adjustment of the quantizer input based on the output, effectively managing noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general  modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the spectrum of quantization noise, it is placed within a feedback loop whose response is designed to attenuate the noise in the band of interest.\n\nTo effectively shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will closely approximate unity over the frequency band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, quantization noise is reduced within the frequency band of interest while the signal remains largely unaffected. High-frequency noise is not reduced by the feedback due to the minimal loop gain at high frequencies. However, additional post-filtering can effectively remove out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore selecting specific functions for $\\mathrm{H}(\\mathrm{z})$, it is essential to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where the gain of $H(z)$ is high. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output levels to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is low will not necessarily cause $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially larger than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma ( $\\Delta \\Sigma$ ) modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and parallels an amplifier implemented using an opamp with feedback. In this analogy, the feedback diminishes the impact of the noise from the opamp's output stage on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. Conversely, at high frequencies where the opamp's gain is minimal, the noise remains unaffected. It's important to note that the quantizer here is illustrated for a general scenario involving multiple output levels. While many oversampling converters employ 1-bit quantizers (i.e., only two output levels) for reasons previously discussed, there is no inherent necessity to limit ourselves to such implementations. Multibit oversampling converters are explored in detail in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, equation (18.16) indicates that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled as (a) illustrates a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal from the output \\( y(n) \\), performing subtraction of the feedback from the input.\n- **Transfer Function Block \\( H(z) \\):** This block processes the output of the adder, representing the filter with a transfer function \\( H(z) \\), essential for noise shaping.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it into discrete levels, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The result of this subtraction is processed by the filter \\( H(z) \\), producing the signal \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized by the Quantizer block, generating the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop crucial for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is labeled \\( x(n) \\), and the output is labeled \\( y(n) \\).\n- The feedback path is clearly indicated, showing the subtraction operation at the adder.\n\n4. **Overall System Function:**\n- The primary function of this  modulator is to shape the spectrum of quantization noise by placing it within a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, enhancing the signal-to-noise ratio in the desired band. This is achieved through the feedback mechanism, which continuously adjusts the input to the quantizer based on the output, effectively controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram represents a general  (Delta-Sigma) modulator, an interpolator structure used to shape the spectrum of quantization noise. This modulator is designed to improve the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through a feedback mechanism.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Positioned at the input, it receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal that drives the modulator.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for attenuating noise within the desired frequency band.\n- **Second Adder ():** This component adds the quantization noise \\( e(n) \\) to the processed signal \\( x(n) \\) to produce the output signal \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously adjusts to minimize quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the system and is immediately combined with the feedback signal \\( y(n) \\) via the first adder/subtractor. The result is passed through the transfer function \\( H(z) \\), shaping the signal.\n- The output of \\( H(z) \\), denoted \\( x(n) \\), is then combined with the quantization noise \\( e(n) \\) in the second adder to produce the final output \\( y(n) \\).\n- The feedback loop ensures that \\( y(n) \\) is continuously subtracted from \\( u(n) \\), allowing the system to dynamically adjust and control noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after processing by \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added to the signal.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The primary function of the  modulator is to shape the quantization noise spectrum by placing it within a feedback loop. The transfer function \\( H(z) \\) is specifically designed to attenuate noise in a desired frequency band, enhancing the signal-to-noise ratio. This is achieved through the feedback mechanism, which allows the system to continuously adjust the input to the quantizer based on the output, effectively controlling noise characteristics within the system.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general $\\Delta \\Sigma$ modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the spectrum of a quantization noise source, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest.\n\nTo effectively shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will closely approximate unity over the frequency band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, the quantization noise is reduced within the frequency band of interest while the signal remains largely unaffected. The high-frequency noise is not reduced by the feedback due to the low loop gain at high frequencies. However, additional post filtering can effectively remove the out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore determining specific functions for $\\mathrm{H}(\\mathrm{z})$, it is crucial to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where the gain of $H(z)$ is high. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output levels to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is low will not necessarily cause the signal $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially larger than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma () modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and parallels an amplifier realized using an operational amplifier (opamp) and feedback. In this analogy, the feedback diminishes the impact of the noise from the opamp's output stage on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is high. At high frequencies, where the opamp's gain is low, the noise remains unaffected. It is important to note that the quantizer depicted here is for the general scenario involving multiple output levels. While many oversampling converters utilize 1-bit quantizers (i.e., only two output levels) for reasons previously discussed, there is no inherent need to limit ourselves to such implementations. Multibit oversampling converters are explored in detail in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (an approximation), we can derive a signal transfer function, \\( \\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z}) \\), and a noise transfer function, \\( \\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z}) \\).\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, \\( N_{T F}(z) \\), correspond to the poles of \\( \\mathrm{H}(\\mathrm{z}) \\). In other words, when \\( H(z) \\) approaches infinity, \\( \\mathrm{N}_{T F}(\\mathrm{z}) \\) will approach zero, as seen in (18.16). We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled as (a) depicts a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing their subtraction.\n- **Transfer Function Block \\( H(z) \\):** This block processes the output from the adder, representing the filter with transfer function \\( H(z) \\), essential for noise shaping.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to a discrete level, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The subtraction result is processed by the filter \\( H(z) \\), generating the signal \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized, producing the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop crucial for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is \\( x(n) \\), and the output is \\( y(n) \\).\n- The feedback path is clearly indicated, showing the subtraction at the adder.\n\n4. **Overall System Function:**\n- The primary role of this  modulator is to shape the quantization noise spectrum by placing it in a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, enhancing the signal-to-noise ratio in the desired band. This is achieved through the feedback mechanism, which continuously adjusts the input to the quantizer based on the output, effectively controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram illustrates a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the quantization noise spectrum. This modulator aims to improve the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through feedback.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal that drives the modulator.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation in the desired band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that minimizes quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the system, combining with the feedback signal \\( y(n) \\) via the first adder/subtractor. The result is processed by \\( H(z) \\), shaping the signal.\n- The output \\( x(n) \\) from \\( H(z) \\) is combined with the quantization noise \\( e(n) \\) in the second adder to produce \\( y(n) \\).\n- The feedback loop ensures \\( y(n) \\) is continuously subtracted from \\( u(n) \\), allowing dynamic noise control.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The  modulator's primary function is to shape the quantization noise spectrum by placing it in a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate noise in a desired frequency band, enhancing the signal-to-noise ratio. This is achieved through feedback, which continuously adjusts the quantizer input based on the output, effectively controlling noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general  modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the quantization noise spectrum, it is placed within a feedback loop whose response is designed to attenuate the noise in the band of interest.\n\nTo effectively shape the quantization noise, we select \\( H(z) \\) such that its magnitude is large from 0 to \\( f_{0} \\) (i.e., over the frequency band of interest). With this choice, the signal transfer function, \\( \\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z}) \\), will approximate unity over the band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, \\( \\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z}) \\), will approximate zero over the same band. Thus, quantization noise is reduced in the frequency band of interest while the signal remains largely unaffected. High-frequency noise is not reduced by the feedback due to low loop gain at high frequencies. However, additional post-filtering can eliminate out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore selecting specific functions for \\( \\mathrm{H}(\\mathrm{z}) \\), it is crucial to ensure that the maximum level of the in-band input signal, \\( \\mathrm{u}(\\mathrm{n}) \\), remains within the maximum levels of the feedback signal, \\( \\mathrm{y}(\\mathrm{n}) \\); otherwise, the high gain in \\( \\mathrm{H}(\\mathrm{z}) \\) will cause the signal \\( x(n) \\) to saturate. For instance, if a 1-bit quantizer with output levels of \\( \\pm 1 \\) is used, the input signal must also stay within \\( \\pm 1 \\) for frequencies where \\( H(z) \\) has high gain. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output bounds to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, \\( u(n) \\), for frequencies where \\( H(z) \\) has low gain will not necessarily cause \\( x(n) \\) to saturate. In other words, the maximum level of the out-of-band input signal can be substantially larger than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma ( $\\Delta \\Sigma$ ) modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and resembles an amplifier implemented using an opamp with feedback. In this comparison, the feedback diminishes the impact of the noise from the opamp's output stage on the closed-loop amplifier's output signal at low frequencies, particularly when the opamp's gain is high. Conversely, at high frequencies where the opamp's gain is low, the noise is not suppressed. It is important to note that the quantizer here is illustrated for a general scenario involving multiple output levels. While many oversampling converters employ 1-bit quantizers (i.e., having only two output levels) for reasons previously discussed, there is no inherent need to limit ourselves to such implementations. Multibit oversampling converters are explored in detail in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, it follows from (18.16) that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled as (a) depicts a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing subtraction to generate the error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal, playing a crucial role in shaping the noise spectrum.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to discrete levels, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The resulting signal is processed by the filter \\( H(z) \\), producing \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized, generating the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop essential for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is \\( x(n) \\), and the output is \\( y(n) \\).\n- The feedback path is clearly indicated, showing the subtraction operation at the adder.\n\n4. **Overall System Function:**\n- The primary function of this  modulator is to shape the quantization noise spectrum by placing it within a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, enhancing the signal-to-noise ratio in the desired band. This is achieved through the feedback mechanism, which continuously adjusts the input to the quantizer based on the output, effectively controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram illustrates a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the spectrum of quantization noise. This modulator aims to improve the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through a feedback mechanism.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation in the desired band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously adjusts to minimize quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) in the first adder/subtractor. The result is processed by \\( H(z) \\), shaping the signal.\n- The output \\( x(n) \\) from \\( H(z) \\) is then combined with the quantization noise \\( e(n) \\) in the second adder to generate the output \\( y(n) \\).\n- The feedback loop ensures continuous adjustment by subtracting \\( y(n) \\) from \\( u(n) \\), dynamically controlling noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added to the signal.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The  modulator's primary function is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate noise in the desired frequency band, thereby improving the signal-to-noise ratio. This is achieved through the feedback mechanism, which allows continuous adjustment of the quantizer input based on the output, effectively controlling noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general $\\Delta \\Sigma$ modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the spectrum of a quantization noise source, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest.\n\nTo effectively shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will closely approximate unity over the frequency band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, the quantization noise is reduced within the frequency band of interest while the signal remains largely unaffected. The high-frequency noise is not reduced by the feedback due to the low loop gain at high frequencies. However, additional post filtering can effectively remove out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore determining specific functions for $\\mathrm{H}(\\mathrm{z})$, it is crucial to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where the gain of $H(z)$ is high. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output levels to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is low will not necessarily cause $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially higher than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma ($\\Delta \\Sigma$) modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and parallels an amplifier realized using an opamp with feedback. In this analogy, the feedback diminishes the impact of the opamp's output stage noise on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. At high frequencies, where the opamp's gain is minimal, the noise remains unaffected. It's important to note that the quantizer here is illustrated for a general scenario involving multiple output levels. While many oversampling converters utilize 1-bit quantizers (i.e., just two output levels) for reasons previously discussed, there is no inherent need to limit ourselves to such implementations. Multibit oversampling converters are elaborated on in Section 18.8.\n\nBy treating the linear model in Fig. 18.6(b) as having two independent inputs (an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, equation (18.16) indicates that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled (a) depicts a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing their subtraction.\n- **Transfer Function Block \\( H(z) \\):** This block processes the adder's output, representing the filter with transfer function \\( H(z) \\), crucial for noise shaping.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to discrete levels, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The subtraction result is processed by the filter \\( H(z) \\), producing \\( x(n) \\).\n- The signal \\( x(n) \\) is quantized, resulting in the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop essential for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is \\( x(n) \\), and the output is \\( y(n) \\).\n- The feedback path is clearly marked, indicating the subtraction at the adder.\n\n4. **Overall System Function:**\n- The  modulator's primary function is to shape the quantization noise spectrum by placing it in a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, enhancing the signal-to-noise ratio in the desired band through continuous feedback adjustments.\n\n(a)\nimage_name:(a)\ndescription:The diagram illustrates a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the quantization noise spectrum. This modulator enhances the signal-to-noise ratio by attenuating quantization noise within a specific frequency band via a feedback mechanism.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the modulator's driving error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation in the desired band.\n- **Second Adder ():** This adds the quantization noise \\( e(n) \\) to the processed signal \\( x(n) \\), producing the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously minimizes quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is combined with the feedback signal \\( y(n) \\) in the first adder/subtractor. The result is processed by \\( H(z) \\), shaping the signal.\n- The output \\( x(n) \\) from \\( H(z) \\) is combined with quantization noise \\( e(n) \\) in the second adder, producing \\( y(n) \\).\n- The feedback loop ensures \\( y(n) \\) is continuously subtracted from \\( u(n) \\), dynamically adjusting noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal post \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The  modulator's main function is to shape the quantization noise spectrum by incorporating it into a feedback loop. The transfer function \\( H(z) \\) is tailored to attenuate noise in a desired frequency band, thus improving the signal-to-noise ratio. This is achieved through feedback, allowing continuous adjustment of the quantizer's input based on the output, effectively controlling noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general $\\Delta \\Sigma$ modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the quantization noise spectrum, it is placed within a feedback loop whose response is designed to attenuate the noise in the band of interest.\n\nTo effectively shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will closely approximate unity over the band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Thus, quantization noise is reduced in the frequency band of interest while the signal remains largely unaffected. High-frequency noise is not reduced by the feedback due to low loop gain at high frequencies. However, additional post-filtering can effectively remove out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore selecting specific functions for $\\mathrm{H}(\\mathrm{z})$, it's crucial to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, stays within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also remain within $\\pm 1$ for frequencies where $H(z)$ has high gain. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer's output bounds to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where $H(z)$ has low gain will not necessarily cause $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially higher than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma ( $\\Delta \\Sigma$ ) modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and parallels an amplifier realized using an opamp with feedback. In this analogy, the feedback diminishes the impact of the noise from the opamp's output stage on the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. Conversely, at high frequencies where the opamp's gain is low, the noise remains unaffected. It is important to note that the quantizer here is illustrated for a general scenario involving multiple output levels. While many oversampling converters employ 1-bit quantizers (i.e., with only two output levels) for reasons previously discussed, there is no inherent necessity to limit ourselves to such implementations. Multibit oversampling converters are explored in detail in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, as $H(z)$ approaches infinity, equation (18.16) indicates that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled (a) illustrates a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block receives the input signal \\( u(n) \\) and the feedback signal \\( y(n) \\), performing subtraction to generate the error signal.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal, playing a crucial role in shaping the noise spectrum.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to a discrete level, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The resulting signal is processed by the filter \\( H(z) \\), producing \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized, generating the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop essential for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is \\( x(n) \\), and the output is \\( y(n) \\).\n- The feedback path is clearly indicated, showing the subtraction operation at the adder.\n\n4. **Overall System Function:**\n- The primary function of this  modulator is to shape the quantization noise spectrum by placing it within a feedback loop. The transfer function \\( H(z) \\) is designed to attenuate quantization noise within a specific frequency band, thereby improving the signal-to-noise ratio in the desired band. This is achieved through the feedback mechanism, which continuously adjusts the input to the quantizer based on the output, effectively controlling the noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram represents a general  (Delta-Sigma) modulator, an interpolator structure designed to shape the spectrum of quantization noise. This modulator enhances the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through a feedback mechanism.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal that drives the modulator.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for noise attenuation within the desired band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously adjusts to minimize quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) via the first adder/subtractor. The result is processed by \\( H(z) \\), shaping the signal.\n- The output \\( x(n) \\) from \\( H(z) \\) is then combined with the quantization noise \\( e(n) \\) in the second adder to produce \\( y(n) \\).\n- The feedback loop ensures continuous adjustment by subtracting \\( y(n) \\) from \\( u(n) \\), dynamically controlling noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added to the signal.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The primary function of the  modulator is to shape the quantization noise spectrum by incorporating it within a feedback loop. The transfer function \\( H(z) \\) is specifically designed to attenuate noise in a desired frequency band, enhancing the signal-to-noise ratio. This is achieved through the feedback mechanism, which allows continuous adjustment of the quantizer input based on the output, effectively controlling the noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general $\\Delta \\Sigma$ modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the spectrum of a quantization noise source, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest.\n\nTo effectively noise-shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will approximate unity over the frequency band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, quantization noise is reduced within the frequency band of interest while the signal remains largely unaffected. High-frequency noise is not reduced by the feedback due to the low loop gain at high frequencies. However, additional post filtering can effectively remove out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore selecting specific functions for $\\mathrm{H}(\\mathrm{z})$, it is crucial to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the high gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where the gain of $H(z)$ is high. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output levels to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is low will not necessarily cause $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially larger than the feedback levels (see Problem 18.6)."
},
{
    "text": "A general noise-shaped delta-sigma () modulator and its linear model are depicted in Fig. 18.6. This configuration is referred to as an interpolative structure and is comparable to an amplifier implemented using an opamp and feedback. In this comparison, the feedback diminishes the impact of the noise from the opamp's output stage in the closed-loop amplifier's output signal at low frequencies when the opamp's gain is substantial. At high frequencies, where the opamp's gain is minimal, the noise remains unaffected. It is important to note that the quantizer here is illustrated for the general scenario involving multiple output levels. While many oversampling converters utilize 1-bit quantizers (i.e., only two output levels) due to previously discussed reasons, there is no inherent necessity to limit ourselves to such implementations. Multibit oversampling converters are comprehensively covered in Section 18.8.\n\nBy treating the linear model shown in Fig. 18.6(b) as having two independent inputs (which is an approximation), we can derive a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, and a noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$.\n\n$$\n\\begin{align*}\n& S_{T F}(z) \\equiv \\frac{Y(z)}{U(z)}=\\frac{H(z)}{1+H(z)}  \\tag{18.15}\\\\\n& N_{T F}(z) \\equiv \\frac{Y(z)}{E(z)}=\\frac{1}{1+H(z)} \\tag{18.16}\n\\end{align*}\n$$\n\nNote that the zeros of the noise transfer function, $N_{T F}(z)$, will correspond to the poles of $\\mathrm{H}(\\mathrm{z})$. In other words, when $H(z)$ approaches infinity, it follows from (18.16) that $\\mathrm{N}_{T F}(\\mathrm{z})$ will approach zero. We can also express the output signal as a combination of the input signal and the noise signal, each filtered by their respective transfer functions. In the frequency domain, this is represented as\n\n$$\n\\begin{equation*}\nY(z)=S_{T F}(z) U(z)+N_{T F}(z) E(z) \\tag{18.17}\n\\end{equation*}\n$$\n\nimage_name:(a)\ndescription:The diagram labeled as (a) depicts a general Delta-Sigma () modulator, commonly used in analog-to-digital conversion to shape quantization noise.\n\n1. **Main Components:**\n- **Adder/Subtractor Node (+):** This block accepts the input signal \\( u(n) \\) and the feedback signal from the output \\( y(n) \\), performing subtraction of the feedback from the input.\n- **Transfer Function Block \\( H(z) \\):** This block processes the output from the adder, representing the filter with a transfer function \\( H(z) \\), essential for noise shaping.\n- **Quantizer:** This block takes the filtered signal \\( x(n) \\) from \\( H(z) \\) and converts it to a discrete level, introducing quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) is fed into the adder, where it is combined with the feedback signal \\( y(n) \\).\n- The subtraction result is processed by the filter \\( H(z) \\), producing the signal \\( x(n) \\).\n- The signal \\( x(n) \\) is then quantized by the Quantizer block, generating the output \\( y(n) \\).\n- The output \\( y(n) \\) is fed back to the adder, forming a feedback loop crucial for noise shaping.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The input is labeled \\( u(n) \\), the intermediate signal after \\( H(z) \\) is labeled \\( x(n) \\), and the output is labeled \\( y(n) \\).\n- The feedback path is clearly marked, indicating the subtraction operation at the adder.\n\n4. **Overall System Function:**\n- The primary role of this  modulator is to shape the spectrum of quantization noise by incorporating it within a feedback loop. The transfer function \\( H(z) \\) is designed to reduce quantization noise in a specific frequency band, enhancing the signal-to-noise ratio in the desired band. This is achieved through the feedback mechanism, which continuously adjusts the input to the quantizer based on the output, effectively controlling noise characteristics.\n\n(a)\nimage_name:(a)\ndescription:The diagram illustrates a general  (Delta-Sigma) modulator, an interpolator structure used for shaping the spectrum of quantization noise. This modulator is designed to enhance the signal-to-noise ratio by attenuating quantization noise within a specific frequency band through a feedback mechanism.\n\n1. **Main Components:**\n- **Adder/Subtractor ():** Located at the input, it receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), generating the error signal that drives the modulator.\n- **Transfer Function Block \\( H(z) \\):** This block processes the error signal to shape the noise spectrum, crucial for attenuating noise in the desired frequency band.\n- **Second Adder ():** This component combines the quantization noise \\( e(n) \\) with the processed signal \\( x(n) \\) to produce the output signal \\( y(n) \\).\n- **Feedback Loop:** The output \\( y(n) \\) is fed back to the input subtractor, forming a closed-loop system that continuously adjusts to minimize quantization noise.\n\n2. **Flow of Information or Control:**\n- The input signal \\( u(n) \\) enters the system and is immediately combined with the feedback signal \\( y(n) \\) via the first adder/subtractor. The result is passed through the transfer function \\( H(z) \\), shaping the signal.\n- The output of \\( H(z) \\), denoted \\( x(n) \\), is then combined with the quantization noise \\( e(n) \\) in the second adder to produce the final output \\( y(n) \\).\n- The feedback loop ensures that \\( y(n) \\) is continuously subtracted from \\( u(n) \\), allowing the system to dynamically adjust and control noise characteristics.\n\n3. **Labels, Annotations, and Key Indicators:**\n- \\( u(n) \\): Input signal.\n- \\( x(n) \\): Intermediate signal after processing by \\( H(z) \\).\n- \\( e(n) \\): Quantization noise added to the signal.\n- \\( y(n) \\): Output signal, also used as feedback.\n\n4. **Overall System Function:**\n- The primary function of the  modulator is to shape the quantization noise spectrum by placing it within a feedback loop. The transfer function \\( H(z) \\) is specifically designed to attenuate noise in a desired frequency band, thus improving the signal-to-noise ratio. This is achieved through the feedback mechanism, which allows the system to continuously adjust the input to the quantizer based on the output, effectively controlling the noise characteristics.\n\n(b)\n\nFig. 18.6 A modulator and its linear model: (a) a general  modulator (interpolator structure); (b) linear model of the modulator showing injected quantization noise.\n\nKey Point: To shape the spectrum of quantization noise, it is placed within a feedback loop whose response is designed to attenuate the quantization noise in the band of interest.\n\nTo effectively shape the quantization noise, we select $H(z)$ such that its magnitude is significant from 0 to $f_{0}$ (i.e., over the frequency band of interest). With this choice, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{Z})$, will approximate unity over the frequency band of interest, similar to an opamp in a unity-gain feedback configuration. Additionally, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, will approximate zero over the same band. Consequently, the quantization noise is reduced in the frequency band of interest while the signal remains largely unaffected. The high-frequency noise is not reduced by the feedback due to the low loop gain at high frequencies. However, additional post filtering can eliminate the out-of-band quantization noise with minimal impact on the desired signal.\n\nBefore determining specific functions for $\\mathrm{H}(\\mathrm{z})$, it is crucial to ensure that the maximum level of the in-band input signal, $\\mathrm{u}(\\mathrm{n})$, remains within the maximum levels of the feedback signal, $\\mathrm{y}(\\mathrm{n})$; otherwise, the large gain in $\\mathrm{H}(\\mathrm{z})$ will cause the signal $x(n)$ to saturate. For instance, if a 1-bit quantizer with output levels of $\\pm 1$ is used, the input signal must also stay within $\\pm 1$ for frequencies where the gain of $H(z)$ is high. In fact, for many modulators, the input signal needs to be significantly smaller than the quantizer output levels to maintain stability. ${ }^{3}$ However, the maximum level of the input signal, $u(n)$, for frequencies where the gain of $H(z)$ is low will not necessarily cause the signal $x(n)$ to saturate. In other words, the maximum level of the out-of-band input signal can be substantially larger than the feedback levels (see Problem 18.6)."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop introduces a zero at dc in the noise transfer function, thereby providing first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must possess a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Given that the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be attained by configuring $H(z)$ as a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is depicted in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The first summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), with the difference then passed to the next block.\n- The second summing junction combines the output from the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is input into a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is fed into a quantizer block, which converts the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is crucial for shaping noise and ensuring system stability, taking the output \\( y(n) \\) and feeding it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The result is processed through the second summing junction and the integrator \\( z^{-1} \\), producing \\( x(n) \\).\n- \\( x(n) \\) is quantized to generate the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and integration process, which together maintain stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). Refer to Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated implementations due to their reduced sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) is used, and the initial state for $\\mathrm{x}(\\mathrm{n})$ is 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, observe that the output pattern is periodic, indicating that the quantization noise is not random in this scenario. (Nevertheless, this result is significantly more satisfactory than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as its output.)\n\nFrequency Domain Perspective From a frequency domain perspective, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is simply a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides yields the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nAssuming $f_{0}<<f_{s}$ (i.e., OSR $>>1$), we can approximate $\\sin \\left((\\pi f) / f_{s}\\right)$ as $(\\pi f) / f_{s}$, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power matches that previously derived in (18.11), the maximum SNR for this case is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for every doubling of OSR.\n\nThis demonstrates that doubling the OSR results in a 9 dB improvement in SQNR for a first-order modulator, which corresponds to a gain of 1.5 bits/octave. This should be compared to the 0.5 bits/octave improvement achieved with oversampling alone, without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop introduces a zero at dc in the noise transfer function, thereby achieving first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must have a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Given that the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be realized by configuring $H(z)$ as a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is depicted in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The first summing junction subtracts the feedback signal $y(n)$ from the input signal $u(n)$, passing the difference to the next block.\n- The second summing junction combines the output of the first summing junction with the feedback signal $y(n)$ that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is fed into a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output $x(n)$ is input to a quantizer block, which converts the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, $y(n)$, is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is crucial for noise shaping and maintaining system stability. It takes the output $y(n)$ and feeds it back to the input of the first summing junction.\n\n**Flow of Information:**\n- The input signal $u(n)$ enters the system and is combined with the feedback signal $y(n)$ at the first summing junction.\n- The result is processed through the second summing junction and the integrator \\( z^{-1} \\), producing $x(n)$.\n- $x(n)$ is quantized, resulting in the output $y(n)$, which is also used as feedback.\n\n**Overall System Function:**\n- The primary function of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is achieved through the feedback mechanism and integration process, which together ensure stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). Refer to Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated realizations due to their lower sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this configuration to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) is used, and the initial state for $x(n)$ is 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as expected. However, also observe that the output pattern is periodic, indicating that the quantization noise is not random in this example. (Nevertheless, this result is significantly better than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as its output.)\n\nFrequency Domain Perspective From a frequency domain perspective, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is simply a delay, while the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides, we obtain the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nNow, the quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nAssuming $f_{0}<<f_{s}$ (i.e., OSR $>>1$), we can approximate $\\sin \\left((\\pi f) / f_{s}\\right)$ as $(\\pi f) / f_{s}$, yielding\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is consistent with that previously derived in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or by 9 dB for each doubling of OSR.\n\nThis demonstrates that doubling the OSR enhances the SQNR for a first-order modulator by 9 dB, or equivalently, by 1.5 bits/octave. This result should be compared to the 0.5 bits/octave improvement achieved with oversampling alone, without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop positions a zero at dc in the noise transfer function, thereby achieving first-order noise shaping for low-pass signals.\n\nTo implement first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must exhibit a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Given that the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be attained by configuring $H(z)$ as a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is depicted in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This outcome indicates that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram represents a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The initial summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\). This difference is then directed to the subsequent block.\n- The second summing junction combines the output from the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is input into a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is fed into a quantizer block. The quantizer transforms the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, signal \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is essential for shaping the noise and ensuring system stability. It takes the output \\( y(n) \\) and feeds it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The resultant signal is processed through the second summing junction and the integrator \\( z^{-1} \\), producing \\( x(n) \\).\n- \\( x(n) \\) is quantized, resulting in the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape the quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and the integration process, which collectively help maintain stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). See Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated realizations due to their lower sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) is used, and the initial state for $\\mathrm{x}(\\mathrm{n})$ is 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, also observe that the output pattern is periodic, indicating that the quantization noise is not random in this scenario. (Nevertheless, this result is significantly more satisfactory than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as its output.)\n\nFrequency Domain Perspective From a frequency domain viewpoint, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is simply a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we let $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides, we obtain the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nBy approximating $f_{0}<<f_{s}$ (i.e., OSR $>>1$), allowing $\\sin \\left((\\pi f) / f_{s}\\right)$ to be approximated as $(\\pi f) / f_{s}$, we derive\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power corresponds to that previously obtained in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for each doubling of OSR.\n\nIt is evident that doubling the OSR results in a 9 dB enhancement in SQNR for a first-order modulator, which is equivalent to a gain of 1.5 bits/octave. This outcome should be compared to the 0.5 bits/octave improvement achieved with oversampling alone, without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop introduces a zero at dc in the noise transfer function, thereby achieving first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must have a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Since the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be realized by making $H(z)$ a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is presented in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Given the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The first summing junction takes the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), passing the difference to the next block.\n- The second summing junction combines the output of the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is input to a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is fed into a quantizer block, which converts the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is essential for shaping noise and ensuring system stability, taking the output \\( y(n) \\) and feeding it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The result is processed through the second summing junction and the integrator \\( z^{-1} \\), producing \\( x(n) \\).\n- \\( x(n) \\) is quantized to generate the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and integration process, which together help maintain stability and prevent quantizer overload.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). See Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated realizations due to their reduced sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when using a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) and an initial state for $\\mathrm{x}(\\mathrm{n})$ of 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, also observe that the output pattern is periodic, indicating that the quantization noise is not random in this example. (Nevertheless, this result is significantly better than directly applying $1 / 3$ to a 1-bit quantizer using simple oversampling, which would yield all 1s as the output.)\n\nFrequency Domain Perspective From a frequency domain viewpoint, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is merely a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides, we obtain the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nAssuming $f_{0}<<f_{s}$ (i.e., OSR $>>1$), we can approximate $\\sin \\left((\\pi f) / f_{s}\\right)$ as $(\\pi f) / f_{s}$, yielding\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is the same as previously derived in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for each doubling of OSR.\n\nWe observe that doubling the OSR results in a 9 dB enhancement in SQNR for a first-order modulator, which translates to a gain of 1.5 bits/octave. This outcome should be compared to the 0.5 bits/octave improvement achieved with oversampling alone, without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within the feedback loop of a $\\Delta \\Sigma$ modulator introduces a zero at dc in the noise transfer function, thereby providing first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must have a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Since the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be attained by configuring $H(z)$ as a discrete-time integrator (i.e., possessing a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is presented in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The first summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), passing the difference to the next block.\n- The second summing junction combines the output of the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is directed to a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is input to a quantizer block, which converts the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is crucial for noise shaping and maintaining system stability. It routes the output \\( y(n) \\) back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The result is then processed through the second summing junction and the integrator \\( z^{-1} \\), producing \\( x(n) \\).\n- \\( x(n) \\) is quantized to generate the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and integration process, which together ensure stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). See Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated realizations due to their reduced sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$, using a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) and an initial state for $\\mathrm{x}(\\mathrm{n})$ of 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, observe that the output pattern is periodic, indicating that the quantization noise is not random in this instance. (Nevertheless, this result is significantly more satisfactory than directly applying $1 / 3$ to a 1-bit quantizer using simple oversampling, which would yield all 1s as the output.)\n\nFrequency Domain Analysis From a frequency domain perspective, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is merely a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides yields the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nAssuming $f_{0}<<f_{s}$ (i.e., OSR $>>1$), we can approximate $\\sin \\left((\\pi f) / f_{s}\\right)$ as $(\\pi f) / f_{s}$, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is consistent with that derived in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for each doubling of OSR.\n\nWe observe that doubling the OSR results in a 9 dB enhancement in SQNR for a first-order modulator, which translates to a gain of 1.5 bits/octave. This should be contrasted with the 0.5 bits/octave improvement achieved through oversampling alone without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop positions a zero at dc in the noise transfer function, thereby achieving first-order noise shaping for low-pass signals.\n\nTo implement first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must exhibit a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Given that the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping is attainable by configuring $H(z)$ as a discrete-time integrator (i.e., possessing a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is presented in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system consists of the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The initial summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), with the difference then forwarded to the next block.\n- The second summing junction combines the output from the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is directed to a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is input to a quantizer block, which transforms the continuous range of input values into discrete levels, thereby introducing quantization noise.\n- The quantizer's output, signal \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is essential for shaping the noise and ensuring system stability, taking the output \\( y(n) \\) and feeding it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The resulting signal is processed through the second summing junction and the integrator \\( z^{-1} \\), producing \\( x(n) \\).\n- \\( x(n) \\) is then quantized to generate the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and integration process, which collectively maintain stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). Refer to Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated implementations due to their reduced sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with substantial gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when employing a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) and an initial state for $\\mathrm{x}(\\mathrm{n})$ of 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, observe that the output pattern is periodic, indicating that the quantization noise is not random in this instance. (Nevertheless, this outcome is significantly more favorable than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as the output.)\n\nFrequency Domain Perspective From a frequency domain viewpoint, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function merely represents a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides yields the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nBy approximating $f_{0}<<f_{s}$ (i.e., OSR $>>1$), allowing $\\sin \\left((\\pi f) / f_{s}\\right)$ to be approximated by $(\\pi f) / f_{s}$, we obtain\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power matches that derived previously in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for each doubling of OSR.\n\nThis demonstrates that doubling the OSR results in a 9 dB enhancement in SQNR for a first-order modulator, which translates to a gain of 1.5 bits/octave. This should be contrasted with the 0.5 bits/octave improvement achieved by oversampling alone without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop introduces a zero at dc in the noise transfer function, thereby providing first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must exhibit a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Given that the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping can be attained by configuring $H(z)$ as a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is presented in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This implies that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator utilized in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The initial summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\), with the result passed to the subsequent block.\n- The second summing junction combines the output from the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is directed to a discrete-time integrator, represented by the block \\( z^{-1} \\). This block integrates the input signal over time, effectively performing discrete-time integration.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is input to a quantizer block, which transforms the continuous range of input values into discrete levels, thereby introducing quantization noise.\n- The quantizer's output, signal \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is crucial for noise shaping and ensuring system stability, taking the output \\( y(n) \\) and feeding it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The resultant signal is processed through the second summing junction and the integrator \\( z^{-1} \\), generating \\( x(n) \\).\n- \\( x(n) \\) is then quantized, producing the output \\( y(n) \\), which is also used for feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and integration process, which collectively maintain stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). Refer to Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated implementations due to their reduced sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$, using a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) and an initial state for $\\mathrm{x}(\\mathrm{n})$ of 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, observe that the output pattern is periodic, indicating that the quantization noise is not random in this scenario. (Nevertheless, this outcome is significantly more favorable than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as the output.)\n\nFrequency Domain Perspective From a frequency domain perspective, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is merely a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we set $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides yields the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nBy approximating $f_{0}<<f_{s}$ (i.e., OSR $>>1$), allowing $\\sin \\left((\\pi f) / f_{s}\\right)$ to be approximated by $(\\pi f) / f_{s}$, we obtain\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power matches that previously derived in (18.11), the maximum SNR for this case is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for each doubling of OSR.\n\nWe observe that doubling the OSR results in a 9 dB enhancement in SQNR for a first-order modulator, which is equivalent to a 1.5 bits/octave gain. This should be compared to the 0.5 bits/octave improvement when oversampling without noise shaping."
},
{
    "text": "Key Point: Incorporating a single integrator within a $\\Delta \\Sigma$ modulator's feedback loop positions a zero at dc in the noise transfer function, thereby achieving first-order noise shaping for low-pass signals.\n\nTo achieve first-order noise shaping, the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathbf{z})$, must have a zero at dc (i.e., $\\mathbf{z}=1$), ensuring that quantization noise is high-pass filtered. Since the zeros of $N_{T F}(z)$ correspond to the poles of $H(z)$, first-order noise shaping is attained by making $H(z)$ a discrete-time integrator (i.e., having a pole at z = 1). ${ }^{4}$ Specifically,\n\n$$\n\\begin{equation*}\nH(z)=\\frac{1}{z-1} \\tag{18.18}\n\\end{equation*}\n$$\n\nA block diagram illustrating this configuration is presented in Fig. 18.7.\nTime Domain Perspective From a time domain standpoint, if the feedback operates correctly and the system remains stable, the signal $x(n)$ remains bounded (i.e., $\\neq \\infty$). Due to the integrator's infinite dc gain, the average value of the discrete-time integrator's input must precisely equal zero (i.e., the average value of $u(n)-y(n)$ equals zero). This outcome indicates that the average value (i.e., dc value) of $u(n)$ must match the average value (i.e., dc value) of $y(n)$.\nimage_name:Fig. 18.7 A first-order noise-shaped interpolative modulator\ndescription:The diagram depicts a first-order noise-shaped interpolative modulator, a type of sigma-delta modulator used in digital signal processing. The system includes the following key components:\n\n1. **Summing Junctions:**\n- The system features two summing points. The first summing junction receives the input signal \\( u(n) \\) and subtracts the feedback signal \\( y(n) \\). This difference is then directed to the next block.\n- The second summing junction combines the output of the first summing junction with the feedback signal \\( y(n) \\) that has passed through a delay element.\n\n2. **Integrator (\\( z^{-1} \\)):**\n- The output from the second summing junction is input into a discrete-time integrator, represented by the block \\( z^{-1} \\). This block accumulates the input signal over time, effectively performing integration in the discrete-time domain.\n\n3. **Quantizer:**\n- The integrator's output \\( x(n) \\) is fed into a quantizer block. The quantizer transforms the continuous range of input values into discrete levels, introducing quantization noise.\n- The quantizer's output, \\( y(n) \\), is also fed back as a negative feedback loop to the first summing junction.\n\n4. **Feedback Loop:**\n- The feedback loop is essential for shaping the noise and ensuring system stability. It takes the output \\( y(n) \\) and feeds it back to the input of the first summing junction.\n\n**Information Flow:**\n- The input signal \\( u(n) \\) enters the system and is combined with the feedback signal \\( y(n) \\) at the first summing junction.\n- The result is then processed through the second summing junction and the integrator \\( z^{-1} \\), generating \\( x(n) \\).\n- \\( x(n) \\) is quantized, resulting in the output \\( y(n) \\), which is also used as feedback.\n\n**System Function:**\n- The primary role of this modulator is to shape the quantization noise and enhance the signal-to-noise ratio (SNR) by shifting the noise to higher frequencies, where it can be more easily filtered out. This is accomplished through the feedback mechanism and the integration process, which together help maintain stability and prevent quantizer overloading.\n\nFig. 18.7 A first-order noise-shaped interpolative modulator.\n3. A modulator is deemed stable if the input to the quantizer does not become excessively large, causing the quantizer error to exceed $\\pm \\Delta / 2$ (a condition known as overloading the quantizer). See Section 18.7.\n4. While continuous-time integrators can be used, discrete-time integrators are more commonly employed in integrated implementations due to their lower sensitivity to sampling jitter and superior distortion characteristics.\n\nThe resemblance of this setup to an opamp with unity-gain feedback is noteworthy. The open-loop transfer function of an opamp closely resembles a first-order integrator with very high gain at low frequencies.\n\n#### EXAMPLE 18.4\n\nDetermine the output sequence and state values for a dc input, $u(n)$, of $1 / 3$ when a two-level quantizer with levels $\\pm 1.0$ (threshold at zero) is used, and the initial state for $\\mathrm{x}(\\mathrm{n})$ is 0.1.\n\n#### Solution\n\nThe output sequence and state values are presented in Table 18.2.\nNote that the average of $y(n)$ precisely equals $1 / 3$ as anticipated. However, also observe that the output pattern is periodic, indicating that the quantization noise is not random in this example. (Nevertheless, this result is significantly better than directly applying $1 / 3$ to a 1-bit quantizer using straightforward oversampling, which would yield all 1s as its output.)\n\nFrequency Domain Perspective From a frequency domain perspective, the signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(z)=\\frac{Y(Z)}{U(Z)}=\\frac{1 /(Z-1)}{1+1 /(Z-1)}=Z^{-1} \\tag{18.19}\n\\end{equation*}\n$$\n\nand the noise transfer function, $\\mathrm{N}_{\\mathrm{TF}}(\\mathrm{Z})$, is given by\n\n$$\n\\begin{equation*}\nN_{T F}(z)=\\frac{Y(z)}{E(z)}=\\frac{1}{1+1 /(z-1)}=\\left(1-z^{-1}\\right) \\tag{18.20}\n\\end{equation*}\n$$\n\nHere, the signal transfer function is simply a delay, whereas the noise transfer function acts as a discrete-time differentiator (i.e., a high-pass filter).\n\nTo determine the magnitude of the noise transfer function, $\\left|N_{T F}(f)\\right|$, we let $Z=e^{j \\omega T}=e^{j 2 \\pi t / f_{s}}$ and derive the following:\n\n$$\n\\begin{align*}\nN_{T F}(f) & =1-e^{-j 2 \\pi \\tau / f_{s}}=\\frac{e^{j \\pi f / f_{s}}-e^{-j \\pi t / f_{s}}}{2 j} \\times 2 j \\times e^{-j \\pi t / f_{s}}  \\tag{18.21}\\\\\n& =\\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\times 2 j \\times e^{-j \\pi f / f_{s}}\n\\end{align*}\n$$\n\nTable 18.2 First-order modulator example.\n\n| $\\mathbf{n}$ | $\\mathbf{x}(\\mathbf{n})$ | $\\mathbf{x}(\\mathbf{n}+\\mathbf{1})$ | $\\mathbf{y ( n )}$ | $\\mathbf{e ( n )}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 1 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 2 | 0.7667 | 0.1 | 1.0 | 0.2333 |\n| 3 | 0.1 | -0.5667 | 1.0 | 0.9 |\n| 4 | -0.5667 | 0.7667 | -1.0 | -0.4333 |\n| 5 | $\\ldots$ | $\\cdots$ | $\\cdots$ | $\\cdots$ |\n\nTaking the magnitude of both sides, we obtain the high-pass function\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right) \\tag{18.22}\n\\end{equation*}\n$$\n\nThe quantization noise power over the frequency band from 0 to $f_{0}$ is calculated as\n\n$$\n\\begin{equation*}\nP_{e}=\\int_{-f_{0}}^{f_{0}} S_{e}^{2}(f)\\left|N_{T F}(f)\\right|^{2} d f=\\int_{-f_{0}}^{f_{0}}\\left(\\frac{\\Delta^{2}}{12}\\right) \\frac{1}{f_{s}}\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} d f \\tag{18.23}\n\\end{equation*}\n$$\n\nAssuming $f_{0}<<f_{s}$ (i.e., OSR $>>1$), we can approximate $\\sin \\left((\\pi f) / f_{s}\\right)$ to be $(\\pi f) / f_{s}$, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong\\left(\\frac{\\Delta^{2}}{12}\\right)\\left(\\frac{\\pi^{2}}{3}\\right)\\left(\\frac{2 \\mathrm{f}_{0}}{\\mathrm{f}_{\\mathrm{s}}}\\right)^{3}=\\frac{\\Delta^{2} \\pi^{2}}{36}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{3} \\tag{18.24}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power matches that previously derived in (18.11), the maximum SNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{3}{\\pi^{2}}(\\mathrm{OSR})^{3}\\right] \\tag{18.25}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-5.17+30 \\log (\\mathrm{OSR}) \\tag{18.26}\n\\end{equation*}\n$$\n\nKey Point: First-order noise shaping allows the SQNR to improve by 1.5 bits/octave relative to the oversampling ratio, or 9 dB for every doubling of OSR.\n\nWe observe that doubling the OSR enhances the SQNR for a first-order modulator by 9 dB, or equivalently, by 1.5 bits/octave. This result should be contrasted with the 0.5 bits/octave improvement achieved by oversampling alone without noise shaping."
},
{
    "text": "The modulator depicted in Fig. 18.10 implements second-order noise shaping, meaning the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function. For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 illustrates a second-order noise-shaping modulator. This system comprises an adder, a delay element, a feedback loop with a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Main Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially fed into an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The adder's output is then passed through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay.\n- **Quantizer:** The delayed signal undergoes quantization, converting it from analog to digital form, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, converting it back to analog for subtraction from the input signal.\n\n2. **Information Flow and Control:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, generating an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized, producing the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, involving the 1-bit D/A converter, provides a feedback signal subtracted from the input at the adder, completing the loop.\n\n3. **Labels and Annotations:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly shown, highlighting the digital-to-analog conversion.\n- The filter \\( H(z) \\) is indicated, signifying its role in noise shaping.\n\n4. **System Function Overview:**\n- This setup is designed for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, shifting it to higher frequencies for easier filtering. The feedback and quantizer enable conversion of an analog input to a digital output with reduced noise in the desired frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This figure shows a first-order A/D modulator using a switched-capacitor approach. It performs analog-to-digital conversion by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator employing a switched-capacitor implementation. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using a single input capacitance for the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter for high-resolution digital signals from analog inputs. The key components and their interactions are:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), entering the system.\n\n2. **Summing Junctions**: Two summing junctions at the start subtract the feedback signal from the input signal, u(n), with the output feeding into a delay block.\n\n3. **Delay Blocks (z)**: Two delay blocks in the system represent discrete-time delays, storing previous output states crucial for noise shaping in  modulators.\n\n4. **Feedback Loops**: Feedback loops take the output signal, y(n), and feed it back to the summing junctions, essential for noise shaping properties.\n\n5. **Quantizer**: After the second delay block, the signal enters a quantizer, converting it from continuous-time to discrete-time digital form, y(n).\n\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced by noise shaping.\n\n**System Function Summary**: The second-order  modulator uses integration and feedback to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output. The combination of summing junctions, delay elements, feedback loops, and the quantizer effectively performs this function.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nThe noise transfer function is given by\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function is\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nyielding the quantization noise power in the frequency band of interest as\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is as in (18.11), the maximum SQNR for this case is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each doubling of OSR, equivalent to 1.5 bits/octave.\n\nHere, doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, by 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is an exercise for the reader."
},
{
    "text": "The depicted modulator in Fig. 18.10 achieves second-order noise shaping (i.e., the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 depicts a second-order noise-shaping modulator. The core components of this system include an adder, a delay element, a feedback loop incorporating a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Core Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially fed into an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The output from the adder passes through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay to the signal.\n- **Quantizer:** The delayed signal is then quantized, converting the analog signal to a digital signal, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, converting the digital signal back to analog for subtraction from the input signal.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, producing an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized, resulting in the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, including the 1-bit D/A converter, provides a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly shown, illustrating the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System Function Overview:**\n- This system is designed for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, effectively shifting the noise to higher frequencies for easier removal. The feedback and quantizer enable the system to convert an analog input to a digital output with reduced noise in the desired frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This figure shows a first-order A/D modulator using a switched-capacitor approach. The circuit performs analog-to-digital conversion by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator using a switched-capacitor method. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches managed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using a single input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The main components and their interactions are as follows:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), entering the system.\n2. **Summing Junctions**: Two summing junctions are at the diagram's start. The first subtracts the feedback signal from the input signal, u(n), with the output fed into a delay block.\n3. **Delay Blocks (z)**: Two delay blocks in the system act as discrete-time delay elements, storing the previous output state crucial for the integrative behavior needed for noise shaping in  modulators.\n4. **Feedback Loops**: The system includes feedback loops that take the output signal, y(n), and feed it back into the summing junctions, essential for the modulator's noise shaping properties.\n5. **Quantizer**: After the second delay block, the signal enters a quantizer, converting the continuous-time signal to a discrete-time digital signal, y(n), the primary output.\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced in resolution due to noise shaping.\n\n**System Function Overview**: The second-order  modulator utilizes its integrative and feedback properties to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from an analog input. The combination of summing junctions, delay elements, feedback loops, and the quantizer effectively performs this function.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is expressed as\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function can be shown to be\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nresulting in the quantization noise power over the frequency band of interest being\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is as derived in (18.11), the maximum SQNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor, alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each doubling of OSR, equivalent to 1.5 bits/octave.\n\nHere, doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, by 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is an exercise for the reader."
},
{
    "text": "The depicted modulator in Fig. 18.10 accomplishes second-order noise shaping (i.e., the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 depicts a second-order noise-shaping modulator. This system's main components include an adder, a delay element, a feedback loop incorporating a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Primary Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially introduced to an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The adder's output is then routed through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay to the signal.\n- **Quantizer:** The delayed signal undergoes quantization. The quantizer transforms the analog signal into a digital signal, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, converting the digital signal back to analog for subtraction from the input signal.\n\n2. **Information Flow and Control:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, generating an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized, producing the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, consisting of the 1-bit D/A converter, provides a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly delineated, showing the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System Function Overview:**\n- This system is engineered for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, effectively shifting the noise to higher frequencies for easier filtering. The feedback and quantizer enable the system to convert an analog input into a digital output with reduced noise in the desired frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This illustrates a first-order A/D modulator using a switched-capacitor approach. The circuit performs analog-to-digital conversion by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator employing a switched-capacitor implementation. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using a single input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The main components and their interactions are as follows:\n\n1. **Input Signal (u(n))**: The process initiates with the input signal, u(n), entering the system.\n2. **Summing Junctions**: Two summing junctions at the diagram's start subtract the feedback signal from the input signal, u(n), with the output feeding into a delay block.\n3. **Delay Blocks (z)**: Two delay blocks represent discrete-time delay elements, storing the previous output state essential for the modulator's integrative behavior.\n4. **Feedback Loops**: The system includes feedback loops that route the output signal, y(n), back to the summing junctions, crucial for noise shaping.\n5. **Quantizer**: Following the second delay block, the signal enters a quantizer, converting the continuous-time signal to a discrete-time digital signal, y(n).\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced by noise shaping.\n\n**System Function Overview**: The second-order  modulator leverages its integrative and feedback properties to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output. The summing junctions, delay elements, feedback loops, and quantizer collectively perform this function efficiently.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is expressed as\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function can be derived as\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nyielding the quantization noise power over the frequency band of interest as\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power corresponds to that in (18.11), the maximum SQNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor, alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each OSR doubling, or equivalently by 1.5 bits/octave.\n\nHere, doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, a gain of 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is left as an exercise for the interested reader."
},
{
    "text": "The depicted modulator in Fig. 18.10 accomplishes second-order noise shaping, meaning the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function. For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 depicts a second-order noise-shaping modulator. This system's main components include an adder, a delay element, a feedback loop incorporating a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Primary Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially routed to an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The adder's output is then passed through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay to the signal.\n- **Quantizer:** The delayed signal undergoes quantization, converting the analog signal to a digital signal, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, which reconverts the digital signal to analog for subtraction from the input signal.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, producing an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized, resulting in the digital output \\( y(n) \\), which is also looped back into the system.\n- The feedback loop, containing the 1-bit D/A converter, generates a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly delineated, showing the digital-to-analog conversion.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System's Overall Function:**\n- This setup is designed for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, effectively shifting the noise to higher frequencies for easier filtration. The feedback and quantizer enable the system to convert an analog input to a digital output with reduced noise in the target frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This figure illustrates a first-order A/D modulator using a switched-capacitor approach. The circuit converts analog to digital by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator employing a switched-capacitor technique. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using a single input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram shows a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The main components and their interactions are as follows:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), entering the system.\n2. **Summing Junctions**: Two summing junctions at the diagram's start subtract the feedback signal from the input signal, u(n), with the output feeding into a delay block.\n3. **Delay Blocks (z)**: Two delay blocks in the system act as discrete-time delay elements, storing previous output states crucial for the integrative behavior needed for noise shaping in  modulators.\n4. **Feedback Loops**: The system includes feedback loops that take the output signal, y(n), and feed it back into the summing junctions, essential for the modulator's noise shaping properties.\n5. **Quantizer**: After the second delay block, the signal enters a quantizer, converting the continuous-time signal to a discrete-time digital signal, y(n), the primary output.\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced in resolution due to noise shaping.\n\n**Overall System Function**: The second-order  modulator employs integrative and feedback properties to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from an analog input. The combination of summing junctions, delay elements, feedback loops, and the quantizer effectively performs this function.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is expressed as\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function can be derived as\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nThis results in the quantization noise power over the frequency band of interest being\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is as derived in (18.11), the maximum SQNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor, alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each doubling of OSR, equivalent to 1.5 bits/octave.\n\nHere, doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, by 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is an exercise for the reader."
},
{
    "text": "The modulator depicted in Fig. 18.10 achieves second-order noise shaping (i.e., the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 illustrates a second-order noise-shaping modulator. The main components of this system include an adder, a delay element, a feedback loop with a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Primary Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially fed into an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The output from the adder is then passed through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay to the signal.\n- **Quantizer:** The delayed signal undergoes quantization. The quantizer transforms the analog signal into a digital signal, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, converting the digital signal back to analog for subtraction from the input signal.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) combines with the feedback signal from the 1-bit D/A in the adder, generating an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized, producing the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, comprising the 1-bit D/A converter, provides a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels and Annotations:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly shown, illustrating the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System Function Overview:**\n- This system is designed for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, effectively shifting the noise to higher frequencies for easier filtering. The feedback and quantizer enable the conversion of an analog input signal to a digital output with reduced noise in the desired frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This depicts a first-order A/D modulator using a switched-capacitor approach. The circuit performs analog-to-digital conversion by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator employing a switched-capacitor implementation. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using a single input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The key components and their interactions are as follows:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), entering the system.\n\n2. **Summing Junctions**: Two summing junctions at the start of the diagram subtract the feedback signal from the input signal, u(n). The output from the first summing junction is fed into a delay block.\n\n3. **Delay Blocks (z)**: Two delay blocks in the system act as discrete-time delay elements, storing the previous output state essential for the integrative behavior in  modulators.\n\n4. **Feedback Loops**: The system includes feedback loops that take the output signal, y(n), and feed it back into the summing junctions. This feedback is crucial for the modulator's noise shaping capabilities, pushing quantization noise out of the desired frequency band.\n\n5. **Quantizer**: After the second delay block, the signal is sent to a quantizer, converting the continuous-time signal into a discrete-time digital signal, y(n).\n\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced in resolution due to noise shaping.\n\n**System Function Summary**: The second-order  modulator utilizes its integrative and feedback properties to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from an analog input. The combination of summing junctions, delay elements, feedback loops, and the quantizer effectively performs this function.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is expressed as\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function can be shown to be\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nresulting in the quantization noise power over the frequency band of interest being\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power is as derived in (18.11), the maximum SQNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor, alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each doubling of OSR, or equivalently by 1.5 bits/octave.\n\nWe observe that doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, by 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is left as an exercise for the interested reader."
},
{
    "text": "The modulator depicted in Fig. 18.10 achieves second-order noise shaping, meaning the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function. For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:Fig. 18.8(a) presents a block diagram of a second-order noise-shaping modulator. This system comprises an adder, a delay element, a feedback loop with a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Primary Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially processed by an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The output from the adder passes through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay.\n- **Quantizer:** The delayed signal undergoes quantization, converting it from analog to digital form, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit D/A converter, reverting the digital signal to analog for subtraction from the input signal.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, producing an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is then quantized, resulting in the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, including the 1-bit D/A converter, provides a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels and Annotations:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly shown, illustrating the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System Function Overview:**\n- This setup is designed for second-order noise shaping, utilizing component arrangement to high-pass filter quantization noise, shifting it to higher frequencies for easier removal. The feedback and quantizer enable the conversion of an analog input to a digital output with reduced noise in the target frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This figure shows a first-order A/D modulator implemented using switched-capacitors. The circuit integrates the input signal and compares it to a reference voltage, latching the output on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator using a switched-capacitor approach. It integrates the input signal and compares it to a reference voltage, latching the output on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator with a single input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:This diagram shows a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The main components and their interactions are:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), entering the system.\n\n2. **Summing Junctions**: Two summing junctions at the start subtract the feedback signal from the input signal, u(n), with the output feeding into a delay block.\n\n3. **Delay Blocks (z)**: Two delay blocks in the system store the previous output state, essential for the integrative behavior needed for noise shaping in  modulators.\n\n4. **Feedback Loops**: Feedback loops take the output signal, y(n), and feed it back to the summing junctions, crucial for the modulator's noise shaping properties.\n\n5. **Quantizer**: After the second delay block, the signal enters a quantizer, converting the continuous-time signal to a discrete-time digital signal, y(n).\n\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the analog input, enhanced by noise shaping.\n\n**System Function Summary**: The second-order  modulator uses integration and feedback to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from an analog input. The summing junctions, delay elements, feedback loops, and quantizer collaborate to perform this function efficiently.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nThe noise transfer function is given by\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function is\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nThe quantization noise power in the frequency band of interest is\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power as in (18.11), the maximum SQNR for this case is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each OSR doubling, or 1.5 bits/octave.\n\nDoubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is an exercise for the reader."
},
{
    "text": "The modulator depicted in Fig. 18.10 implements second-order noise shaping (i.e., the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 illustrates a second-order noise-shaping modulator. The key components of this system include an adder, a delay element, a feedback loop incorporating a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Main Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially fed into an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The output from the adder passes through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay to the signal.\n- **Quantizer:** The delayed signal is then quantized, converting the analog signal to a digital signal, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit digital-to-analog converter, converting the digital signal back to analog for subtraction from the input signal.\n\n2. **Information and Control Flow:**\n- The input signal \\( u(n) \\) combines with the feedback signal from the 1-bit D/A in the adder, producing an error signal that passes through the delay element \\( z^{-1} \\).\n- The delayed signal is quantized by the quantizer, yielding the digital output \\( y(n) \\), which is also fed back into the system.\n- The feedback loop, including the 1-bit D/A converter, provides a feedback signal subtracted from the input signal at the adder, completing the loop.\n\n3. **Labels, Annotations, and Key Indicators:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly shown, illustrating the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **Overall System Function:**\n- This system is designed for second-order noise shaping. The component arrangement facilitates high-pass filtering of quantization noise, effectively shifting the noise to higher frequencies for easier filtration. The feedback and quantizer enable the system to convert an analog input signal to a digital output with reduced noise in the desired frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This depicts a first-order A/D modulator using a switched-capacitor approach. The circuit performs analog-to-digital conversion by integrating the input signal and comparing it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:This circuit is a first-order A/D modulator using a switched-capacitor implementation. It integrates the input signal and compares it to a reference voltage. The output is latched on the falling edge of 2, with switches controlled by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator using only one input capacitance to the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter designed for high-resolution digital signals from analog inputs. The primary components and their interactions are as follows:\n\n1. **Input Signal (u(n))**: The process starts with the input signal, u(n), fed into the system.\n2. **Summing Junctions**: Two summing junctions at the diagram's start subtract the feedback signal from the input signal, u(n), with the output fed into a delay block.\n3. **Delay Blocks (z)**: Two delay blocks in the system act as discrete-time delay elements, storing previous output states crucial for the integrative behavior needed for noise shaping in  modulators.\n4. **Feedback Loops**: The system includes feedback loops that take the output signal, y(n), and feed it back into the summing junctions, essential for the modulator's noise shaping properties.\n5. **Quantizer**: After the second delay block, the signal enters a quantizer, converting the continuous-time signal to a discrete-time digital signal, y(n), the primary output.\n6. **Output Signal (y(n))**: The quantizer's output is the digital representation of the input analog signal, enhanced by the system's noise shaping properties.\n\n**Overall System Function**: The second-order  modulator uses its integrative and feedback properties to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from an analog input. The combination of summing junctions, delay elements, feedback loops, and the quantizer effectively performs this function.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is given by\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the magnitude of the noise transfer function can be expressed as\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nresulting in the quantization noise power over the frequency band of interest being approximated by\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAgain, assuming the maximum signal power is as derived in (18.11), the maximum SQNR for this case is given by\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor, equivalently,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Point: Second-order noise shaping boosts SQNR by 15 dB for each doubling of OSR, or equivalently by 1.5 bits/octave.\n\nWe observe that doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or equivalently, a gain of 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is left as an exercise for the interested reader."
},
{
    "text": "The depicted modulator in Fig. 18.10 accomplishes second-order noise shaping (where the noise transfer function, $\\mathrm{N}_{T F}(\\mathrm{z})$, is a second-order high-pass function). For this modulator, the signal transfer function is expressed as\n\n$$\n\\begin{equation*}\nS_{T F}(f)=z^{-1} \\tag{18.27}\n\\end{equation*}\n$$\n\nimage_name:Fig. 18.8(a)\ndescription:The block diagram in Fig. 18.8 depicts a second-order noise-shaping modulator. Its main components include an adder, a delay element, a feedback loop with a digital-to-analog converter (D/A), and a quantizer.\n\n1. **Primary Components:**\n- **Adder:** The input signal \\( u(n) \\) is initially processed by an adder, which subtracts the feedback signal from the input.\n- **Delay Element (\\( z^{-1} \\)):** The adder's output is then routed through a delay element, part of the filter \\( H(z) \\), introducing a unit sample delay.\n- **Quantizer:** The delayed signal undergoes quantization, converting it from analog to digital form, \\( y(n) \\).\n- **1-bit D/A Converter:** The quantizer's output is fed back through a 1-bit D/A converter, reverting the digital signal to analog for subtraction from the input signal.\n\n2. **Information Flow and Control:**\n- The input signal \\( u(n) \\) combines with the feedback from the 1-bit D/A in the adder, producing an error signal that passes through the delay element \\( z^{-1} \\).\n- This delayed signal is quantized, yielding the digital output \\( y(n) \\), which is also looped back into the system.\n- The feedback loop, incorporating the 1-bit D/A converter, generates a feedback signal subtracted from the input at the adder, completing the loop.\n\n3. **Labels and Annotations:**\n- The system is marked with input \\( u(n) \\) and output \\( y(n) \\) signals.\n- The feedback path is clearly delineated, showing the conversion from digital to analog.\n- The filter \\( H(z) \\) is indicated, highlighting its role in noise shaping.\n\n4. **System Function Overview:**\n- This setup is tailored for second-order noise shaping, leveraging component arrangement to high-pass filter quantization noise, effectively shifting it to higher frequencies for easier filtration. The feedback and quantizer enable the conversion of an analog input to a digital output with minimized noise in the target frequency band.\n\nimage_name:Fig. 18.8(b) switched-capacitor implementation\ndescription:This figure shows a first-order A/D modulator utilizing a switched-capacitor approach. The circuit integrates the input signal and compares it to a reference voltage, with output latching on the falling edge of 2 and switch control by clock phases 1 and 2.\n\nFig. 18.8 First-order A/D modulator: (a) block diagram; (b) switched-capacitor implementation.\nimage_name:Fig. 18.9\ndescription:Illustrated is a first-order A/D modulator with a switched-capacitor design. It integrates the input signal, compares it to a reference voltage, and latches the output on the falling edge of 2, with switches governed by clock phases 1 and 2.\nFig. 18.9 First-order A/D modulator employing a single input capacitance for the discrete-time integrator.\n\nimage_name:Fig. 18.10 Second-order  modulator\ndescription:The diagram presents a second-order Delta-Sigma () modulator, an analog-to-digital converter aimed at high-resolution digital signals from analog inputs. Its key components and interactions are:\n\n1. **Input Signal (u(n))**: The process initiates with the input signal, u(n), entering the system.\n\n2. **Summing Junctions**: Two summing junctions at the start subtract the feedback signal from the input, u(n), with the output feeding into a delay block.\n\n3. **Delay Blocks (z)**: Two delay blocks in the system act as discrete-time delay elements, storing previous output states crucial for noise shaping in  modulators.\n\n4. **Feedback Loops**: The system incorporates feedback loops that route the output signal, y(n), back to the summing junctions, essential for noise shaping and shifting quantization noise out of the band of interest.\n\n5. **Quantizer**: Post the second delay block, the signal enters a quantizer, converting it from continuous-time to discrete-time digital form, y(n).\n\n6. **Output Signal (y(n))**: The quantizer's output is the digital equivalent of the input analog signal, enhanced in resolution due to noise shaping.\n\n**System Function Summary**: The second-order  modulator employs integrative and feedback mechanisms to shape quantization noise away from the frequency band of interest, achieving high-resolution digital output from analog input. The collective function of summing junctions, delay elements, feedback loops, and the quantizer effectively realizes this purpose.\n\nFig. 18.10 Second-order $\\Delta \\Sigma$ modulator.\nand the noise transfer function is articulated as\n\n$$\n\\begin{equation*}\nN_{T F}(f)=\\left(1-z^{-1}\\right)^{2} \\tag{18.28}\n\\end{equation*}\n$$\n\nAdditionally, the noise transfer function's magnitude is given by\n\n$$\n\\begin{equation*}\n\\left|N_{T F}(f)\\right|=\\left[2 \\sin \\left(\\frac{\\pi f}{f_{s}}\\right)\\right]^{2} \\tag{18.29}\n\\end{equation*}\n$$\n\nyielding the quantization noise power within the frequency band of interest as\n\n$$\n\\begin{equation*}\n\\mathrm{P}_{\\mathrm{e}} \\cong \\frac{\\Delta^{2} \\pi^{4}}{60}\\left(\\frac{1}{\\mathrm{OSR}}\\right)^{5} \\tag{18.30}\n\\end{equation*}\n$$\n\nAssuming the maximum signal power aligns with (18.11), the maximum SQNR for this scenario is\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=10 \\log \\left(\\frac{\\mathrm{P}_{\\mathrm{s}}}{\\mathrm{P}_{\\mathrm{e}}}\\right)=10 \\log \\left(\\frac{3}{2} 2^{2 \\mathrm{~N}}\\right)+10 \\log \\left[\\frac{5}{\\pi^{4}}(\\mathrm{OSR})^{5}\\right] \\tag{18.31}\n\\end{equation*}\n$$\n\nor alternatively,\n\n$$\n\\begin{equation*}\n\\mathrm{SQNR}_{\\max }=6.02 \\mathrm{~N}+1.76-12.9+50 \\log (\\mathrm{OSR}) \\tag{18.32}\n\\end{equation*}\n$$\n\nKey Insight: Second-order noise shaping boosts SQNR by 15 dB per OSR doubling, or equivalently by 1.5 bits/octave.\n\nHere, doubling the OSR enhances the SQNR for a second-order modulator by 15 dB, or alternatively, by 2.5 bits/octave.\n\nThe implementation of the second-order modulator using switched-capacitor techniques is posed as an exercise for the reader."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are illustrated in Fig. 18.11. Observe that within the band of interest (i.e., from 0 to $f_{0}$), the noise power diminishes as the noise-shaping order rises. Conversely, the out-of-band noise escalates for higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 features a Bode plot depicting various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in a digital signal processing context. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint indicated at \\( \\frac{f_s}{2} \\). The y-axis charts the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot comprises three distinct curves:\n\n1. **No Noise Shaping:** This is depicted by a horizontal line across the frequency spectrum, signifying a uniform noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the horizontal line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This illustrates noise reduction within the frequency band of interest and an increase outside it.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order pattern but with a more pronounced peak and steeper gradients. It begins at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then drops back to the baseline at \\( f_s \\). This signifies a more substantial noise reduction within the band of interest but a greater increase in out-of-band noise.\n\nOverall, the behavior underscores that higher-order noise shaping leads to more effective noise reduction within the target frequency band, albeit with a trade-off of increased out-of-band noise. This is a typical compromise in noise shaping techniques employed in digital signal processing systems.\n\nFig. 18.11 Some different noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nConsidering a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, for straightforward oversampling as well as first- and second-order noise shaping?\n\n#### Solution\n\nOversampling with No Noise Shaping From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\nFirst-Order Noise Shaping First-order noise shaping yields $9 \\mathrm{~dB} /$ octave, where 1 octave represents doubling the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, or 10.56 octaves. Therefore, the required sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis compares very favorably with straightforward oversampling, although it remains relatively high.\nSecond-Order Noise Shaping Second-order noise shaping provides $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Consequently, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of merely 5.8 MHz. However, this simplified calculation does not account for the reduced input range necessary for stability in a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are depicted in Fig. 18.11. Observe that within the band of interest (spanning from 0 to \\( f_{0} \\)), the noise power diminishes as the noise-shaping order rises. Conversely, the out-of-band noise escalates with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 illustrates a Bode plot showing various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled frequency \\( f \\), ranges from 0 to \\( f_s \\) (the sampling frequency), with a midpoint indicated at \\( \\frac{f_s}{2} \\). The y-axis denotes the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** This is depicted as a horizontal line across the frequency spectrum, signifying a consistent noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the flat line at \\( f = 0 \\), peaks before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This pattern reflects reduced noise within the frequency band of interest and elevated noise outside it.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order curve but with a more pronounced peak and steeper inclines. It begins at the baseline at \\( f = 0 \\), reaches a higher peak, and then returns to the baseline at \\( f_s \\). This indicates a more substantial noise reduction in the band of interest but a greater increase in out-of-band noise.\n\nOverall, the behavior suggests that higher-order noise shaping enhances noise reduction within the target frequency band but also leads to increased out-of-band noise, a typical trade-off in digital signal processing noise shaping techniques.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nConsidering a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if \\( \\mathrm{f}_{0}=25 \\mathrm{kHz} \\) for straightforward oversampling and for first- and second-order noise shaping?\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, with 1 octave representing a doubling of the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Therefore, the required sampling rate, \\( f_{s} \\), is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis compares favorably with straightforward oversampling, though it remains relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Thus, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of just 5.8 MHz. However, this simplistic calculation overlooks the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are illustrated in Fig. 18.11. Observe that within the band of interest (i.e., from 0 to $f_{0}$), the noise power diminishes as the noise-shaping order rises. Conversely, the out-of-band noise escalates for higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 features a Bode plot depicting various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in a digital signal processing context. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint indicated at \\( \\frac{f_s}{2} \\). The y-axis denotes the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot includes three distinct curves:\n\n1. **No Noise Shaping:** Represented by a horizontal line across the frequency spectrum, signifying a consistent noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the flat line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This pattern signifies reduced noise within the frequency band of interest and elevated noise outside it.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order curve but with a more pronounced peak and steeper gradients. It begins at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then returns to the baseline at \\( f_s \\). This indicates a more substantial noise reduction within the band of interest but a more marked increase in out-of-band noise.\n\nOverall, the graph suggests that higher-order noise shaping achieves more effective noise reduction within the targeted frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in noise shaping techniques employed in digital signal processing systems.\n\nFig. 18.11 Different noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nFor a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, considering straight oversampling and first- and second-order noise shaping?\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, where one octave corresponds to doubling the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Therefore, the required sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis compares favorably with straight oversampling, though it remains relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Consequently, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of just 5.8 MHz. However, this simplified calculation does not account for the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are illustrated in Fig. 18.11. It is observed that within the frequency range of interest (from 0 to $f_{0}$), the noise power diminishes as the order of noise shaping increases. Conversely, the out-of-band noise rises with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 presents a Bode plot depicting various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint at \\( \\frac{f_s}{2} \\). The y-axis shows the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** This curve is a horizontal line across the frequency spectrum, signifying a consistent noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the horizontal line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically drops back to the baseline at \\( f_s \\). This reflects reduced noise in the target frequency band and increased noise outside this band.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order pattern but with a more accentuated peak and steeper inclines. It starts at the baseline at \\( f = 0 \\), reaches a higher peak than the first-order curve, and then declines to the baseline at \\( f_s \\). This indicates a more substantial noise reduction in the band of interest but a greater increase in out-of-band noise.\n\nOverall, the graph demonstrates that higher-order noise shaping enhances noise reduction within the desired frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in digital signal processing noise shaping techniques.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nFor a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, determine the required sample rate to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) when $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, considering straight oversampling and first- and second-order noise shaping.\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** As per Example 18.3, straight oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, with one octave corresponding to doubling the OSR. Given a 5 dB loss, 95 dB is required, divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Thus, the necessary sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis rate is significantly lower than that for straight oversampling, though still relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Therefore, 103 dB divided by $15 \\mathrm{~dB} /$ octave results in a required sampling rate of just 5.8 MHz. However, this simplified calculation does not account for the reduced input range necessary for stability in a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are depicted in Fig. 18.11. Observe that within the frequency range of interest (i.e., from 0 to $f_{0}$), the noise power diminishes as the order of noise shaping rises. Conversely, the out-of-band noise escalates with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 illustrates a Bode plot showing various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint at \\( \\frac{f_s}{2} \\). The y-axis denotes the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** This is depicted by a horizontal line across the frequency spectrum, signifying a consistent noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the horizontal line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This illustrates reduced noise within the frequency band of interest and elevated noise outside this band.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order pattern but with a more accentuated peak and steeper gradients. It starts at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then drops back to the baseline at \\( f_s \\). This indicates a more substantial noise reduction within the band of interest but a more pronounced noise increase outside it.\n\nOverall, the graph suggests that higher-order noise shaping leads to more effective noise reduction within the target frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in noise shaping techniques employed in digital signal processing systems.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nIf a 1-bit A/D converter has a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) with $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, for straightforward oversampling and for first- and second-order noise shaping?\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, where one octave represents a doubling of the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Therefore, the required sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis compares very favorably with straightforward oversampling, though it remains relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Thus, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, resulting in a required sampling rate of just 5.8 MHz. However, this simplistic calculation does not account for the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are illustrated in Fig. 18.11. Observe that within the frequency range of interest (i.e., from 0 to $f_{0}$), the noise power diminishes as the order of noise shaping rises. Conversely, the noise outside this band escalates with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 presents a Bode plot depicting various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint at \\( \\frac{f_s}{2} \\). The y-axis charts the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** This is depicted by a horizontal line across the frequency spectrum, signifying a uniform noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the horizontal line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This illustrates noise reduction within the target frequency band and an increase outside it.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order pattern but with a more pronounced peak and steeper gradients. It begins at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then returns to the baseline at \\( f_s \\). This implies a more substantial noise reduction in the band of interest but a greater noise increase outside it.\n\nOverall, the behavior suggests that higher-order noise shaping enhances noise reduction within the desired frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in digital signal processing noise shaping techniques.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nGiven a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, for straightforward oversampling and for first- and second-order noise shaping?\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, where one octave corresponds to doubling the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Thus, the required sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis is significantly better than straightforward oversampling, though still relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Therefore, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of just 5.8 MHz. However, this simplified calculation does not account for the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are depicted in Fig. 18.11. Observe that within the frequency band of interest (ranging from 0 to $f_{0}$), the noise power diminishes as the noise-shaping order rises. Conversely, the out-of-band noise escalates with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 illustrates a Bode plot showing various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint at \\( \\frac{f_s}{2} \\). The y-axis measures the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** Represented by a horizontal line across the frequency spectrum, signifying a uniform noise level.\n\n2. **First-Order Noise Shaping:** This curve begins at the same level as the flat line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This pattern reflects reduced noise in the target frequency band and elevated noise outside it.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order curve but with a more intense peak and steeper gradients. It starts at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then drops back to the baseline at \\( f_s \\). This indicates a more substantial noise reduction within the band of interest but a more pronounced increase in out-of-band noise.\n\nThe overall trend demonstrates that higher-order noise shaping enhances noise reduction within the desired frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in noise shaping methods employed in digital signal processing systems.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nConsidering a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, what sample rate is necessary to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if $\\mathrm{f}_{0}=25 \\mathrm{kHz}$, for straightforward oversampling and for first- and second-order noise shaping?\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping provides $9 \\mathrm{~dB} /$ octave, with 1 octave representing a doubling of the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Hence, the required sampling rate, $f_{s}$, is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis is significantly more favorable than straightforward oversampling, though still relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping yields $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Therefore, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of just 5.8 MHz. However, this simplified calculation does not account for the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "The general forms of zero-, first-, and second-order noise-shaping curves are depicted in Fig. 18.11. Observe that within the band of interest (ranging from 0 to \\( f_{0} \\)), the noise power diminishes as the noise-shaping order rises. Conversely, out-of-band noise escalates with higher-order modulators.\nimage_name:Fig. 18.11\ndescription:Fig. 18.11 presents a Bode plot illustrating various noise transfer functions (NTFs) for zero-, first-, and second-order noise shaping in digital signal processing. The x-axis, labeled with frequency \\( f \\), spans from 0 to \\( f_s \\) (the sampling frequency), with a midpoint at \\( \\frac{f_s}{2} \\). The y-axis charts the magnitude of the noise transfer function \\( |N_{TF}(f)| \\).\n\nThe plot features three distinct curves:\n\n1. **No Noise Shaping:** This is depicted by a horizontal line across the frequency spectrum, signifying a uniform noise level.\n\n2. **First-Order Noise Shaping:** This curve initiates at the same level as the horizontal line at \\( f = 0 \\), climbs to a peak before \\( \\frac{f_s}{2} \\), and then symmetrically declines back to the baseline at \\( f_s \\). This indicates noise reduction within the frequency band of interest and an increase outside this band.\n\n3. **Second-Order Noise Shaping:** This curve mirrors the first-order pattern but with a more pronounced peak and steeper gradients. It begins at the baseline at \\( f = 0 \\), ascends to a higher peak than the first-order curve, and then returns to the baseline at \\( f_s \\). This implies a more substantial noise reduction within the band of interest but a more significant noise rise outside it.\n\nOverall, the behavior suggests that higher-order noise shaping enhances noise reduction within the target frequency band, albeit at the cost of increased out-of-band noise. This trade-off is typical in digital signal processing noise shaping techniques.\n\nFig. 18.11 Various noise-shaping transfer functions.\n\n#### EXAMPLE 18.5\n\nFor a 1-bit A/D converter with a $6-\\mathrm{dB}$ SQNR, determine the necessary sample rate to achieve a $96-\\mathrm{dB}$ SNR (equivalent to 16 bits) if \\( \\mathrm{f}_{0}=25 \\mathrm{kHz} \\) for straightforward oversampling and for first- and second-order noise shaping.\n\n#### Solution\n\n**Oversampling with No Noise Shaping:** From Example 18.3, straightforward oversampling necessitates a sampling rate of 54,000 GHz.\n\n**First-Order Noise Shaping:** First-order noise shaping yields $9 \\mathrm{~dB} /$ octave, with 1 octave representing a doubling of the OSR. Given a 5 dB loss, we need 95 dB divided by $9 \\mathrm{~dB} /$ octave, equating to 10.56 octaves. Therefore, the required sampling rate, \\( f_{s} \\), is\n\n$$\nf_{s}=2^{10.56} \\times 2 f_{0} \\approx 75 \\mathrm{MHz}\n$$\n\nThis is significantly more favorable than straightforward oversampling, though still relatively high.\n\n**Second-Order Noise Shaping:** Second-order noise shaping provides $15 \\mathrm{~dB} /$ octave but incurs a 13 dB loss. Thus, we need 103 dB divided by $15 \\mathrm{~dB} /$ octave, leading to a required sampling rate of just 5.8 MHz. However, this calculation overlooks the reduced input range necessary for the stability of a second-order modulator."
},
{
    "text": "Assuming the output of a 1-bit modulator is $\\pm 1$, the total power of the output signal, $y(n)$, can be directly determined to be a normalized power of 1 watt. Given that $y(n)$ comprises both signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously suggested, the signal level is frequently restricted to well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is set at only $\\pm 0.25$, the resulting maximum signal power would be 62.5 mW (relative to a $1 \\Omega$ load). This indicates a signal power roughly 12 dB lower than that predicted by (18.11), leading to a corresponding decrease in the SQNR estimates derived from (18.11). Since the sum of signal power and quantization noise power equals 1 W, in this scenario, the maximum signal power is approximately 12 dB beneath the total quantization noise power., as discussed earlier, the quantization noise power predominantly resides in a different frequency range from the signal power, allowing it to be filtered out. However, it is crucial that the filter possesses a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the case of a $\\Delta \\Sigma A / D$ converter, the filtering process is executed by digital filters subsequent to the quantizer."
},
{
    "text": "Given that the output of a 1-bit modulator is $\\pm 1$, one can readily calculate the total power of the output signal, $y(n)$, to be a normalized 1 watt. Since $y(n)$ comprises both the signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously hinted, the signal level is typically constrained well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is assumed to be only $\\pm 0.25$, the maximum signal power would then be 62.5 mW (relative to a $1 \\Omega$ load). This suggests a signal power roughly 12 dB lower than that predicted by (18.11), leading to a corresponding decrease in the SQNR estimates derived from (18.11). Given that the sum of the signal power and quantization noise power equals 1 W, in this scenario, the maximum signal power is approximately 12 dB beneath the total quantization noise power. Fortunately, as discussed earlier, the quantization noise power predominantly resides in a different frequency band than the signal power, allowing it to be filtered out. However, it is crucial that the filter possesses a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the case of a $\\Delta \\Sigma A / D$ converter, the filtering is accomplished by digital filters subsequent to the quantizer."
},
{
    "text": "Assuming a 1-bit modulator's output is $\\pm 1$, the total power of the output signal, $y(n)$, can be directly calculated as a normalized power of 1 watt. Given that $y(n)$ includes both signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously suggested, the signal level in higher-order modulators is typically restricted to well below the $\\pm 1$ threshold to ensure stability. For instance, if the maximum peak signal level is set at only $\\pm 0.25$, the highest achievable signal power is 62.5 mW (relative to a $1 \\Omega$ load). This scenario indicates a signal power roughly 12 dB lower than the value predicted by (18.11), leading to a corresponding decrease in the SQNR estimates derived from (18.11). Since the combined power of the signal and quantization noise totals 1 W, in this case, the maximum signal power is approximately 12 dB beneath the total quantization noise power. Fortunately, as discussed earlier, the quantization noise power predominantly resides in a different frequency band than the signal power, allowing it to be effectively filtered out. However, it is crucial that the filter possesses a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the context of a $\\Delta \\Sigma A / D$ converter, this filtering is typically performed by digital filters subsequent to the quantizer."
},
{
    "text": "If the output of a 1-bit modulator is $\\pm 1$, the total power of the output signal, $y(n)$, can be immediately identified as a normalized power of 1 watt. Given that $y(n)$ comprises both the signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously suggested, the signal level is typically constrained well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is assumed to be only $\\pm 0.25$, the maximum signal power would be 62.5 mW (relative to a $1 \\Omega$ load). This indicates a signal power roughly 12 dB lower than that predicted by (18.11), leading to a corresponding decrease in the SQNR estimates derived from (18.11). Since the sum of the signal power and quantization noise power equals 1 W, in this scenario, the maximum signal power is approximately 12 dB below the total quantization noise power. Fortunately, as discussed earlier, the quantization noise power predominantly resides in a different frequency range than the signal power, allowing it to be filtered out. However, it is important to note that the filter must possess a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the case of a $\\Delta \\Sigma A / D$ converter, the filtering is performed by digital filters subsequent to the quantizer."
},
{
    "text": "Given that the output of a 1-bit modulator is $\\pm 1$, one can readily ascertain the total power of the output signal, $y(n)$, to be a normalized value of 1 watt. As $y(n)$ comprises both the signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously hinted, the signal level is typically constrained to well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is\n\nKey Point: The input signal power is frequently restricted to significantly below the maximum quantizer swing to preserve stability, leading to a diminished SQNR.\nonly $\\pm 0.25$, the maximum signal power amounts to 62.5 mW (relative to a $1 \\Omega$ load). This suggests a signal power roughly 12 dB lower than that predicted by (18.11), accompanied by a corresponding decrease in the SQNR estimates derived from (18.11). Since the combined power of the signal and quantization noise equals 1 W, in this scenario, the maximum signal power is approximately 12 dB beneath the total quantization noise power. Fortunately, as observed earlier, the quantization noise power predominantly resides in a different frequency band than the signal power, allowing it to be filtered out. However, it is crucial that the filter possesses a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the case of a $\\Delta \\Sigma A / D$ converter, the filtering is executed by digital filters subsequent to the quantizer."
},
{
    "text": "Given that the output of a 1-bit modulator is $\\pm 1$, the total power of the output signal, $y(n)$, can be directly calculated as a normalized power of 1 watt. Since $y(n)$ comprises both the signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Furthermore, as previously hinted, the signal level is frequently constrained to well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is\n\nKey Point: The input signal power is typically restricted to significantly below the maximum quantizer swing to maintain stability, leading to a decrease in SQNR.\nonly $\\pm 0.25$, the maximum signal power amounts to 62.5 mW (relative to a $1 \\Omega$ load). This suggests a signal power roughly 12 dB lower than that predicted by (18.11), and a corresponding decline in the SQNR estimates derived from (18.11). Given that the sum of the signal power and quantization noise power equals 1 W, in this scenario, the maximum signal power is approximately 12 dB beneath the total quantization noise power.$y(n)$$\\Delta \\Sigma A / D$"
},
{
    "text": "Assuming the output of a 1-bit modulator is $\\pm 1$, one can readily determine the total power of the output signal, $y(n)$, to be a normalized power of 1 watt. Given that $y(n)$ comprises both signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. In fact, as previously hinted, the signal level is frequently restricted to well below the $\\pm 1$ level in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is\n\nKey Point: The input signal power is often constrained to well below the maximum quantizer swing to ensure stability, leading to a reduced SQNR.\nonly $\\pm 0.25$, then the maximum signal power amounts to 62.5 mW (referenced to a $1 \\Omega$ load). This suggests a signal power roughly 12 dB lower than that predicted by (18.11), and a corresponding decrease in the SQNR estimates derived from (18.11). Since the sum of the signal power and quantization noise power equals 1 W, in this case, the maximum signal power is approximately 12 dB below the total quantization noise power. Fortunately, as observed earlier, the quantization noise power predominantly resides in a different frequency region than the signal power, allowing it to be filtered out. However, it is important to note that the filter must possess a dynamic range sufficient to handle the full power of $y(n)$ at its input. For a $\\Delta \\Sigma A/D$ converter, this filtering is accomplished by digital filters following the quantizer."
},
{
    "text": "Given that the output of a 1-bit modulator is $\\pm 1$, one can readily ascertain that the total power of the output signal, $y(n)$, is a normalized 1 watt. Since $y(n)$ comprises both the signal and quantization noise, it is evident that the signal power cannot exceed 1 watt. Indeed, as previously suggested, the signal level is frequently restricted to well below the $\\pm 1$ threshold in higher-order modulators to ensure stability. For instance, if the maximum peak signal level is\n\nKey Point: The input signal power is often constrained to significantly below the maximum quantizer swing to preserve stability, leading to a diminished SQNR.\nonly $\\pm 0.25$, then the maximum signal power amounts to 62.5 mW (relative to a $1 \\Omega$ load). This indicates a signal power roughly 12 dB lower than that predicted by (18.11), resulting in a corresponding decrease in the SQNR estimates derived from (18.11). Given that the sum of the signal power and quantization noise power equals 1 W, in this scenario, the maximum signal power is approximately 12 dB beneath the total quantization noise power. Fortunately, as observed earlier, the quantization noise power predominantly resides in a different frequency band than the signal power, allowing it to be filtered out. However, it is crucial that the filter possesses a dynamic range sufficient to handle the full power of $y(n)$ at its input. In the case of a $\\Delta \\Sigma A / D$ converter, the filtering is accomplished by digital filters subsequent to the quantizer."
},
{
    "text": "Before concluding this section, it is noteworthy to examine another configuration for implementing a delta-sigma modulatoran error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The main components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block takes the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and yields a quantized output, \\(y(n)\\). This is generally a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path comprises a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is merged with the feedback signal from the \\(G(z) - 1\\) block.\n- The resultant \\(x(n)\\) is then quantized by the quantizer, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to create the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redistributes quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating understanding of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, making it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. In contrast, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high dc gain can typically be achieved in analog implementations using opamps with substantial open-loop gains and does not depend on component matching. The error feedback structure is discussed here because it is valuable for analytical purposes and can perform well in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may need to be addressed. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay to the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, contributing to the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with the feedback signal.\n- The resulting \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is denoted \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are labeled \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to indicate their function.\n- The gain block is labeled with \"2\" to signify the amplification factor.\n\nSystem Function Overview:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more easily filtered out. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is worthwhile to examine an alternative structure for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates an error-feedback structure of a generic Delta-Sigma () modulator. The main components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and emits a quantized version, \\(y(n)\\). This is generally a non-linear element that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path comprises a block denoted \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, yielding the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to produce the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in comprehending the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully canceled at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high gain at dc can typically be achieved in analog implementations using opamps with substantial open-loop gains, independent of component matching. The error feedback structure is discussed here due to its analytical utility and effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is shown in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For these more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This configuration is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals, corresponding to the z-transform delay operation.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters via the first adder, where it is combined with the feedback signal.\n- The resulting signal \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) undergoes delay and amplification by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Indicators:\n- The input is denoted \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are labeled \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to signify their role in the z-domain.\n- The gain block is indicated with a \"2\" to represent the amplification factor.\n\nSystem Function:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, incorporating delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies for easier filtering. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is noteworthy to examine another configuration for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback structure possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:The illustration in Fig. 18.12 showcases an error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and yields a quantized output, \\(y(n)\\). This is generally a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is merged with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redirects quantization noise out of the band of interest. This is particularly advantageous in applications necessitating high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are distinctly labeled as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in comprehending the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, is equivalent to $G(z)$. Thus, for a first-order modulator, $G(z)=1-z^{-1}$, or in essence, the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nUnfortunately, even a minor coefficient error can lead to substantial degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is not ideal for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This infinite gain at dc can typically be achieved in analog implementations through the use of opamps with high open-loop gains, without relying on component matching. The error feedback structure is discussed here due to its analytical utility and its effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nthis is identical to (18.28), and it indicates that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may need to be addressed. For more advanced topics in this area, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:The block diagram in Fig. 18.13 represents the error-feedback structure of a second-order Delta-Sigma () modulator. This design is utilized in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks within the feedback path. These introduce a unit delay to the signals, implementing the z-transform delay operation.\n3. **Gain Block (2)**: This block increases the amplitude of the delayed signal by a factor of 2, which is part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically a non-linear component that introduces quantization noise into the system.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with a feedback signal.\n- The resulting signal \\(x(n)\\) is fed to the quantizer, which produces the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is marked as \\(u(n)\\), the output as \\(y(n)\\), and intermediate signals as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to denote their function in the z-domain.\n- The gain block is marked with a \"2\" to indicate the amplification factor.\n\nSystem Function Summary:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more easily filtered out. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is noteworthy to examine an alternative structure for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, equal to unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and emits a quantized version, \\(y(n)\\). This block is typically non-linear and introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is merged with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized, yielding the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redistributes quantization noise, pushing it out of the desired frequency band. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating understanding of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. Thus, for a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nUnfortunately, even a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is likely. In contrast, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high dc gain can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on precise component matching. The error feedback structure is discussed here due to its analytical utility and its effectiveness in fully digital implementations (such as in D/A converters), where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as overflow prevention and complexity reduction may be necessary. For more in-depth coverage of these advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, contributing to the feedback loop.\n4. **Quantizer**: The central element in the diagram is the quantizer, which converts the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters via the first adder, where it is combined with the feedback signal.\n- The resultant signal \\(x(n)\\) is processed by the quantizer, producing the digital output \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) undergoes delay and amplification by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is labeled \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are denoted as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to signify their role in the z-domain.\n- The gain block is labeled with a \"2\" to indicate the amplification factor.\n\nSystem Function Summary:\nThe primary function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more easily filtered. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine another configuration for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block takes the quantizer's output and subtracts it from \\(x(n)\\) to yield the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and produces a quantized output, \\(y(n)\\). This is generally a non-linear element that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block denoted as \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to produce the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating understanding of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, is equal to $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ simplifies to $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift results in the quantization noise not being completely nullified at dc, making it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high gain at dc can typically be achieved in analog implementations using opamps with substantial open-loop gains, independent of component matching. The error feedback structure is discussed here due to its analytical utility and its effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches are absent.\n\nA second-order modulator based on the error-feedback structure is presented in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is identical to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 shows the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is utilized in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals, corresponding to the z-transform delay operation.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which converts the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with the feedback signal.\n- The resulting signal \\(x(n)\\) is processed by the quantizer, producing the digital output \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is calculated by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is marked \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are denoted as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are labeled with \\(z^{-1}\\) to signify their role in the z-domain.\n- The gain block is marked with a \"2\" to indicate the amplification factor.\n\nSystem Function Overview:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more readily filtered out. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine an alternative structure for implementing a delta-sigma modulatorthe error-feedback configuration, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block takes the quantizer's output and subtracts it from \\(x(n)\\) to yield the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and produces a quantized output, \\(y(n)\\). This block is typically non-linear and introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path comprises a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resultant \\(x(n)\\) is then quantized, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to produce the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications requiring high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating understanding of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nUnfortunately, even a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, making it unsuitable for high oversampling ratios. Consequently, this structure is not ideal for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high dc gain can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on precise component matching. The error feedback structure is discussed here due to its analytical utility and effectiveness in fully digital implementations (such as in D/A converters), where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is presented in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 shows the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which converts the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\), introducing quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) is fed into the system via the first adder, where it combines with a feedback signal.\n- The resulting \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is labeled \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are denoted as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to indicate their role in the z-domain.\n- The gain block is labeled \"2\" to signify the amplification factor.\n\nSystem Function:\nThe primary function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, incorporating delay elements and a gain block, alters the quantization noise characteristics, pushing the noise to higher frequencies for easier filtering. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine another configuration for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates an error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and emits a quantized version, \\(y(n)\\). This is generally a non-linear element that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path comprises a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is merged with the feedback signal from the \\(G(z) - 1\\) block.\n- The resultant \\(x(n)\\) is then quantized by the quantizer, yielding the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redirects quantization noise out of the band of interest. This is especially advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating comprehension of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a generic $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to substantial degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being completely nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high dc gain can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on component matching. The error feedback structure is discussed here due to its utility for analytical purposes and its effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For these more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay to the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, contributing to the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters via the first adder, where it is combined with the feedback signal.\n- The resulting \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) undergoes delay and amplification by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is denoted \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are labeled \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to signify their role in the z-domain.\n- The gain block is indicated with a \"2\" to represent the amplification factor.\n\nSystem Function Overview:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, incorporating delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies for easier filtering. This improves the SNR of the A/D conversion process, making it ideal for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is noteworthy to examine another configuration for implementing a delta-sigma modulatoran error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback structure possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and emits a quantized version, \\(y(n)\\). This is generally a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block denoted as \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it merges with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, yielding the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, pushing it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in understanding the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. Thus, for a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nUnfortunately, even a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, making it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. In contrast, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high gain at dc can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on precise component matching. The error feedback structure is discussed here due to its analytical utility and effectiveness in fully digital implementations (such as in D/A converters), where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is presented in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is identical to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For these more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 shows the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is utilized in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals, corresponding to the z-transform delay operation.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which converts the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nFlow of Information or Control:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with a feedback signal.\n- The resultant signal \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is labeled \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are denoted as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to indicate their role in the z-domain.\n- The gain block is labeled with a \"2\" to signify the amplification factor.\n\nOverall System Function:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more easily filtered. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine another configuration for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and yields a quantized output, \\(y(n)\\). This is typically a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block denoted as \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to generate the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in comprehending the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, making it unsuitable for high oversampling ratios. Consequently, this structure is not ideal for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high gain at dc can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on component matching. The error feedback structure is discussed here due to its utility for analytical purposes and its effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is shown in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is identical to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may be necessary. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals, corresponding to the z-transform delay operation.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central block is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with the feedback signal.\n- The resulting signal \\(x(n)\\) is fed to the quantizer, which produces the digital output \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is denoted as \\(u(n)\\), the output as \\(y(n)\\), and intermediate signals as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to indicate their role in the z-domain.\n- The gain block is labeled with a \"2\" to signify the amplification factor.\n\nSystem Function Overview:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, pushing the noise to higher frequencies where it can be more easily filtered. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is insightful to examine an alternative structure for implementing a delta-sigma modulatoran error-feedback configuration, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:The illustration in Fig. 18.12 portrays the error-feedback architecture of a generic Delta-Sigma () modulator. The key components of this system are as follows:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to yield the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and produces a quantized output, \\(y(n)\\). This is generally a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block denoted as \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized by the quantizer, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to produce the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) equal to unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively shapes the quantization noise, shifting it out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in comprehending the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback architecture of a generic $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, even a minor coefficient error can lead to significant degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This infinite gain at dc can typically be achieved in analog implementations using opamps with high open-loop gains, without relying on precise component matching. The error feedback structure is discussed here because it is valuable for analytical purposes and can perform effectively in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is identical to (18.28), indicating that second-order noise shaping is achieved. In practical implementations, additional considerations such as overflow prevention and complexity reduction may need to be addressed. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:The block diagram in Fig. 18.13 represents the error-feedback structure of a second-order Delta-Sigma () modulator. This design is utilized in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay in the signals, corresponding to the z-transform delay operation.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, forming part of the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which converts the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer is typically non-linear and introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with a feedback signal.\n- The resulting signal \\(x(n)\\) is fed to the quantizer, which outputs the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, contributing to the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is designated as \\(u(n)\\), the output as \\(y(n)\\), and intermediate signals as \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to denote their function in the z-domain.\n- The gain block is indicated with a \"2\" to signify the amplification factor.\n\nSystem Function Summary:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies where it can be more easily filtered. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine another configuration for implementing a delta-sigma modulatorthe error-feedback structure, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are as follows:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and yields a quantized output, \\(y(n)\\). This is generally a non-linear element that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path comprises a block designated \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is combined with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function Overview:**\n- The primary role of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function $\\mathrm{S}_{\\mathrm{TF}}(z)$ of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redirects quantization noise out of the desired frequency band. This is particularly advantageous in applications necessitating high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), facilitating comprehension of the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, is equal to $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to substantial degradation in noise shaping with this error-feedback configuration. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being completely nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This infinite gain at dc can typically be achieved in analog implementations through the use of opamps with high open-loop gains, without relying on precise component matching. The error feedback structure is discussed here due to its analytical utility and its effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches do not occur.\n\nA second-order modulator based on the error-feedback structure is illustrated in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), demonstrating that second-order noise shaping is achieved. In practical implementations, additional considerations such as preventing overflow and reducing complexity may need to be addressed. For more in-depth coverage of these advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 presents the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: Two delay blocks are present in the feedback path, each introducing a unit delay to the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, contributing to the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer typically introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) enters the system via the first adder, where it is combined with the feedback signal.\n- The resulting signal \\(x(n)\\) is processed by the quantizer, producing the digital output \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) undergoes delay and amplification by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- The input is designated \\(u(n)\\), the output is \\(y(n)\\), and intermediate signals are labeled \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to denote their function in the z-domain.\n- The gain block is indicated with a \"2\" to signify the amplification factor.\n\nSystem Function Summary:\nThe main function of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, incorporating delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies for easier filtration. This improves the SNR of the A/D conversion process, making it suitable for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "Before concluding this section, it is pertinent to examine an alternative structure for implementing a delta-sigma modulatorthe error-feedback configuration, as depicted in Fig. 18.12 [Anastassiou, 1989]. By employing a linear model for the quantizer, it can be readily demonstrated that this error-feedback configuration possesses a signal transfer function, $\\mathrm{S}_{\\mathrm{TF}}(\\mathrm{z})$, of unity, whereas\nimage_name:Fig. 18.12\ndescription:Fig. 18.12 illustrates the error-feedback structure of a generic Delta-Sigma () modulator. The key components of this system are:\n\n1. **Summation Blocks:**\n- The initial summation block accepts the input signal \\(u(n)\\) and a feedback signal, generating the intermediate signal \\(x(n)\\).\n- The subsequent summation block receives the quantizer's output and subtracts it from \\(x(n)\\) to produce the error signal \\(e(n)\\).\n\n2. **Quantizer:**\n- The quantizer processes the signal \\(x(n)\\) and yields a quantized output, \\(y(n)\\). This is generally a non-linear component that introduces quantization noise.\n\n3. **Feedback Path with Transfer Function \\(G(z) - 1\\):**\n- The feedback path incorporates a block denoted as \\(G(z) - 1\\), which processes the error signal \\(e(n)\\) and feeds it back to the initial summation block.\n\n**Information Flow:**\n- The input signal \\(u(n)\\) enters the system at the initial summation block, where it is merged with the feedback signal from the \\(G(z) - 1\\) block.\n- The resulting signal, \\(x(n)\\), is then quantized, producing the output \\(y(n)\\).\n- The quantized output is subtracted from \\(x(n)\\) in the subsequent summation block to form the error signal \\(e(n)\\).\n- The error signal \\(e(n)\\) is processed by the \\(G(z) - 1\\) block and fed back to the initial summation block.\n\n**System Function:**\n- The main function of this error-feedback  modulator is to achieve noise shaping. By maintaining a signal transfer function \\(\\mathrm{S}_{\\mathrm{TF}}(z)\\) of unity and a noise transfer function \\(N_{TF}(z)\\) equal to \\(G(z)\\), the system effectively redirects quantization noise out of the band of interest. This is particularly advantageous in applications demanding high precision, such as digital audio or communication systems.\n\n**Labels and Annotations:**\n- Inputs and outputs are clearly marked as \\(u(n)\\), \\(x(n)\\), \\(e(n)\\), and \\(y(n)\\), aiding in comprehending the signal flow and transformations within the system.\n\nFig. 18.12 The error-feedback structure of a general $\\Delta \\Sigma$ modulator.\nthe noise transfer function, $N_{T F}(z)$, equals $G(z)$. For a first-order modulator, $G(z)=1-z^{-1}$, meaning the block $(G(z)-1)$ is simply $-z^{-1}$.\n\nHowever, a minor coefficient error can lead to substantial degradation in noise shaping with this error-feedback structure. For instance, in a first-order scenario, if the delayed signal becomes $-0.99 z^{-1}$ (instead of $-z^{-1}$), then $G(z)=1-0.99 z^{-1}$, causing the zero to shift away from dc. Such a shift prevents the quantization noise from being fully nullified at dc, rendering it unsuitable for high oversampling ratios. Consequently, this structure is less appropriate for analog implementations where coefficient mismatch is prevalent. Conversely, an interpolative structure offers the benefit that the zeros of the noise transfer function remain at dc as long as $\\mathrm{H}(\\mathrm{z})$ exhibits infinite gain at dc. This high dc gain can typically be achieved in analog implementations using opamps with substantial open-loop gains, without relying on precise component matching. The error feedback structure is discussed here due to its analytical utility and effectiveness in fully digital implementations (such as in D/A converters) where coefficient mismatches are absent.\n\nA second-order modulator based on the error-feedback structure is presented in Fig. 18.13. For this scenario, we have\n\n$$\n\\begin{equation*}\nG(z)-1=z^{-1}\\left(z^{-1}-2\\right) \\tag{18.33}\n\\end{equation*}\n$$\n\nwhich implies that\n\n$$\n\\begin{align*}\n\\mathrm{G}(\\mathrm{z}) & =1-2 \\mathrm{z}^{-1}+\\mathrm{z}^{-2} \\\\\n& =\\left(1-\\mathrm{z}^{-1}\\right)^{2} \\tag{18.34}\n\\end{align*}\n$$\n\nThis is equivalent to (18.28), demonstrating that second-order noise shaping is achieved. In practical implementations, additional considerations such as overflow prevention and complexity reduction may be necessary. For more advanced topics, the reader is referred to [Temes, 1996].\nimage_name:Fig. 18.13\ndescription:Fig. 18.13 showcases the system block diagram of the error-feedback structure for a second-order Delta-Sigma () modulator. This architecture is employed in oversampled analog-to-digital (A/D) converters to shape quantization noise and enhance the signal-to-noise ratio (SNR).\n\nKey Components:\n1. **Adder ()**: The diagram features two summing nodes (adders). The first adder merges the input signal \\(u(n)\\) with the feedback signal.\n2. **Delay Elements (\\(z^{-1}\\))**: There are two delay blocks in the feedback path, each introducing a unit delay to the signals.\n3. **Gain Block (2)**: This block amplifies the delayed signal by a factor of 2, integral to the feedback loop.\n4. **Quantizer**: The central element in the diagram is a quantizer, which transforms the analog signal \\(x(n)\\) into a digital signal \\(y(n)\\). The quantizer typically introduces quantization noise.\n5. **Error Signal (e(n))**: The second adder computes the error signal \\(e(n)\\) by subtracting the feedback from the quantizer output.\n\nInformation and Control Flow:\n- The input signal \\(u(n)\\) is introduced into the system via the first adder, where it is combined with a feedback signal.\n- The resultant signal \\(x(n)\\) is processed by the quantizer, producing the digital signal \\(y(n)\\).\n- The quantizer output \\(y(n)\\) is fed back, and the error signal \\(e(n)\\) is determined by subtracting the feedback signal from \\(x(n)\\).\n- The error signal \\(e(n)\\) is then delayed and amplified by a factor of 2, forming part of the feedback loop that shapes the noise.\n\nLabels, Annotations, and Key Indicators:\n- Inputs and outputs are labeled as \\(u(n)\\), \\(y(n)\\), with intermediate signals \\(x(n)\\) and \\(e(n)\\).\n- Delay elements are marked with \\(z^{-1}\\) to denote their z-domain function.\n- The gain block is indicated with a \"2\" to signify the amplification factor.\n\nSystem Function:\nThe primary role of this second-order  modulator is to perform noise shaping on the input signal. The feedback loop, comprising delay elements and a gain block, alters the quantization noise characteristics, shifting the noise to higher frequencies for easier filtering. This improves the SNR of the A/D conversion process, making it ideal for high-resolution digital audio and other precision applications.\n\nFig. 18.13 The error-feedback structure of a second-order $\\Delta \\Sigma$ modulator."
},
{
    "text": "The architecture of a standard $\\Delta \\Sigma$ oversampling analog-to-digital (A/D) converter can be observed in Figure 18.14, along with sample signal spectra depicted in Figure 18.15. In the realm of digital audio, varying sampling frequencies may include $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$, signifying an oversampling ratio of 128. The input signal, $x_{c}(t)$, is sampled and held to create the signal $x_{\\text {sh }}(t)$. This sampled signal is then input into an $A / D \\Delta \\Sigma$ modulator, which emits a 1-bit digital signal $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. This 1-bit signal is believed to be linearly correlated with the input signal $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$ with a high level of resolution precision, despite the presence of considerable out-of-band quantization noise. To mitigate this out-of-band quantization noise, a digital decimation filter is implemented, as illustrated. The decimation process can be conceptually understood as initially diminishing the quantization noise through the utilization of a digital low-pass filter, leading to the multi-bit signal $x_{1 p}(n)$. Notably, this low-pass filter also removes any high-frequency components that were originally part of the input signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, thereby serving as an anti-aliasing filter to confine signals to one-half the final output sampling rate, $2 \\mathrm{f}_{0}$. Unlike in a Nyquist-rate $A / D$ converter, where $f_{s}$ is merely slightly higher than $2 f_{0}$, the analog anti-aliasing filter must have an extremely sharp cutoff to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Consequently, oversampling A/D converters necessitate additional digital low-pass filtering, while requiring less analog anti-aliasing filteringa favorable compromise often encountered in integrated circuits.\n\nSubsequently, $x_{1 p}(n)$ is re-sampled at $2 f_{0}$ to generate $x_{s}(n)$ by merely preserving samples at submultiples of the oversampling rate and discarding the rest. Figure 18.15 presents an oversampling rate of 6 for clarity purposes, compared to the commonly used values of 64 or 128 in numerous commercial applications. This decimation procedure does not lead to any loss of information, as the bandwidth of the original signal was assumed to be $f_{0}$. Put differently, the oversampled signal $x_{10}(n)$ contains redundant information since it is an oversampled signal where all its spectral data is assumed to lie well below $\\pi$, and by discarding samples, the spectral information is distributed over the range from 0 to $\\pi$. Additionally, it is important to note that there is no requirement to actually generate the signal $x_{1 p}(n)$, and substantial digital circuit complexity can be avoided by integrating the digital low-pass filter with the resampling block, thereby directly\n\nKey Point: Oversampling A/D converters necessitate additional digital low-pass filtering but require less analog anti-aliasing filtering, which is often an advantageous trade-off in integrated circuits.\n\nNext, $x_{1 p}(n)$ is resampled at $2 f_{0}$ to obtain $x_{s}(n)$ by retaining samples at submultiples of the oversampling rate and discarding the rest. In Figure 18.15, an oversampling rate of only 6 is depicted for clarity, as opposed to the more common values of 64 or 128 used in many commercial applications. This decimation process does not result in any loss of information, as the bandwidth of the original signal was assumed to be $f_{0}$. In other words, the signal $x_{10}(n)$ contains redundant information since it is an oversampled signal where all its spectral information\n\nKey Point: Oversampling A/D converters require additional digital low-pass filtering, but less analog anti-aliasing filtering often provides a desirable trade-off in integrated circuits.\n\nlies well below $\\pi$, and by discarding samples, the spectral information is spread over the range from 0 to $\\pi$. Finally, it should be noted that there is no need to actually create the signal $x_{1 p}(n)$, and significant digital circuit complexity can be saved by combining the digital low-pass filter with the resampling block to directly\n\nKey Point: The linearity of oversampled A/D converters is more heavily influenced by the linearity of the internal digital-to-analog (D/A) converter rather than the internal quantizer.\n\nIt is pertinent to consider which component most profoundly impacts the linearity of this oversampling A/D system. Referring back to the $\\Delta \\Sigma$ modulator, it is observed that an internal 1-bit D/A converter is utilized, whose output signal is combined with the input signal in such a way that, within the band of interest, these signals are nearly identical. Therefore, the overall linearity of this $\\Delta \\Sigma$ modulator converter is greatly influenced by the linearity of its internal D/A converter. For instance, in the presence of a nonlinear internal D/A converter and a slowly varying linear ramp input signal, the low-frequency content of the D/A converter's output would closely resemble that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to accommodate the D/A converter's nonlinearity. Given that the subsequent digital circuitry is linear, the overall linearity of this oversampling A/D converter is primarily contingent upon the achievement of a linear D/A converter within the $\\Delta \\Sigma$ modulator. In fact, nonlinearity within the internal A/D converter (assuming it were multi-bit) has only a minor impact on the linearity of the entire converter, as the high gain in the feedback loop offsets this nonlinearity."
},
{
    "text": "The architectural layout of a standard delta-sigma oversampling analog-to-digital converter is depicted in Figure 18.14, alongside illustrative signal spectrums in Figure 18.15. In scenarios involving digital audio, sampling frequencies such as \\( f_{s}=5.6448 \\mathrm{MHz}, f_{0}=44.1 \\mathrm{kHz} \\) are commonly employed, corresponding to an oversampling ratio of 128. In this context, the input signal \\( x_{c}(t) \\) undergoes sampling and holding, yielding the signal \\( x_{\\text {sh }}(t) \\). This sampled-and-held signal is then subjected to an \\( A / D \\Delta \\Sigma \\) modulator, which outputs a 1-bit digital signal \\( \\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n}) \\). This 1-bit digital signal is considered linearly linked to the input signal \\( \\mathrm{x}_{\\mathrm{c}}(\\mathrm{t}) \\), accurate to many bits of resolution, despite incorporating a substantial amount of out-of-band quantization noise. To eliminate this out-of-band quantization noise, a digital decimation filter is utilized, as illustrated. Conceptually, the decimation process can be envisioned as initially reducing the quantization noise using a digital low-pass filter, resulting in the multi-bit signal \\( x_{1 p}(n) \\). Notably, this low-pass filter will also eliminate any higher-frequency content originally present in the input signal \\( \\mathrm{x}_{\\mathrm{c}}(\\mathrm{t}) \\), thus serving as an anti-aliasing filter to restrict the signals to one-half of the ultimate output sampling rate, \\( 2 \\mathrm{f}_{0} \\), as opposed to the anti-aliasing filter at the input, which only needed to limit the signals to frequencies below \\( f_{s} / 2 \\). In contrast, within a Nyquist-rate \\( A / D \\) converter, where \\( f_{s} \\) is just slightly greater than \\( 2 f_{0} \\), the analog anti-aliasing filter must possess an exceptionally sharp cutoff to prevent unwanted signal content, including thermal noise, from aliasing into the band of interest. Consequently, oversampling A/D converters necessitate extra digital lowpass filtering, albeit less analog anti-aliasing filteringa frequently favored trade-off in integrated circuits.\n\nSubsequently, \\( x_{1 p}(n) \\) is resampled at \\( 2 f_{0} \\) to obtain \\( x_{s}(n) \\) by simply retaining samples at a submultiple of the oversampling rate and discarding the remainder. In Figure 18.15, an oversampling rate of merely 6 is presented for clarity, as opposed to the more customary rates of 64 or 128 employed in numerous commercial applications. This decimation process does not result in any loss of information, since the bandwidth of the original signal was assumed to be \\( f_{0} \\). Alternatively stated, the signal \\( x_{10}(n) \\) contains redundant information because it is an oversampled signal with all its spectral information confined well below \\( \\pi \\), and by discarding samples, the spectral information is distributed over 0 to \\( \\pi \\). Ultimately, it should be recognized that there is no requirement to physically generate the signal \\( x_{1 p}(n) \\), and significant digital circuit complexity can be conserved by amalgamating the digital low-pass filter with the resampling block, enabling direct conversion.\n\nA pivotal consideration is that oversampling A/D converters require supplementary digital low-pass filtering but less analog anti-aliasing filteringa generally desirable compromise in integrated circuit design."
},
{
    "text": "---[Rephrased Text]---\nThe architecture of a typical $\\Delta \\Sigma$ oversampling A/D converter is depicted in Fig. 18.14, with example signal spectra illustrated in Fig. 18.15. For digital audio applications, various sampling frequencies like $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$ are used, corresponding to an oversampling ratio of 128. The input signal, $x_{c}(t)$, is sampled and held to produce $x_{\\text {sh }}(t)$. This sampled signal is then fed into an A/D $\\Delta \\Sigma$ modulator, which outputs a 1-bit digital signal, $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. This 1-bit signal is linearly related to the input signal $x_{c}(t)$ (with high resolution), despite containing a significant amount of out-of-band quantization noise. To eliminate this noise, a digital decimation filter is employed. Conceptually, the decimation process involves reducing quantization noise using a digital low-pass filter, resulting in the multi-bit signal $x_{1 p}(n)$. This low-pass filter also removes any high-frequency content from the input signal $x_{c}(t)$, acting as an anti-aliasing filter to limit signals to one-half the final output sampling rate, $2 \\mathrm{f}_{0}$. In contrast, a Nyquist-rate A/D converter, where $f_{s}$ is slightly greater than $2 f_{0}$, requires a sharp cutoff analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Therefore, oversampling A/D converters necessitate additional digital lowpass filtering but less analog antialiasing filtering, often a favorable compromise in integrated circuits.\n\n$x_{1 p}(n)$ is subsequently resampled at $2 f_{0}$ to obtain $x_{s}(n)$ by retaining samples at a submultiple of the oversampling rate and discarding the rest. In Fig. 18.15, an oversampling rate of 6 is shown for clarity, as opposed to the more common values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, assuming the bandwidth of the original signal is $f_{0}$. In other words, the signal $x_{10}(n)$ contains redundant information due to oversampling, with all spectral\nThe provided text has been rephrased to maintain the original meaning and length. Here is the rephrased text:\n\nThe architecture for a standard $\\Delta \\Sigma$ oversampling A/D converter is depicted in Fig. 18.14, and example signal spectra are presented in Fig. 18.15. In digital audio applications, sampling frequencies such as $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$ are used, corresponding to an oversampling ratio of 128. The input signal, $x_{c}(t)$, is sampled and held to generate $x_{\\text {sh }}(t)$. This sampled signal is then processed by an A/D $\\Delta \\Sigma$ modulator, which outputs a 1-bit digital signal, $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. Although this 1-bit signal contains a substantial amount of out-of-band quantization noise, it is linearly related to the input signal $x_{c}(t)$ (with high resolution). A digital decimation filter is used to eliminate this noise. The decimation process effectively reduces quantization noise using a digital low-pass filter, producing the multi-bit signal $x_{1 p}(n)$. This low-pass filter also removes any high-frequency content from the input signal $x_{c}(t)$, acting as an anti-aliasing filter to limit signals to one-half the final output sampling rate, $2 \\mathrm{f}_{0}$. In comparison, a Nyquist-rate A/D converter, where $f_{s}$ is slightly greater than $2 f_{0}$, requires a sharp cutoff analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Consequently, oversampling A/D converters require additional digital lowpass filtering but less analog antialiasing filtering, often a desirable trade-off in integrated circuits.\n\n$x_{1 p}(n)$ is then resampled at $2 f_{0}$ to obtain $x_{s}(n)$ by retaining samples at a submultiple of the oversampling rate and discarding the rest. In Fig. 18.15, an oversampling rate of 6 is shown for clarity, as opposed to the more common values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, assuming the bandwidth of the original signal is $f_{0}$. In other words, the signal $x_{10}(n)$ contains redundant information due to oversampling, with all of its spectral information lying well below $\\pi$. By discarding samples, the spectral information is spread over 0 to $\\pi$. Finally, it should be noted that there is no need to actually create the signal $x_{1 p}(n)$, and much digital circuit complexity can be saved by combining the digital low-pass filter with the resampling block to directly produce the downsampled signal $x_{\\mathrm{s}}(\\mathrm{n})$, as discussed in Section 18.4. The final signal, $x_{\\mathrm{s}}(\\mathrm{n})$, would typically have 16-bit resolution in digital audio applications.\n\nThe linearity of oversampled A/D converters is more strongly influenced by the linearity of its internal D/A converter than by its internal quantizer. It is of interest to investigate which element most significantly affects the linearity of this oversampling A/D system. In the $\\Delta \\Sigma$ modulator, an internal 1-bit D/A converter is used whose output signal is combined with the input signal such that, over the frequency band of interest, these two signals are nearly identical. As a result, the overall linearity of this $\\Delta \\Sigma$ modulator converter depends heavily on the linearity of its internal D/A converter. For instance, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would essentially match that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to compensate for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is most strongly dependent on achieving a linear D/A converter inside the $\\Delta \\Sigma$ modulator. In fact, nonlinearities in the internal A/D converter (if it was multi-bit) have only a minor effect on the linearity of the overall converter, since the high gain in the feedback loop compensates for that nonlinearity."
},
{
    "text": "The architecture of a conventional  oversampling analog-to-digital (A/D) converter is depicted in Fig. 18.14, with sample signal spectra presented in Fig. 18.15. Digital audio applications may employ various sampling frequencies such as \\( f_{s}=5.6448 \\mathrm{MHz} \\) and \\( f_{0}=44.1 \\mathrm{kHz} \\), corresponding to an oversampling ratio of 128. The input signal, \\( x_{c}(t) \\), undergoes sampling and holding, yielding the signal \\( x_{\\text {sh }}(t) \\). This sampled signal is then fed into an A/D  modulator, which outputs a 1-bit digital signal \\( \\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n}) \\). This signal is assumed to be linearly correlated with the input signal \\( \\mathrm{x}_{\\mathrm{c}}(\\mathrm{t}) \\) to a high degree of precision, despite containing significant out-of-band quantization noise. To eliminate this noise, a digital decimation filter is employed. Essentially, the decimation process involves reducing quantization noise through a digital low-pass filter to produce the multi-bit signal \\( x_{1 p}(n) \\). It's important to note that this filter also removes any high-frequency content from the original input signal \\( \\mathrm{x}_{\\mathrm{c}}(\\mathrm{t}) \\), thereby acting as an anti-aliasing filter to confine signals to a maximum of half the final output sampling rate, \\( 2 \\mathrm{f}_{0} \\), as opposed to the input anti-aliasing filter, which only needs to restrict frequencies below \\( f_{s} / 2 \\). In comparison, a Nyquist-rate A/D converter, where \\( f_{s} \\) is slightly greater than \\( 2 f_{0} \\), necessitates a very steep cutoff in its analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the frequency band of interest. Consequently, oversampling A/D converters demand more extensive digital low-pass filtering but less analog anti-aliasing filteringa trade-off that is often favorable in integrated circuits.\n\nSubsequently, \\( x_{1 p}(n) \\) is resampled at \\( 2 f_{0} \\) to generate \\( x_{s}(n) \\) by retaining only the samples that are a submultiple of the oversampling rate and discarding the rest. For illustrative purposes, Fig. 18.15 depicts an oversampling rate of 6, as opposed to the more common values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, assuming the bandwidth of the original signal is \\( f_{0} \\). In other words, the signal \\( x_{10}(n) \\) contains redundant information because it is an oversampled signal with all its spectral information confined well below . By discarding samples, the spectral information is spread across 0 to . It's worth noting that there's no necessity to physically generate the signal \\( x_{1 p}(n) \\), and much of the digital circuit complexity can be reduced by integrating the digital low-pass filter with the resampling block to directly produce the downsampled signal \\( \\mathrm{x}_{\\mathrm{s}}(\\mathrm{n}) \\), as discussed in Section 18.4. The final signal, \\( \\mathrm{x}_{\\mathrm{s}}(\\mathrm{n}) \\), would typically exhibit 16-bit resolution in digital audio applications.\n\nA key point to consider is that the linearity of oversampled A/D converters is more significantly influenced by the linearity of its internal D/A converter than by its internal quantizer. The element that most critically impacts the linearity of this oversampling A/D system is of particular interest. Referring back to the  modulator, it incorporates an internal 1-bit D/A converter whose output signal is combined with the input signal such that, over the frequency band of interest, these two signals are almost identical. Consequently, the overall linearity of this  modulator converter is highly dependent on the linearity of its internal D/A converter. For instance, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would essentially mirror that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to compensate for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is most strongly dependent on achieving a linear D/A converter within the  modulator. Indeed, nonlinearities in the internal A/D converter (if it were multi-bit) have only a minor effect on the linearity of the overall converter, since the high gain in the feedback loop compensates for that nonlinearity."
},
{
    "text": "The architecture of a standard $\\Delta \\Sigma$ oversampling A/D converter is depicted in Fig. 18.14, with various signal spectra exemplified in Fig. 18.15. For digital audio applications, the sampling frequencies might be $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$, corresponding to an oversampling ratio of 128. The input signal, $x_{c}(t)$, undergoes sampling and holding, resulting in the signal $x_{\\text {sh }}(t)$. This sampled-and-held signal is then processed by an $A / D \\Delta \\Sigma$ modulator, which outputs a 1-bit digital signal $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. This 1-bit digital signal is linearly related to the input signal $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$ with high precision, despite containing significant out-of-band quantization noise. To eliminate this noise, a digital decimation filter is employed, conceptually functioning as a digital low-pass filter that reduces the quantization noise and yields a multi-bit signal $x_{1 p}(n)$. This filter also removes any high-frequency content from the original input signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, effectively acting as an anti-aliasing filter that restricts signals to one-half the final output sampling rate, $2 \\mathrm{f}_{0}$. In contrast, a Nyquist-rate $A / D$ converter, where $f_{s}$ is slightly greater than $2 f_{0}$, requires an analog anti-aliasing filter with a very sharp cutoff to prevent aliasing of unwanted signal content, including thermal noise, into the band of interest. Therefore, oversampling A/D converters necessitate additional digital lowpass filtering but require less analog antialiasing filtering, often representing a favorable compromise in integrated circuits.\n\nThe signal $x_{1 p}(n)$ is subsequently resampled at $2 f_{0}$ to generate $x_{s}(n)$ by retaining samples at a submultiple of the oversampling rate and discarding the rest. For clarity, Fig. 18.15 illustrates an oversampling rate of only 6, rather than the more common values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, assuming the bandwidth of the original signal is $f_{0}$. The signal $x_{10}(n)$ contains redundant information due to oversampling, with all spectral information lying well below $\\pi$. By discarding samples, the spectral information is spread across 0 to $\\pi$. It is important to note that it is not necessary to physically generate the signal $x_{1 p}(n)$, and much of the digital circuit complexity can be eliminated by integrating the digital low-pass filter with the resampling block to directly produce the downsampled signal $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$, as discussed in Section 18.4. The final signal, $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$, would typically have 16-bit resolution in digital audio applications.\n\nThe linearity of oversampled A/D converters is more strongly influenced by the linearity of their internal $D / A$ converter than by their internal quantizer. It is intriguing to examine which element most significantly impacts the linearity of this oversampling $\\mathrm{A} / \\mathrm{D}$ system. Focusing on the $\\Delta \\Sigma$ modulator, an internal 1-bit D/A converter is utilized, whose output signal is combined with the input signal such that, within the frequency band of interest, these two signals are nearly identical. Consequently, the overall linearity of this $\\Delta \\Sigma$ modulator converter is highly dependent on the linearity of its internal D/A converter. For instance, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would essentially mirror that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to compensate for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is most significantly dependent on achieving a linear $\\mathrm{D} / \\mathrm{A}$ converter within the $\\Delta \\Sigma$ modulator. In fact, nonlinearities in the internal A/D converter (if it was multi-bit) have only a minor effect on the linearity of the overall converter, as the high gain in the feedback loop mitigates that nonlinearity."
},
{
    "text": "The architecture for a standard $\\Delta \\Sigma$ oversampling analog-to-digital (A/D) converter is depicted in Fig. 18.14, with sample signal spectra displayed in Fig. 18.15. For digital audio, various sampling frequencies include $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$, representing an oversampling ratio of 128. The input signal, $x_{c}(t)$, undergoes sampling and holding, resulting in the signal $x_{\\text{sh}}(t)$. This sampled signal is then fed into an $A/D \\Delta \\Sigma$ modulator, which outputs a 1-bit digital signal $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. This 1-bit digital signal is considered linearly proportional to the input signal $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$ (with high resolution), despite containing significant out-of-band quantization noise. A digital decimation filter is employed to eliminate this noise, conceptually viewed as a process that first reduces quantization noise using a digital low-pass filter, yielding the multi-bit signal $x_{1p}(n)$. It is important to note that this low-pass filter also removes any superfluous high-frequency content from the original input signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, and acts as an anti-aliasing filter to confine signals to a maximum of half the final output sampling rate, $2 \\mathrm{f}_{0}$. In comparison, a Nyquist-rate $A/D$ converter, where $f_{s}$ is slightly above $2 f_{0}$, necessitates a sharp cutoff in the analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Thus, oversampling A/D converters necessitate additional digital lowpass filtering, offset by a reduction in analog anti-aliasing filtering, often a favorable compromise in integrated circuits.\n\n$x_{1p}(n)$ is subsequently resampled at $2 f_{0}$ to yield $x_{s}(n)$ by selectively retaining samples at fractions of the oversampling rate and discarding the rest. In Fig. 18.15, an oversampling rate of 6 is depicted for illustrative purposes, as opposed to the more conventional values of 64 or 128 utilized in commercial applications. This decimation process does not entail any loss of information, given that the bandwidth of the original signal is assumed to be $f_{0}$. Put differently, the signal $x_{10}(n)$ contains redundant information due to oversampling, with all spectral information concentrated well below $\\pi$. By eliminating samples, the spectral information is disseminated across 0 to $\\pi$. It is noteworthy that there is no need to physically generate the signal $x_{1p}(n)$, and significant digital circuit complexity can be reduced by merging the digital low-pass filter with the resampling block to directly produce the downsampled signal $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$, as detailed in Section 18.4. The resultant signal, $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$, typically exhibits 16-bit resolution in digital audio applications.\n\nA pivotal point to consider is that the linearity of oversampled A/D converters is more critically dependent on the linearity of their internal $D/A$ converter than on their internal quantizer. It is instructive to examine which element most significantly influences the linearity of this oversampling $\\mathrm{A}/\\mathrm{D}$ system. Focusing on the $\\Delta \\Sigma$ modulator, it incorporates an internal 1-bit D/A converter whose output signal is combined with the input signal to ensure they closely align over the frequency band of interest. Consequently, the overall linearity of this $\\Delta \\Sigma$ modulator converter is heavily contingent on the linearity of its internal D/A converter. For instance, a nonlinear internal D/A converter, paired with a slow linear ramp input signal, would produce a low-frequency output essentially mirroring that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp, reflecting the D/A converter's nonlinearity. As the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is predominantly determined by the ability to implement a linear $\\mathrm{D}/\\mathrm{A}$ converter within the $\\Delta \\Sigma$ modulator. In essence, nonlinearities in the internal A/D converter (were it multi-bit) would have a minimal impact on the overall converter's linearity, due to the high gain in the feedback loop that mitigates that nonlinearity."
},
{
    "text": "The architecture of a conventional $\\Delta \\Sigma$ oversampling A/D converter is depicted in Fig. 18.14, with Fig. 18.15 illustrating some signal spectra examples. In digital audio applications, sampling frequencies such as $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$ are commonly used, corresponding to an oversampling ratio of 128. The input signal, $x_{c}(t)$, undergoes sampling and holding, producing $x_{\\text {sh }}(t)$. This held signal is then fed into an $A / D \\Delta \\Sigma$ modulator, generating a 1-bit digital signal $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. Although this 1-bit signal is linearly related to the input signal $x_{c}(t)$ (with high resolution), it contains significant out-of-band quantization noise. To eliminate this noise, a digital decimation filter is employed. The decimation process effectively reduces quantization noise using a digital low-pass filter, resulting in the multi-bit signal $x_{1 p}(n)$. It is important to note that this low-pass filter also removes any high-frequency content from the original input signal $x_{c}(t)$, acting as an anti-aliasing filter to confine signals to a maximum frequency of $2 \\mathrm{f}_{0}$, unlike the input anti-aliasing filter, which only needs to limit frequencies to less than $f_{s} / 2$. In contrast, a Nyquist-rate A/D converter, where $f_{s}$ is slightly higher than $2 f_{0}$, requires a very sharp cutoff in its analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Consequently, oversampling A/D converters necessitate additional digital low-pass filtering, but with reduced analog anti-aliasing filteringa trade-off that is often advantageous in integrated circuits.\n\nSubsequently, $x_{1 p}(n)$ is resampled at $2 f_{0}$ to yield $x_{s}(n)$ by retaining samples at intervals of the oversampling rate and discarding the rest. For clarity, Fig. 18.15 demonstrates an oversampling rate of 6, as opposed to the more common values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, given that the bandwidth of the original signal is assumed to be $f_{0}$. In other words, the signal $x_{10}(n)$ contains redundant information due to oversampling, with its spectral information concentrated below $\\pi$. By discarding samples, the spectral information is spread across 0 to $\\pi$. It should be noted that it is not necessary to explicitly generate the signal $x_{1 p}(n)$, and significant digital circuit complexity can be saved by integrating the digital low-pass filter with the resampling block to directly produce the downsampled signal $x_{\\mathrm{s}}(\\mathrm{n})$, as discussed in Section 18.4. The final signal, $x_{\\mathrm{s}}(\\mathrm{n})$, typically exhibits 16-bit resolution in digital audio applications.\n\nKey Point: The linearity of oversampled A/D converters is more significantly influenced by the linearity of its internal D/A converter than by its internal quantizer.\n\nUnderstanding the element that most significantly impacts the linearity of this oversampling A/D system is of interest. Considering the $\\Delta \\Sigma$ modulator, an internal 1-bit D/A converter is utilized, and its output signal is combined with the input signal such that, within the frequency band of interest, these two signals are nearly identical. Consequently, the overall linearity of the $\\Delta \\Sigma$ modulator converter is highly dependent on the linearity of its internal D/A converter. For instance, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would closely resemble that ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to compensate for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is most strongly determined by achieving a linear D/A converter within the $\\Delta \\Sigma$ modulator. In fact, nonlinearities in the internal A/D converter (if it were multi-bit) have only a minor impact on the linearity of the overall converter, as the high gain in the feedback loop mitigates that nonlinearity."
},
{
    "text": "The system architecture of a conventional $\\Delta \\Sigma$ oversampling A/D converter is depicted in Fig. 18.14, with Fig. 18.15 illustrating example signal spectra. In digital audio applications, sampling frequencies such as $f_{s}=5.6448 \\mathrm{MHz}$ and $f_{0}=44.1 \\mathrm{kHz}$ are common, resulting in an oversampling ratio of 128. The input signal, $x_{c}(t)$, undergoes sampling and holding, yielding $x_{\\text {sh }}(t)$. This sampled-and-held signal is then processed by an $A / D \\Delta \\Sigma$ modulator, producing a 1-bit digital signal $\\mathrm{x}_{\\mathrm{dsm}}(\\mathrm{n})$. This 1-bit digital signal is linearly related to the input signal $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$ (with high resolution), although it contains significant out-of-band quantization noise. To eliminate this noise, a digital decimation filter is employed. The decimation process can be viewed as reducing quantization noise through a digital low-pass filter, resulting in the multi-bit signal $x_{1 p}(n)$. This low-pass filter also removes any high-frequency content from the original input signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, acting as an anti-aliasing filter to limit signals to one-half the final output sampling rate, $2 \\mathrm{f}_{0}$. In contrast, a Nyquist-rate $A / D$ converter, where $f_{s}$ is slightly greater than $2 f_{0}$, requires a sharp cutoff analog anti-aliasing filter to prevent unwanted signal content (including thermal noise) from aliasing into the band of interest. Thus, oversampling A/D converters necessitate additional digital lowpass filtering but require less analog antialiasing filteringa favorable trade-off in integrated circuits.\n\nSubsequently, $x_{1 p}(n)$ is resampled at $2 f_{0}$ to obtain $x_{s}(n)$ by retaining samples at a submultiple of the oversampling rate and discarding the rest. For clarity, an oversampling rate of only 6 is depicted in Fig. 18.15, as opposed to the more typical values of 64 or 128 used in commercial applications. This decimation process does not result in any loss of information, assuming the bandwidth of the original signal is $f_{0}$. In other words, the signal $x_{10}(n)$ contains redundant information due to oversampling, with all its spectral information lying well below $\\pi$. By discarding samples, the spectral information is spread over 0 to $\\pi$. It is important to note that the signal $x_{1 p}(n)$ does not need to be physically created, and digital circuit complexity can be reduced by combining the digital low-pass filter with the resampling block to directly produce the downsampled signal $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$. The final signal, $\\mathrm{x}_{\\mathrm{s}}(\\mathrm{n})$, typically has 16-bit resolution in digital audio applications.\n\nA key point to consider is that the linearity of oversampled A/D converters is more dependent on the linearity of its internal $D / A$ converter than on its internal quantizer. The linearity of the oversampling A/D system is significantly influenced by the internal D/A converter within the $\\Delta \\Sigma$ modulator. For instance, with a nonlinear internal D/A converter and a slow linear ramp input signal, the low-frequency content of the D/A converter's output would closely resemble the ramp. However, the low-frequency content of the digital input to the D/A converter would be a nonlinear ramp to compensate for the D/A converter's nonlinearity. Since the remaining digital circuitry is linear, the overall linearity of this oversampling A/D converter is primarily determined by the linearity of the internal $\\mathrm{D} / \\mathrm{A}$ converter within the $\\Delta \\Sigma$ modulator. In fact, nonlinearities in the internal A/D converter (if it were multi-bit) have only a minor impact on the overall converter's linearity, as the high gain in the feedback loop mitigates that nonlinearity."
},
{
    "text": "Much of the discussion thus far has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but a significant portion also pertains to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with some specific qualifications. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Illustrative signals that might appear in this system are shown in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly above the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is used with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. However, $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, so its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Next, the input signal is upsampled to a higher sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., an oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image signals, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally removing these images. This interpolation filter effectively acts as a digital brick-wall-type filter that passes 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejects all other frequencies. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which exhibits excellent linearity properties but still contains a significant amount of out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by using an analog filter to eliminate this out-of-band quantization noise. The analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nSeveral points are worth noting here. While oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some of the specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to remove signal images instead of a precise digital interpolation filter handling this task. This requirement can be particularly stringent, as in digital-audio applications where near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while up to 20 kHz should pass with unity gain. With oversampling, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. Indeed, oversampling is often employed in audio applications with multi-bit D/A converters simply to reduce the complexity of the analog-smoothing filter.\n\nAnother important consideration is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The rationale for this choice is that if the analog filter's order matches that of the modulator, the rising slope of the quantization noise will align with the filter's falling attenuation, resulting in approximately constant spectral density of the quantization noise up to half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the spectral density of the output signal's quantization noise will have a bandwidth similar to the analog filter's bandwidth, around $f_{0}$.\n\nLastly, it is crucial that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$. This analog filter must also be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, the implementation of these filters, especially if integrated, is nontrivial.\n\nKey Point: Oversampling D/A converters necessitate a highly linear but low-resolution internal D/A converter, along with an analog smoothing filter whose order should exceed that of the noise shaping by at least one, and it must possess sufficient dynamic range to handle both signal and substantial quantization noise power at its input."
},
{
    "text": "Most of the discussion to date has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but much of it also pertains to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with some caveats. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Illustrative signals that might appear in this system are shown in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly above the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is utilized with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. Note, however, that $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, and thus its depicted frequency spectrum has normalized the sample rate to $2 \\pi$. Subsequently, the input signal is upsampled to a higher equivalent sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., an oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image signals, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally filtering out these images. This interpolation filter effectively acts as a digital brick-wall-type filter that passes 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejects all other frequencies. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed into a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which boasts excellent linearity properties but still contains a significant amount of out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by applying an analog filter to remove this out-of-band quantization noise. The analog filter may comprise a combination of switched-capacitor and continuous-time filtering elements.\n\nSeveral points warrant attention here. Firstly, while oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some of the specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to eliminate the images in the signal instead of a precise digital interpolation filter doing so. This requirement can be particularly stringent, as in a digital-audio application where a near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while frequencies up to 20 kHz should pass with unity gain. With an oversampling approach, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. In fact, oversampling is frequently employed in audio applications with multi-bit D/A converters simply to reduce the complexity of the analog-smoothing filter.\n\nAnother crucial point is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The rationale for this choice is that if the analog filter's order matches that of the modulator, the rising slope of the quantization noise will align with the filter's falling attenuation, resulting in quantization noise with approximately constant spectral density up to one-half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the spectral density of the output signal's quantization noise will span a bandwidth similar to that of the analog filter, around $f_{0}$.\n\nLastly, it is essential that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$. This analog filter must also be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, the implementation of these filters, especially if they are integrated, poses significant challenges."
},
{
    "text": "Much of the prior discussion has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but a significant portion also pertains to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with some caveats. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram of Fig. 18.16. Illustrative signals within this system are presented in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ exceeds the highest input signal frequency slightly. For instance, in a compact disc audio application, a 16-bit input signal with a frequency band from 0 to 20 kHz is used, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. Note, however, that $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, and its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Subsequently, the input signal is upsampled to a higher sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the illustrated example, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ is often near 5 MHz (i.e., an oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image signals, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally filtering out these images. This interpolation filter effectively acts as a digital brick-wall-type filter, passing frequencies from 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejecting all others. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by substantial shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to utilize a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which boasts excellent linearity but still contains considerable out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by applying an analog filter to remove this out-of-band quantization noise. This analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nSeveral points warrant attention here. While oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to eliminate signal images instead of a precise digital interpolation filter. This requirement can be particularly stringent in digital-audio applications, where near 96-dB attenuation is necessary at 24 kHz, while frequencies up to 20 kHz should pass with unity gain. With oversampling, the digital interpolation filter confronts this strict specification rather than the analog smoothing filter. Indeed, oversampling is often employed in audio applications with multi-bit D/A converters merely to simplify the analog-smoothing filter's design.\n\nAnother crucial point is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. This choice is justified because if the analog filter's order matches the modulator's, the rising slope of the quantization noise would align with the filter's falling attenuation, resulting in approximately constant spectral density quantization noise up to half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the spectral density of the output signal's quantization noise will span a bandwidth similar to that of the analog filter, around $f_{0}$.\n\nLastly, it is essential that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$. This analog filter must also be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, particularly when these filters are integrated, their realization is nontrivial.\n\nKey Point: Oversampling D/A converters necessitate a highly linear but low-resolution internal D/A converter and an analog smoothing filter whose order should exceed that of the noise shaping by at least one, and it must possess sufficient dynamic range to handle both signal and substantial quantization noise power at its input.\n\nThe block diagram in Fig. 18.16 illustrates a 1-bit oversampling Digital-to-Analog (D/A) converter system. The system's main function is to convert a digital signal into an analog signal using oversampling and noise shaping techniques. Here's a detailed description of the diagram:\n\n**Main Components:**\n1. **Input Digital Signal (x_s(n))**: The process initiates with a digital input signal, represented as a sequence of discrete samples.\n2. **Oversampling Process (x_s2(n))**: The input digital signal undergoes oversampling, increasing the sampling rate to spread quantization noise over a broader frequency band, transitioning from x_s(n) to x_s2(n).\n3. **Low-pass Filter (x_lp(n))**: Following oversampling, the signal passes through a low-pass filter to remove high-frequency components introduced by oversampling, resulting in a smoother signal x_lp(n).\n4. ** Modulator (x_dsm(n))**: The filtered signal is processed by a Delta-Sigma () modulator, which shapes the quantization noise, pushing it out of the frequency band of interest, depicted as x_dsm(n).\n5. **1-bit D/A Converter (x_da(t))**: The modulated signal is converted from digital to analog using a 1-bit D/A converter, producing x_da(t).\n6. **Analog Filter**: The analog signal undergoes final smoothing through an analog filter, which strongly attenuates high-frequency noise, ensuring the output signal is smooth and practical for applications.\n\n**Flow of Information or Control:**\n- The process starts with the digital input signal x_s(n), which is oversampled to become x_s2(n).\n- The oversampled signal is filtered to x_lp(n), then modulated by the  modulator to produce x_dsm(n).\n- The 1-bit D/A conversion transforms x_dsm(n) into the analog signal x_da(t).\n- The final output, x_c(t), is achieved after analog filtering, resulting in a smooth analog signal.\n\n**Labels, Annotations, and Key Indicators:**\n- The diagram includes frequency domain representations for each stage, illustrating the spectral density changes.\n- Sequential steps are indicated by annotations like (1), (2), and (3).\n- Frequency labels such as f_0 and f_s denote the baseband frequency and sampling frequency, respectively.\n\n**Overall System Function:**\nThe system's primary function is to convert a digital signal into a high-quality analog signal using oversampling and noise shaping. This arrangement minimizes quantization noise in the desired frequency band and ensures the final analog output is smooth and accurate, suitable for audio and communication applications.\n\nThe diagram labeled \"Fig. 18.17\" presents plots illustrating signals and their spectra in an oversampling D/A converter system. The graph is divided into two columns: the left column shows time-domain signals, and the right column displays their corresponding frequency spectra.\n\n**Time-Domain Signals (Left Column):**\n- **Top Plot:** $x_s(n)$ is shown as a discrete-time signal with samples at specific intervals, marked by vertical lines, suggesting a continuous waveform.\n- **Second Plot:** $x_{lp}(n)$ represents a low-pass filtered version of $x_s(n)$, with denser samples indicating a smoother transition.\n- **Third Plot:** $x_{dsm}(n)$ shows a delta-sigma modulated signal, characterized by high-frequency switching between discrete levels.\n- **Fourth Plot:** $x_{da}(t)$ is the analog signal after D/A conversion, resembling the original signal shape.\n- **Bottom Plot:** $x_c(t)$ is the final continuous-time output signal, smooth and free from high-frequency components.\n\n**Frequency Spectra (Right Column):**\n- **Top Plot:** $X_s(\\omega)$ displays the spectrum of $x_s(n)$, showing repeated spectral replicas due to sampling.\n- **Second Plot:** $X_{s2}(\\omega)$ represents the spectrum of the oversampled signal, with closer spectral replicas.\n- **Third Plot:** $X_{lp}(\\omega)$ shows the spectrum after low-pass filtering, with only the fundamental frequency component remaining.\n- **Fourth Plot:** $X_{dsm}(\\omega)$ illustrates the spectrum of the delta-sigma modulated signal, with noise shaping pushing quantization noise to higher frequencies.\n- **Fifth Plot:** $X_{da}(f)$ is the spectrum of the D/A converted signal, with a strong peak at the desired frequency $f_0$.\n- **Bottom Plot:** $X_c(f)$ displays the final frequency spectrum, with a clear peak at $f_0$ and minimal high-frequency content.\n\n**Overall Behavior and Trends:**\n- The time-domain plots transition from discrete, high-frequency components to smooth, continuous signals through processing stages.\n- The frequency spectra demonstrate the reduction of high-frequency noise and preservation of desired frequency components.\n\n**Key Features and Technical Details:**\n- Oversampling increases the sampling rate for effective noise shaping.\n- Delta-sigma modulation pushes quantization noise out of the band of interest.\n- The final analog filter ensures high-frequency noise removal, resulting in a clean output signal at $f_0$.\n\nFig. 18.17 Signals and spectra in an oversampling D/A converter."
},
{
    "text": "Most of the discussion thus far has concentrated on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but much of it is also pertinent to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with certain qualifications. A high-resolution oversampling D/A converter utilizing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Some representative signals that might appear in this system are illustrated in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly above the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is employed with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. However, $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially just a sequence of numbers, and thus its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Next, the input signal is upsampled to a higher equivalent sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image components, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally eliminating these images. This interpolation filter effectively acts as a digital brick-wall-type filter that passes 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejects all other signals. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which possesses excellent linearity properties but still contains a significant amount of out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by utilizing an analog filter to remove this out-of-band quantization noise. The analog filter may comprise a combination of switched-capacitor and continuous-time filtering.\n\nSeveral points warrant attention here. Firstly, while oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some of the specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to eliminate the images in the signal instead of a precise digital interpolation filter doing so. This requirement can be particularly stringent, as in a digital-audio application where near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while up to 20 kHz should pass with unity gain. With the adoption of an oversampling approach, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. In fact, oversampling is often employed in audio applications with multi-bit D/A converters merely to reduce the complexity of this analog-smoothing filter.\n\nAnother important consideration is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The rationale for this choice is that if the analog filter's order matches that of the modulator, the slope of the rising quantization noise would align with the filter's falling attenuation, resulting in approximately constant spectral density of the quantization noise up to one-half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the spectral density of the output signal's quantization noise will have a bandwidth similar to the analog filter's bandwidth, around $f_{0}$.\n\nLastly, it is crucial that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$, and this analog filter must be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, the implementation of these filters, especially if they are integrated, is nontrivial.\n\nKey Point: Oversampling D/A converters necessitate a highly linear but low-resolution internal D/A converter, along with an analog smoothing filter whose order should be at least one greater than that of the noise shaping, and it must possess sufficient dynamic range to accommodate both the signal and the substantial quantization noise power at its input."
},
{
    "text": "Most of the prior discussion has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but much of it is also relevant to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with some exceptions. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Illustrative signals that might appear in this system are shown in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly above the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is used with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. Note, however, that $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, and thus its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Next, the input signal is upsampled to a higher equivalent sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ is often near a $5-\\mathrm{MHz}$ rate (i.e., oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image signals, so an interpolation filter is used to create the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally removing these images. This interpolation filter effectively acts as a digital brick-wall-type filter that passes 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejects all other signals. The resulting signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which generates a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for converting to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which possesses excellent linearity properties but still contains a significant amount of out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by employing an analog filter to eliminate this out-of-band quantization noise. The analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nSome important considerations include the fact that while oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes certain specifications of the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to remove signal images instead of a precise digital interpolation filter doing so. This requirement can be particularly stringent, as in digital-audio applications where near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while up to 20 kHz should pass with unity gain. With oversampling, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. In fact, oversampling is often employed in audio applications with multi-bit D/A converters simply to reduce the complexity of the analog-smoothing filter.\n\nAnother crucial point is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The reason for this choice is that if the analog filter's order matches that of the modulator, the slope of the rising quantization noise will align with the filter's falling attenuation, resulting in approximately constant spectral density of the quantization noise up to one-half the sampling rate (i.e., $f_{s} / 2$). By using a higher-order analog filter, the spectral density of the output signal's quantization noise will have a bandwidth similar to the analog filter's bandwidth, around $f_{0}$.\n\nLastly, it is essential that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$, and this analog filter must be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, the implementation of these filters, especially if integrated, is nontrivial."
},
{
    "text": "Much of the preceding discussion has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but a significant portion also applies to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with certain caveats. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Illustrative signals that might arise in this system are presented in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ exceeds the highest input signal frequency slightly. For instance, in a compact disc audio application, a 16-bit input signal spans a frequency band from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. However, $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, so its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Subsequently, the input signal is upsampled to a higher sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the illustrated example, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., an oversampling rate of 128). Nevertheless, $x_{s 2}(n)$ retains significant image artifacts, necessitating an interpolation filter to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally eliminating these images. This interpolation filter effectively acts as a digital brick-wall-type filter, passing frequencies from 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejecting all others. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by substantial shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to utilize a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which boasts excellent linearity but still contains considerable out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by applying an analog filter to remove this out-of-band quantization noise. The analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nKey considerations include the fact that while oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to eliminate signal images, a task more demanding than digital interpolation filter removal. This is particularly challenging in digital-audio applications, where near $96-\\mathrm{dB}$ attenuation is required at 24 kHz, while frequencies up to 20 kHz must pass with unity gain. With oversampling, the digital interpolation filter confronts this stringent specification instead of the analog smoothing filter. Indeed, oversampling is often employed in audio applications with multi-bit D/A converters simply to reduce the complexity of the analog-smoothing filter.\n\nAnother crucial point is that the analog low-pass filter's order should exceed that of the $\\Delta \\Sigma$ modulator by at least one order. This necessity arises because if the analog filter's order matches the modulator's, the rising slope of the quantization noise would align with the filter's falling attenuation, resulting in a roughly constant spectral density of quantization noise up to half the sampling rate (i.e., $f_{s} / 2$). A higher-order analog filter ensures that the spectral density of the output signal's quantization noise spans a bandwidth similar to the analog filter's, around $f_{0}$.\n\nLastly, the analog filter must robustly attenuate high-frequency noise, as much of the quantization noise centers around $f_{s} / 2$. This filter must also be linear to prevent modulation of noise back into the frequency band of interest. In many applications, especially when integrated, realizing these filters is nontrivial."
},
{
    "text": "Most of the discussion to date has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but much of it also pertains to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with certain qualifications. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Some representative signals that might appear in this system are illustrated in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ is slightly above the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is utilized with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. Note, however, that $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, and thus its depicted frequency spectrum has normalized the sample rate to $2 \\pi$. Next, the input signal is upsampled to a higher equivalent sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., an oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image signals, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally filtering out these images. This interpolation filter effectively acts as a digital brick-wall-type filter that passes 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejects all other signals. The resulting signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed to a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter to create $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which boasts excellent linearity properties but still contains a significant amount of out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by using an analog filter to remove this out-of-band quantization noise. The analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nSeveral points merit attention here. Firstly, while oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some of the specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to eliminate the images in the signal instead of a precise digital interpolation filter doing so. This requirement can be particularly stringent, as in a digital-audio application where a near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while up to 20 kHz should pass with unity gain. With the adoption of an oversampling approach, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. In fact, oversampling is frequently employed in audio applications with multi-bit D/A converters simply to reduce the complexity of this analog-smoothing filter.\n\nAnother noteworthy point is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The rationale for this choice is that if the analog filter's order matches that of the modulator, the slope of the rising quantization noise will align with the filter's falling attenuation, resulting in approximately constant spectral density of the quantization noise up to one-half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the\n\nKey Point: Oversampling D/A converters necessitate a highly linear but low-resolution internal D/A converter, along with an analog smoothing filter whose order should exceed that of the noise shaping by at least one, and it must possess sufficient dynamic range to accommodate both the signal and the substantial quantization noise power at its input.\nimage_name:Fig. 18.16 Block diagram of a 1-bit oversampling D/A converter\ndescription:The block diagram of a 1-bit oversampling D/A converter comprises several key components that collaborate to convert a digital signal into an analog output. Here's a detailed description of the system:\n\n1. **Main Components:**\n- **OSR (Oversampling Ratio):** This block elevates the sampling rate of the input digital signal \\( x_s(n) \\), initially at a rate of \\( 2f_0 \\). The oversampling ratio is defined as \\( \\frac{f_s}{2f_0} \\), where \\( f_s \\) is the new sampling frequency.\n- **Interpolation (Low-Pass) Filter:** This block smooths the oversampled signal \\( x_{s2}(n) \\) and prepares it for further processing by eliminating high-frequency components, resulting in \\( x_{lp}(n) \\).\n- ** Modulator:** This digital block receives the filtered signal \\( x_{lp}(n) \\) and performs noise shaping, producing a 1-bit digital output \\( x_{dsm}(n) \\). This process aids in reducing quantization noise in the band of interest.\n- **1-bit D/A Converter:** This component converts the 1-bit digital signal \\( x_{dsm}(n) \\) into an analog signal \\( x_{da}(t) \\).\n- **Analog Low-Pass Filter:** The final block in the sequence, it smooths the analog signal \\( x_{da}(t) \\), removing high-frequency quantization noise and producing the final analog signal \\( x_c(t) \\).\n\n2. **Flow of Information or Control:**\n- The process initiates with the digital input signal \\( x_s(n) \\), which is oversampled by the OSR block to increase its sampling frequency to \\( f_s \\).\n- The oversampled signal \\( x_{s2}(n) \\) then passes through the interpolation filter to remove unwanted high-frequency components, yielding \\( x_{lp}(n) \\).\n- The  modulator processes \\( x_{lp}(n) \\) and applies noise shaping, generating a high-frequency 1-bit signal \\( x_{dsm}(n) \\).\n- The 1-bit D/A converter transforms this digital signal into an analog signal \\( x_{da}(t) \\).\n- Finally, the analog low-pass filter smooths \\( x_{da}(t) \\), resulting in the continuous analog output \\( x_c(t) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram labels the signals at each stage: \\( x_s(n), x_{s2}(n), x_{lp}(n), x_{dsm}(n), x_{da}(t), x_c(t) \\).\n- The oversampling ratio (OSR) is clearly defined as \\( \\frac{f_s}{2f_0} \\).\n- Blocks are marked to indicate whether they handle digital or analog signals.\n\n4. **Overall System Function:**\n- The primary function of this system is to convert a digital signal into an analog signal using oversampling and noise shaping techniques. By oversampling and employing a  modulator, the system minimizes quantization noise in the desired frequency band. The 1-bit D/A conversion followed by analog filtering ensures a smooth and accurate analog output signal suitable for various applications in audio and communication systems.\n\nFig. 18.16 Block diagram of a 1-bit oversampling D/A converter.\nimage_name:Fig. 18.16\ndescription:The block diagram in Fig. 18.16 illustrates a 1-bit oversampling Digital-to-Analog (D/A) converter system. The main function of this system is to convert a digital signal into an analog signal using oversampling and noise shaping techniques. Here's a detailed description of the diagram:\n\nMain Components:\n1. **Input Digital Signal (x_s(n))**: The process starts with a digital input signal, represented as a sequence of discrete samples.\n2. **Oversampling Process (x_s2(n))**: The input digital signal is oversampled, involving an increase in the sampling rate to spread quantization noise over a broader frequency band. This transition is shown from x_s(n) to x_s2(n).\n3. **Low-pass Filter (x_lp(n))**: After oversampling, the signal undergoes low-pass filtering. This filter is essential for removing high-frequency components introduced by oversampling, resulting in a smoother signal x_lp(n).\n4. ** Modulator (x_dsm(n))**: The filtered signal is then processed by a Delta-Sigma () modulator, which shapes the quantization noise to move it out of the frequency band of interest, depicted as x_dsm(n).\n5. **1-bit D/A Converter (x_da(t))**: The modulated signal is converted from digital to analog form using a 1-bit D/A converter, producing x_da(t).\n6. **Analog Filter**: Finally, the analog signal passes through an analog filter, which strongly attenuates high-frequency noise and ensures the output signal is smooth and suitable for practical applications.\n\nFlow of Information or Control:\n- The flow begins with the digital input signal x_s(n) and progresses through the oversampling process to x_s2(n).\n- The oversampled signal is filtered to become x_lp(n), which is then modulated by the  modulator to produce x_dsm(n).\n- The 1-bit D/A conversion transforms x_dsm(n) into an analog signal x_da(t).\n- The final output is achieved after analog filtering, resulting in x_c(t), a smooth analog signal.\n\nLabels, Annotations, and Key Indicators:\n- The diagram includes frequency domain representations for each stage, showing how the spectral density of the signals changes through the process.\n- Annotations like (1), (2), and (3) indicate the sequential steps of the conversion process.\n- Frequency labels such as f_0 and f_s denote the baseband frequency and the sampling frequency, respectively.\n\nOverall System Function:\nThe system's primary function is to convert a digital signal into a high-quality analog signal by employing oversampling and noise shaping techniques. The arrangement of the blocks ensures that quantization noise is minimized in the desired frequency band, and the final analog output is smooth and accurate, making it suitable for audio and communication applications.\nimage_name:Fig. 18.17\ndescription:Fig. 18.17 presents a series of plots illustrating signals and their spectra in an oversampling D/A converter system. The graph is divided into two columns, with the left column showing time-domain signals and the right column displaying their corresponding frequency spectra.\n\n1. **Time-Domain Signals (Left Column):**\n- **Top Plot:** The signal \\( x_s(n) \\) is depicted as a discrete-time signal with samples at specific intervals, indicated by vertical lines. The dotted line suggests a continuous waveform that the samples follow. The signal is sampled at a rate exceeding the Nyquist rate to enable oversampling.\n- **Second Plot:** \\( x_{lp}(n) \\) represents a low-pass filtered version of the original sampled signal \\( x_s(n) \\). The discrete samples are more closely spaced, indicating a smoother transition between them.\n- **Third Plot:** \\( x_{dsm}(n) \\) shows a delta-sigma modulated signal, characterized by high-frequency switching between discrete levels. This modulation is used to shape the noise and move it out of the band of interest.\n- **Fourth Plot:** \\( x_{da}(t) \\) is the analog signal after D/A conversion, with a continuous waveform resembling the original signal shape.\n- **Bottom Plot:** \\( x_c(t) \\) is the final continuous-time output signal, which is smooth and free from the high-frequency components seen in \\( x_{dsm}(n) \\).\n\n2. **Frequency Spectra (Right Column):**\n- **Top Plot:** \\( X_s(\\omega) \\) displays the spectrum of the sampled signal \\( x_s(n) \\), showing repeated spectral replicas due to sampling, spaced at intervals of \\( 2\\pi \\).\n- **Second Plot:** \\( X_{s2}(\\omega) \\) represents the spectrum of the oversampled signal, with spectral replicas spaced more closely, indicating a higher sampling rate.\n- **Third Plot:** \\( X_{lp}(\\omega) \\) shows the spectrum after low-pass filtering, with only the fundamental frequency component remaining and higher frequencies attenuated.\n- **Fourth Plot:** \\( X_{dsm}(\\omega) \\) illustrates the spectrum of the delta-sigma modulated signal, with a broad noise shaping curve that moves quantization noise to higher frequencies.\n- **Fifth Plot:** \\( X_{da}(f) \\) is the spectrum of the D/A converted signal, showing a strong peak at the desired frequency \\( f_0 \\) and reduced noise at higher frequencies.\n- **Bottom Plot:** \\( X_c(f) \\) displays the final frequency spectrum, with a clear peak at \\( f_0 \\) and minimal high-frequency content, indicating effective filtering.\n\n**Overall Behavior and Trends:**\n- The time-domain plots transition from discrete, high-frequency components to smooth, continuous signals as the system processes the signal through various stages.\n- The frequency spectra demonstrate the reduction of high-frequency noise and the preservation of the desired frequency components through oversampling and filtering techniques.\n\n**Key Features and Technical Details:**\n- The oversampling process increases the sampling rate, allowing for more effective noise shaping.\n- Delta-sigma modulation is used to move quantization noise out of the band of interest.\n- The final analog filter ensures the removal of high-frequency noise, resulting in a clean output signal at \\( f_0 \\).\n\nFig. 18.17 Signals and spectra in an oversampling D/A converter.\nspectral density of the output signal's quantization noise will have a bandwidth similar to the analog filter's bandwidth, which is around $f_{0}$.\n\nFinally, it is crucial that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$, and this analog filter should be linear to avoid modulating the noise back into the frequency band of interest. In many applications, the realization of these filters, especially if they are integrated, is nontrivial."
},
{
    "text": "Much of the discussion to date has centered on $\\Delta \\Sigma \\mathrm{A} / \\mathrm{D}$ converters, but a significant portion also applies to $\\Delta \\Sigma \\mathrm{D} / \\mathrm{A}$ converters, with certain caveats. A high-resolution oversampling D/A converter employing a 1-bit converter can be implemented as depicted in the block diagram in Fig. 18.16. Illustrative signals that might appear in this system are presented in Fig. 18.17. The digital input signal, $x_{s}(n)$, is a multi-bit signal with an equivalent sample rate of $2 f_{0}$, where $f_{0}$ slightly exceeds the highest input signal frequency. For instance, in a compact disc audio application, a 16-bit input signal is utilized with a frequency band of interest from 0 to 20 kHz, while the sample rate, $2 \\mathrm{f}_{0}$, is 44.1 kHz. However, $\\mathrm{X}_{\\mathrm{s}}(\\mathrm{n})$ is essentially a sequence of numbers, so its depicted frequency spectrum normalizes the sample rate to $2 \\pi$. Next, the input signal is upsampled to a higher equivalent sampling rate, $\\mathrm{f}_{\\mathrm{s}}$, resulting in the upsampled signal $x_{s 2}(n)$. In the example provided, the oversampling rate is six (i.e., $f_{s}=6 \\times 2 f_{0}$), whereas in typical audio applications, $f_{s}$ often approaches a $5-\\mathrm{MHz}$ rate (i.e., an oversampling rate of 128). However, $x_{s 2}(n)$ retains significant image components, so an interpolation filter is employed to generate the multi-bit digital signal, $\\mathrm{x}_{\\mathrm{lp}}(\\mathrm{n})$, by digitally removing these images. This interpolation filter effectively acts as a digital brick-wall-type filter, passing 0 to $\\left(2 \\pi f_{0}\\right) / f_{s}$ and rejecting all other signals. The resultant signal, $\\mathrm{x}_{1 \\mathrm{p}}(\\mathrm{n})$, is then fed into a fully digital $\\Delta \\Sigma$ modulator, which produces a 1-bit output signal, $x_{d s m}(n)$, characterized by a substantial amount of shaped quantization noise. As previously discussed, the primary rationale for transitioning to a 1-bit digital signal is to enable the use of a 1-bit $\\mathrm{D} / \\mathrm{A}$ converter for creating $\\mathrm{x}_{\\mathrm{da}}(\\mathrm{t})$, which boasts excellent linearity properties but still contains considerable out-of-band quantization noise. Ultimately, the desired output signal, $\\mathrm{x}_{\\mathrm{c}}(\\mathrm{t})$, is obtained by applying an analog filter to eliminate this out-of-band quantization noise. The analog filter may combine switched-capacitor and continuous-time filtering techniques.\n\nSeveral points merit attention here. While oversampling facilitates the use of a 1-bit D/A converter with excellent linearity, it also relaxes some specifications for the analog-smoothing filter. For example, if a 16-bit converter were used at the Nyquist rate, $2 \\mathrm{f}_{0}$, the analog-smoothing filter would need to remove signal images instead of a precise digital interpolation filter. This requirement can be particularly stringent, as in digital-audio applications where near $96-\\mathrm{dB}$ attenuation is necessary at 24 kHz, while up to 20 kHz should pass with unity gain. With oversampling, the digital interpolation filter faces this stringent specification rather than the analog smoothing filter. Indeed, oversampling is often employed in audio applications with multi-bit D/A converters simply to reduce the complexity of the analog-smoothing filter.\n\nAnother crucial point is that the order of the analog low-pass filter should be at least one order higher than that of the $\\Delta \\Sigma$ modulator. The rationale for this choice is that if the analog filter's order matches that of the modulator, the rising slope of the quantization noise would align with the filter's falling attenuation, resulting in approximately constant spectral density quantization noise up to half the sampling rate (i.e., $f_{s} / 2$). By employing a higher-order analog filter, the spectral density of the output signal's quantization noise will have a bandwidth akin to the analog filter's bandwidth, around $f_{0}$.\n\nLastly, it is essential that the analog filter can strongly attenuate high-frequency noise, as much of the quantization noise is centered around $f_{s} / 2$, and this filter must be linear to prevent the modulation of noise back into the frequency band of interest. In many applications, realizing these filters, especially if integrated, is nontrivial.\n\nKey Point: Oversampling D/A converters necessitate a highly linear but low-resolution internal D/A converter, along with an analog smoothing filter whose order should exceed that of the noise shaping by at least one, and it must possess sufficient dynamic range to handle both signal and substantial quantization noise power at its input.\n\nimage_name: Fig. 18.16\ndescription: The block diagram of a 1-bit oversampling D/A converter comprises several key components working together to convert a digital signal into an analog output. Here's a detailed description:\n\n1. **Main Components:**\n- **OSR (Oversampling Ratio):** This block increases the sampling rate of the input digital signal \\( x_s(n) \\), initially at \\( 2f_0 \\). The oversampling ratio is defined as \\( \\frac{f_s}{2f_0} \\), where \\( f_s \\) is the new sampling frequency.\n- **Interpolation (Low-Pass) Filter:** This block smooths the oversampled signal \\( x_{s2}(n) \\) and prepares it for further processing by removing high-frequency components, resulting in \\( x_{lp}(n) \\).\n- ** Modulator:** This digital block receives the filtered signal \\( x_{lp}(n) \\) and performs noise shaping, producing a 1-bit digital output \\( x_{dsm}(n) \\). This process helps reduce quantization noise in the band of interest.\n- **1-bit D/A Converter:** This component converts the 1-bit digital signal \\( x_{dsm}(n) \\) into an analog signal \\( x_{da}(t) \\).\n- **Analog Low-Pass Filter:** The final block smooths the analog signal \\( x_{da}(t) \\), removing high-frequency quantization noise and outputting the final analog signal \\( x_c(t) \\).\n\n2. **Flow of Information or Control:**\n- The process starts with the digital input signal \\( x_s(n) \\), which is oversampled by the OSR block to increase its sampling frequency to \\( f_s \\).\n- The oversampled signal \\( x_{s2}(n) \\) is then filtered by the interpolation filter to remove unwanted high-frequency components, resulting in \\( x_{lp}(n) \\).\n- The  modulator takes \\( x_{lp}(n) \\) and applies noise shaping, producing a high-frequency 1-bit signal \\( x_{dsm}(n) \\).\n- The 1-bit D/A converter transforms this digital signal into an analog signal \\( x_{da}(t) \\).\n- Finally, the analog low-pass filter smooths \\( x_{da}(t) \\), resulting in the continuous analog output \\( x_c(t) \\).\n\n3. **Labels, Annotations, and Key Indicators:**\n- The diagram labels the signals at each stage: \\( x_s(n), x_{s2}(n), x_{lp}(n), x_{dsm}(n), x_{da}(t), x_c(t) \\).\n- The oversampling ratio (OSR) is clearly defined as \\( \\frac{f_s}{2f_0} \\).\n- Blocks are marked to indicate whether they handle digital or analog signals.\n\n4. **Overall System Function:**\n- The primary function of this system is to convert a digital signal into an analog signal using oversampling and noise shaping techniques. By oversampling and applying a  modulator, the system reduces quantization noise in the desired frequency band. The 1-bit D/A conversion followed by analog filtering ensures a smooth and accurate analog output signal suitable for various applications in audio and communication systems.\n\nFig. 18.16 Block diagram of a 1-bit oversampling D/A converter.\n\nimage_name: Fig. 18.16\ndescription: The block diagram in Fig. 18.16 represents a 1-bit oversampling Digital-to-Analog (D/A) converter system. The primary function of this system is to convert a digital signal into an analog signal using oversampling and noise shaping techniques. Here's a detailed description:\n\nMain Components:\n1. **Input Digital Signal (x_s(n))**: The process begins with a digital input signal, represented as a sequence of discrete samples.\n2. **Oversampling Process (x_s2(n))**: The input digital signal is oversampled, increasing the sampling rate to spread quantization noise over a wider frequency band, transitioning from x_s(n) to x_s2(n).\n3. **Low-pass Filter (x_lp(n))**: After oversampling, the signal passes through a low-pass filter to remove high-frequency components introduced by oversampling, resulting in a smoother signal x_lp(n).\n4. ** Modulator (x_dsm(n))**: The filtered signal is processed by a Delta-Sigma () modulator, which shapes the quantization noise to push it out of the frequency band of interest, depicted as x_dsm(n).\n5. **1-bit D/A Converter (x_da(t))**: The modulated signal is converted from digital to analog form using a 1-bit D/A converter, producing x_da(t).\n6. **Analog Filter**: Finally, the analog signal passes through an analog filter to strongly attenuate high-frequency noise, ensuring the output signal is smooth and suitable for practical applications.\n\nFlow of Information or Control:\n- The flow starts with the digital input signal x_s(n) and progresses through the oversampling process to x_s2(n).\n- The oversampled signal is filtered to become x_lp(n), which is then modulated by the  modulator to produce x_dsm(n).\n- The 1-bit D/A conversion transforms x_dsm(n) into an analog signal x_da(t).\n- The final output is achieved after analog filtering, resulting in x_c(t), a smooth analog signal.\n\nLabels, Annotations, and Key Indicators:\n- The diagram includes frequency domain representations for each stage, showing how the spectral density of the signals changes through the process.\n- Annotations like (1), (2), and (3) indicate the sequential steps of the conversion process.\n- Frequency labels such as f_0 and f_s denote the baseband frequency and the sampling frequency, respectively.\n\nOverall System Function:\nThe system's primary function is to convert a digital signal into a high-quality analog signal by employing oversampling and noise shaping techniques. The arrangement of the blocks ensures that quantization noise is minimized in the desired frequency band, and the final analog output is smooth and accurate, making it suitable for audio and communication applications.\n\nimage_name: Fig. 18.17\ndescription: The diagram labeled as \"Fig. 18.17\" presents a series of plots illustrating signals and their spectra in an oversampling D/A converter system. The graph is divided into two columns, with the left column showing time-domain signals and the right column displaying their corresponding frequency spectra.\n\n1. **Time-Domain Signals (Left Column):**\n- **Top Plot:** The signal \\( x_s(n) \\) is shown as a discrete-time signal with samples at specific intervals, marked by vertical lines. The dotted line suggests a continuous waveform that the samples follow. The signal is sampled at a rate exceeding the Nyquist rate to allow oversampling.\n- **Second Plot:** \\( x_{lp}(n) \\) represents a low-pass filtered version of the original sampled signal \\( x_s(n) \\). The discrete samples are more densely packed, indicating a smoother transition between them.\n- **Third Plot:** \\( x_{dsm}(n) \\) shows a delta-sigma modulated signal, characterized by high-frequency switching between discrete levels. This modulation shapes the noise and pushes it out of the band of interest.\n- **Fourth Plot:** \\( x_{da}(t) \\) is the analog signal after D/A conversion, with a continuous waveform closely resembling the original signal shape.\n- **Bottom Plot:** \\( x_c(t) \\) is the final continuous-time output signal, smooth and free from the high-frequency components seen in \\( x_{dsm}(n) \\).\n\n2. **Frequency Spectra (Right Column):**\n- **Top Plot:** \\( X_s(\\omega) \\) displays the spectrum of the sampled signal \\( x_s(n) \\), showing repeated spectral replicas due to sampling, spaced at intervals of \\( 2\\pi \\).\n- **Second Plot:** \\( X_{s2}(\\omega) \\) represents the spectrum of the oversampled signal, with spectral replicas spaced more closely, indicating a higher sampling rate.\n- **Third Plot:** \\( X_{lp}(\\omega) \\) shows the spectrum after low-pass filtering, with only the fundamental frequency component remaining and higher frequencies attenuated.\n- **Fourth Plot:** \\( X_{dsm}(\\omega) \\) illustrates the spectrum of the delta-sigma modulated signal, with a broad noise shaping curve pushing quantization noise to higher frequencies.\n- **Fifth Plot:** \\( X_{da}(f) \\) is the spectrum of the D/A converted signal, showing a strong peak at the desired frequency \\( f_0 \\) and reduced noise at higher frequencies.\n- **Bottom Plot:** \\( X_c(f) \\) displays the final frequency spectrum, with a clear peak at \\( f_0 \\) and minimal high-frequency content, indicating effective filtering.\n\n**Overall Behavior and Trends:**\n- The time-domain plots transition from discrete, high-frequency components to smooth, continuous signals as the system processes the signal through various stages.\n- The frequency spectra demonstrate the reduction of high-frequency noise and the preservation of the desired frequency components through oversampling and filtering techniques.\n\n**Key Features and Technical Details:**\n- The oversampling process increases the sampling rate, allowing for more effective noise shaping.\n- Delta-sigma modulation is used to push quantization noise out of the band of interest.\n- The final analog filter ensures the removal of high-frequency noise, resulting in a clean output signal at \\( f_0 \\).\n\nFig. 18.17 Signals and spectra in an oversampling D/A converter."
},
{
    "text": "A common technique for implementing decimation filters involves a multi-stage process, as depicted in Fig. 18.18. Initially, the first-stage FIR filter, labeled as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly reduces quantization noise, enabling a downsampling of the output to four times the Nyquist rate (or $8 \\mathrm{f}_{0}$). This lower-rate output is then processed by the second-stage filter, which could be an IIR filter as shown in Fig. 18.18(a), or a series of FIR filters as presented in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is a sequence of $L+1$ averaging filters. An individual averaging filter's transfer function, $T_{\\text {avg }}(z)$, is defined by\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ is the integer ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). It is worth noting that this filter's impulse response is finite, identifying it as an FIR filter. Additionally, all its impulse response coefficients are symmetric (indeed, they are all equal), classifying it as a linear-phase filter. ${ }^{6}$ Moreover, when $M$ is a power of two, the $1 / \\mathrm{M}$ multiplication term can be conveniently realized by adjusting the position of the fractional bits.\n\nTo demonstrate the effect of a series of averaging filters in diminishing quantization noise, consider an average-of-four filter (i.e., $M=4$) acting on the output of the 1-bit signal in Example 18.4. Given the output 1-bit sequence is $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nFor greater attenuation of the quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can also be processed by a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nRepeating this process to obtain $x_{1 p 3}(n)$ yields\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a series of all samples equalling $1 / 3$, as expected. To illustrate the sinc-like behavior of an averaging filter's frequency response, $\\mathrm{T}_{\\text {avg }}(z)$, it is helpful to rewrite (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nwhich can also be expressed as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nCombining $Y(z)$ terms, the transfer function of this averaging filter can also be represented in a recursive form as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response for this filter is found by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$. A cascade of $L+1$ averaging filters has the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe rationale for employing $L+1$ of these averaging filters in series mirrors the reasoning that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should exceed the order of the $\\Delta \\Sigma$ modulator. Specifically, the filter's attenuation slope should surpass the rising quantization noise to ensure the noise rolls off at a relatively low frequency. Otherwise, the noise would integrate over a very wide bandwidth, typically resulting in excessive total noise.\n\nAn efficient way to implement this cascade-of-averaging filters is to express (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand realize it as shown in Fig. 18.19 [Candy, 1992]. An important point to note is that at first glance, this circuit may seem as though it will not function correctly due to a dc input causing saturation of the discrete-time integrators."
},
{
    "text": "A multi-stage strategy is employed for implementing decimation filters, as depicted in Fig. 18.18. Initially, the first-stage FIR filter, denoted as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly reduces quantization noise, allowing the output to be downsampled to four times the Nyquist rate (or $8 \\mathrm{f}_{0}$). This downsampled output then feeds into the second-stage filter, which can be either an IIR filter, as shown in Fig. 18.18(a), or a series of FIR filters, as shown in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is a concatenation of $L+1$ averaging filters, where the transfer function of a single averaging filter, $T_{\\text {avg }}(z)$, is expressed as\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ denotes the ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). The impulse response of this filter is finite, confirming its FIR nature. Additionally, all impulse response coefficients are symmetric (indeed, they are all equal), making it a linear-phase filter. ${ }^{6}$ It is worth noting that the $1 / \\mathrm{M}$ multiplication can be conveniently implemented by adjusting the position of the fractional bits when M is a power of two.\n\nTo demonstrate the noise reduction capability of a series of averaging filters, consider an average-of-four filter (i.e., $M=4$) applied to the output of the 1-bit signal in Example 18.4. Given the output 1-bit sequence as\nCertainly technique-stage strategy is utilized for the\nImplementing decimation filters often involves a multi-stage strategy, as depictedified in Fig. 18.18. The the initial stage, the FIR filter $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$ significantly mitig\nA multi-stage approach is utilized used\nAimation filters can commonly realized through a multi-stage technique, as depicted in Fig. 18.18. The first stage involves the FIR filter $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$,\nDec multi-stage technique is employed employed in the implementation of decimation filters, as illustrated in Fig. 18.18. In FIR stage consists of the FIR filter $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, which"
},
{
    "text": "Decimation filters can be effectively implemented using a multi-stage design, as depicted in Fig. 18.18. Initially, a first-stage FIR filter, denoted as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly reduces quantization noise, enabling the output to be downsampled to a rate four times the Nyquist frequency (or $8 \\mathrm{f}_{0}$). This reduced-rate signal is then processed by a second-stage filter, which can either be an IIR filter, as shown in Fig. 18.18(a), or a series of FIR filters, as illustrated in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter comprises a sequence of $L+1$ averaging filters. Each averaging filter, represented by $T_{\\text {avg }}(z)$, has a transfer function expressed as\n\n$$\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n$$\n\nHere, $M$ is the integer ratio of the sampling frequency $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). The impulse response of this filter is finite, classifying it as an FIR-type filter. Additionally, all its impulse response coefficients are symmetric (indeed, they are all equal), making it a linear-phase filter. It is also worth noting that the $1 / \\mathrm{M}$ multiplication factor can be easily implemented by adjusting the position of the fractional bits when $M$ is a power of two.\n\nTo demonstrate the noise reduction achieved by a series of averaging filters, consider an average-of-four filter (i.e., $M=4$) applied to the output of the 1-bit signal from Example 18.4. Given the output 1-bit sequence as $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, is computed as\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nTo achieve greater attenuation of quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can be further processed with a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nRepeating this process to obtain $x_{1 p 3}(n)$ yields\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a series of all samples equalling $1 / 3$, as expected. To illustrate the sinc-type behavior of the frequency response of an averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, it is helpful to rewrite (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nThis can also be rewritten as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nGrouping together $Y(z)$ terms, the transfer function of this averaging filter can be expressed in a recursive form as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response for this filter is found by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$. A cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe choice of using $L+1$ averaging filters in cascade is akin to the rationale that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should exceed that of the $\\Delta \\Sigma$ modulator. Specifically, the filter's attenuation slope should be steeper than the rising quantization noise to ensure that the resulting noise diminishes at a lower frequency. Otherwise, the noise would spread across a very wide bandwidth, typically resulting in excessive total noise.\n\nAn efficient realization of this cascade-of-averaging filters can be achieved by expressing (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand implementing it as shown in Fig. 18.19 [Candy, 1992]. One point to note is that at first glance, it may seem that this circuit will not function correctly due to a dc input potentially causing saturation of the discrete-time integrators.\n\nReferring again to Fig. 18.18, the role of the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter is twofold. They serve to eliminate any higher-frequency input signals (effectively acting as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). In other words, while the $T_{\\text {sinc }}(z)$ filter excels at filtering out quantization noise, it lacks the sharpness required to serve as an effective anti-aliasing filter for input signals slightly above $f_{0}$. A second purpose is to compensate for the passband frequency drop caused by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter can be implemented using a single IIR filter, as shown in Fig. 18.18(a), or a combination of halfband FIR filters along with a separate sinc-compensation FIR filter, as depicted in Fig. 18.18(b). A halfband FIR filter has a passband ranging from 0 to $\\pi / 2$, while its stopband spans from $\\pi / 2$ to $\\pi$, with every second coefficient being zero [Vaidyanathan, 1993]. Thus, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that in certain applications, these halfband and sinc-compensation filters can be realized without the need for general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "A multi-stage strategy is employed for implementing decimation filters, as depicted in Fig. 18.18. In this approach, the initial stage utilizes a FIR filter, denoted as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, which significantly mitigates quantization noise, enabling the output to be downsampled to a rate four times the Nyquist frequency (or $8 \\mathrm{f}_{0}$). This reduced-rate output is then processed by a second-stage filter, which can be either an IIR filter, as illustrated in Fig. 18.18(a), or a sequence of FIR filters, as shown in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is a series of $L+1$ averaging filters. The transfer function of a single averaging filter, $T_{\\text {avg }}(z)$, is expressed as\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nwhere $M$ is the ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). It is noted that the impulse response of this filter is finite, indicating that it is an FIR-type filter. Additionally, all its impulse response coefficients are symmetric (in fact, they are all equal), making it a linear-phase filter. ${ }^{6}$ Furthermore, the $1 / \\mathrm{M}$ multiplication term can be readily implemented by adjusting the position of the fractional bits when M is set to a power of two.\n\nTo demonstrate the effectiveness of a series of averaging filters in reducing quantization noise, consider an average-of-four filter (i.e., $M=4$) applied to the output of the 1-bit signal in Example 18.4. Given the output 1-bit sequence as $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nTo achieve greater attenuation of the quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can also be processed by a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nBy repeating this process to obtain $x_{1 p 3}(n)$, we get\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nIt is observed that these sequences converge to a series of all samples equalling $1 / 3$, as expected.\n\nTo illustrate the sinc-type behavior of the frequency response of an averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, it is beneficial to rewrite (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nwhich can also be expressed as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nBy grouping the $Y(z)$ terms, the transfer function of this averaging filter can be written in recursive form as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response of this filter is obtained by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$.\n\nA cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe rationale for using $L+1$ of these averaging filters in series is analogous to the argument that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should be higher than the order of the $\\Delta \\Sigma$ modulator. Specifically, the slope of the attenuation for this low-pass filter should exceed the rising quantization noise, causing the resulting noise to decrease at a relatively low frequency. Otherwise, the noise would be integrated over a very broad bandwidth, typically leading to excessive total noise.\n\nAn efficient method for realizing this cascade of averaging filters is to express (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand implement it as shown in Fig. 18.19 [Candy, 1992]. One point to note is that at first glance, it may seem that this circuit will not function properly due to a dc input causing saturation of the discrete-time integrators.\n\nReferring back to Fig. 18.18, the purpose of the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter is twofold. One reason is to eliminate any higher-frequency input signals (effectively serving as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). In other words, while the $T_{\\text {sinc }}(z)$ filter excels at filtering out quantization noise, it lacks the sharpness required to act as a reasonable anti-aliasing filter for input signals slightly higher than $f_{0}$. A second reason is to compensate for the frequency drop in the passband caused by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter can be realized using a single IIR filter, as shown in Fig. 18.18(a), or a combination of halfband FIR filters and a separate sinc-compensation FIR filter, as depicted in Fig. 18.18(b). A halfband FIR filter has a passband from 0 to $\\pi / 2$, while its stopband is from $\\pi / 2$ to $\\pi$ with every second coefficient being zero [Vaidyanathan, 1993]. Thus, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that in some applications, these halfband and sinc-compensation filters can be realized without the need for general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "A technique for implementing decimation filters involves a multi-stage process, as depicted in Fig. 18.18. In this process, the initial FIR filter stage, denoted as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly diminishes quantization noise, allowing the signal to be downsampled to a rate of four times the Nyquist frequency (or $8 \\mathrm{f}_{0}$). This downsampled signal is then fed into a subsequent filter stage, which can be either an IIR filter as seen in Fig. 18.18(a), or a series of FIR filters as in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter comprises a sequence of $L+1$ averaging filters, each characterized by the transfer function $T_{\\text {avg }}(z)$, which is expressed as\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ denotes the ratio of $f_{s}$ to $8 f_{0}$ (thus, $8 f_{0}=f_{s} / M$). Notably, the filter's impulse response is finite, classifying it as an FIR filter. Moreover, all its impulse response coefficients are symmetric and equal, which makes it a linear-phase filter. When $M$ is chosen to be a power of two, the $1 / \\mathrm{M}$ multiplication can be efficiently achieved by adjusting the position of the fractional bits.\n\nTo demonstrate the effectiveness of averaging filters in reducing quantization noise, consider an example of an average-of-four filter (with $M=4$) applied to the output of the 1-bit signal from Example 18.4. The resulting first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nFor further quantization noise attenuation, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can be processed by a running-average-of-four filter to yield $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nand repeating this process for $x_{1 p 3}(n)$ would result in\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a constant value of $1 / 3$, as expected. The frequency response of the averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, exhibits sinc-type behavior, as can be shown by rewriting (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nwhich can also be expressed as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nGrouping $Y(z)$ terms yields the recursive form of the averaging filter's transfer function:\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response of this filter is found by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$. A cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe rationale for using $L+1$ averaging filters in series is akin to the requirement for the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter to have a higher order than the $\\Delta \\Sigma$ modulator. Specifically, the filter's attenuation slope should surpass the rising quantization noise to ensure that the noise decreases at a lower frequency. If not, the noise would spread over a wide bandwidth, typically leading to excessive total noise.\n\nAn efficient realization of this cascade is to express (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand implement it as shown in Fig. 18.19 [Candy, 1992]. A potential concern with this circuit is that a dc input might cause saturation of the discrete-time integrators. However, this issue does not arise with 2's-complement arithmetic due to its wrap-around property. Although the dc levels at the integrator outputs might be incorrect, the differentiators compare the current sample with the one from M samples ago, effectively discarding the dc component. Hence, as long as this difference is correctly maintained (as it would be with 2's-complement arithmetic), the correct computation is ensured.\n\nIn reference to Fig. 18.18 again, the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter serve a dual purpose. They are employed to eliminate any input signals with frequencies higher than the desired bandwidth (acting as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). While the $T_{\\text {sinc }}(z)$ filter excels at suppressing quantization noise, it lacks the sharpness required for anti-aliasing of input signals slightly above $f_{0}$. The second reason for their use is to compensate for the passband frequency attenuation introduced by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter can be implemented using a single IIR filter, as shown in Fig. 18.18(a), or a combination of halfband FIR filters and a separate sinc-compensation FIR filter, as depicted in Fig. 18.18(b). A halfband FIR filter has a passband from 0 to $\\pi / 2$ and a stopband from $\\pi / 2$ to $\\pi$, with every second coefficient being zero [Vaidyanathan, 1993]. Hence, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that in certain applications, these halfband and sinc-compensation filters can be realized without using general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "A practical technique for implementing decimation filters involves a multi-stage strategy, as depicted in Fig. 18.18. Initially, a first-stage FIR filter, denoted as $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly diminishes quantization noise, allowing the signal to be downsampled to a rate of four times the Nyquist frequency (or $8 \\mathrm{f}_{0}$). The resulting lower-rate signal is then processed by a second-stage filter, which can be either an IIR filter, as depicted in Fig. 18.18(a), or a series of FIR filters, as shown in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is composed of a sequence of $L+1$ averaging filters, with the transfer function of a single averaging filter, $T_{\\text {avg }}(z)$, expressed as\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ represents the ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). The finite impulse response of this filter indicates it is an FIR-type filter. Moreover, all its impulse response coefficients are symmetric (indeed, they are all equal), classifying it as a linear-phase filter. ${ }^{6}$ Additionally, the $1 / \\mathrm{M}$ multiplication factor is conveniently achieved by adjusting the position of the fractional bits when M is set as a power of two.\n\nTo exemplify the reduction of quantization noise using a series of averaging filters, consider an average-of-four filter (i.e., $M=4$) operating on the output of the 1-bit signal from Example 18.4. Given the output 1-bit sequence is $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nFor further attenuation of the quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can also be processed by a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nIterating this process to obtain $x_{1 p 3}(n)$ yields\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a series of all samples equalling $1 / 3$, as anticipated. To demonstrate that the frequency response of an averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, exhibits sinc-type behavior, it is helpful to rewrite (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nThis can also be rewritten as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nGrouping $Y(z)$ terms together, we find the transfer function of this averaging filter can also be expressed in a recursive form as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response for this filter is derived by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$. A cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe rationale for employing $L+1$ of these averaging filters in series mirrors the argument that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should exceed that of the $\\Delta \\Sigma$ modulator. Specifically, the slope of the attenuation for this low-pass filter must be steeper than the rising quantization noise to ensure that the resulting noise decays at a lower frequency. If not, the noise would spread across a very broad bandwidth, typically leading to excessive total noise.\n\nAn effective way to implement this cascade of averaging filters is to express (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand realize it as shown in Fig. 18.19 [Candy, 1992]. A key observation here is that the circuit initially seems like it might not function correctly due to a dc input potentially causing saturation of the discrete-time integrators.\n\nRegarding Fig. 18.18, the role of the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter is twofold. One reason for their application is to eliminate any higher-frequency input signals (acting as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). In other words, while the $T_{\\text {sinc }}(z)$ filter excels at suppressing quantization noise, it lacks the sharpness required to serve as an effective anti-aliasing filter for input signals slightly above $f_{0}$. A second reason is to compensate for the frequency attenuation in the passband caused by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter can be implemented using a single IIR filter, as shown in Fig. 18.18(a), or a combination of halfband FIR filters and a separate sinc-compensation FIR filter, as depicted in Fig. 18.18(b). A halfband FIR filter possesses a passband ranging from 0 to $\\pi / 2$, with its stopband extending from $\\pi / 2$ to $\\pi$, characterized by every second coefficient being zero [Vaidyanathan, 1993]. Consequently, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that in certain applications, these halfband and sinc-compensation filters can be realized without the need for general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "A technique for implementing decimation filters involves a multi-stage process, as depicted in Fig. 18.18. The initial stage employs a FIR filter, $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, which significantly reduces quantization noise, enabling the output to be downsampled to four times the Nyquist rate (i.e., $8 \\mathrm{f}_{0}$). This reduced-rate output is then processed by a second-stage filter, which can be either an IIR filter, as shown in Fig. 18.18(a), or a series of FIR filters, as presented in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is a sequence of $L+1$ averaging filters, where each averaging filter's transfer function, $T_{\\text {avg }}(z)$, is defined by\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ is the integer ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). Notably, this filter has a finite impulse response, classifying it as an FIR-type filter. Additionally, all its impulse response coefficients are symmetric (indeed, they are all equal), making it a linear-phase filter. ${ }^{6}$ Furthermore, the $1 / \\mathrm{M}$ multiplication factor can be easily implemented by adjusting the position of the fractional bits when M is chosen to be a power of two.\n\nAs an example of a sequence of averaging filters reducing quantization noise, consider an average-of-four filter (i.e., $M=4$) applied to the output of the 1-bit signal in Example 18.4. Given the output 1-bit sequence is $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nTo achieve greater attenuation of the quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can also be processed by a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nRepeating this process to obtain $x_{1 p 3}(n)$ would give\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a series of all samples equalling $1 / 3$, as expected. To demonstrate that the frequency response of an averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, exhibits sinc-type behavior, it is helpful to rewrite (18.35) as\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nwhich can also be expressed as\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nBy grouping the $Y(z)$ terms, we find that the transfer function of this averaging filter can also be represented recursively as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response of this filter is obtained by substituting $z=e^{j \\omega}$, leading to\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$. A cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe rationale for employing $L+1$ of these averaging filters in series is akin to the argument that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should exceed the order of the $\\Delta \\Sigma$ modulator. Specifically, the slope of the attenuation for this low-pass filter should surpass the increasing quantization noise, causing the resulting noise to diminish at a relatively low frequency. Otherwise, the noise would be integrated over a very broad bandwidth, typically resulting in excessive total noise.\n\nAn efficient method to implement this cascade-of-averaging filters is to express (18.40) as\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand thus realize it as shown in Fig. 18.19 [Candy, 1992]. A point to note here is that at first glance it appears as though this circuit will not operate properly due to a dc input causing saturation of the discrete-time integrators.\n\nReferring back to Fig. 18.18, the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter serve a dual purpose. One reason for their use is to eliminate any higher-frequency input signals (effectively acting as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). In other words, while the $T_{\\text {sinc }}(z)$ filter excels at filtering out quantization noise, it lacks the sharpness to function as an adequate anti-aliasing filter for input signals slightly above $f_{0}$. A second reason is to compensate for the frequency drop in the passband caused by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter could be realized using a single IIR filter, as depicted in Fig. 18.18(a). Alternatively, a combination of halfband FIR filters and a separate sinc-compensation FIR filter could be employed, as shown in Fig. 18.18(b). A halfband FIR filter has a passband ranging from 0 to $\\pi / 2$, while its stopband spans from $\\pi / 2$ to $\\pi$, with every second coefficient being zero [Vaidyanathan, 1993]. Thus, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that in certain applications, these halfband and sinc-compensation filters can be realized without the need for general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "A common strategy for implementing decimation filters involves a multi-stage process, as depicted in Fig. 18.18. Initially, a first-stage FIR filter, $\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})$, significantly reduces quantization noise, allowing the output to be downsampled to four times the Nyquist rate, or $8 \\mathrm{f}_{0}$. This downsampled output is then fed into a second-stage filter, which can be either an IIR filter, as seen in Fig. 18.18(a), or a series of FIR filters, as demonstrated in Fig. 18.18(b).\n\nThe sinc ${ }^{L+1}$ FIR filter is composed of $L+1$ averaging filters in series. The transfer function of a single averaging filter, $T_{\\text {avg }}(z)$, is expressed as:\n\n$$\n\\begin{equation*}\nT_{\\mathrm{avg}}(z)=\\frac{Y(z)}{U(z)}=\\frac{1}{M} \\sum_{i=0}^{M-1} z^{-i} \\tag{18.35}\n\\end{equation*}\n$$\n\nHere, $M$ is the integer ratio of $f_{s}$ to $8 f_{0}$ (i.e., $8 f_{0}=f_{s} / M$). Notably, the impulse response of this filter is finite, identifying it as an FIR-type filter. Moreover, all its impulse response coefficients are symmetric (indeed, they are all equal), making it a linear-phase filter. ${ }^{6}$ Additionally, the $1 / \\mathrm{M}$ multiplication term can be easily implemented by adjusting the position of the fractional bits when M is a power of two.\n\nTo illustrate the reduction of quantization noise by a series of averaging filters, consider an average-of-four filter (i.e., $M=4$) applied to the output of the 1-bit signal in Example 18.4. Given the output 1-bit sequence $\\{1,1,-1,1,1,-1,1,1,-1, \\ldots\\}$, the first averaged output, $\\mathrm{x}_{\\mathrm{lp} 1}(\\mathrm{n})$, would be:\n\n$$\n\\mathrm{x}_{\\mathrm{lp} \\mathrm{l}}(\\mathrm{n})=\\{0.5,0.5,0.0,0.5,0.5,0.0, \\ldots\\}\n$$\n\nTo achieve greater attenuation of the quantization noise, the signal $\\mathrm{x}_{\\mathrm{pl} 1}(\\mathrm{n})$ can also be processed by a running-average-of-four filter, resulting in $\\mathrm{x}_{\\mathrm{lp} 2}(\\mathrm{n})$ as:\n\n$$\nx_{\\mathrm{lp} 2}(n)=\\{0.375,0.375,0.25,0.375,0.375,0.25, \\ldots\\}\n$$\n\nRepeating this process to obtain $x_{1 p 3}(n)$ would yield:\n\n$$\nx_{1 \\mathrm{p} 3}(\\mathrm{n})=\\{0.344,0.344,0.313,0.344,0.344,0.313, \\ldots\\}\n$$\n\nThese sequences converge to a series of all samples equalling $1 / 3$, as expected.\n\nTo demonstrate that the frequency response of an averaging filter, $\\mathrm{T}_{\\text {avg }}(z)$, exhibits sinc-type behavior, it is helpful to rewrite (18.35) as:\n\n$$\n\\begin{equation*}\nM Y(z)=\\left(\\sum_{i=0}^{M-1} z^{-i}\\right) U(z)=\\left(1+z^{-1}+z^{-2}+\\cdots+z^{-(M-1)}\\right) U(z) \\tag{18.36}\n\\end{equation*}\n$$\n\nThis can also be rewritten as:\n\n$$\n\\begin{align*}\nM Y(z) & =\\left(z^{-1}+z^{-2}+\\cdots+z^{-M}\\right) U(z)+\\left(1-z^{-M}\\right) U(z)  \\tag{18.37}\\\\\n& =M z^{-1} Y(z)+\\left(1-z^{-M}\\right) U(z)\n\\end{align*}\n$$\n\nGrouping $Y(z)$ terms together, the transfer function of this averaging filter can also be expressed in recursive form as:\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}(\\mathrm{z})=\\frac{\\mathrm{Y}(\\mathrm{z})}{\\mathrm{U}(\\mathrm{z})}=\\frac{1}{\\mathrm{M}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{z}^{-1}}\\right) \\tag{18.38}\n\\end{equation*}\n$$\n\nThe frequency response for this filter is obtained by substituting $z=e^{j \\omega}$, leading to:\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\mathrm{avg}}\\left(\\mathrm{e}^{\\mathrm{j} \\omega}\\right)=\\frac{\\operatorname{sinc}\\left(\\frac{\\omega \\mathrm{M}}{2}\\right)}{\\operatorname{sinc}\\left(\\frac{\\omega}{2}\\right)} \\tag{18.39}\n\\end{equation*}\n$$\n\nwhere $\\operatorname{sinc}(\\mathrm{x}) \\equiv \\sin (\\mathrm{x}) / \\mathrm{x}$.\n\nA cascade of $L+1$ averaging filters yields the response $T_{\\text {sinc }}(z)$ given by:\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}}\\left(\\frac{1-\\mathrm{z}^{-\\mathrm{M}}}{1-\\mathrm{Z}^{-1}}\\right)^{\\mathrm{L}+1} \\tag{18.40}\n\\end{equation*}\n$$\n\nThe choice of using $L+1$ averaging filters in series is analogous to the argument that the order of the analog low-pass filter in an oversampling $\\mathrm{D} / \\mathrm{A}$ converter should exceed the order of the $\\Delta \\Sigma$ modulator. Specifically, the attenuation slope of the low-pass filter should surpass the rising quantization noise, causing the resulting noise to decay at a relatively low frequency. Otherwise, the noise would be integrated over a very wide bandwidth, typically leading to excessive total noise.\n\nAn efficient way to implement this cascade-of-averaging filters is to express (18.40) as:\n\n$$\n\\begin{equation*}\n\\mathrm{T}_{\\text {sinc }}(\\mathrm{z})=\\left(\\frac{1}{1-\\mathrm{z}^{-1}}\\right)^{\\mathrm{L}+1}\\left(1-\\mathrm{z}^{\\mathrm{M}}\\right)^{\\mathrm{L}+1} \\frac{1}{\\mathrm{M}^{\\mathrm{L}+1}} \\tag{18.41}\n\\end{equation*}\n$$\n\nand realize it as shown in Fig. 18.19 [Candy, 1992]. A point to note is that, at first glance, it may seem that this circuit will not function properly due to a dc input causing saturation of the discrete-time integrators.\n\nRegarding Fig. 18.18, the purpose of the filters following the $\\mathrm{T}_{\\text {sinc }}(z)$ filter is twofold. One reason for their use is to eliminate any higher-frequency input signals (effectively acting as a sharp anti-aliasing filter) before the signal is downsampled to the final Nyquist rate (i.e., $2 \\mathrm{f}_{0}$). In other words, while the $T_{\\text {sinc }}(z)$ filter excels at filtering out quantization noise, it lacks the sharpness required to serve as an effective anti-aliasing filter for input signals slightly above $f_{0}$. The second reason is to compensate for the frequency drop in the passband caused by the $T_{\\text {sinc }}(z)$ filter. This anti-aliasing and sinc-compensation filter might be implemented using a single IIR filter, as shown in Fig. 18.18(a). Alternatively, a combination of halfband FIR filters and a separate sinc-compensation FIR filter could be used, as depicted in Fig. 18.18(b). A halfband FIR filter has a passband from 0 to $\\pi / 2$, while its stopband is from $\\pi / 2$ to $\\pi$, with every second coefficient being zero [Vaidyanathan, 1993]. Thus, with a sufficiently high filter order, its output can be downsampled by a factor of two. It has also been demonstrated that, in certain applications, these halfband and sinc-compensation filters can be realized without general multi-bit multipliers [Saramaki, 1990]."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Despite the high FIR order, no multi-bit multiplications are necessary due to the 1-bit input signal, simplifying all multiplications. Moreover, the output only needs to be computed at the Nyquist rate, as intermediate samples would be discarded.\n\nKey Point: In single-stage decimation, a single filter processes a low-resolution noise-shaped signal to produce the decimated output. Due to the high filter order, multiple time-interleaved filters can be employed in parallel.\n\nThis results in 2048 additions per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate must be 2048 times the Nyquist rate. For example, with a Nyquist rate of 48 kHz, the accumulator would need a clock rate of 98.3 MHz. To mitigate this, 32 separate FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and an output rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses an accumulator operating at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters and across the two stereo channels, and the ROM size can be halved if coefficients are duplicated, as in linear-phase FIR filtering.\n\nAdditionally, the number of additions can be reduced by grouping input bits. For instance, grouping four input bits allows the use of a 16-word ROM lookup table instead of three additions. With this grouping, each of the 32 FIR filters would require only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Despite the high FIR order, no multi-bit multiplications are necessary due to the 1-bit input signal, simplifying all multiplications. Additionally, the output only needs to be computed at the Nyquist rate, as intermediate samples would be discarded.\n\nKey Point: In single-stage decimation, a single filter processes a low-resolution noise-shaped signal to produce the decimated output. Due to the high filter order, multiple time-interleaved filters can be employed in parallel.\n\nThus, 2048 additions are needed per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would be 2048 times the Nyquist rate. For instance, with a Nyquist rate of 48 kHz, the accumulator would need to operate at 98.3 MHz. To mitigate this high clock rate, 32 separate FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and producing an output at a 1.5 kHz clock rate. Consequently, each of the 32 FIR filters uses an accumulator running at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as in linear-phase FIR filtering.\n\nFurthermore, the number of additions can be reduced by grouping input bits. For example, grouping four input bits allows the use of a 16-word ROM lookup table instead of three additions. With this grouping, each of the 32 FIR filters would require only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Despite the seemingly high FIR order, it's important to note that no multi-bit multiplications are necessary, as the input signal is merely 1-bit, making all multiplications straightforward. Additionally, the output only needs to be computed at the Nyquist rate (intermediate samples would be discarded), resulting in 2048 additions per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For example, with a Nyquist rate of 48 kHz, the accumulator would require a clock rate of 98.3 MHz. To mitigate this high clock rate, 32 separate FIR filters are implemented in a time-interleaved manner (sharing coefficients), each with 2048 coefficients and producing an output at a clock rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses one accumulator operating at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as seen in linear-phase FIR filtering.\n\nFurthermore, it's feasible to decrease the number of additions by grouping input bits. For instance, grouping four input bits allows the use of a 16-word ROM lookup table instead of performing three additions. With such input bit grouping, each of the 32 FIR filters would necessitate only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Despite the high FIR order, no multi-bit multiplications are necessary due to the 1-bit input signal, simplifying all multiplications. Additionally, the output only needs to be computed at the Nyquist rate, as intermediate samples are discarded.\n\nKey Point: In single-stage decimation, a single filter processes a low-resolution noise-shaped signal to produce the decimated output. Due to the high filter order, multiple time-interleaved filters may be employed in parallel.\n\nThus, 2048 additions are required per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For instance, with a Nyquist rate of 48 kHz, the accumulator would need a clock rate of 98.3 MHz. To mitigate this high clock rate, 32 separate FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and operating at a clock rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses an accumulator running at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as in linear-phase FIR filtering.\n\nFurthermore, the number of additions can be reduced by grouping input bits. For example, grouping four input bits allows the use of a 16-word ROM lookup table instead of three additions. With this approach, each of the 32 FIR filters would require only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Although this FIR order appears substantial, it's important to note that multi-bit multiplications are unnecessary due to the 1-bit input signal, rendering all multiplications straightforward. Additionally, the output only needs to be computed at the Nyquist rate (as intermediate samples would be discarded anyway), resulting in 2048 additions per clock cycle at this rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For example, with a Nyquist rate of 48 kHz, the accumulator would require a clock rate of 98.3 MHz. To mitigate this high clock rate, 32 individual FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and an output rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses a single accumulator operating at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as seen in linear-phase FIR filtering.\n\nFurthermore, it's feasible to decrease the number of additions by clustering input bits. For instance, grouping four input bits allows the use of a 16-word ROM lookup table instead of performing three additions. With this input bit grouping, each of the 32 FIR filters would necessitate only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Although this FIR order appears substantial, it's important to note that no multi-bit multiplications are necessary due to the 1-bit input signal, making all multiplications straightforward. Additionally, the output only needs to be computed at the Nyquist rate, as intermediate samples would be discarded anyway.\n\nKey Point: In single-stage decimation, a single filter processes a low-resolution noise-shaped signal to produce the decimated output. Due to the high filter order, multiple time-interleaved filters can be employed in parallel.\n\nThus, 2048 additions are required per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For example, with a Nyquist rate of 48 kHz, the accumulator would need to operate at 98.3 MHz. To mitigate this high clock rate, 32 separate FIR filters are implemented in a time-interleaved manner, sharing coefficients, each with 2048 coefficients and producing an output at a clock rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses an accumulator running at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as in linear-phase FIR filtering.\n\nFurthermore, it's feasible to decrease the number of additions by grouping input bits. For instance, grouping four input bits allows the use of a 16-word ROM lookup table instead of three additions. With this approach, each of the 32 FIR filters would necessitate only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, [Dattorro, 1989] utilized a 2048-tap FIR filter to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Although this FIR order appears substantial, it's important to note that multi-bit multiplications are unnecessary due to the 1-bit input signal, simplifying all multiplications. Moreover, the output only needs to be computed at the Nyquist rate, as intermediate samples would be discarded anyway.\n\nKey Point: In single-stage decimation, a single filter processes a low-resolution, noise-shaped signal to produce the decimated output. Due to the high filter order, multiple time-interleaved filters can be employed in parallel.\n\nThus, 2048 additions are necessary per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For instance, with a Nyquist rate of 48 kHz, the accumulator would require a clock speed of 98.3 MHz. To mitigate this high clock rate, 32 individual FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and operating at a clock rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses one accumulator running at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as seen in linear-phase FIR filtering.\n\nAdditionally, the number of additions can be reduced by grouping input bits. For example, grouping four input bits allows the use of a 16-word ROM lookup table instead of three additions. With this input bit grouping, each of the 32 FIR filters would need only 512 additions."
},
{
    "text": "An alternative method for implementing decimation filters involves employing a high-order FIR filter. For instance, in [Dattorro, 1989], a 2048-tap FIR filter was utilized to decimate 1-bit stereo outputs from two $\\Delta \\Sigma$ modulators, each with an oversampling ratio of 64. Despite the seemingly high FIR order, it's important to note that no multi-bit multiplications are necessary, as the input signal is merely 1-bit, making all multiplications straightforward. Additionally, the output only needs to be computed at the Nyquist rate (intermediate samples would be discarded), resulting in 2048 additions per clock cycle at the Nyquist rate. However, if a single accumulator handles all 2048 additions, its clock rate would need to be 2048 times the Nyquist rate. For example, with a Nyquist rate of 48 kHz, the accumulator would require a clock rate of 98.3 MHz. To mitigate this high clock rate, 32 separate FIR filters (sharing coefficients) are implemented in a time-interleaved manner, each with 2048 coefficients and producing an output at a clock rate of 1.5 kHz. Consequently, each of the 32 FIR filters uses a single accumulator operating at 3 MHz (i.e., 2048 times 1.5 kHz). The coefficient ROM values are shared among the FIR filters (and across the two stereo channels), and the ROM size can be halved if coefficients are duplicated, as seen in linear-phase FIR filtering.\n\nFurthermore, it's feasible to reduce the number of additions by grouping input bits. For instance, grouping four input bits allows the use of a 16-word ROM lookup table instead of performing three additions. With this input bit grouping, each of the 32 FIR filters would need only 512 additions."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow flexible placement of noise transfer function zeros, leading to enhanced SQNR performance, particularly at lower OSR levels. However, ensuring stability for these structures is complex, often necessitating the integration of multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more conducive to analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One pioneering approach to developing higher-order interpolative modulators was introduced in [Chao, 1990], utilizing a filtering framework akin to a direct-form filter. Nonetheless, this direct-form structure was prone to component variation-induced shifts in the noise transfer function zeros from the unit circle. To mitigate this sensitivity, resonators were incorporated with a refined interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It's important to note that a single 1-bit D/A signal remains employed for feedback, thereby ensuring its linearity.\n\nu(n)\nimage_name:Fig. 18.20 A block diagram of a fifth-order modulator\ndescription:The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed examination of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Numerous summing nodes are present, merging input and feedback signals.\n2. **Integrators ():** Five integrators, symbolized by triangles with integral signs, perform signal integration over time.\n3. **Feedback Paths:** Feedback loops associated with coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These regulate the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is fed into a comparator, likely converting the analog signal to digital for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal is combined with feedback at the initial summing node.\n- **Integration Sequence:** The resultant signal undergoes a series of integrations, each further modifying it.\n- **Feedback Loops:** Feedback from specific integrators, weighted by \\( f_1 \\) and \\( f_2 \\), is reintroduced into earlier nodes, shaping the noise transfer function.\n- **Output and Feedback:** The final output, derived from the comparator, also feeds back into the system, ensuring stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** These are marked along feedback paths, highlighting their role in zero placement.\n\nOverall System Function:\nThis fifth-order modulator's primary role is to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By leveraging resonators and a modified interpolative structure, it achieves superior dynamic range performance compared to conventional direct-form designs. The integration of feedback loops and integrators ensures system stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nwill remain superior. The resonators in this setup, resulting from feedback signals linked to \\( f_1 \\) and \\( f_2 \\), facilitate the distribution of zeros across the frequency band of interest, offering improved dynamic range performance over concentrating all zeros at dc, as previously assumed.\n\nUnfortunately, modulators of order two or higher can become unstable, particularly under large input signals, and may not stabilize even when these signals diminish. Ensuring stability for interpolative modulators is challenging, a topic further explored in Section 18.7. Specifically, the adoption of multi-bit internal quantizers enhances stability, making them a common complement to higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow for the flexible positioning of noise transfer function zeros, which enhances SQNR performance, particularly at lower OSR levels, compared to positioning all zeros at dc. However, ensuring stability for these structures is challenging, leading to their frequent integration with multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more suitable for analog modulator implementations due to its lower sensitivity, when contrasted with the error-feedback structure. One of the pioneering methods for developing higher-order interpolative modulators was introduced in [Chao, 1990]. This approach utilized a filtering structure akin to a direct-form filter; nevertheless, the direct-form design's susceptibility to component variations could cause the noise transfer function zeros to deviate from the unit circle. To mitigate this sensitivity, resonators can be incorporated with a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It is important to note that a single 1-bit D/A signal is still employed for feedback, ensuring its linearity will\nu(n)\nimage_name: Fig. 18.20 A block diagram of a fifth-order modulator\ndescription: The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Here is a detailed examination of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Several summing nodes are present, merging input signals with feedback signals.\n2. **Integrators ():** Five integrators, symbolized by triangles with integral signs, perform signal integration over time.\n3. **Feedback Paths:** Feedback loops linked to coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These regulate the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is directed to a comparator, likely for analog-to-digital conversion for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal enters and combines with feedback at the initial summing node.\n- **Integration Sequence:** The merged signal undergoes a series of integrations, each further altering it over time.\n- **Feedback Loops:** Feedback from specific integrators, adjusted by coefficients \\( f_1 \\) and \\( f_2 \\), is reintroduced into earlier summing nodes, aiding in noise transfer function shaping.\n- **Output and Feedback:** The final output emerges from the comparator, which also provides feedback to the system, ensuring stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** These are marked along the feedback paths, highlighting their role in zero placement in the noise transfer function.\n\nOverall System Function:\nThe primary role of this fifth-order modulator is to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By using resonators and a modified interpolative structure, this design surpasses traditional direct-form structures in dynamic range performance. The integration of feedback loops and integrators ensures system stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nremain superior. The resonators in this setup, resulting from feedback signals linked to \\( f_1 \\) and \\( f_2 \\), facilitate the distribution of zeros in the noise transfer function across the frequency band of interest. This configuration offers superior dynamic range performance compared to concentrating all zeros at dc, as previously assumed.\n\nHowever, modulators of order two or higher can become unstable, particularly under large input signals. Once unstable, they may not regain stability even after the large input signals cease. Ensuring stability for interpolative modulators is complex and is further addressed in Section 18.7. Specifically, the adoption of multi-bit internal quantizers enhances stability, making them a common pairing with higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow for flexible placement of noise transfer function zeros, leading to enhanced SQNR performance, particularly at lower OSR values. However, ensuring stability for these structures is challenging, often necessitating the integration of multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more conducive to analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One pioneering approach to developing higher-order interpolative modulators was introduced in [Chao, 1990], employing a filtering mechanism akin to a direct-form filter. Nevertheless, this direct-form structure was prone to component variation-induced shifts in the noise transfer function zeros from the unit circle. To mitigate this sensitivity, resonators can be incorporated alongside a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It's noteworthy that a single 1-bit D/A signal is still utilized for feedback, ensuring its linearity will\nu(n)\nimage_name: Fig. 18.20 A block diagram of a fifth-order modulator\ndescription: The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed overview of the system components and their interactions:\n\nMain Components:\n1. **Summing Nodes (+):** Several summing nodes are present, merging input and feedback signals.\n2. **Integrators ():** Five integrators, symbolized by triangles with integral signs, integrate input signals over time.\n3. **Feedback Paths:** Feedback loops involving coefficients \\( f_1 \\) and \\( f_2 \\) are integral for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These regulate the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is directed to a comparator, likely for analog-to-digital conversion for feedback purposes.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal is initially combined with feedback signals at the first summing node.\n- **Integration Sequence:** The integrated signal undergoes successive modifications through a series of integrators.\n- **Feedback Loops:** Feedback from specific integrators, adjusted by coefficients \\( f_1 \\) and \\( f_2 \\), is reintroduced into earlier summing nodes, aiding in noise transfer function shaping.\n- **Output and Feedback:** The comparator's output serves as the final output and also feeds back into the system, ensuring stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** These are marked along feedback paths, highlighting their role in zero placement within the noise transfer function.\n\nOverall System Function:\nThis fifth-order modulator's primary role is to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By leveraging resonators and a modified interpolative structure, this design surpasses traditional direct-form structures in dynamic range performance. The integration of feedback loops and integrators ensures system stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nremain superior. The resonators in this setup, driven by feedback signals related to \\( f_1 \\) and \\( f_2 \\), facilitate the distribution of zeros across the frequency-of-interest band, thereby enhancing dynamic range performance compared to concentrating all zeros at dc, as previously assumed.\n\nUnfortunately, modulators of order two or higher can become unstable, particularly under large input signals, and may not regain stability even after the input signals diminish. Ensuring stability for interpolative modulators is complex, a topic further explored in Section 18.7. Specifically, the adoption of multi-bit internal quantizers can bolster stability, making them a common complement to higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow flexible placement of noise transfer function zeros, leading to enhanced SQNR performance, particularly at lower OSR levels. However, ensuring stability for these structures is challenging, often necessitating the integration of multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more conducive to analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One of the pioneering methods for developing higher-order interpolative modulators was introduced in [Chao, 1990]. This approach utilized a filtering setup akin to a direct-form filter; nevertheless, the direct-form structure's susceptibility to component variations could shift the noise transfer function zeros away from the unit circle. To mitigate this sensitivity, resonators can be incorporated alongside a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It is important to note that a single 1-bit D/A signal remains in use for feedback, thereby ensuring its linearity will\nu(n)\nimage_name: Fig. 18.20 A block diagram of a fifth-order modulator\ndescription: The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed overview of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Several summing nodes are present, merging input and feedback signals.\n2. **Integrators ():** Five integrators, symbolized by triangles with integral signs, perform signal integration over time.\n3. **Feedback Paths:** Feedback loops involving coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These regulate the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and affect the integrators' timing and frequency response.\n6. **Comparator:** The final integrators output feeds into a comparator, likely converting the analog signal to digital for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal enters and combines with feedback at the initial summing node.\n- **Integration Sequence:** The merged signal undergoes a series of integrations, each modifying it over time.\n- **Feedback Loops:** Feedback from specific integrators, adjusted by coefficients \\( f_1 \\) and \\( f_2 \\), is reintroduced into earlier nodes, shaping the noise transfer function.\n- **Output and Feedback:** The final output comes from the comparator, which also provides feedback to maintain system stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** Annotated along feedback paths, they indicate their role in zero placement in the noise transfer function.\n\nOverall System Function:\nThis fifth-order modulator primarily aims to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By employing resonators and a modified interpolative structure, it achieves superior dynamic range performance compared to traditional direct-form designs. The integration of feedback loops and integrators ensures stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nremain superior. The resonators in this setup, driven by feedback signals linked to \\( f_1 \\) and \\( f_2 \\), facilitate the distribution of zeros across the frequency band of interest, thereby enhancing dynamic range performance compared to concentrating all zeros at dc, as previously assumed.\n\nUnfortunately, modulators of order two or higher can become unstable, particularly under large input signals, and may not regain stability even after the input signals diminish. Ensuring stability for interpolative modulators is complex, as discussed in Section 18.7. Specifically, the incorporation of multi-bit internal quantizers can enhance stability, making them a common pairing with higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow for flexible placement of noise transfer function zeros, leading to enhanced SQNR performance, particularly at lower OSR values. However, ensuring stability for these configurations is complex, often necessitating the integration of multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more favorable for analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One of the pioneering methods for developing higher-order interpolative modulators was introduced in [Chao, 1990]. This approach utilized a filtering structure akin to a direct-form filter; however, its direct-form nature made it susceptible to component variations, potentially displacing the noise transfer function zeros from the unit circle. To mitigate this sensitivity, resonators can be incorporated with a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It is important to note that a single 1-bit D/A signal is still employed for feedback, ensuring its linearity.\n\nimage_name:Fig. 18.20 A block diagram of a fifth-order modulator\ndescription:The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed overview of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Numerous summing nodes are present, merging input signals with feedback signals.\n2. **Integrators ():** Five integrators, each symbolized by a triangle with an integral sign, are included to integrate input signals over time.\n3. **Feedback Paths:** Feedback loops linked to coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These coefficients are applied to both feedback and feedforward paths, regulating their impact on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is directed to a comparator, likely converting the analog signal to digital for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal enters and is immediately combined with feedback signals at the initial summing node.\n- **Integration Sequence:** The merged signal undergoes a series of integrations, each further refining it over time.\n- **Feedback Loops:** Feedback from specific integrators, weighted by \\( f_1 \\) and \\( f_2 \\), is fed back to earlier summing nodes, aiding in noise transfer function shaping.\n- **Output and Feedback:** The final output is derived from the comparator, which also provides feedback to the system, ensuring stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** These are marked along the feedback paths, highlighting their role in zero placement.\n\nOverall System Function:\nThis fifth-order modulator's primary role is to modulate the input signal while minimizing noise and distortion through strategic zero placement in the noise transfer function. By incorporating resonators and a modified interpolative structure, it achieves superior dynamic range performance compared to conventional direct-form structures. The integration of feedback loops and integrators ensures system stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nThe resonators in this setup, resulting from feedback signals linked to \\( f_1 \\) and \\( f_2 \\), enable the distribution of zeros across the frequency-of-interest band, offering better dynamic range performance than concentrating all zeros at dc, as previously assumed.\n\nUnfortunately, modulators of order two or higher can become unstable, particularly under large input signals. Once unstable, they may not regain stability even after the large signals subside. Ensuring stability for interpolative modulators is challenging and is further explored in Section 18.7. Specifically, the adoption of multi-bit internal quantizers enhances stability, making them a common complement to higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow flexible placement of noise transfer function zeros, enhancing SQNR performance, particularly at lower OSR levels. However, ensuring stability for these structures is challenging, leading to their frequent pairing with multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more suitable for analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One early method for developing higher-order interpolative modulators was introduced in [Chao, 1990], utilizing a filtering approach akin to a direct-form filter. Nevertheless, this direct-form structure was prone to component variation-induced shifts in the noise transfer function zeros from the unit circle. To mitigate this sensitivity, resonators were incorporated with a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It's important to note that a single 1-bit D/A signal remains in use for feedback, ensuring its linearity.\n\nimage_name: Fig. 18.20 A block diagram of a fifth-order modulator\ndescription: The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed overview of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Several summing nodes are present, merging input and feedback signals.\n2. **Integrators ():** Five integrators, symbolized by triangles with integral signs, perform signal integration over time.\n3. **Feedback Paths:** Feedback loops involving coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These regulate the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is processed by a comparator, likely converting the analog signal to digital for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal is combined with feedback at the initial summing node.\n- **Integration Sequence:** The resultant signal undergoes integration through a series of integrators.\n- **Feedback Loops:** Feedback from specific integrators, weighted by \\( f_1 \\) and \\( f_2 \\), is reintroduced into earlier summing nodes, aiding in noise transfer function shaping.\n- **Output and Feedback:** The final output is derived from the comparator, which also provides system feedback for stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** Annotated along feedback paths, they signify their role in zero placement in the noise transfer function.\n\nOverall System Function:\nThis fifth-order modulator's primary role is to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By integrating resonators and a modified interpolative structure, it surpasses traditional direct-form structures in dynamic range performance. The system's stability and high linearity, crucial for high-fidelity processing, are maintained through feedback loops and integrators.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nremains excellent. The resonators in this setup, driven by feedback signals related to \\( f_1 \\) and \\( f_2 \\), enable the spreading of zeros across the frequency band of interest, offering superior dynamic range performance compared to concentrating all zeros at dc, as previously assumed.\n\nHowever, modulators of order two or higher can become unstable, particularly under large input signals, and may not stabilize even when these signals subside. Ensuring stability for interpolative modulators is complex, as discussed in Section 18.7. Specifically, employing multi-bit internal quantizers enhances stability, making them a common complement to higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow for flexible placement of noise transfer function zeros, leading to enhanced SQNR performance, particularly at lower OSR values. However, ensuring stability for these structures is challenging, which is why they are frequently paired with multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more conducive to analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. One of the pioneering methods for developing higher-order interpolative modulators was introduced in [Chao, 1990]. This approach utilized a filtering architecture akin to a direct-form filter; however, the direct-form structure's susceptibility to component variations could cause the noise transfer function zeros to deviate from the unit circle. To mitigate this sensitivity, resonators can be integrated with a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. It is important to note that a single 1-bit D/A signal is still employed for feedback, ensuring its linearity.\n\nimage_name: Fig. 18.20 A block diagram of a fifth-order modulator\ndescription: The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Here is a detailed description of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Several summing nodes are present, merging input signals with feedback signals.\n2. **Integrators ():** Five integrators, each symbolized by a triangle with an integral sign, are included to integrate input signals over time.\n3. **Feedback Paths:** Feedback loops associated with coefficients \\( f_1 \\) and \\( f_2 \\) are essential for positioning zeros in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These coefficients are applied to both feedback and feedforward paths, regulating their impact on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and affect the timing and frequency response of the integrators.\n6. **Comparator:** The final integrator's output is directed to a comparator, which likely converts the analog signal to a digital format for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal enters and is immediately combined with feedback signals at the initial summing node.\n- **Integration Sequence:** The combined signal undergoes a series of integrations, each further altering the signal over time.\n- **Feedback Loops:** Feedback from specific integrator outputs, weighted by coefficients \\( f_1 \\) and \\( f_2 \\), is fed back into earlier summing nodes, aiding in shaping the noise transfer function.\n- **Output and Feedback:** The final output is derived from the comparator, which also provides feedback to the system, ensuring stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for adjusting the system's response and are applied at various stages in the signal path.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** These are marked along the feedback paths, highlighting their role in zero placement within the noise transfer function.\n\nOverall System Function:\nThe primary role of this fifth-order modulator is to modulate the input signal while minimizing noise and distortion through strategic zero placement in the noise transfer function. By incorporating resonators and a modified interpolative structure, this design surpasses traditional direct-form structures in dynamic range performance. The integration of feedback loops and integrators ensures the system's stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nwill be excellent. The resonators in this configuration are a result of the feedback signals linked to \\( f_1 \\) and \\( f_2 \\), leading to zeros in the noise transfer function being distributed across the frequency band of interest. This setup offers superior dynamic range performance compared to concentrating all zeros at dc, as previously assumed.\n\nUnfortunately, modulators of order two or higher can become unstable, especially under large input signals. Once unstable, they may not regain stability even when the large input signals cease. Ensuring stability for an interpolative modulator is complex and is further discussed in Section 18.7. Specifically, the adoption of multi-bit internal quantizers enhances stability, making them a common choice in conjunction with higher-order interpolative architectures."
},
{
    "text": "Key Point: Interpolative higher-order modulators allow for flexible placement of noise transfer function zeros, enhancing SQNR performance, particularly at lower OSR levels. However, ensuring stability for these structures is complex, often necessitating the integration of multi-bit internal quantizers.\n\nAs previously mentioned, the interpolative structure depicted in Fig. 18.6(a) is more suitable for analog modulator implementations due to its lower sensitivity compared to the error-feedback structure. An early method for developing higher-order interpolative modulators was introduced in [Chao, 1990], employing a filtering approach akin to a direct-form filter. Nevertheless, this direct-form structure was prone to component variation-induced shifts in the noise transfer function zeros from the unit circle. To mitigate this sensitivity, resonators were incorporated with a modified interpolative structure, as illustrated in Fig. 18.20 [Ferguson, 1991]. Note that a single 1-bit D/A signal is still utilized for feedback, ensuring its linearity.\n\nimage_name:Fig. 18.20 A block diagram of a fifth-order modulator\ndescription:The block diagram in Fig. 18.20 depicts a fifth-order modulator designed to enhance component sensitivity and dynamic range performance. Heres a detailed overview of the system:\n\nMain Components:\n1. **Summing Nodes (+):** Multiple summing nodes are present, merging input and feedback signals.\n2. **Integrators ():** Five integrators, each symbolized by a triangle with an integral sign, perform signal integration over time.\n3. **Feedback Paths:** Feedback loops associated with coefficients \\( f_1 \\) and \\( f_2 \\) are essential for zero placement in the noise transfer function.\n4. **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These control the impact of feedback and feedforward paths on the overall signal.\n5. **Capacitors (\\( c_1, c_2, c_3, c_4, c_5 \\)):** These components store charge and influence the integrators' timing and frequency response.\n6. **Comparator:** The final integrator's output is fed into a comparator, likely converting the analog signal to digital for feedback.\n\nFlow of Information or Control:\n- **Input Signal Flow:** The input signal is combined with feedback at the initial summing node.\n- **Integration Sequence:** The combined signal undergoes a series of integrations, each modifying it over time.\n- **Feedback Loops:** Feedback from specific integrators, weighted by \\( f_1 \\) and \\( f_2 \\), is fed back to earlier nodes, shaping the noise transfer function.\n- **Output and Feedback:** The final output is from the comparator, which also provides system feedback for stability and linearity.\n\nLabels, Annotations, and Key Indicators:\n- **Gain Coefficients (\\( a_1, a_2, a_3, a_4, a_5 \\)):** These are vital for system response tuning and are applied at various stages.\n- **Feedback Coefficients (\\( f_1, f_2 \\)):** Annotated along feedback paths, they indicate their role in zero placement.\n\nOverall System Function:\nThis fifth-order modulator's primary role is to modulate input signals while minimizing noise and distortion through strategic zero placement in the noise transfer function. By using resonators and a modified interpolative structure, it achieves superior dynamic range performance compared to traditional direct-form designs. The feedback loops and integrators ensure system stability and high linearity, essential for high-fidelity signal processing.\n\nFig. 18.20 A block diagram of a fifth-order modulator.\nremains excellent. The resonators in this setup, resulting from feedback signals linked to \\( f_1 \\) and \\( f_2 \\), enable the spreading of zeros across the frequency band of interest, offering better dynamic range than concentrating all zeros at dc, as previously assumed.\n\nHowever, modulators of order two or higher can become unstable, especially under large input signals, and may not regain stability even when these signals cease. Ensuring stability for interpolative modulators is challenging, a topic further explored in Section 18.7. Specifically, the adoption of multi-bit internal quantizers enhances stability, often paired with higher-order interpolative architectures."
},
{
    "text": "An alternative method for implementing modulators involves employing a cascade-type structure where a higher-order modulator is built from lower-order ones. The benefit of this method is that the stability of the lower-order modulators ensures the overall system's stability. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nFig. 18.21 illustrates the setup for creating a second-order modulator using two first-order modulators. The fundamental concept is to transmit the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and merge the outputs of both modulators to completely eliminate the first section's quantization noise. The resulting output contains only the second section's quantization noise, which has been filtered twiceonce by the second modulator and once by the subsequent digital circuitry. Assuming linear models for the quantizers, a straightforward linear analysis for the first stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a system block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, which comprises two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nMain Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** These combine the input signal \\( u(n) \\) with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** This introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** The amplifier, with a gain of +1, produces the quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts the digital output back to an analog signal for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** These merge the error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Another unit delay is introduced here.\n- **Amplifier with Feedback:** This amplifier has a gain of +2 and generates the quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Similar to the first stage, it converts the digital output to an analog signal for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** These combine the outputs from both modulators to produce the final output \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** These are used to shape the signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated in the diagram.\n\nFlow of Information or Control:\n- The input signal \\( u(n) \\) is processed by the first modulator, where it is combined with feedback and delayed. The resulting signal \\( X_1(z) \\) depends on the input and the first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then fed into the second modulator, which processes it through addition, delay, and amplification to produce \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The outputs from both modulators are combined digitally to produce the final output \\( y(n) \\).\n\nLabels, Annotations, and Key Indicators:\n- The diagram includes annotations of transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) that define the system's signal and noise transfer characteristics.\n- The gain values of the amplifiers and the presence of delay elements are clearly marked.\n\nOverall System Function:\nThe primary role of this MASH modulator is to convert an analog input signal into a digital output while shaping the noise to minimize the impact of quantization errors. By cascading two first-order modulators, the system achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the desired frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nand for the second stage\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is then formed by passing the two digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$ then the entire second term disappears, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nso that the only remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In the case of Fig. 18.21, this implies second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Point: Multi-stage noise shaping (MASH) oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. Since each stage is first- or second-order, stability is easier to ensure. However, MASH converters necessitate digital filtering with coefficients matched to the analog circuitry.\n\nThis approach can be generalized to include more than two modulators. Thus, the MASH method offers the advantage of achieving higher-order noise filtering through lower-order modulators, which are less prone to instability compared to a single high-order feedback interpolator structure. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches causing gain errors. Such errors lead to finite gain and pole frequencies in the analog integrators (see Section 18.7.5), making it challenging to precisely match $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ for the cancellation of quantization noise $\\mathrm{E}_{1}(\\mathrm{z})$ in (18.44). In the example above, this would result in first-order noise leakage from the first modulator, thereby reducing dynamic range performance.\n\nTo mitigate the mismatch issue, the first stage can be a higher-order modulator, so any noise leak-through has a lesser effect than if the first modulator were first-order. For instance, a third-order modulator could be realized with a second-order modulator in the first stage and a first-order modulator in the second stage.\n\nAnother strategy to address errors in MASH architectures is to digitally cancel these errors by appropriately adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and later digitally cancelled while using them to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$ and match them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. Additionally, it is crucial to minimize errors due to input-offset voltages caused by clock feedthrough or opamp input-offset voltages. Typically, additional circuit design techniques are employed in practical implementations to minimize these effects.\n\nFinally, note that the MASH approach results in the digital output signal, $y(n)$, being a four-level signal (instead of two-level) due to the combination of the original two-level signals. Such a four-level signal would require a linear four-level D/A converter in D/A applications. For A/D applications, it makes the FIR decimation filter slightly more complex."
},
{
    "text": "Another method for implementing modulators involves a cascade-type structure, where higher-order modulators are built using lower-order ones. This approach benefits from the stability of the lower-order modulators, ensuring overall system stability. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nFig. 18.21 illustrates the setup for a second-order modulator constructed from two first-order modulators. The primary method involves forwarding the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and merging the outputs of both to eliminate the first section's quantization noise entirely. The resulting output contains only the second section's quantization noise, which has been filtered twiceonce by the second modulator and once by the subsequent digital circuitry. Assuming linear quantizer models, a straightforward linear analysis of the first stage yields:\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, comprising two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nKey Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** Combine input signal \\( u(n) \\) and feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** Has a gain of +1, producing quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts digital output back to analog for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** Merge error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Provides another unit delay.\n- **Amplifier with Feedback:** Features a gain of +2, generating quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Converts digital output to analog for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** Blend outputs from both modulators to produce final output \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** Shape signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated in the diagram.\n\nInformation Flow:\n- The input signal \\( u(n) \\) is processed by the first modulator, combined with feedback, and delayed, resulting in signal \\( X_1(z) \\), influenced by input and first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then input to the second modulator, processed similarly, producing \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- Outputs from both modulators are combined digitally to yield the final output \\( y(n) \\).\n\nAnnotations:\n- Transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) are annotated, defining the system's signal and noise characteristics.\n- Gain values and delay elements are clearly marked.\n\nSystem Function:\nThe MASH modulator's main role is to convert an analog input into a digital output, shaping noise to minimize quantization errors. By cascading two first-order modulators, it achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the target frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nFor the second stage:\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is formed by passing the digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$, the entire second term vanishes, resulting in:\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nThus, the remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In Fig. 18.21, this implies second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Point: Multi-stage noise shaping (MASH) oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. Stability is easier to ensure since each stage is first- or second-order. However, MASH converters need digital filtering with coefficients matching those of the analog circuitry.\n\nThis approach can be generalized to cascade more than two modulators, enabling higher-order noise filtering with lower-order modulators. Lower-order modulators are less prone to instability compared to a single high-order feedback interpolator structure. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches causing gain errors. These errors result in finite gain and pole frequencies for analog integrators (see Section 18.7.5), making it challenging to precisely ensure $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ for quantization noise $\\mathrm{E}_{1}(\\mathrm{z})$ cancellation in (18.44). This can cause first-order noise leakage from the first modulator, reducing dynamic range performance.\n\nTo mitigate mismatches, the first stage can be a higher-order modulator, minimizing the impact of noise leak-through compared to a first-order modulator. For instance, a third-order modulator can be realized with a second-order modulator in the first stage and a first-order modulator in the second stage.\n\nAnother method to address errors in MASH architectures is digital error cancellation by adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and digitally cancelled to accurately identify $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$, matching them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. It is crucial to minimize errors from input-offset voltages due to clock feedthrough or opamp input-offset voltages. Practical implementations often employ additional circuit design techniques to reduce these effects.\n\nFinally, note that the MASH approach results in a four-level digital output signal, $y(n)$, due to the combination of the original two-level signals. Such a four-level signal requires a linear four-level D/A converter in D/A applications and makes the FIR decimation filter slightly more complex in A/D applications."
},
{
    "text": "An alternative method for implementing modulators involves employing a cascade-type architecture where a higher-order modulator is built from lower-order components. This method's key benefit is that the system's overall stability is maintained due to the inherent stability of the lower-order modulators. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nFig. 18.21 illustrates the setup for creating a second-order modulator using two first-order modulators. The core idea is to transmit the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and merge the outputs of both to eliminate the first section's quantization noise entirely. The resulting output solely contains the second section's quantization noise, which undergoes dual filteringonce by the second modulator and once by subsequent digital circuitry. Assuming linear quantizer models, a straightforward linear analysis for the initial stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, comprising two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nKey Components:\n1. **First-Order Modulator (Upper Section):**\n   - **Adder/Subtractor Blocks:** These combine the input signal \\( u(n) \\) with feedback signals.\n   - **Delay Element (\\( z^{-1} \\)):** This introduces a unit delay in the signal path.\n   - **Amplifier with Feedback:** Features a gain of +1, producing the quantization error \\( e_1 \\).\n   - **1-bit D/A Converter:** Converts digital output back to analog for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n   - **Adder/Subtractor Blocks:** Merge the error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n   - **Delay Element (\\( z^{-1} \\)):** Introduces another unit delay.\n   - **Amplifier with Feedback:** Has a gain of +2, generating the quantization error \\( e_2 \\).\n   - **1-bit D/A Converter:** Similar to the first stage, converts digital output to analog for feedback.\n\n3. **Output Stage:**\n   - **Adder/Subtractor Blocks:** Combine outputs from both modulators to produce the final output \\( y(n) \\).\n   - **Delay Elements and Transfer Functions:** Shape the signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as shown in the diagram.\n\nInformation Flow:\n- The input signal \\( u(n) \\) is processed by the first modulator, combined with feedback, and delayed, resulting in \\( X_1(z) \\), a function of the input and the first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then fed into the second modulator, processed similarly, producing \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The outputs from both modulators are combined digitally to form the final output \\( y(n) \\).\n\nAnnotations:\n- The diagram includes transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) defining the system's signal and noise characteristics.\n- Gain values and delay elements are clearly marked.\n\nSystem Function:\nThe MASH modulator's primary role is to convert an analog input to a digital output while shaping noise to minimize quantization errors. By cascading two first-order modulators, it achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the desired frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nFor the second stage, we have\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is formed by passing the digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$, the entire second term vanishes, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nThus, the remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In Fig. 18.21, this indicates second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Insight: Multi-stage noise shaping (MASH) oversampling converters utilize cascaded lower-order modulators to achieve high-order noise shaping. Stability is easily ensured since each stage is first- or second-order. However, MASH converters necessitate digital filtering with coefficients matching those of the analog circuitry.\n\nThis approach can be expanded to include more than two modulators. Thus, the MASH method offers the advantage of attaining higher-order noise filtering through lower-order modulators, which are less prone to instability compared to a single high-order feedback interpolator structure. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches causing gain errors. Such errors result in finite gain and pole frequencies in the analog integrators (see Section 18.7.5), complicating the precise matching of $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ required for $\\mathrm{E}_{1}(\\mathrm{z})$ noise cancellation in (18.44). In the example, this leads to first-order noise leakage from the first modulator, reducing dynamic range performance.\n\nTo mitigate mismatches, the first stage can be a higher-order modulator, minimizing the impact of any noise leak-through compared to a first-order modulator. For instance, a third-order modulator can be realized with a second-order modulator in the first stage and a first-order modulator in the second stage.\n\nAnother strategy to address errors in MASH architectures is digital error cancellation by adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and subsequently cancelled digitally, using them to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$ and match them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. Additionally, minimizing errors from input-offset voltages due to clock feedthrough or opamp input-offset voltages is crucial. Typically, additional circuit design techniques are employed to minimize these effects.\n\nFinally, note that the MASH approach results in the digital output signal, $y(n)$, being a four-level signal (instead of two-level) due to the combination of the original two-level signals. Such a four-level signal requires a linear four-level D/A converter in D/A applications. For A/D applications, it complicates the FIR decimation filter slightly."
},
{
    "text": "An alternative method for implementing modulators involves employing a cascade-type architecture, where a higher-order modulator is built from lower-order ones. This method's key benefit is the enhanced stability of the overall system, owed to the inherent stability of the lower-order modulators. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nFig. 18.21 illustrates the setup for creating a second-order modulator using two first-order modulators. The fundamental strategy involves transmitting the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to a second modulator and merging the outputs of both to completely eliminate the first section's quantization noise. The resultant output retains only the second section's quantization noise, which undergoes dual filteringonce by the second modulator and once by the subsequent digital circuitry. Assuming linear quantizer models, a straightforward linear analysis of the first stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a block diagram of a second-order MASH modulator, assembled from two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nKey Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** These combine the input \\( u(n) \\) with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** Features a gain of +1, producing the quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts digital output back to analog for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** Merge the error signal \\( e_1(n) \\) from the first modulator with feedback.\n- **Delay Element (\\( z^{-1} \\)):** Adds another unit delay.\n- **Amplifier with Feedback:** Has a gain of +2, generating the quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Similar to the first stage, converts digital to analog for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** Blend outputs from both modulators to form the final \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** Shape signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated.\n\nInformation Flow:\n- The input \\( u(n) \\) is processed by the first modulator, combined with feedback, and delayed, resulting in \\( X_1(z) \\), a function of \\( U(z) \\) and \\( E_1(z) \\).\n- The error \\( e_1(n) \\) is then fed into the second modulator, processed similarly to produce \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The combined outputs from both modulators form the final digital output \\( y(n) \\).\n\nAnnotations:\n- The diagram includes transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) defining system characteristics.\n- Gain values and delay elements are clearly marked.\n\nSystem Function:\nThe MASH modulator's primary role is to convert an analog input to a digital output while shaping noise to minimize quantization errors. By cascading two first-order modulators, it achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the target frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nFor the second stage:\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is formed by passing the digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$, the second term vanishes, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nThus, the remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In Fig. 18.21, this indicates second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Insight: MASH oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. The stability of the individual stages, typically first- or second-order, is easier to maintain. However, MASH converters necessitate digital filtering with coefficients matching those of the analog components.\n\nThis approach can be expanded to include more than two modulators, allowing higher-order noise filtering through lower-order modulators. These lower-order modulators are less prone to instability compared to a single high-order feedback interpolator. Nevertheless, MASH or cascade methods are sensitive to finite opamp gain, bandwidth, and mismatches causing gain errors. Such errors lead to finite gain and pole frequencies in analog integrators (see Section 18.7.5), complicating the precise matching of $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ required for $\\mathrm{E}_{1}(\\mathrm{z})$ noise cancellation in (18.44). This can result in first-order noise leakage from the first modulator, reducing dynamic range performance.\n\nTo mitigate mismatches, the first stage can be a higher-order modulator, minimizing the impact of any noise leak-through compared to a first-order modulator. For instance, a third-order modulator can be realized with a second-order modulator in the first stage and a first-order modulator in the second stage.\n\nAnother strategy to counter errors in MASH architectures is digital error cancellation by adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and digitally cancelled to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$, ensuring they match $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. It is crucial to minimize errors from input-offset voltages due to clock feedthrough or opamp input-offset voltages. Practical implementations often employ additional circuit design techniques to reduce these effects.\n\nLastly, note that the MASH approach results in a four-level digital output signal, $y(n)$, due to the combination of the original two-level signals. Such a four-level signal requires a linear four-level D/A converter in D/A applications. For A/D applications, it complicates the FIR decimation filter slightly."
},
{
    "text": "An alternative method for implementing modulators involves employing a cascade-type structure, where a higher-order modulator is built from lower-order ones. The main benefit of this method is that the stability of the lower-order modulators ensures the overall system's stability. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nThe setup for creating a second-order modulator using two first-order modulators is depicted in Fig. 18.21. The fundamental idea is to transmit the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and merge the outputs of both modulators in a manner that completely eliminates the first section's quantization noise. The resulting output contains only the second section's quantization noise, which has been filtered twiceonce by the second modulator and once by the post digital circuitry. Assuming linear models for the quantizers, a straightforward linear analysis for the first stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a system block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, constructed from two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nKey Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** These combine the input signal \\( u(n) \\) with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** This introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** Features a gain of +1 and produces the quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts the digital output back to an analog signal for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** These merge the error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Introduces another unit delay in this stage.\n- **Amplifier with Feedback:** Has a gain of +2 and generates the quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Similar to the first stage, it converts the digital output to an analog signal for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** These combine the outputs from both modulators to produce the final output \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** These shape the signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated in the diagram.\n\nInformation Flow:\n- The input signal \\( u(n) \\) is processed by the first modulator, where it is combined with feedback and delayed. The resulting signal \\( X_1(z) \\) depends on the input and the first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then fed into the second modulator, which processes it through addition, delay, and amplification to produce \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The outputs from both modulators are combined digitally to produce the final output \\( y(n) \\).\n\nLabels and Annotations:\n- The diagram includes transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) that define the system's signal and noise transfer characteristics.\n- Gain values and the presence of delay elements are clearly marked.\n\nSystem Function:\nThe primary role of this MASH modulator is to convert an analog input signal into a digital output while shaping the noise to minimize the impact of quantization errors. By cascading two first-order modulators, the system achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the desired frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nand for the second stage\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is then formed by passing the two digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$ then the entire second term vanishes, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nThus, the only remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In the case of Fig. 18.21, this implies second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Point: Multi-stage noise shaping (MASH) oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. Since each stage is either first- or second-order, stability is easier to maintain. However, MASH converters necessitate digital filtering with coefficients that match those of the analog circuitry.\n\nThis approach can be generalized to include more than two modulators. Therefore, the MASH method offers the advantage of achieving higher-order noise filtering through the use of lower-order modulators. These lower-order modulators are less prone to instability compared to a single high-order interpolator with a single feedback loop. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches, leading to gain errors. Such errors cause the analog integrators to have finite gain and pole frequencies (see Section 18.7.5), making it challenging to precisely ensure $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ as required for the cancellation of the quantization noise $\\mathrm{E}_{1}(\\mathrm{z})$ in (18.44). In the example provided, this would result in first-order noise leakage from the first modulator, thereby reducing dynamic range performance.\n\nTo mitigate the mismatch issue, the first stage can be a higher-order modulator, so any noise leak-through has a lesser effect than if the first modulator were first-order. For instance, a third-order modulator could be realized by using a second-order modulator for the first stage and a first-order modulator for the second stage.\n\nAnother strategy to address errors in MASH architectures is to digitally cancel these errors by appropriately adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and later digitally cancelled, using them to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$ and match them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. Additionally, it is crucial to minimize errors due to input-offset voltages, which may arise from clock feedthrough or opamp input-offset voltages. In practical implementations, additional circuit design techniques are often employed to minimize these effects.\n\nFinally, note that the MASH approach results in the digital output signal, $y(n)$, being a four-level signal (instead of two-level) due to the combination of the original two-level signals. Such a four-level signal would require a linear four-level D/A converter in D/A applications. For A/D applications, it makes the FIR decimation filter slightly more complex."
},
{
    "text": "Another method for implementing modulators involves using a cascade-type structure where a higher-order modulator is built from lower-order ones. This approach benefits from the stability of the lower-order modulators, ensuring the overall system remains stable. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nThe setup for creating a second-order modulator using two first-order modulators is depicted in Fig. 18.21. The fundamental method involves transferring the first section's quantization error, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and merging the outputs of both modulators to completely eliminate the first section's quantization noise. The resulting output contains only the second section's quantization noise, which has been filtered twiceonce by the second modulator and once by the subsequent digital circuitry. Assuming linear models for the quantizers, a straightforward linear analysis for the first stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a system block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, constructed from two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nMain Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** These combine the input signal \\( u(n) \\) with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** This introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** The amplifier, with a gain of +1, produces the quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts the digital output back to an analog signal for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** These merge the error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Another unit delay is introduced here.\n- **Amplifier with Feedback:** This amplifier has a gain of +2 and generates the quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Similar to the first stage, it converts the digital output to an analog signal for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** These combine the outputs from both modulators to produce the final output \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** These are used to shape the signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated in the diagram.\n\nFlow of Information or Control:\n- The input signal \\( u(n) \\) is processed by the first modulator, where it is combined with feedback and delayed. The resulting signal \\( X_1(z) \\) is a function of the input and the first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then fed into the second modulator, which processes it through addition, delay, and amplification to produce \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The outputs from both modulators are combined in the digital domain to produce the final output \\( y(n) \\).\n\nLabels, Annotations, and Key Indicators:\n- The diagram includes annotations of transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) that define the system's signal and noise transfer characteristics.\n- The gain values of the amplifiers and the presence of delay elements are clearly marked.\n\nOverall System Function:\nThe primary role of this MASH modulator is to convert an analog input signal into a digital output while shaping the noise to minimize the impact of quantization errors. By cascading two first-order modulators, the system achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the desired frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nand for the second stage\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is then formed by passing the two digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$ then the entire second term disappears, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nso that the only remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In the case of Fig. 18.21, this implies second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Point: Multi-stage noise shaping (MASH) oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. Since each stage is first- or second-order, stability is easier to ensure. However, MASH converters necessitate digital filtering with coefficients matched to the analog circuitry.\n\nThis approach can be generalized to include more than two modulators. Thus, the MASH method allows for higher-order noise filtering using lower-order modulators, which are less prone to instability than a single high-order feedback interpolator. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches causing gain errors. Such errors result in finite gain and pole frequencies for the analog integrators (see Section 18.7.5), making it challenging to precisely match $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ as required for canceling the quantization noise $\\mathrm{E}_{1}(\\mathrm{z})$ in (18.44). In the example above, this would cause first-order noise to leak through from the first modulator, reducing dynamic range performance.\n\nTo mitigate the mismatch issue, the first stage can be a higher-order modulator, so any leaked noise has a lesser effect than if the first modulator were first-order. For instance, a third-order modulator could be realized using a second-order modulator for the first stage and a first-order modulator for the second stage.\n\nAnother strategy to address errors in MASH architectures is to digitally cancel these errors by appropriately adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and later digitally canceled while using them to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$ and match them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. Additionally, it is crucial to minimize errors due to input-offset voltages arising from clock feedthrough or opamp input-offset voltages. Typically, additional circuit design techniques are employed in practical implementations to minimize these effects.\n\nFinally, note that using the MASH approach results in the digital output signal, $y(n)$, being a four-level signal (instead of two-level) due to the combination of the original two-level signals. Such a four-level signal would require a linear four-level D/A converter in D/A applications. For A/D applications, it makes the FIR decimation filter slightly more complex."
},
{
    "text": "Another method for implementing modulators involves using a cascade-type structure where a higher-order modulator is built from lower-order ones. The benefit of this method is that the overall system stability is maintained due to the inherent stability of the lower-order modulators. This configuration is known as MASH (Multi-stAge noise SHaping) [Matsuya, 1987].\n\nThe setup for creating a second-order modulator using two first-order modulators is depicted in Fig. 18.21. The fundamental concept is to pass the quantization error from the first section, $\\mathrm{e}_{1}(\\mathrm{n})$, to another modulator and combine the outputs of both modulators in a manner that completely eliminates the first section's quantization noise. The resulting output contains only the second section's quantization noise, which has been filtered twiceonce by the second modulator and once by the subsequent digital circuitry. Assuming linear models for the quantizers, a straightforward linear analysis for the first stage yields\n\n$$\n\\begin{align*}\n\\mathrm{X}_{1}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{U}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{1}(\\mathrm{z}) \\tag{18.42}\n\\end{align*}\n$$\n\nimage_name:Fig. 18.21\ndescription:Fig. 18.21 presents a system block diagram of a second-order MASH (Multi-stage Noise Shaping) modulator, which comprises two first-order modulators. This system processes an input signal, \\( u(n) \\), and generates a four-level digital output, \\( y(n) \\).\n\nMain Components:\n1. **First-Order Modulator (Upper Section):**\n- **Adder/Subtractor Blocks:** These combine the input signal \\( u(n) \\) with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** This introduces a unit delay in the signal path.\n- **Amplifier with Feedback:** The amplifier, with a gain of +1, produces the quantization error \\( e_1 \\).\n- **1-bit D/A Converter:** Converts the digital output back to an analog signal for feedback.\n\n2. **Second-Order Modulator (Lower Section):**\n- **Adder/Subtractor Blocks:** These merge the error signal \\( e_1(n) \\) from the first modulator with feedback signals.\n- **Delay Element (\\( z^{-1} \\)):** Introduces another unit delay in this stage.\n- **Amplifier with Feedback:** This amplifier has a gain of +2 and generates the quantization error \\( e_2 \\).\n- **1-bit D/A Converter:** Similar to the first stage, it converts the digital output to an analog signal for feedback.\n\n3. **Output Stage:**\n- **Adder/Subtractor Blocks:** These blend the outputs from both modulators to produce the final output \\( y(n) \\).\n- **Delay Elements and Transfer Functions:** These are utilized to shape the signal and noise transfer functions, \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\), as indicated in the diagram.\n\nFlow of Information or Control:\n- The input signal \\( u(n) \\) is processed by the first modulator, where it is combined with feedback and delayed. The resulting signal \\( X_1(z) \\) is a function of the input and the first quantization error \\( E_1(z) \\).\n- The error signal \\( e_1(n) \\) is then fed into the second modulator, which processes it through addition, delay, and amplification to produce \\( X_2(z) \\), a function of \\( E_1(z) \\) and \\( E_2(z) \\).\n- The outputs from both modulators are combined in the digital domain to produce the final output \\( y(n) \\).\n\nLabels, Annotations, and Key Indicators:\n- The diagram includes annotations of transfer functions \\( S_{TF1}, N_{TF1}, S_{TF2}, N_{TF2} \\) that define the system's signal and noise transfer characteristics.\n- The gain values of the amplifiers and the presence of delay elements are clearly marked.\n\nOverall System Function:\nThe primary role of this MASH modulator is to convert an analog input signal into a digital output while shaping the noise to minimize the impact of quantization errors. By cascading two first-order modulators, the system achieves higher-order noise shaping, enhancing the signal-to-noise ratio in the desired frequency band.\n\nFig. 18.21 A second-order MASH modulator using two first-order modulators. Note that the output, $y(n)$, is a four-level signal.\nand for the second stage\n\n$$\n\\begin{align*}\n\\mathrm{X}_{2}(\\mathrm{z}) & =\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{1}(\\mathrm{z})+\\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\\\\n& =\\mathrm{z}^{-1} \\mathrm{E}_{1}(\\mathrm{z})+\\left(1-\\mathrm{z}^{-1}\\right) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.43}\n\\end{align*}\n$$\n\nThe MASH output is then formed by passing the two digital outputs $x_{1}$ and $x_{2}$ through digital filters designed to match $S_{T F 2}$ and $N_{T F 1}$ respectively.\n\n$$\n\\begin{align*}\n\\mathrm{Y}(\\mathrm{Z})= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{X}_{1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{X}_{2}(\\mathrm{z}) \\\\\n= & \\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\left[\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 1}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})\\right] \\mathrm{E}_{1}(\\mathrm{z})  \\tag{18.44}\\\\\n& +\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z})\n\\end{align*}\n$$\n\nIf $\\hat{N}_{\\mathrm{TF}_{1} 1}(\\mathrm{Z})=\\mathrm{N}_{\\mathrm{TF}_{1}}(\\mathrm{Z})$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF}_{2}}(\\mathrm{Z})$ then the entire second term disappears, resulting in\n\n$$\n\\begin{equation*}\n\\mathrm{Y}(\\mathrm{z})=\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}(\\mathrm{Z}) \\mathrm{S}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{U}(\\mathrm{z})+\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}(\\mathrm{z}) \\mathrm{N}_{\\mathrm{TF} 2}(\\mathrm{z}) \\mathrm{E}_{2}(\\mathrm{z}) \\tag{18.45}\n\\end{equation*}\n$$\n\nThus, the only remaining quantization noise is $\\mathrm{E}_{2}$, shaped by both $\\mathrm{N}_{T F_{1}}$ and $\\mathrm{N}_{\\mathrm{TF} 2}$. In the case of Fig. 18.21, this implies second-order noise shaping using two first-order modulators.\n\n$$\n\\begin{equation*}\nY(z)=z^{-2} U(z)-\\left(1-z^{-1}\\right)^{2} E_{2}(z) \\tag{18.46}\n\\end{equation*}\n$$\n\nKey Point: Multi-stage noise shaping (MASH) oversampling converters use cascaded lower-order modulators to achieve high-order noise shaping. Since each stage is either first- or second-order, stability is easier to ensure. However, MASH converters necessitate digital filtering with coefficients that match those of the analog circuitry.\n\nThis approach can be generalized to include more than two modulators in the cascade. Therefore, the MASH method allows for higher-order noise filtering using lower-order modulators, which are less prone to instability compared to a single high-order feedback interpolator structure. Unfortunately, MASH or cascade approaches are sensitive to finite opamp gain, bandwidth, and mismatches, leading to gain errors. These errors cause the analog integrators to have finite gain and pole frequencies (see Section 18.7.5), making it challenging to precisely ensure $N_{T F_{1}}(\\mathrm{Z})=N_{T F_{1}}(\\mathrm{z})$ and $\\hat{S}_{T F_{2}}(\\mathrm{Z})=\\mathrm{S}_{\\mathrm{TF} 2}(\\mathrm{Z})$ as required for the cancellation of quantization noise $\\mathrm{E}_{1}(\\mathrm{z})$ in (18.44). In the given example, this would result in first-order noise leakage from the first modulator, thereby reducing dynamic range performance.\n\nTo mitigate the mismatch issue, the first stage can be a higher-order modulator, so any noise leak-through has a lesser effect than if the first modulator were first-order. For instance, a third-order modulator could be realized by using a second-order modulator for the first stage and a first-order modulator for the second stage.\n\nAnother strategy to address errors in MASH architectures is to digitally cancel these errors by appropriately adjusting the digital filters $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{\\mathrm{S}}_{\\mathrm{TF} 2}$ in Fig. 18.21. For example, test signals can be injected and later digitally cancelled while using them to accurately determine $\\mathrm{N}_{\\mathrm{TF} 1}$ and $\\mathrm{S}_{\\mathrm{TF} 2}$ and match them with $\\hat{\\mathrm{N}}_{\\mathrm{TF} 1}$ and $\\hat{S}_{\\mathrm{TF} 2}$ [Kiss, 2000]. Additionally, it is crucial to minimize errors due to input-offset voltages that may arise from clock feedthrough or opamp input-offset voltages. Typically, practical implementations employ additional circuit design techniques to minimize these effects.\n\nFinally, note that the MASH approach results in the digital output signal, $y(n)$, being a four-level signal (instead of two-level) due to the combination of the original two-level signals. Such a four-level signal would require a linear four-level D/A converter in D/A applications. For A/D applications, it complicates the FIR decimation filter slightly."
}
]