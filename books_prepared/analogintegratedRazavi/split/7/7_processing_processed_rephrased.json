[

{
    "text": "Noise constrains the minimum signal level a circuit can handle while maintaining acceptable quality. Contemporary analog designers frequently grapple with noise issues, as it intersects with power dissipation, speed, and linearity.\n\nThis chapter elucidates the nature of noise and its impact on analog circuits. The goal is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although seemingly intricate, noise is introduced early to guide the reader throughout the book, becoming more intuitive through diverse examples.\n\nAfter a broad overview of noise characteristics in both frequency and time domains, we delve into thermal and flicker noise. Subsequently, we explore techniques for modeling noise in circuits. Lastly, we examine the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the minimum signal level a circuit can handle with adequate quality. Contemporary analog designers frequently grapple with noise issues as it interacts with power consumption, speed, and linearity.\n\nIn this chapter, we explore the nature of noise and its impact on analog circuits. Our goal is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although noise appears intricate, it is introduced early in the book to familiarize readers with it throughout, making it more intuitive via diverse examples.\n\nAfter providing an overview of noise characteristics in both frequency and time domains, we delve into thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the lowest signal level a circuit can handle with satisfactory quality. Contemporary analog designers frequently grapple with noise issues, as it interacts with power consumption, speed, and linearity.\n\nThis chapter explores the nature of noise and its impact on analog circuits. The goal is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, and so on. Although noise appears intricate, it is introduced early in the book to familiarize readers with it throughout, making it more intuitive via numerous examples.\n\nAfter a broad overview of noise characteristics in both frequency and time domains, we delve into thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the lowest signal level a circuit can handle with satisfactory quality. Contemporary analog designers frequently grapple with noise issues as it intertwines with power dissipation, speed, and linearity.\n\nIn this chapter, we delve into the nature of noise and its impact on analog circuits. The aim is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although seemingly intricate, noise is introduced early to remain a consistent topic throughout the book, becoming more comprehensible via numerous examples.\n\nAfter outlining noise characteristics in both frequency and time domains, we discuss thermal and flicker noise. Subsequently, we explore techniques for modeling noise in circuits. Lastly, we examine the influence of noise on single-stage and differential amplifiers, including the trade-offs with other performance metrics."
},
{
    "text": "Noise restricts the lowest signal level a circuit can handle with adequate quality. Contemporary analog designers frequently confront the issue of noise, as it intersects with power consumption, speed, and linearity.\n\nIn this chapter, we explore the nature of noise and its impact on analog circuits. Our goal is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although seemingly intricate, noise is introduced early to guide the reader throughout the book, becoming more intuitive through diverse examples.\n\nAfter providing an overview of noise characteristics in both frequency and time domains, we delve into thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the lowest signal level a circuit can handle while maintaining acceptable quality. Contemporary analog designers frequently grapple with noise issues as it intersects with power consumption, speed, and linearity.\n\nIn this section, we delve into the nature of noise and its impact on analog circuits. Our aim is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, and so on. Although noise appears intricate, it is introduced early in the text to familiarize readers with it throughout the book, making it more intuitive through diverse examples.\n\nAfter providing an overview of noise characteristics in both frequency and time domains, we explore thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the lowest signal level a circuit can handle with satisfactory quality. Contemporary analog designers frequently grapple with noise issues, as it interacts with power consumption, speed, and linearity.\n\nThis chapter delves into the nature of noise and its impact on analog circuits. The goal is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although noise appears intricate, it is introduced early to remain a constant companion throughout the book, becoming more intuitive via numerous examples.\n\nAfter outlining noise characteristics in both frequency and time domains, we explore thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, including its trade-offs with other performance metrics."
},
{
    "text": "Noise constrains the lowest signal level a circuit can handle while maintaining acceptable quality. Contemporary analog designers frequently grapple with noise issues as it interacts with power dissipation, speed, and linearity.\n\nThis chapter delves into the nature of noise and its impact on analog circuits. The aim is to furnish a comprehensive grasp of the issue, ensuring that subsequent chapters on analog circuit development inherently consider noise alongside other parameters like gain, input and output impedances, etc. Although noise appears intricate, it is introduced early in the text to accompany readers throughout the book, becoming more intuitive via numerous examples.\n\nAfter providing an overview of noise characteristics in both frequency and time domains, we explore thermal and flicker noise. Subsequently, we examine techniques for modeling noise in circuits. Lastly, we discuss the influence of noise on single-stage and differential amplifiers, as well as the trade-offs with other performance metrics."
},
{
    "text": "Noise is a random process, meaning its value at any given time cannot be predicted, even with knowledge of past values. Consider comparing the output of a sine-wave generator to that of a microphone capturing the sound of a river (Fig. 7.1). While the value of \\( x_1(t) \\) at \\( t = t_1 \\) can be predicted from its waveform, the value of \\( x_2(t) \\) at \\( t = t_2 \\) cannot. This highlights the key difference between deterministic and random phenomena.\n\nIf the instantaneous value of noise in the time domain is unpredictable, how can it be integrated into circuit analysis? This is achieved by observing the noise over an extended period and using the data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be predicted, a statistical model provides insights into other significant properties of the noise, which are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be predicted? Often, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal generally exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if a random process can be so unpredictable that even its average power is indeterminate. Such processes do exist, but fortunately, most noise sources in circuits display a consistent average power.\n\n**Signal Generator Diagram Description:**\nThe \"Signal Generator\" diagram comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river, each associated with a waveform diagram labeled (a) and (b), respectively.\n\n1. **Main Components:**\n   - **Signal Generator Block:** This is depicted as a rectangular block with two output terminals, representing a device that generates a periodic signal, shown as \\( x_1(t) \\) in the waveform diagram.\n   - **River Illustration:** This visual represents a natural environment, likely a source of random noise, connected to a block resembling a microphone or sensor capturing the river's sound, with the output waveform \\( x_2(t) \\).\n\n2. **Flow of Information or Control:**\n   - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude, shown as a smooth sinusoidal signal over time, indicating a controlled and predictable output.\n   - **River Sound Capture:** The river's sound is captured by the microphone or sensor, producing waveform \\( x_2(t) \\), which is irregular and represents a random signal, illustrating the natural variability and randomness of environmental noise.\n\n3. **Labels, Annotations, and Key Indicators:**\n   - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n   - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n\n4. **Overall System Function:**\n   - The diagram compares the characteristics of a controlled periodic signal from a signal generator with the random, unpredictable nature of a signal from a natural source like a river. The signal generator provides a stable output, while the river sound demonstrates variability and randomness in amplitude and frequency, illustrating concepts of average power and randomness in signal processing.\n\n**Graph (a) Description:**\nThe graph labeled \"(a)\" shows a time-domain waveform generated by a signal generator. It is a sinusoidal waveform, indicating periodic and smooth oscillation over time. The horizontal axis is time \"t,\" and the vertical axis is the signal amplitude \"x1(t).\"\n\n1. **Type of Graph and Function:**\n   - A time-domain sinusoidal waveform.\n   - Illustrates the output of a signal generator.\n\n2. **Axes Labels and Units:**\n   - x-axis: time \"t.\"\n   - y-axis: amplitude \"x1(t).\"\n   - Linear scale.\n\n3. **Overall Behavior and Trends:**\n   - Sinusoidal, showing regular, periodic oscillations.\n   - Consistent amplitude and frequency, indicating a stable signal output.\n\n4. **Key Features and Technical Details:**\n   - Displays a clear periodic pattern with peaks and troughs.\n   - A specific time point, \"t1,\" is marked, indicating a reference or significant time point.\n   - No visible distortion or irregularities, suggesting a clean output from the signal generator.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at \"t1,\" indicating a point of interest or measurement reference.\n\n**Graph (b) Description:**\nThe graph labeled \"(b)\" is a time-domain waveform representing the sound of a river. The horizontal axis is \"t\" for time, and the vertical axis is \"x2(t)\" for the amplitude of the signal.\n\n1. **Type of Graph and Function:**\n   - Time-domain waveform showing the amplitude of a signal over time.\n\n2. **Axes Labels and Units:**\n   - Horizontal Axis (t): Time.\n   - Vertical Axis (x2(t)): Amplitude of the sound signal.\n   - No specific units or scales provided.\n\n3. **Overall Behavior and Trends:**\n   - Random, noisy behavior typical of natural sounds like a river.\n   - No clear periodic patterns or regular oscillations.\n   - Amplitude fluctuates randomly with varying peaks and troughs.\n\n4. **Key Features and Technical Details:**\n   - Irregular waveform with no discernible repeating patterns.\n   - Multiple peaks and valleys, indicating varying intensity of the river sound.\n   - Signal does not return to a baseline consistently, suggesting continuous noise.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at \"t2,\" indicating a specific moment in time, though no specific data value is provided.\n\n**Figure 7.1 (a) and (b):** The output of a generator and the sound of a river.\n\n**Figure 7.2 (a) Description:**\nThe image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n   - **Components and Structure:**\n     - Left side: Simple illustration of a tree and a winding path, metaphorically representing a natural environment.\n     - Next to it: Icon of a generator (circle with a vertical line) connected to two terminals, symbolizing a generic signal generator.\n   - **Connections and Interactions:**\n     - Generator connected to a graph on the right, representing the output signal over time.\n     - Graph labeled \\( x_A(t) \\), showing a waveform fluctuating slightly around a baseline, indicating a relatively stable output with minor variations.\n   - **Annotations and Key Features:**\n     - Waveform plotted against time axis \\( t \\), with an unspecified vertical axis.\n     - Signal appears consistent, suggesting a controlled output from the generator.\n\n2. **Figure 7.1(b): Sound of a River**\n   - **Components and Structure:**\n     - Similar to part (a), includes a tree and a winding path, suggesting a natural setting.\n     - Same generator icon present.\n   - **Connections and Interactions:**\n     - Generator connected to another graph on the right, representing a different output signal.\n     - Graph labeled \\( x_B(t) \\), showing a more erratic waveform, suggesting a more complex or noisy signal compared to \\( x_A(t) \\).\n   - **Annotations and Key Features:**\n     - Waveform plotted with respect to time \\( t \\), with no specific values on the vertical axis.\n     - Irregularity of the waveform represents the variability in the sound of a river.\n\n**Figure 7.2 (b) Description:**\nThe graph labeled (b) represents the sound of a river over time. It is a time-domain waveform graph with the x-axis for time (t) and the y-axis for the amplitude of the sound signal (x_B(t)).\n\n1. **Type of Graph and Function:**\n   - Time-domain waveform graph showing the amplitude of a sound signal over time.\n\n2. **Axes Labels and Units:**\n   - x-axis: Time (t), no specific units provided.\n   - y-axis: Amplitude of the sound signal (x_B(t)).\n\n3. **Overall Behavior and Trends:**\n   - Continuous and irregular pattern, indicating a random and complex signal typical of natural sounds like a river.\n   - Amplitude fluctuates with no clear periodicity, suggesting continuous noise.\n\n4. **Key Features and Technical Details:**\n   - No specific peaks or valleys highlighted, but amplitude varies over time, depicting the dynamic nature of the river sound.\n\n5. **Annotations and Specific Data Points:**\n   - No annotations or specific data points marked.\n\n**Figure 7.2:** Illustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and must be defined carefully. From basic circuit theory, the average power delivered by a periodic voltage \\( v(t) \\) to a load resistance \\( R_L \\) is given by:\n\n$$\n\\begin{equation*}\nP_{av} = \\frac{1}{T} \\int_{-T/2}^{+T/2} \\frac{v^2(t)}{R_L} dt \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere \\( T \\) denotes the period. Measured in watts, this quantity represents the average heat produced in \\( R_L \\) by \\( v(t) \\).\n\nHow do we define \\( P_{av} \\) for a random signal? In Fig. 7.2, \\( x_B(t) \\) is expected to generate more heat than \\( x_A(t) \\) if driving a resistive load. However, since the signals are not periodic, the measurement must be over a long time:\n\n$$\n\\begin{equation*}\nP_{av} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} \\frac{x^2(t)}{R_L} dt \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere \\( x(t) \\) is a voltage quantity. Figure 7.3 illustrates this process: the signal is squared, the area under the resulting waveform is calculated for a long time \\( T \\), and the average power is obtained by normalizing the area to \\( T \\).\n\n**Figure 7.3 Average Noise Power Description:**\nThe graph in Figure 7.3 illustrates the process of calculating average noise power from a non-periodic signal. It consists of two main sections:\n\n1. **Original Signal:**\n   - **Type of Graph:** Time-domain waveform.\n   - **Axes Labels and Units:** Horizontal axis represents time \\( t \\), vertical axis represents the amplitude of the voltage signal \\( x(t) \\).\n   - **Overall Behavior and Trends:** Complex, non-periodic oscillation around the horizontal axis, indicating a fluctuating voltage signal with varying amplitudes and frequencies.\n   - **Key Features and Technical Details:** Multiple zero crossings, peaks, and valleys, but no specific numerical values or annotations.\n   - **Annotations and Specific Data Points:** Time interval \\( T \\) marked with dashed vertical lines.\n\n2. **Squared Signal:**\n   - **Type of Graph:** Time-domain waveform of the squared signal.\n   - **Axes Labels and Units:** Horizontal axis represents time \\( t \\), vertical axis represents the squared amplitude \\( x^2(t) \\).\n   - **Overall Behavior and Trends:** Entirely above the horizontal axis, showing more pronounced peaks due to squaring.\n   - **Key Features and Technical Details:** Maintains the same zero crossings as the original signal, but all values are positive.\n   - **Annotations and Specific Data Points:** Time interval \\( T \\) marked with dashed vertical lines, indicating the duration for averaging the power.\n\n**Figure 7.3:** Average noise power.\n\nTo simplify calculations, \\( P_{av} \\) is defined as:\n\n$$\n\\begin{equation*}\nP_{av} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} x^2(t) dt \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere \\( P_{av} \\) is expressed in \\( \\mathrm{V}^2 \\) rather than W. If \\( P_{av} \\) from (7.3) is known, the actual power delivered to a load \\( R_L \\) can be calculated as \\( P_{av} / R_L \\). Analogous to deterministic signals, the root-mean-square (rms) voltage for noise can be defined as \\( \\sqrt{P_{av}} \\), where \\( P_{av} \\) is given by (7.3)."
},
{
    "text": "Noise represents a random process. In the context of this book, this implies that the value of noise at any given time cannot be predicted, even with knowledge of its past values. Consider comparing the output of a sine-wave generator to that of a microphone capturing the sound of a river (Fig. 7.1). While the value of $x_{1}(t)$ at $t=t_{1}$ can be anticipated based on the observed waveform, the value of $x_{2}(t)$ at $t=t_{2}$ remains unpredictable. This distinction is fundamental between deterministic and random phenomena.\n\nIf the instantaneous value of noise in the time domain is unpredictable, how can we integrate noise into circuit analysis? This is achieved by observing the noise over an extended period and using the collected data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be predicted, a statistical model provides insights into other crucial properties of the noise that are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be anticipated? In many instances, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal, on average, exhibits larger variations and thus higher power (Fig. 7.2). One might wonder if a random process can be so unpredictable that even its average power is indeterminate. Such processes do exist, but fortunately, most noise sources in circuits display a consistent average power.\n\n**Image Description: Signal Generator**\nThe diagram titled \"Signal Generator\" comprises two primary sections: a block labeled \"Signal Generator\" and an illustration of a river. Each section is associated with a waveform diagram, labeled (a) and (b), respectively.\n\n1. **Main Components:**\n   - **Signal Generator Block:** This is depicted as a rectangular block with two output terminals, representing a device that generates a periodic signal, shown as \\( x_1(t) \\) in the accompanying waveform diagram.\n   - **River Illustration:** This visual depicts a natural setting, likely indicating a source of random noise. It is connected to a block resembling a microphone or sensor, capturing the river's sound. The output is represented by the waveform \\( x_2(t) \\).\n\n2. **Information and Control Flow:**\n   - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude. The diagram shows this as a smooth, sinusoidal signal over time, indicating a controlled and predictable output.\n   - **River Sound Capture:** The river's sound is captured by the microphone or sensor, producing the waveform \\( x_2(t) \\). This waveform is irregular, representing a random signal and illustrating the natural variability and randomness of environmental noise.\n\n3. **Labels and Annotations:**\n   - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n   - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n\n4. **System Function:**\n   - The diagram compares the characteristics of a controlled periodic signal from a signal generator with the random, unpredictable nature of a signal from a natural source like a river. The signal generator provides stable and predictable output, while the river sound demonstrates variability and randomness in amplitude and frequency, illustrating concepts of average power and randomness in signal processing.\n\n**Image Description: (a)**\nThe graph labeled \"(a)\" depicts a time-domain waveform generated by a signal generator. This sinusoidal waveform indicates periodic and smooth oscillation over time. The horizontal axis is labeled \"t\" for time, and the vertical axis is labeled \"x1(t)\" for signal amplitude.\n\n1. **Graph Type and Function:**\n   - A time-domain sinusoidal waveform.\n   - Illustrates the output of a signal generator.\n\n2. **Axes Labels and Units:**\n   - X-axis: time \"t.\"\n   - Y-axis: signal amplitude \"x1(t).\"\n   - Linear scale.\n\n3. **Behavior and Trends:**\n   - Sinusoidal waveform with regular, periodic oscillations.\n   - Consistent amplitude and frequency, indicating stable signal output.\n\n4. **Key Features:**\n   - Clear periodic pattern with peaks and troughs.\n   - A specific time point, \"t1,\" marked as a reference.\n   - No visible distortion, suggesting clean output from the signal generator.\n\n5. **Annotations:**\n   - Vertical dashed line at \"t1,\" indicating a point of interest.\n   - No numerical values, but periodic nature is evident.\n\n**Image Description: (b)**\nThe graph labeled \"(b)\" is a time-domain waveform representing the sound of a river. The horizontal axis is labeled 't' for time, without specific units. The vertical axis is labeled 'x2(t)' for the amplitude of the signal, also without specific units.\n\n1. **Graph Type and Function:**\n   - Time-domain waveform showing signal amplitude over time.\n\n2. **Axes Labels and Units:**\n   - Horizontal Axis (t): Time.\n   - Vertical Axis (x2(t)): Amplitude of the sound signal.\n   - No specific units or scales.\n\n3. **Behavior and Trends:**\n   - Random, noisy behavior typical of natural sounds like a river.\n   - No clear periodic patterns or regular oscillations.\n   - Random amplitude fluctuations with varying peaks and troughs.\n\n4. **Key Features:**\n   - Irregular waveform with no repeating patterns.\n   - Multiple peaks and valleys, indicating varying intensity of the river sound.\n   - Continuous noise without consistent baseline return.\n\n5. **Annotations:**\n   - Vertical dashed line at 't2,' highlighting a specific moment.\n   - No specific data value provided.\n\n**Figure 7.1 (a) Output of a generator, and (b) sound of a river.**\n\n**Image Description: Figure 7.2 (a)**\nThis image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n   - **Components:**\n     - Left: Illustration of a tree and winding path, symbolizing a natural environment.\n     - Right: Icon of a generator (circle with a vertical line) connected to two terminals.\n   - **Connections:**\n     - Generator connected to a graph representing the output signal over time.\n     - Graph labeled \\( x_A(t) \\), showing a waveform fluctuating slightly around a baseline, indicating a stable output with minor variations.\n   - **Annotations:**\n     - Waveform plotted against time axis \\( t \\), with an unspecified vertical axis.\n     - Consistent signal, suggesting controlled output from the generator.\n\n2. **Figure 7.1(b): Sound of a River**\n   - **Components:**\n     - Similar to part (a), includes a tree and winding path, representing the sound of flowing water.\n     - Same generator icon.\n   - **Connections:**\n     - Generator connected to a graph representing a different output signal.\n     - Graph labeled \\( x_B(t) \\), showing a more erratic waveform, suggesting a complex or noisy signal compared to \\( x_A(t) \\).\n   - **Annotations:**\n     - Waveform plotted with respect to time \\( t \\), with no specific values on the vertical axis.\n     - Irregular waveform represents the variability in the sound of a river.\n\nThe image contrasts two different signal outputs, one stable and one erratic, to illustrate different signal behaviors or metaphorically represent natural phenomena through signal processing.\n\n**Image Description: Figure 7.2 (b)**\nThe graph labeled (b) represents the sound of a river over time. This time-domain waveform graph has the x-axis representing time (t) and the y-axis representing the amplitude of the sound signal, denoted as x_B(t).\n\n1. **Graph Type and Function:**\n   - Time-domain waveform graph showing the amplitude of a sound signal over time.\n\n2. **Axes Labels and Units:**\n   - X-axis: 't', representing time, with no specific units.\n   - Y-axis: 'x_B(t)', representing the amplitude of the sound signal.\n\n3. **Behavior and Trends:**\n   - Continuous and irregular pattern, indicating a random and complex signal typical of natural sounds like a river.\n   - Fluctuating amplitude with no clear periodicity, suggesting continuous noise.\n\n4. **Key Features:**\n   - No specific peaks or valleys highlighted, but amplitude varies over time, depicting the dynamic nature of the river sound.\n   - No annotations or markers indicating particular data points.\n\n5. **Annotations:**\n   - No annotations or specific data points marked.\n\nThis graph effectively represents the complex and random nature of a river's sound, characterized by continuous amplitude variations without a consistent baseline.\n\n**Figure 7.2 Illustration of the average power of a random signal.**\n\nThe concept of average power is crucial in our analysis and requires careful definition. Recall from basic circuit theory that the average power delivered by a periodic voltage $v(t)$ to a load resistance $R_{L}$ is given by\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere $T$ denotes the period. This quantity, measured in watts, represents the average heat produced in $R_{L}$ by $v(t)$.\n\nHow do we define $P_{a v}$ for a random signal? In Fig. 7.2, we expect $x_{B}(t)$ to generate more heat than $x_{A}(t)$ if the microphone drives a resistive load. However, since the signals are not periodic, the measurement must be conducted over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere $x(t)$ is a voltage quantity. Figure 7.3 illustrates this process: the signal is squared, the area under the resulting waveform is calculated for a long time $T$, and the average power is obtained by normalizing the area to $T$.\n\n**Image Description: Figure 7.3 Average Noise Power**\nThe graph in Figure 7.3 illustrates the process of calculating average noise power from a non-periodic signal. It consists of two main sections:\n\n1. **Original Signal:**\n   - **Graph Type:** Time-domain waveform.\n   - **Axes Labels:** Horizontal axis represents time \\( t \\), with no specific units. Vertical axis represents the amplitude of the voltage signal \\( x(t) \\).\n   - **Behavior:** Complex, non-periodic oscillation around the horizontal axis, indicating a fluctuating voltage signal with varying amplitudes and frequencies.\n   - **Key Features:** Multiple zero crossings, peaks, and valleys, but no specific numerical values or annotations.\n   - **Annotations:** Time interval \\( T \\) marked with dashed vertical lines.\n\n2. **Squared Signal:**\n   - **Graph Type:** Time-domain waveform of the squared signal.\n   - **Axes Labels:** Horizontal axis represents time \\( t \\), vertical axis represents the squared amplitude \\( x^2(t) \\).\n   - **Behavior:** Entirely above the horizontal axis, as squaring eliminates negative values. General shape mirrors the original waveform but with all values non-negative.\n   - **Key Features:** Maintains the same zero crossings as the original, but all values are positive. Gray shaded area under the curve represents the integral of the squared signal over time \\( T \\).\n   - **Annotations:** Time interval \\( T \\) marked with dashed vertical lines.\n\n**Figure 7.3 Average Noise Power.**\n\nTo simplify calculations, we express $P_{a v}$ as\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere $P_{a v}$ is in $\\mathrm{V}^{2}$ rather than W. If $P_{a v}$ from (7.3) is known, the actual power delivered to a load $R_{L}$ can be calculated as $P_{a v} / R_{L}$. Analogous to deterministic signals, we can define a root-mean-square (rms) voltage for noise as $\\sqrt{P_{a v}}$, where $P_{a v}$ is given by (7.3)."
},
{
    "text": "Noise is a random phenomenon. In the context of this book, this implies that the value of noise at any given time cannot be predicted, even with knowledge of its past values. Consider the comparison between the output of a sine-wave generator and the sound of a river captured by a microphone (Fig. 7.1). While the value of $x_{1}(t)$ at $t=t_{1}$ can be anticipated from the observed waveform, the value of $x_{2}(t)$ at $t=t_{2}$ remains unpredictable. This distinction highlights the fundamental difference between deterministic and random phenomena.\n\nGiven that the instantaneous value of noise in the time domain is unpredictable, how can we integrate noise into circuit analysis? This is achieved by observing the noise over an extended period and using the collected data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be foreseen, a statistical model provides insights into other significant properties of the noise that are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be anticipated? Often, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal generally exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if there are random processes so unpredictable that even their average power is uncertain. Such processes do exist, but幸运的是, most noise sources in circuits display a constant average power.\n\n**Signal Generator Diagram Description:**\nThe \"Signal Generator\" diagram comprises two main sections: a block labeled \"Signal Generator\" and an illustration of a river, each associated with a waveform diagram labeled (a) and (b), respectively.\n\n1. **Main Components:**\n   - **Signal Generator Block:** This is depicted as a rectangular block with two output terminals, representing a device that generates a periodic signal, shown as \\( x_1(t) \\) in the accompanying waveform diagram.\n   - **River Illustration:** This visualizes a natural environment, likely indicating a source of random noise, connected to a block resembling a microphone or sensor that captures the river's sound, with the output represented by the waveform \\( x_2(t) \\).\n\n2. **Flow of Information or Control:**\n   - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude, depicted as a smooth sinusoidal signal over time, indicating a controlled and predictable output.\n   - **River Sound Capture:** The river's sound is captured by the microphone or sensor, with the corresponding waveform \\( x_2(t) \\) shown as an irregular, random signal, illustrating the natural variability and randomness of environmental noise.\n\n3. **Labels, Annotations, and Key Indicators:**\n   - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n   - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n\n4. **Overall System Function:**\n   - The diagram compares the characteristics of a controlled periodic signal from a signal generator with the random, unpredictable nature of a signal from a natural source like a river. The signal generator provides a stable and predictable output, while the river sound demonstrates variability and randomness in terms of amplitude and frequency, illustrating concepts of average power and randomness in signal processing.\n\n**Graph (a) Description:**\nThe graph labeled \"(a)\" depicts a time-domain waveform generated by a signal generator. It is a sinusoidal waveform, indicating smooth and periodic oscillations over time. The horizontal axis is labeled \"t\" for time, and the vertical axis is labeled \"x1(t)\" for signal amplitude.\n\n1. **Type of Graph and Function:**\n   - A time-domain sinusoidal waveform.\n   - Illustrates the output of a signal generator.\n\n2. **Axes Labels and Units:**\n   - X-axis: Time \"t.\"\n   - Y-axis: Signal amplitude \"x1(t).\"\n   - The scale appears linear.\n\n3. **Overall Behavior and Trends:**\n   - Sinusoidal waveform with regular, periodic oscillations.\n   - Consistent amplitude and frequency, indicating a stable signal output.\n\n4. **Key Features and Technical Details:**\n   - Displays a clear periodic pattern with peaks and troughs.\n   - A specific time point, \"t1,\" is marked, possibly indicating a reference or significant time point.\n   - No visible distortion or irregularities, suggesting a clean output from the signal generator.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at \"t1\" indicates a point of interest or measurement reference.\n   - No numerical values provided, but the waveform's periodic nature is evident.\n\n**Graph (b) Description:**\nThe graph labeled \"(b)\" represents a time-domain waveform of the sound of a river. The horizontal axis is labeled 't' for time, without specific units, and the vertical axis is labeled 'x2(t)' for the amplitude of the signal, also without specific units.\n\n1. **Type of Graph and Function:**\n   - A time-domain waveform showing the amplitude of a signal over time.\n\n2. **Axes Labels and Units:**\n   - Horizontal Axis (t): Time.\n   - Vertical Axis (x2(t)): Amplitude of the sound signal.\n   - No specific units or scales provided.\n\n3. **Overall Behavior and Trends:**\n   - Exhibits random, noisy behavior typical of natural sounds like a river.\n   - No clear periodic patterns or regular oscillations.\n   - Amplitude fluctuates randomly with varying peaks and troughs.\n\n4. **Key Features and Technical Details:**\n   - Irregular waveform with no discernible repeating patterns.\n   - Multiple peaks and valleys indicate varying intensity of the river sound.\n   - Signal does not return to a baseline consistently, suggesting continuous noise.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at 't2' indicates a specific moment in time, with no specific data value provided.\n   - Highlights a particular feature or event within the waveform, but the context is not clear from the graph alone.\n\nFigure 7.1 (a) Output of a generator, and (b) sound of a river.\n\n**Figure 7.2 (a) Description:**\nThe image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n   - **Components and Structure:**\n     - A simple illustration of a tree and a winding path on the left, symbolizing a natural environment.\n     - An icon of a generator next to it, depicted as a circle with a vertical line through it, connected to two terminals.\n   - **Connections and Interactions:**\n     - The generator is connected to a graph on the right, representing the output signal over time.\n     - The graph is labeled \\( x_A(t) \\), showing a waveform that fluctuates slightly around a baseline, indicating a relatively stable output with minor variations.\n   - **Annotations and Key Features:**\n     - The waveform is plotted against a horizontal time axis \\( t \\), with an unspecified vertical axis.\n     - The signal appears consistent, suggesting a controlled output from the generator.\n\n2. **Figure 7.1(b): Sound of a River**\n   - **Components and Structure:**\n     - Similar to part (a), includes a tree and a winding path, suggesting a natural setting representing the sound of flowing water.\n     - The same generator icon is present.\n   - **Connections and Interactions:**\n     - The generator is connected to another graph on the right, representing a different output signal.\n     - This graph is labeled \\( x_B(t) \\) and shows a more erratic waveform, suggesting a more complex or noisy signal compared to \\( x_A(t) \\).\n   - **Annotations and Key Features:**\n     - The waveform is plotted with respect to time \\( t \\), with no specific values on the vertical axis.\n     - The irregularity of the waveform represents the variability in the sound of a river, highlighting the natural randomness of such a sound source.\n\nOverall, the image contrasts two different signal outputs, one stable and one more erratic, to illustrate different types of signal behavior or metaphorically represent natural phenomena through signal processing.\n\n**Figure 7.2 (b) Description:**\nThe graph labeled (b) represents the sound of a river over time. This is a time-domain waveform graph where the x-axis represents time (t) and the y-axis represents the amplitude of the sound signal, denoted as x_B(t).\n\n1. **Type of Graph and Function:**\n   - A time-domain waveform graph showing the amplitude of a sound signal over time.\n\n2. **Axes Labels and Units:**\n   - X-axis: Time 't', with no specific units provided.\n   - Y-axis: Amplitude of the sound signal 'x_B(t)'.\n\n3. **Overall Behavior and Trends:**\n   - Shows a continuous and irregular pattern, indicating a random and complex signal typical of natural sounds like a river.\n   - Amplitude exhibits fluctuations with no clear periodicity or repetitive pattern, suggesting continuous noise.\n\n4. **Key Features and Technical Details:**\n   - The graph does not display specific peaks or valleys but shows varying amplitude over time, depicting the dynamic nature of the river sound.\n   - No specific annotations or markers indicating particular data points or events.\n\n5. **Annotations and Specific Data Points:**\n   - No annotations or specific data points marked on the graph. The context suggests a natural, random signal without distinct events or features highlighted.\n\nThis graph effectively represents the complex and random nature of a river's sound, characterized by continuous variations in amplitude without returning to a consistent baseline.\n\nFigure 7.2 Illustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and must be defined carefully. Recall from basic circuit theory that the average power delivered by a periodic voltage $v(t)$ to a load resistance $R_{L}$ is given by\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere $T$ denotes the period. Measured in watts, this quantity can be visualized as the average heat produced in $R_{L}$ by $v(t)$.\n\nHow do we define $P_{a v}$ for a random signal? In the example of Fig. 7.2, we expect that $x_{B}(t)$ generates more heat than $x_{A}(t)$ if the microphone drives a resistive load. However, since the signals are not periodic, the measurement must be carried out over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere $x(t)$ is a voltage quantity. Figure 7.3 illustrates the operation on $x(t)$: the signal is squared, the area under the resulting waveform is calculated for a long time $T$, and the average power is obtained by normalizing the area to $T$.\n\n**Figure 7.3 Average Noise Power Description:**\nThe graph in Figure 7.3 illustrates the process of calculating average noise power from a non-periodic signal. It consists of two main sections:\n\n1. **Original Signal:**\n   - **Type of Graph**: Time-domain waveform.\n   - **Axes Labels and Units**: Horizontal axis represents time \\( t \\), with no specific units or scale marked. Vertical axis represents the amplitude of the voltage signal \\( x(t) \\).\n   - **Overall Behavior and Trends**: Shows a complex, non-periodic oscillation around the horizontal axis, indicating a fluctuating voltage signal. The oscillations have varying amplitudes and frequencies with no discernible pattern or periodicity.\n   - **Key Features and Technical Details**: The waveform crosses the horizontal axis multiple times, indicating zero crossings. There are several peaks and valleys, but no specific numerical values or annotations are provided.\n   - **Annotations and Specific Data Points**: The time interval \\( T \\) is marked with dashed vertical lines, showing the duration over which the signal is observed.\n\n2. **Squared Signal:**\n   - **Type of Graph**: Time-domain waveform of the squared signal.\n   - **Axes Labels and Units**: Similar to the original signal, the horizontal axis represents time \\( t \\), and the vertical axis represents the squared amplitude \\( x^2(t) \\).\n   - **Overall Behavior and Trends**: The waveform is entirely above the horizontal axis, as squaring the signal eliminates negative values. The general shape mirrors the original waveform but with all values non-negative, showing more pronounced peaks due to squaring.\n   - **Key Features and Technical Details**: Maintains the same zero crossings as the original, but all values are positive. The area under the curve, shaded in gray, represents the integral of the squared signal over time \\( T \\), used to calculate average power.\n   - **Annotations and Specific Data Points**: The time interval \\( T \\) is again marked with dashed vertical lines, indicating the duration for averaging the power.\n\nFigure 7.3 Average noise power.\n\nTo simplify calculations, we write the definition of $P_{a v}$ as\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere $P_{a v}$ is expressed in $\\mathrm{V}^{2}$ rather than W. The idea is that if we know $P_{a v}$ from (7.3), then the actual power delivered to a load $R_{L}$ can be readily calculated as $P_{a v} / R_{L}$. In analogy with deterministic signals, we can also define a root-mean-square (rms) voltage for noise as $\\sqrt{P_{a v}}$, where $P_{a v}$ is given by (7.3)."
},
{
    "text": "Noise is a random process. For our purposes in this book, this means that the value of noise at any given time cannot be predicted, even if past values are known. Compare the output of a sine-wave generator with that of a microphone capturing the sound of a river (Fig. 7.1). While the value of $x_{1}(t)$ at $t=t_{1}$ can be predicted from the observed waveform, the value of $x_{2}(t)$ at $t=t_{2}$ cannot. This is the key difference between deterministic and random phenomena.\n\nIf the instantaneous value of noise in the time domain is unpredictable, how can we integrate noise into circuit analysis? This is achieved by observing the noise over an extended period and using the collected data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be predicted, a statistical model provides insights into other significant properties of the noise that are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be predicted? In many instances, the average power of noise is predictable. For example, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal, on average, exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if a random process can be so unpredictable that even its average power is indeterminate. Such processes do exist, but fortunately, most noise sources in circuits display a consistent average power.\n\nThe diagram titled \"Signal Generator\" comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river, each associated with a waveform diagram labeled (a) and (b), respectively.\n\n1. **Main Components:**\n- **Signal Generator Block:** This is depicted as a rectangular block with two output terminals, representing a device that generates a periodic signal, shown as \\( x_1(t) \\) in the accompanying waveform diagram.\n- **River Illustration:** This visual represents a natural environment, likely indicating a source of random noise. It is connected to a block resembling a microphone or sensor, capturing the river's sound. The output is represented by the waveform \\( x_2(t) \\).\n\n2. **Flow of Information or Control:**\n- **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude. The diagram shows this as a smooth, sinusoidal signal over time, indicating a controlled and predictable output.\n- **River Sound Capture:** The river's sound is captured by the microphone or sensor, producing the waveform \\( x_2(t) \\). This waveform is irregular, representing a random signal, illustrating the natural variability and randomness of environmental noise.\n\n3. **Labels, Annotations, and Key Indicators:**\n- **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n- **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n\n4. **Overall System Function:**\n- The diagram compares the characteristics of a controlled periodic signal from a signal generator with the random, unpredictable nature of a signal from a natural source like a river. The signal generator provides a stable and predictable output, while the river sound demonstrates variability and randomness, illustrating concepts of average power and randomness in signal processing.\n\nThe graph labeled \"(a)\" depicts a time-domain waveform generated by a signal generator. This sinusoidal waveform indicates a periodic and smooth oscillation over time. The horizontal axis is labeled \"t,\" representing time, while the vertical axis is labeled \"x1(t),\" representing the signal amplitude.\n\n1. **Type of Graph and Function:**\n- A time-domain sinusoidal waveform.\n- Illustrates the output of a signal generator.\n\n2. **Axes Labels and Units:**\n- The x-axis is time \"t.\"\n- The y-axis is the amplitude of the signal \"x1(t).\"\n- The scale appears linear.\n\n3. **Overall Behavior and Trends:**\n- The waveform is sinusoidal, showing regular, periodic oscillations.\n- It has consistent amplitude and frequency, indicating a stable signal output.\n\n4. **Key Features and Technical Details:**\n- The waveform displays a clear periodic pattern with peaks and troughs.\n- A specific time point, \"t1,\" is marked, possibly indicating a reference or significant time point in the waveform.\n- The waveform shows no visible distortion or irregularities, suggesting a clean output from the signal generator.\n\n5. **Annotations and Specific Data Points:**\n- A vertical dashed line at \"t1\" indicates a point of interest or measurement reference in the waveform.\n- No numerical values are provided, but the waveform's periodic nature is evident.\n\nThe graph labeled as (b) is a time-domain waveform representing the sound of a river. The horizontal axis is labeled 't', indicating time, though no specific units are provided. The vertical axis is labeled 'x2(t)', representing the amplitude of the signal, again without specific units.\n\n1. **Type of Graph and Function:**\n- A time-domain waveform showing the amplitude of a signal over time.\n\n2. **Axes Labels and Units:**\n- **Horizontal Axis (t):** Represents time.\n- **Vertical Axis (x2(t)):** Represents the amplitude of the sound signal.\n- No specific units or scales are provided for either axis.\n\n3. **Overall Behavior and Trends:**\n- The graph exhibits random, noisy behavior typical of natural sounds like a river.\n- There are no clear periodic patterns or regular oscillations.\n- The amplitude fluctuates randomly, with varying peaks and troughs.\n\n4. **Key Features and Technical Details:**\n- The waveform is irregular, with no discernible repeating patterns.\n- Multiple peaks and valleys indicate the varying intensity of the river sound.\n- The signal does not return to a baseline consistently, suggesting continuous noise.\n\n5. **Annotations and Specific Data Points:**\n- A vertical dashed line at a point labeled 't2' indicates a specific moment in time, though no specific data value is provided.\n- This point might highlight a particular feature or event within the waveform, but the context is not clear from the graph alone.\n\nFigure 7.1 (a) The output of a generator, and (b) the sound of a river.\n\nThe image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n- **Components and Structure:**\n- On the left, a simple illustration of a tree and a winding path represents a natural environment metaphorically.\n- Next to this, an icon of a generator, depicted as a circle with a vertical line through it, connected to two terminals, symbolizes a generic signal generator.\n- **Connections and Interactions:**\n- The generator is connected to a graph on the right, representing the output signal over time.\n- The graph is labeled \\( x_A(t) \\), showing a waveform that fluctuates slightly around a baseline, indicating a relatively stable output with minor variations.\n- **Annotations and Key Features:**\n- The waveform is plotted against a horizontal time axis \\( t \\), with an unspecified vertical axis.\n- The signal appears consistent, suggesting a controlled output from the generator.\n\n2. **Figure 7.1(b): Sound of a River**\n- **Components and Structure:**\n- Similar to part (a), this section includes a tree and a winding path, suggesting a natural setting, possibly representing the sound of flowing water.\n- The same generator icon is present, indicating the source of the signal.\n- **Connections and Interactions:**\n- The generator is connected to another graph on the right, representing a different output signal.\n- This graph is labeled \\( x_B(t) \\) and shows a more erratic waveform, suggesting a more complex or noisy signal compared to \\( x_A(t) \\).\n- **Annotations and Key Features:**\n- The waveform is plotted with respect to time \\( t \\), with no specific values on the vertical axis.\n- The irregularity of the waveform might represent the variability in the sound of a river, highlighting the natural randomness of such a sound source.\n\nOverall, the image contrasts two different signal outputs, one stable and one more erratic, possibly to illustrate different types of signal behavior or to metaphorically represent natural phenomena through signal processing.\n\nThe graph labeled (b) represents the sound of a river over time. This is a time-domain waveform graph where the x-axis represents time (t) and the y-axis represents the amplitude of the sound signal, denoted as x_B(t).\n\n1. **Type of Graph and Function:**\n- A time-domain waveform graph showing the amplitude of a sound signal over time.\n\n2. **Axes Labels and Units:**\n- The x-axis is labeled as 't', representing time, though specific units are not provided.\n- The y-axis is labeled as 'x_B(t)', representing the amplitude of the sound signal.\n\n3. **Overall Behavior and Trends:**\n- The waveform shows a continuous and irregular pattern, indicating a random and complex signal typical of natural sounds like a river.\n- The amplitude exhibits fluctuations, with no clear periodicity or repetitive pattern, suggesting the presence of continuous noise.\n\n4. **Key Features and Technical Details:**\n- The graph does not display specific peaks or valleys that are highlighted, but the amplitude varies over time, depicting the dynamic nature of the river sound.\n- There are no specific annotations or markers indicating particular data points or events.\n\n5. **Annotations and Specific Data Points:**\n- No annotations or specific data points are marked on the graph. The context suggests a natural, random signal without distinct events or features highlighted.\n\nThis graph effectively represents the complex and random nature of a river's sound, characterized by continuous variations in amplitude without returning to a consistent baseline.\n\nFigure 7.2 Illustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and must be defined carefully. Recall from basic circuit theory that the average power delivered by a periodic voltage $v(t)$ to a load resistance $R_{L}$ is given by\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere $T$ denotes the period. Measured in watts, this quantity can be visualized as the average heat produced in $R_{L}$ by $v(t)$.\n\nHow do we define $P_{a v}$ for a random signal? In the example of Fig. 7.2, we expect that $x_{B}(t)$ generates more heat than $x_{A}(t)$ if the microphone drives a resistive load. However, since the signals are not periodic, the measurement must be carried out over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere $x(t)$ is a voltage quantity. Figure 7.3 illustrates the operation on $x(t)$: the signal is squared, the area under the resulting waveform is calculated for a long time $T$, and the average power is obtained by normalizing the area to $T$.\n\nThe graph in Figure 7.3 illustrates the process of calculating average noise power from a non-periodic signal. It consists of two main sections:\n\n1. **Original Signal:**\n- **Type of Graph**: Time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis represents time \\( t \\), with no specific units or scale marked, indicating a general representation of time. The vertical axis represents the amplitude of the voltage signal \\( x(t) \\).\n- **Overall Behavior and Trends**: The waveform shows a complex, non-periodic oscillation around the horizontal axis, indicating a fluctuating voltage signal. The oscillations have varying amplitudes and frequencies, with no discernible pattern or periodicity.\n- **Key Features and Technical Details**: The waveform crosses the horizontal axis multiple times, indicating zero crossings. There are several peaks and valleys, but no specific numerical values or annotations are provided.\n- **Annotations and Specific Data Points**: The time interval \\( T \\) is marked with dashed vertical lines, showing the duration over which the signal is observed.\n\n2. **Squared Signal:**\n- **Type of Graph**: Time-domain waveform of the squared signal.\n- **Axes Labels and Units**: Similar to the original signal, the horizontal axis represents time \\( t \\), and the vertical axis represents the squared amplitude \\( x^2(t) \\).\n- **Overall Behavior and Trends**: The waveform is entirely above the horizontal axis, as squaring the signal eliminates negative values. The general shape mirrors the original waveform but with all values non-negative, showing more pronounced peaks due to squaring.\n- **Key Features and Technical Details**: The squared signal maintains the same zero crossings as the original, but now all values are positive. The area under the curve, shaded in gray, represents the integral of the squared signal over time \\( T \\), which is used to calculate average power.\n- **Annotations and Specific Data Points**: The time interval \\( T \\) is again marked with dashed vertical lines, indicating the duration for averaging the power.\n\nFigure 7.3 Average noise power.\n\nTo simplify calculations, we write the definition of $P_{a v}$ as\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere $P_{a v}$ is expressed in $\\mathrm{V}^{2}$ rather than W. The idea is that if we know $P_{a v}$ from (7.3), then the actual power delivered to a load $R_{L}$ can be readily calculated as $P_{a v} / R_{L}$. In analogy with deterministic signals, we can also define a root-mean-square (rms) voltage for noise as $\\sqrt{P_{a v}}$, where $P_{a v}$ is given by (7.3)."
},
{
    "text": "Noise is a random process. For our purposes in this book, this means that the value of noise at any given time cannot be predicted, even if past values are known. Compare the output of a sine-wave generator with that of a microphone capturing the sound of a river (Fig. 7.1). While the value of $x_{1}(t)$ at $t=t_{1}$ can be predicted from the observed waveform, the value of $x_{2}(t)$ at $t=t_{2}$ cannot. This highlights the key difference between deterministic and random phenomena.\n\nIf the instantaneous value of noise in the time domain is unpredictable, how can we incorporate it into circuit analysis? This is achieved by observing the noise over an extended period and using the measured data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be predicted, a statistical model provides insights into other important properties of the noise that are useful and sufficient for circuit analysis.\n\nWhich properties of noise can be predicted? In many cases, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal generally exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if a random process can be so unpredictable that even its average power is indeterminate. Such processes do exist, but fortunately, most noise sources in circuits display a constant average power.\n\n**Image Descriptions:**\n\n- **Signal Generator Diagram:**\n  - The diagram titled \"Signal Generator\" comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river. Each part is associated with a waveform diagram, labeled (a) and (b), respectively.\n  - **Main Components:**\n    - **Signal Generator Block:** Represented as a rectangular block with two output terminals, this device generates a periodic signal, depicted as \\( x_1(t) \\) in the waveform diagram.\n    - **River Illustration:** A visual depiction of a natural environment, likely indicating a source of random noise, connected to a block resembling a microphone or sensor, capturing the river's sound. The output is represented by the waveform \\( x_2(t) \\).\n  - **Flow of Information:**\n    - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude, shown as a smooth sinusoidal signal over time.\n    - **River Sound Capture:** The microphone or sensor captures the river's sound, producing the waveform \\( x_2(t) \\), which is irregular and represents a random signal.\n  - **Labels and Annotations:**\n    - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n    - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n  - **Overall Function:** The diagram compares the characteristics of a controlled periodic signal from a generator with the random, unpredictable nature of a signal from a natural source like a river.\n\n- **Graph (a):**\n  - Represents a time-domain waveform generated by a signal generator, showing a sinusoidal waveform indicating periodic and smooth oscillation over time.\n  - **Axes:** Horizontal axis is time \"t,\" vertical axis is signal amplitude \"x1(t).\"\n  - **Behavior:** Sinusoidal with regular, periodic oscillations, consistent amplitude, and frequency, indicating a stable signal output.\n  - **Key Features:** Clear periodic pattern with peaks and troughs, a specific time point \"t1\" marked, no visible distortion or irregularities.\n\n- **Graph (b):**\n  - A time-domain waveform representing the sound of a river, with the horizontal axis labeled 't' (time) and the vertical axis labeled 'x2(t)' (amplitude).\n  - **Behavior:** Random, noisy behavior typical of natural sounds, no clear periodic patterns, amplitude fluctuates randomly.\n  - **Key Features:** Irregular waveform with varying peaks and valleys, no consistent baseline, a vertical dashed line at 't2' indicating a specific moment.\n\n**Figure 7.1 (a) Output of a generator, and (b) sound of a river.**\n\n- **Figure 7.2 (a):**\n  - Consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n  - **Figure 7.1(a): Output of a Generator:**\n    - **Components:** Illustration of a tree and a winding path, symbolizing a natural environment, and an icon of a generator connected to two terminals.\n    - **Connections:** Generator connected to a graph showing the output signal \\( x_A(t) \\), which fluctuates slightly around a baseline.\n    - **Annotations:** Waveform plotted against time \\( t \\), consistent signal suggesting controlled output.\n  - **Figure 7.1(b): Sound of a River:**\n    - **Components:** Similar natural setting with a tree and path, same generator icon.\n    - **Connections:** Generator connected to a graph showing a more erratic waveform \\( x_B(t) \\).\n    - **Annotations:** Waveform plotted against time \\( t \\), irregular pattern representing natural sound variability.\n\n- **Figure 7.2 (b):**\n  - Represents the sound of a river over time, with the x-axis as time (t) and the y-axis as amplitude (x_B(t)).\n  - **Behavior:** Continuous, irregular pattern indicating a random and complex signal, amplitude fluctuates with no clear periodicity.\n  - **Key Features:** No specific peaks or valleys highlighted, amplitude varies over time, no annotations or specific data points.\n\n**Figure 7.2 Illustration of the average power of a random signal.**\n\nThe concept of average power is crucial in our analysis and must be defined carefully. Recall from basic circuit theory that the average power delivered by a periodic voltage $v(t)$ to a load resistance $R_{L}$ is given by\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere $T$ denotes the period. Measured in watts, this quantity represents the average heat produced in $R_{L}$ by $v(t)$.\n\nHow do we define $P_{a v}$ for a random signal? In the example of Fig. 7.2, we expect that $x_{B}(t)$ generates more heat than $x_{A}(t)$ if the microphone drives a resistive load. However, since the signals are not periodic, the measurement must be carried out over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere $x(t)$ is a voltage quantity. Figure 7.3 illustrates this process: the signal is squared, the area under the resulting waveform is calculated for a long time $T$, and the average power is obtained by normalizing the area to $T$.\n\n- **Figure 7.3 Average Noise Power:**\n  - Illustrates the process of calculating average noise power from a non-periodic signal, consisting of two main sections:\n    - **Original Signal:**\n      - **Type of Graph:** Time-domain waveform.\n      - **Axes:** Horizontal axis represents time \\( t \\), vertical axis represents voltage amplitude \\( x(t) \\).\n      - **Behavior:** Complex, non-periodic oscillation with varying amplitudes and frequencies.\n      - **Key Features:** Multiple zero crossings, peaks, and valleys, time interval \\( T \\) marked with dashed lines.\n    - **Squared Signal:**\n      - **Type of Graph:** Time-domain waveform of the squared signal.\n      - **Axes:** Horizontal axis represents time \\( t \\), vertical axis represents squared amplitude \\( x^2(t) \\).\n      - **Behavior:** Entirely above the horizontal axis, more pronounced peaks due to squaring.\n      - **Key Features:** Same zero crossings as the original, area under the curve shaded in gray represents the integral over time \\( T \\).\n\n**Figure 7.3 Average noise power.**\n\nTo simplify calculations, we write the definition of $P_{a v}$ as\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere $P_{a v}$ is expressed in $\\mathrm{V}^{2}$ rather than W. The idea is that if we know $P_{a v}$ from (7.3), then the actual power delivered to a load $R_{L}$ can be readily calculated as $P_{a v} / R_{L}$. In analogy with deterministic signals, we can also define a root-mean-square (rms) voltage for noise as $\\sqrt{P_{a v}}$, where $P_{a v}$ is given by (7.3)."
},
{
    "text": "Noise is a random phenomenon. In the context of this book, this implies that the value of noise at any given time cannot be predicted, even if past values are known. Consider the comparison between the output of a sine-wave generator and the sound of a river captured by a microphone (Fig. 7.1). While the value of \\( x_1(t) \\) at \\( t = t_1 \\) can be anticipated from the observed waveform, the value of \\( x_2(t) \\) at \\( t = t_2 \\) remains unpredictable. This distinction is fundamental between deterministic and random phenomena.\n\nGiven that the instantaneous value of noise in the time domain is unpredictable, how can we integrate noise into circuit analysis? This is achieved by observing the noise over an extended period and using the collected data to develop a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be foreseen, a statistical model provides insights into other crucial properties of the noise that are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be anticipated? Often, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal generally exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if a random process can be so unpredictable that even its average power is indeterminate. Such processes do exist, but fortunately, most noise sources in circuits display a consistent average power.\n\n**Image Descriptions:**\n- **Signal Generator Diagram:** This diagram comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river. Each part is associated with a waveform diagram, labeled (a) and (b), respectively.\n  - **Signal Generator Block:** Depicted as a rectangular block with two output terminals, it represents a device generating a periodic signal, shown as \\( x_1(t) \\) in the waveform diagram.\n  - **River Illustration:** A visual representation of a natural environment, likely indicating a source of random noise, connected to a block resembling a microphone or sensor, capturing the river's sound. The output is represented by the waveform \\( x_2(t) \\).\n  - **Flow of Information:** The signal generator outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude, shown as a smooth sinusoidal signal. The river sound capture results in an irregular waveform \\( x_2(t) \\), illustrating natural variability and randomness.\n  - **Labels and Annotations:** Waveform \\( x_1(t) \\) is marked with a time point \\( t_1 \\), and waveform \\( x_2(t) \\) with \\( t_2 \\), highlighting the difference between predictable and random signals.\n\n- **Graph (a):** Represents a time-domain sinusoidal waveform from a signal generator.\n  - **Type of Graph:** Time-domain sinusoidal waveform.\n  - **Axes Labels:** Horizontal axis is time \"t,\" vertical axis is signal amplitude \"x1(t).\"\n  - **Behavior:** Regular, periodic oscillations with consistent amplitude and frequency.\n  - **Key Features:** Clear periodic pattern with peaks and troughs, marked with a vertical dashed line at \\( t_1 \\).\n\n- **Graph (b):** Time-domain waveform of a river's sound.\n  - **Type of Graph:** Time-domain waveform showing signal amplitude over time.\n  - **Axes Labels:** Horizontal axis is time \"t,\" vertical axis is amplitude \"x2(t).\"\n  - **Behavior:** Random, noisy behavior with no clear periodic patterns, fluctuating amplitude.\n  - **Key Features:** Irregular waveform with multiple peaks and valleys, marked with a vertical dashed line at \\( t_2 \\).\n\n**Figure 7.1:** (a) Output of a generator, and (b) sound of a river.\n\n- **Figure 7.2 (a):** Conceptual representation of a signal generator and its output waveform.\n  - **Components:** Illustration of a tree and path, symbolizing a natural environment, and a generator icon connected to a graph labeled \\( x_A(t) \\).\n  - **Behavior:** Graph shows a waveform fluctuating slightly around a baseline, indicating a stable output.\n  - **Figure 7.2 (b):** Similar setup with a more erratic waveform \\( x_B(t) \\), representing a complex or noisy signal.\n\n**Figure 7.2:** Illustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and requires precise definition. From basic circuit theory, the average power delivered by a periodic voltage \\( v(t) \\) to a load resistance \\( R_L \\) is given by:\n\n\\[ P_{av} = \\frac{1}{T} \\int_{-T/2}^{+T/2} \\frac{v^2(t)}{R_L} dt \\tag{7.1} \\]\n\nwhere \\( T \\) is the period. This quantity, measured in watts, represents the average heat produced in \\( R_L \\) by \\( v(t) \\).\n\nFor a random signal, how do we define \\( P_{av} \\)? In Fig. 7.2, \\( x_B(t) \\) is expected to generate more heat than \\( x_A(t) \\) if driving a resistive load. However, since the signals are not periodic, the measurement must be over a long period:\n\n\\[ P_{av} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} \\frac{x^2(t)}{R_L} dt \\tag{7.2} \\]\n\nwhere \\( x(t) \\) is a voltage quantity. Figure 7.3 illustrates this process: the signal is squared, the area under the resulting waveform is calculated over a long time \\( T \\), and the average power is obtained by normalizing the area to \\( T \\).\n\n**Figure 7.3:** Average noise power.\nTo simplify calculations, we express \\( P_{av} \\) as:\n\n\\[ P_{av} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} x^2(t) dt \\tag{7.3} \\]\n\nwhere \\( P_{av} \\) is in \\( \\mathrm{V}^2 \\) rather than W. Knowing \\( P_{av} \\) from (7.3), the actual power delivered to a load \\( R_L \\) can be calculated as \\( P_{av} / R_L \\). Analogous to deterministic signals, we can define a root-mean-square (rms) voltage for noise as \\( \\sqrt{P_{av}} \\), where \\( P_{av} \\) is given by (7.3)."
},
{
    "text": "Noise is a random process. For our purposes in this book, this means that the value of noise at any given time cannot be predicted, even if past values are known. Compare the output of a sine-wave generator with that of a microphone capturing the sound of a river (Fig. 7.1). While the value of $x_{1}(t)$ at $t=t_{1}$ can be predicted from the observed waveform, the value of $x_{2}(t)$ at $t=t_{2}$ cannot. This is the key difference between deterministic and random phenomena.\n\nIf the instantaneous value of noise in the time domain is unpredictable, how can we incorporate it into circuit analysis? This is achieved by observing the noise over an extended period and using the measured data to create a \"statistical model\" for the noise. Although the instantaneous amplitude of noise cannot be predicted, a statistical model provides insights into other important properties of the noise that are useful and sufficient for circuit analysis.\n\nWhat properties of noise can be predicted? Often, the average power of noise is predictable. For instance, if a microphone capturing the sound of a river is moved closer to the river, the resulting electrical signal, on average, exhibits larger fluctuations and thus higher power (Fig. 7.2). One might wonder if a random process can be so random that even its average power is unpredictable. Such processes do exist, but fortunately, most noise sources in circuits display a constant average power.\n\n**Image Description: Signal Generator**\nThe diagram titled \"Signal Generator\" comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river. Each part is associated with a waveform diagram, labeled (a) and (b), respectively.\n\n1. **Main Components:**\n   - **Signal Generator Block:** This is depicted as a rectangular block with two output terminals, representing a device that generates a periodic signal, shown as \\( x_1(t) \\) in the accompanying waveform diagram.\n   - **River Illustration:** This visual represents a natural environment, likely indicating a source of random noise. It is connected to a block resembling a microphone or sensor, capturing the river's sound. The output is represented by the waveform \\( x_2(t) \\).\n\n2. **Flow of Information or Control:**\n   - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude. The diagram shows this as a smooth, sinusoidal signal over time, indicating a controlled and predictable output.\n   - **River Sound Capture:** The river's sound is captured by the microphone or sensor, and the corresponding waveform \\( x_2(t) \\) is shown. This waveform is irregular, representing a random signal, illustrating the natural variability and randomness of environmental noise.\n\n3. **Labels, Annotations, and Key Indicators:**\n   - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the periodic cycle.\n   - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting a particular instance in the random signal.\n\n4. **Overall System Function:**\n   - The diagram compares the characteristics of a controlled periodic signal from a signal generator with the random, unpredictable nature of a signal from a natural source like a river. The signal generator provides a stable and predictable output, while the river sound demonstrates variability and randomness in amplitude and frequency, illustrating concepts of average power and randomness in signal processing.\n\n**Image Description: (a)**\nThe graph labeled \"(a)\" depicts a time-domain waveform generated by a signal generator. This is a sinusoidal waveform, indicating a periodic and smooth oscillation over time. The horizontal axis is labeled \"t,\" representing time, while the vertical axis is labeled \"x1(t),\" representing the signal amplitude.\n\n1. **Type of Graph and Function:**\n   - A time-domain sinusoidal waveform.\n   - Illustrates the output of a signal generator.\n\n2. **Axes Labels and Units:**\n   - x-axis: time \"t.\"\n   - y-axis: signal amplitude \"x1(t).\"\n   - The scale appears linear.\n\n3. **Overall Behavior and Trends:**\n   - Sinusoidal waveform with regular, periodic oscillations.\n   - Consistent amplitude and frequency, indicating a stable signal output.\n\n4. **Key Features and Technical Details:**\n   - Displays a clear periodic pattern with peaks and troughs.\n   - A specific time point, \"t1,\" is marked, possibly indicating a reference or significant time point.\n   - No visible distortion or irregularities, suggesting a clean output from the signal generator.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at \"t1,\" indicating a point of interest or measurement reference.\n   - No numerical values provided, but the waveform's periodic nature is evident.\n\n**Image Description: (b)**\nThe graph labeled as (b) is a time-domain waveform representing the sound of a river. The horizontal axis is labeled 't', indicating time, though no specific units are provided. The vertical axis is labeled 'x2(t)', representing the amplitude of the signal, again without specific units.\n\n1. **Type of Graph and Function:**\n   - A time-domain waveform showing the amplitude of a signal over time.\n\n2. **Axes Labels and Units:**\n   - **Horizontal Axis (t):** Represents time.\n   - **Vertical Axis (x2(t)):** Represents the amplitude of the sound signal.\n   - No specific units or scales provided.\n\n3. **Overall Behavior and Trends:**\n   - Exhibits random, noisy behavior typical of natural sounds like a river.\n   - No clear periodic patterns or regular oscillations.\n   - Amplitude fluctuates randomly with varying peaks and troughs.\n\n4. **Key Features and Technical Details:**\n   - Irregular waveform with no discernible repeating patterns.\n   - Multiple peaks and valleys, indicating varying intensity of the river sound.\n   - Signal does not return to a baseline consistently, suggesting continuous noise.\n\n5. **Annotations and Specific Data Points:**\n   - A vertical dashed line at a point labeled 't2', indicating a specific moment in time, though no specific data value is provided.\n   - This point might highlight a particular feature or event within the waveform, but the context is not clear from the graph alone.\n\nFigure 7.1 (a) The output of a generator, and (b) the sound of a river.\n\n**Image Description: Figure 7.2 (a)**\nThe image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its corresponding output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n   - **Components and Structure:**\n     - On the left, a simple illustration of a tree and a winding path represents a natural environment.\n     - Next to this, an icon of a generator, depicted as a circle with a vertical line through it, connected to two terminals, symbolizes a generic signal generator.\n   - **Connections and Interactions:**\n     - The generator is connected to a graph on the right, representing the output signal over time.\n     - The graph is labeled as \\( x_A(t) \\), showing a waveform that fluctuates slightly around a baseline, indicating a relatively stable output with minor variations.\n   - **Annotations and Key Features:**\n     - The waveform is plotted against a horizontal time axis \\( t \\), with an unspecified vertical axis.\n     - The signal appears consistent, suggesting a controlled output from the generator.\n\n2. **Figure 7.1(b): Sound of a River**\n   - **Components and Structure:**\n     - Similar to part (a), this section includes a tree and a winding path, suggesting a natural setting, possibly representing the sound of flowing water.\n     - The same generator icon is present, indicating the source of the signal.\n   - **Connections and Interactions:**\n     - The generator is connected to another graph on the right, representing a different output signal.\n     - This graph is labeled \\( x_B(t) \\) and shows a more erratic waveform, suggesting a more complex or noisy signal compared to \\( x_A(t) \\).\n   - **Annotations and Key Features:**\n     - The waveform is plotted with respect to time \\( t \\), with no specific values on the vertical axis.\n     - The irregularity of the waveform might represent the variability in the sound of a river, highlighting the natural randomness of such a sound source.\n\nOverall, the image contrasts two different signal outputs, one stable and one more erratic, possibly to illustrate different types of signal behavior or to metaphorically represent natural phenomena through signal processing.\n\n**Image Description: Figure 7.2 (b)**\nThe graph labeled (b) represents the sound of a river over time. This is a time-domain waveform graph where the x-axis represents time (t) and the y-axis represents the amplitude of the sound signal, denoted as x_B(t).\n\n1. **Type of Graph and Function:**\n   - A time-domain waveform graph showing the amplitude of a sound signal over time.\n\n2. **Axes Labels and Units:**\n   - The x-axis is labeled as 't', representing time, though the specific units are not provided.\n   - The y-axis is labeled as 'x_B(t)', representing the amplitude of the sound signal.\n\n3. **Overall Behavior and Trends:**\n   - The waveform shows a continuous and irregular pattern, indicating a random and complex signal typical of natural sounds like a river.\n   - The amplitude exhibits fluctuations, with no clear periodicity or repetitive pattern, suggesting the presence of continuous noise.\n\n4. **Key Features and Technical Details:**\n   - The graph does not display any specific peaks or valleys that are highlighted, but the amplitude varies over time, depicting the dynamic nature of the river sound.\n   - There are no specific annotations or markers indicating particular data points or events.\n\n5. **Annotations and Specific Data Points:**\n   - No annotations or specific data points marked on the graph. The context suggests a natural, random signal without distinct events or features highlighted.\n\nThis graph effectively represents the complex and random nature of a river's sound, characterized by continuous variations in amplitude without returning to a consistent baseline.\n\nFigure 7.2 Illustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and must be defined carefully. Recall from basic circuit theory that the average power delivered by a periodic voltage $v(t)$ to a load resistance $R_{L}$ is given by\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere $T$ denotes the period. Measured in watts, this quantity can be visualized as the average heat produced in $R_{L}$ by $v(t)$.\n\nHow do we define $P_{a v}$ for a random signal? In the example of Fig. 7.2, we expect that $x_{B}(t)$ generates more heat than $x_{A}(t)$ if the microphone drives a resistive load. However, since the signals are not periodic, the measurement must be carried out over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere $x(t)$ is a voltage quantity. Figure 7.3 illustrates the operation on $x(t)$: the signal is squared, the area under the resulting waveform is calculated for a long time $T$, and the average power is obtained by normalizing the area to $T$.\n\n**Image Description: Figure 7.3 Average Noise Power**\nThe graph in Figure 7.3 illustrates the process of calculating average noise power from a non-periodic signal. It consists of two main sections:\n\n1. **Original Signal:**\n   - **Type of Graph**: Time-domain waveform.\n   - **Axes Labels and Units**: The horizontal axis represents time \\( t \\), with no specific units or scale marked, indicating a general representation of time. The vertical axis represents the amplitude of the voltage signal \\( x(t) \\).\n   - **Overall Behavior and Trends**: The waveform shows a complex, non-periodic oscillation around the horizontal axis, indicating a fluctuating voltage signal. The oscillations have varying amplitudes and frequencies, with no discernible pattern or periodicity.\n   - **Key Features and Technical Details**: The waveform crosses the horizontal axis multiple times, indicating zero crossings. There are several peaks and valleys, but no specific numerical values or annotations are provided.\n   - **Annotations and Specific Data Points**: The time interval \\( T \\) is marked with dashed vertical lines, showing the duration over which the signal is observed.\n\n2. **Squared Signal:**\n   - **Type of Graph**: Time-domain waveform of the squared signal.\n   - **Axes Labels and Units**: Similar to the original signal, the horizontal axis represents time \\( t \\), and the vertical axis represents the squared amplitude \\( x^2(t) \\).\n   - **Overall Behavior and Trends**: The waveform is entirely above the horizontal axis, as squaring the signal eliminates negative values. The general shape mirrors the original waveform but with all values non-negative, showing more pronounced peaks due to squaring.\n   - **Key Features and Technical Details**: The squared signal maintains the same zero crossings as the original, but all values are positive. The area under the curve, shaded in gray, represents the integral of the squared signal over time \\( T \\), used to calculate average power.\n   - **Annotations and Specific Data Points**: The time interval \\( T \\) is again marked with dashed vertical lines, indicating the duration for averaging the power.\n\nFigure 7.3 Average noise power.\n\nTo simplify calculations, we write the definition of $P_{a v}$ as\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere $P_{a v}$ is expressed in $\\mathrm{V}^{2}$ rather than W. The idea is that if we know $P_{a v}$ from (7.3), then the actual power delivered to a load $R_{L}$ can be readily calculated as $P_{a v} / R_{L}$. In analogy with deterministic signals, we can also define a root-mean-square (rms) voltage for noise as $\\sqrt{P_{a v}}$, where $P_{a v}$ is given by (7.3)."
},
{
    "text": "Noise is a random process, meaning its value at any given time cannot be predicted, even with knowledge of past values. To illustrate, compare the output of a sine-wave generator with the sound of a river captured by a microphone (Fig. 7.1). While the value of \\( x_{1}(t) \\) at \\( t=t_{1} \\) can be predicted from its waveform, the value of \\( x_{2}(t) \\) at \\( t=t_{2} \\) cannot. This highlights the key difference between deterministic and random phenomena.\n\nIf the instantaneous noise value in the time domain is unpredictable, how do we integrate noise into circuit analysis? This is achieved by observing the noise over an extended period and using the data to build a \"statistical model\" for the noise. Although the instantaneous amplitude of noise is unpredictable, this model provides insights into other important noise properties useful for circuit analysis.\n\nWhich noise properties can be predicted? Often, the average power of noise is predictable. For instance, if a microphone capturing river sounds is moved closer to the river, the resulting electrical signal shows larger excursions and higher average power (Fig. 7.2). One might wonder if a random process could be so random that even its average power is unpredictable. Such processes do exist, but幸运ly, most noise sources in circuits exhibit constant average power.\n\n**Signal Generator Diagram Description:**\nThe \"Signal Generator\" diagram comprises two main parts: a block labeled \"Signal Generator\" and an illustration of a river, each associated with waveform diagrams (a) and (b).\n\n1. **Main Components:**\n   - **Signal Generator Block:** This rectangular block with two output terminals represents a device generating a periodic signal, depicted as \\( x_1(t) \\) in the waveform diagram.\n   - **River Illustration:** This visual shows a natural environment, likely indicating a noise source, connected to a microphone or sensor capturing the river's sound, represented by the waveform \\( x_2(t) \\).\n\n2. **Flow of Information:**\n   - **Signal Generator:** Outputs a periodic waveform \\( x_1(t) \\) with specific frequency and amplitude, shown as a smooth sinusoidal signal.\n   - **River Sound Capture:** The microphone captures the river sound, producing the waveform \\( x_2(t) \\), which is irregular and represents random noise.\n\n3. **Labels and Annotations:**\n   - **Waveform \\( x_1(t) \\):** Labeled with a time point \\( t_1 \\), indicating a specific moment in the cycle.\n   - **Waveform \\( x_2(t) \\):** Labeled with a time point \\( t_2 \\), highlighting an instance in the random signal.\n\n4. **System Function:**\n   - The diagram compares the characteristics of a controlled periodic signal from the generator with the random, unpredictable nature of a natural sound signal.\n\n**Graph (a) Description:**\nThe graph labeled \"(a)\" shows a time-domain sinusoidal waveform from a signal generator. The horizontal axis is time \"t,\" and the vertical axis is the signal amplitude \"x1(t).\"\n\n1. **Graph Type and Function:**\n   - A time-domain sinusoidal waveform illustrating a signal generator's output.\n\n2. **Axes Labels:**\n   - x-axis: time \"t\"\n   - y-axis: amplitude \"x1(t)\"\n   - Linear scale.\n\n3. **Behavior and Trends:**\n   - Sinusoidal, showing regular, periodic oscillations with consistent amplitude and frequency.\n\n4. **Key Features:**\n   - Clear periodic pattern with peaks and troughs.\n   - A specific time point \"t1\" is marked.\n\n5. **Annotations:**\n   - Vertical dashed line at \"t1\" indicates a point of interest.\n\n**Graph (b) Description:**\nThe graph labeled \"(b)\" represents the sound of a river in the time domain. The horizontal axis is 't' for time, and the vertical axis is 'x2(t)' for amplitude.\n\n1. **Graph Type and Function:**\n   - Time-domain waveform showing the amplitude of a sound signal over time.\n\n2. **Axes Labels:**\n   - Horizontal Axis (t): Time.\n   - Vertical Axis (x2(t)): Amplitude.\n   - No specific units.\n\n3. **Behavior and Trends:**\n   - Random, noisy behavior typical of natural sounds.\n   - No clear periodic patterns, with fluctuating amplitude.\n\n4. **Key Features:**\n   - Irregular waveform with varying peaks and valleys.\n\n5. **Annotations:**\n   - Vertical dashed line at 't2' indicates a specific moment.\n\n**Figure 7.1:**\n(a) Output of a generator, and (b) sound of a river.\n\n**Figure 7.2 (a) Description:**\nThe image consists of two parts labeled (a) and (b), each depicting a conceptual representation of a signal generator and its output waveform.\n\n1. **Figure 7.1(a): Output of a Generator**\n   - **Components:** Illustration of a tree and path, symbolizing a natural environment, and an icon of a generator with two terminals.\n   - **Connections:** Generator connected to a graph showing the output signal \\( x_A(t) \\), fluctuating slightly around a baseline.\n   - **Annotations:** Waveform plotted against time \\( t \\), indicating a controlled output.\n\n2. **Figure 7.1(b): Sound of a River**\n   - **Components:** Similar natural setting and generator icon.\n   - **Connections:** Generator connected to a graph showing a more erratic signal \\( x_B(t) \\).\n   - **Annotations:** Waveform plotted against time \\( t \\), representing natural randomness.\n\n**Figure 7.2 (b) Description:**\nThe graph labeled (b) shows the sound of a river over time. The x-axis is time 't', and the y-axis is the amplitude 'x_B(t)'.\n\n1. **Graph Type and Function:**\n   - Time-domain waveform of a sound signal.\n\n2. **Axes Labels:**\n   - x-axis: time 't'\n   - y-axis: amplitude 'x_B(t)'\n\n3. **Behavior and Trends:**\n   - Continuous, irregular pattern indicating random noise.\n\n4. **Key Features:**\n   - Fluctuating amplitude with no clear periodicity.\n\n5. **Annotations:**\n   - No specific annotations or data points.\n\n**Figure 7.2:**\nIllustration of the average power of a random signal.\n\nThe concept of average power is crucial in our analysis and must be defined carefully. From basic circuit theory, the average power delivered by a periodic voltage \\( v(t) \\) to a load resistance \\( R_{L} \\) is given by:\n\n$$\n\\begin{equation*}\nP_{a v}=\\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{v^{2}(t)}{R_{L}} d t \\tag{7.1}\n\\end{equation*}\n$$\n\nwhere \\( T \\) is the period. Measured in watts, this represents the average heat produced in \\( R_{L} \\) by \\( v(t) \\).\n\nFor a random signal, how do we define \\( P_{a v} \\)? In Fig. 7.2, \\( x_{B}(t) \\) generates more heat than \\( x_{A}(t) \\) if driving a resistive load. Since the signals are not periodic, the measurement must be over a long time:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} \\frac{x^{2}(t)}{R_{L}} d t \\tag{7.2}\n\\end{equation*}\n$$\n\nwhere \\( x(t) \\) is a voltage quantity. Figure 7.3 illustrates this process: the signal is squared, the area under the waveform is calculated for a long time \\( T \\), and the average power is obtained by normalizing the area to \\( T \\).\n\n**Figure 7.3 Average Noise Power Description:**\nThe graph in Figure 7.3 shows the process of calculating average noise power from a non-periodic signal, consisting of two sections:\n\n1. **Original Signal:**\n   - **Graph Type:** Time-domain waveform.\n   - **Axes Labels:** Horizontal axis for time \\( t \\), vertical axis for voltage amplitude \\( x(t) \\).\n   - **Behavior:** Complex, non-periodic oscillations with varying amplitudes and frequencies.\n   - **Key Features:** Multiple zero crossings, peaks, and valleys.\n   - **Annotations:** Time interval \\( T \\) marked with dashed lines.\n\n2. **Squared Signal:**\n   - **Graph Type:** Time-domain waveform of the squared signal.\n   - **Axes Labels:** Horizontal axis for time \\( t \\), vertical axis for squared amplitude \\( x^2(t) \\).\n   - **Behavior:** Entirely above the horizontal axis, with more pronounced peaks.\n   - **Key Features:** Maintains zero crossings, positive values.\n   - **Annotations:** Time interval \\( T \\) marked, shaded area represents the integral for average power calculation.\n\n**Figure 7.3:**\nAverage noise power.\n\nTo simplify calculations, \\( P_{a v} \\) is defined as:\n\n$$\n\\begin{equation*}\nP_{a v}=\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x^{2}(t) d t \\tag{7.3}\n\\end{equation*}\n$$\n\nwhere \\( P_{a v} \\) is in \\( \\mathrm{V}^{2} \\). Knowing \\( P_{a v} \\) from (7.3), the actual power delivered to a load \\( R_{L} \\) can be calculated as \\( P_{a v} / R_{L} \\). Analogous to deterministic signals, the root-mean-square (rms) voltage for noise can be defined as \\( \\sqrt{P_{a v}} \\), where \\( P_{a v} \\) is given by (7.3)."
},
{
    "text": "Rephrased text:\n\nThe adaptability of the average power concept increases when defined in terms of the frequency composition of noise. Noise produced by a group of men typically exhibits weaker high-frequency elements compared to that generated by a group of women, a distinction that can be discerned through the \"spectrum\" unique to each type of noise. This spectrum, also known as the \"power spectral density\" (PSD), illustrates the distribution of power across various frequencies within a signal. Specifically, the PSD, denoted as $S_{x}(f)$, for a noise waveform $x(t)$, is defined as the average power conveyed by $x(t)$ within a one-hertz bandwidth centered at $f$. As depicted in Fig. 7.4(a), the process involves passing $x(t)$ through a bandpass filter centered at $f_{1}$ with a bandwidth of 1 Hz, squaring the resulting output $x_{f 1}(t)$, and then averaging this squared output over an extended period to determine $S_{x}\\left(f_{1}\\right)$. By repeating this process using bandpass filters with different center frequencies, we obtain map the complete shape of $S_{x}(f)$, as shown in Fig. 7.4(b). Generally, $S_{x}(f)$ is measured in watts per hertz. The total\nI apologize for the confusion, but it seems there may overlooked an mistake. The need not the impression that you re was to rephrase the entire text while the [Context Provided] section while maintaining the original meaning and length. However, the see understand that you task was to rephrase the entire passageContext Provided] section, including the image and image descriptions, and equations associated\nThephrased text andThe adapt of the average power concept is enhanced when considered's defined in relation to the frequency content\nI apologize for the confusion.. Here's re with the rephrased text of the entire text while including\nThephrased text:\n\nThe adaptability of the concept power concept increases when defined in terms of the frequency composition of noise. Noise produced by a group of men typically exhibits weaker high-frequency elements compared to that generated by a group of women, a distinction that can be discerned through the \"spectrum\" unique to each type of noise. This spectrum, also known as the \"power spectral density\" (PSD), illustrates the distribution of power across various frequencies within a signal. Specifically, the PSD, denoted as $S_{x}(f)$, for a noise waveform $x(t)$, is defined as the average power conveyed by $x(t)$ within a one-hertz bandwidth centered at $f$. As depicted in Fig. 7.4(a), the process involves passing $x(t)$ through a bandpass filter centered at $f_{1}$ with a bandwidth of 1 Hz, squaring the resulting output $x_{f 1}(t)$, and then averaging this squared output over an extended period to determine $S_{x}\\left(f_{1}\\right)$. By repeating this process using bandpass filters with differing center frequencies, we can construct the complete profile of $S_{x}(f)$, as shown in Fig. 7.4(b). Typically, $S_{x}(f)$ is measured in watts per hertz. The total area under $S_{x}(f)$ represents the power carried by the signal (or the noise) across all frequencies; i.e., the total power.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of voice for men and women. What does the difference imply about their time-domain waveforms?\n(b) Estimate the averaging time, $T$, in Eq. (7.3) for voice signals.\n\nThe\nThephrased text:\n\nThe adapt of the average power concept expands when it is linked to the frequency makeup of noise. Typically, the noise generated by a group of men has a pronounced\nIphrased text:\n\nThe versatility of the average power concept expands when it is linked to the frequency components of noise. Typically, the noise generated by a group of men has less high\nRe apologize for the confusion.. Let's proceed with the rephrased version of the provided text, including the text, image descriptions, and any equations or equations mentioned. Here ensure that the rephrased version maintains the original meaning and length.\n\nRephrased text:\n\nThe concept of average power gains flexibility when analyzed through the lens of noise frequency. Typically, the noise produced by a group of men features lower high-frequency components compared to the noise from a group of women, a distinction evident in the \"spectrum\" of each noise type. This spectrum, known as the \"power spectral density\" (PSD), illustrates the power distribution across different frequencies in a signal. Specifically, the PSD, denoted as $S_{x}(f)$, for a noise waveform $x(t)$, represents the average power carried by $x(t)$ within a one-hertz bandwidth centered at $f$. As depicted in Fig. 7.4(a), this involves passing $x(t)$ through a bandpass filter centered at $f_{1}$ with a bandwidth of 1 Hz, squaring the resulting output $x_{f 1}(t)$, and then averaging this squared output over an extended period to determine $S_{x}\\left(f_{1}\\right)$. By repeating this process using bandpass filters with differing center frequencies, we can construct the complete profile of $S_{x}(f)$, as shown in Fig. 7.4(b). Typically, $S_{x}(f)$ is measured in watts per hertz. The total area under $S_{x}(f)$ represents the power carried by the signal (or the noise) at all frequencies; i.e., the total power.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of voice for men and women. What does the difference imply about their time-domain waveforms?\n(b) Estimate the averaging time, $T$, in Eq. (7.3) for voice signals.\n\n---\n\nFigure 7.4(a) description:\n\nThe diagram labeled '(a)' illustrates the process of shaping a signal's spectrum using a band-pass filter. The system consists of the following main components:\n\n1. **Input Signal, x(t):**\n   - The diagram begins with an input signal, denoted as \\(x(t)\\), which is a time-domain waveform. This signal is depicted as a waveform with varying amplitude over time.\n\n2. **Band-Pass Filter:**\n   - The input signal \\(x(t)\\) is fed into a band-pass filter. This filter is characterized by a specific frequency range, centered at \\(f_1\\), and has a bandwidth of 1 Hz. The purpose of the band-pass filter is to allow only the frequencies within this narrow band to pass through, effectively isolating a portion of the signal's frequency spectrum.\n\n3. **Filtered Signal, x_{f1}(t):**\n   - The output from the band-pass filter is a filtered version of the input signal, denoted as \\(x_{f1}(t)\\). This signal is shown as a sinusoidal waveform, indicating that only the frequency components around \\(f_1\\) are present.\n\n4. **Squaring Block:**\n   - The filtered signal \\(x_{f1}(t)\\) is then passed through a squaring block. This block computes the square of the amplitude of the signal, resulting in \\(|x_{f1}(t)|^2\\). Squaring the signal typically emphasizes the power of the signal components.\n\n5. **Output Signal, |x_{f1}(t)|^2:**\n   - The final output is the squared amplitude of the filtered signal, \\(|x_{f1}(t)|^2\\), which is shown as a waveform with increased amplitude variations over time. This represents the power of the signal components within the band-pass filter's frequency range.\n\n**Flow of Information:**\n   - The signal flow starts with the input \\(x(t)\\), which is processed by the band-pass filter to produce \\(x_{f1}(t)\\). This filtered signal is then squared to yield \\(|x_{f1}(t)|^2\\). The flow of information is linear, with no feedback loops or additional control mechanisms.\n\n**Overall System Function:**\n   - The primary function of this system is to isolate a specific frequency component from the input signal using a band-pass filter and then to analyze the power of this component by squaring its amplitude. This process is useful in spectral analysis where the power at specific frequency bands is of interest.\n\nFigure 7.4(b) description:\n\nThe graph labeled (b) is a frequency spectrum plot, specifically depicting the noise spectrum $S_x(f)$ of a signal.\n\n1. **Type of Graph and Function:**\n   - This is a frequency-domain graph representing the power spectral density (PSD) of a signal, $S_x(f)$.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis represents frequency ($f$), typically measured in Hertz (Hz).\n   - The vertical axis represents the power spectral density, $S_x(f)$, measured in watts per hertz (W/Hz).\n   - There are no specific scales mentioned, but it appears to be a linear scale for both axes.\n\n3. **Overall Behavior and Trends:**\n   - The spectrum displays a series of peaks and valleys, indicating varying power levels at different frequencies.\n   - The graph starts with a peak at $f_1$, followed by a dip at $f_2$, then another peak, and gradually decreases as frequency increases towards $f_n$.\n   - This suggests that the signal has strong frequency components at certain frequencies, which diminish as the frequency increases.\n\n4. **Key Features and Technical Details:**\n   - Peaks are observed at specific frequencies ($f_1$, $f_2$, ..., $f_n$), which are marked by vertical dashed lines.\n   - The highest peak is located between $f_2$ and $f_n$, indicating the frequency with the most power.\n   - The spectrum shows a decreasing trend in power as the frequency increases beyond the highest peak.\n\n5. **Annotations and Specific Data Points:**\n   - The graph is annotated with open circles at key frequencies, highlighting significant points in the spectrum.\n   - These markers likely correspond to the center frequencies of band-pass filters used in calculating the spectrum.\n\nOverall, this graph provides a visual representation of how the power of the signal is distributed across different frequencies, with specific frequencies showing higher power levels, indicative of the signal's characteristics in the frequency domain.\n\nFigure 7.4 Calculation of noise spectrum.\n\n#### Solution\n\n(a) The human voice exhibits frequencies from 20 Hz to 20 kHz. Since women's voices contain stronger high-frequency components, we expect the two spectra to differ as shown in Fig. 7.5(a). In the time domain, we observe faster changes in women's voices [Fig. 7.5(b)].\n(b) The averaging time must be long enough to include a sufficient number of cycles of the lowest frequencies. That is, the averaging must capture the slowest dynamics in the signal. We must therefore choose $T$ to be at least about 10 cycles of 20 Hz, i.e., roughly 500 ms.\n\nAs with the definition of $P_{av}$ in (7.3), it is customary to eliminate $R_{L}$ from $S_{x}(f)$. Thus, since each value on the plot in Fig. 7.4(b) is measured for a 1-Hz bandwidth, $S_{x}(f)$ is expressed in $\\mathrm{V}^{2} / \\mathrm{Hz}$ rather than W/Hz. It is also common to take the square root of $S_{x}(f)$, expressing the result in $\\mathrm{V} / \\sqrt{\\mathrm{Hz}}$. For example, we say that the input noise voltage of an amplifier at 100 MHz is equal to $3 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}}$, simply to mean that the average power in a 1-Hz bandwidth at 100 MHz is equal to $\\left(3 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2}$.\n\nFigure 7.6 White spectrum description:\n\nThe graph in Figure 7.6 represents a 'white spectrum' or white noise power spectral density (PSD). This type of graph is a frequency-domain representation, specifically showing the PSD of a noise signal.\n\n1. **Type of Graph and Function:**\n   - This is a frequency-domain plot, specifically a power spectral density (PSD) graph.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis is labeled as 'f,' representing frequency, typically in hertz (Hz).\n   - The vertical axis is labeled as 'S_n(f),' which represents the power spectral density, often expressed in units of V²/Hz or W/Hz.\n   - The scale of both axes is linear.\n\n3. **Overall Behavior and Trends:**\n   - The graph shows a constant value across all frequencies, indicating that the noise power is uniformly distributed across the frequency spectrum. This flat line is characteristic of white noise, where the power spectral density does not change with frequency.\n\n4. **Key Features and Technical Details:**\n   - There are no peaks, valleys, or inflection points since the graph is a flat line.\n   - The graph implies that the noise has equal power at all frequencies within the band of interest.\n   - The flat nature of the spectrum suggests infinite total power if integrated over an infinite frequency range, which is a theoretical concept since practical systems have limited bandwidth.\n\n5. **Annotations and Specific Data Points:**\n   - There are no specific annotations or markers on the graph, as it is a simple representation of a white noise spectrum.\n   - The graph is a typical illustration of the concept of white noise, used to explain its uniform power distribution across frequencies.\n\nAn example of a common type of noise PSD is the \"white spectrum,\" also called white noise. Shown in Fig. 7.6, such a PSD displays the same value at all frequencies (similar to white light). Strictly speaking, we note that white noise does not exist because the total area under the power spectral density, i.e., the total power carried by the noise, is infinite. In practice, however, any noise spectrum that is flat in the band of interest is usually called white.\n\nThe PSD is a powerful tool in analyzing the effect of noise in circuits, especially in conjunction with the following theorem.\n\nTheorem: If a signal with spectrum $S_{x}(f)$ is applied to a linear time-invariant system with transfer function $H(s)$, then the output spectrum is given by\n\n$$\nS_{Y}(f) = S_{x}(f)|H(f)|^{2}\n$$\n\nwhere $H(f) = H(s=2 \\pi j f)$. The proof can be found in textbooks on signal processing or communications.\n\nSomewhat similar to the relation $Y(s) = X(s) H(s)$, this theorem agrees with our intuition that the spectrum of the signal should be \"shaped\" by the transfer function of the system (Fig. 7.7). For example, as illustrated in Fig. 7.8, since regular telephones have a bandwidth of approximately 4 kHz, they suppress the high-frequency components of the caller's voice. Note that, owing to its limited bandwidth, $x_{\\text{out}}(t)$ exhibits slower changes than does $x_{\\text{in}}(t)$. This bandwidth limitation sometimes makes it difficult to recognize the caller's voice.\n\nFigure 7.7 description:\n\nThe diagram in Figure 7.7 illustrates the concept of noise shaping by a transfer function. It consists of three parts, each representing a different stage of the frequency response transformation.\n\n1. **Type of Graph and Function:**\n   - The graph is a frequency response diagram showing how a signal's spectrum is shaped by a system's transfer function.\n\n2. **Axes Labels and Units:**\n   - Each part of the diagram has the horizontal axis labeled as frequency \\( f \\), though specific units are not provided, it is typically in hertz (Hz).\n\n3. **Overall Behavior and Trends:**\n   - **First Part (Left):** The initial spectrum \\( S_x(f) \\) is shown as a flat, constant value across a certain frequency range, indicating a uniform distribution of power across these frequencies.\n   - **Middle Part:** The transfer function \\( |H(f)|^2 \\) is depicted with a bell-shaped curve with two peaks. This suggests that the system emphasizes certain frequencies more than others, corresponding to the peaks.\n   - **Last Part (Right):** The resulting spectrum \\( S_y(f) \\) after the transfer function is applied shows a shaped spectrum with peaks at the same frequencies as \\( |H(f)|^2 \\), indicating that these frequencies are emphasized in the output.\n\n4. **Key Features and Technical Details:**\n   - The flat spectrum \\( S_x(f) \\) suggests an input signal with equal power across a range of frequencies.\n   - The transfer function \\( |H(f)|^2 \\) has a double-peaked shape, indicating selective amplification or attenuation at certain frequencies.\n   - The output spectrum \\( S_y(f) \\) reflects the shaping effect of the transfer function, with noticeable peaks aligning with those of \\( |H(f)|^2 \\).\n\n5. **Annotations and Specific Data Points:**\n   - No specific numerical values or annotations are provided, but the emphasis is on the transformation process from \\( S_x(f) \\) to \\( S_y(f) \\) through \\( |H(f)|^2 \\).\n\nThis diagram effectively demonstrates how a transfer function can shape the spectrum of a signal, emphasizing certain frequency components while suppressing others.\n\nFigure 7.7 Noise shaping by a transfer function.\n\nSince $S_{x}(f)$ is an even function of $f$ for real $x(t)$, as depicted in Fig. 7.9, the total power carried by $x(t)$ in the frequency range $\\left[f_{1}, f_{2}\\right]$ is equal to\n\n$$\nP_{f_1, f_2} = \\int_{-f_{2}}^{-f_{1}} S_{x}(f) df + \\int_{+f_{1}}^{+f_{2}} S_{x}(f) df = \\int_{+f_{1}}^{+f_{2}} 2 S_{x}(f) df\n$$\n\nFigure 7.9(a) description:\n\nThe graph labeled \\( (a) \\) is a two-sided noise spectrum plot. It represents the spectral power density \\( S_X(f) \\) as a function of frequency \\( f \\). The plot is symmetric about the vertical axis, indicating that it includes both positive and negative frequencies. This symmetry is typical of two-sided spectra, where negative frequencies are mirrored and combined with positive frequencies.\n\n**Axes Labels and Units:**\n   - The horizontal axis represents frequency \\( f \\), with specific points marked as \\(-f_2, -f_1, 0, f_1,\\) and \\( f_2 \\). While no units are specified, frequency is typically measured in hertz (Hz).\n   - The vertical axis represents the spectral power density \\( S_X(f) \\), which may be measured in units such as watts per hertz (W/Hz) or decibels (dB).\n\n**Overall Behavior and Trends:**\n   - The graph shows a central"
},
{
    "text": "The versatility of the average power concept increases when it pertains to the frequency composition of noise. For instance, the noise produced by a group of men generally has weaker high-frequency elements compared to that generated by a group of women. This distinction is discernible through the \"spectrum,\" also known as the \"power spectral density\" (PSD), which illustrates the distribution of power across various frequencies within a signal. Specifically, the PSD, denoted as $S_{x}(f)$, of a noise waveform $x(t)$, represents the average power of $x(t)$ within a one-hertz bandwidth centered at frequency $f$. As depicted in Fig. 7.4(a), the process involves passing $x(t)$ through a bandpass filter with a center frequency of $f_{1}$ and a bandwidth of 1 Hz, squaring the resulting signal $x_{f 1}(t)$, and averaging this squared signal over an extended period to obtain $S_{x}\\left(f_{1}\\right)$. Repeating this for bandpass filters with various center frequencies constructs the complete shape of $S_{x}(f)$ [Fig. 7.4(b)]. Commonly, $S_{x}(f)$ is measured in watts per hertz. The total area beneath the $S_{x}(f)$ curve signifies the total power carried by the signal or noise across all frequencies.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of male and female voices. What does the difference imply about their respective time-domain waveforms?\n(b) Estimate the averaging time, $T$, as stated in Eq. (7.3) for voice signals.\n\n[The original descriptions of the figures are not included here as they are not part of the rephrased text.]\n\n#### Solution\n\n(a) The human voice spans frequencies from 20 Hz to 20 kHz. Women's voices, containing stronger high-frequency components, would thus show a different spectrum compared to men's, as exemplified in Fig. 7.5(a). This translates into the time domain as faster fluctuations in women's voices [Fig. 7.5(b)].\n(b) The averaging time should be sufficient to capture a considerable number of cycles of the lowest frequencies. This means that the averaging process must account for the slowest variations in the signal. Therefore, $T$ should be at least around 10 cycles of 20 Hz, approximately 500 ms.\n\nSimilar to the definition of $P_{a v}$ in (7.3), it is standard practice to remove $R_{L}$ from $S_{x}(f)$. Consequently, since each point on the plot in Fig. 7.4(b) corresponds to a 1-Hz bandwidth, $S_{x}(f)$ is reported in $\\mathrm{V}^{2} / \\mathrm{Hz}$ instead of W/Hz. Additionally, it is usual to take the square root of $S_{x}(f)$, expressing the result in $\\mathrm{V} / \\sqrt{\\mathrm{Hz}}$. For instance, when stating that the input noise voltage of an amplifier at 100 MHz is $3 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}}$, it implies that the average power within a 1-Hz bandwidth at 100 MHz equals $\\left(3 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2}$.\n\n[The original descriptions of the figures are not included here as they are not part of the rephrased text.]\n\nThe PSD is an invaluable tool for analyzing noise impact in circuits, particularly when used in conjunction with the following theorem.\n\nTheorem: If a signal with spectrum $S_{x}(f)$ is processed by a linear time-invariant system with a transfer function $H(s)$, the output spectrum is determined by\n\n$$\n\\begin{equation*}\nS_{Y}(f)=S_{x}(f)|H(f)|^{2} \\tag{7.4}\n\\end{equation*}\n$$\n\nwhere $H(f)=H(s=2 \\pi j f)$. Proof of this theorem can be found in signal processing or communications textbooks, e.g., [1].\n\nThis theorem resonates with our understanding that the signal's spectrum should be \"shaped\" by the system's transfer function (Fig. 7.7). For example, as depicted in Fig. 7.8, standard telephones, with a bandwidth of roughly 4 kHz, filter out the high-frequency components of the speaker's voice. Consequently, the output signal $x_{\\text {out }}(t)$ exhibits slower changes compared to the input $x_{i n}(t)$. Such bandwidth limitations can occasionally make it challenging to discern the speaker's voice.\n\nSince $S_{x}(f)$ is an even function of $f$ for real $x(t)$ [1], as shown in Fig. 7.9, the total power of $x(t)$ within the frequency range $\\left[f_{1} f_{2}\\right]$ is given by\n\n$$\n\\begin{align*}\nP_{f 1, f 2} & =\\int_{-f_{2}}^{-f_{1}} S_{x}(f) d f+\\int_{+f_{1}}^{+f_{2}} S_{x}(f) d f  \\tag{7.5}\\\\\n& =\\int_{+f_{1}}^{+f_{2}} 2 S_{x}(f) d f \\tag{7.6}\n\\end{align*}\n$$\n\n[The original descriptions of the figures are not included here as they are not part of the rephrased text.]\n\nIn actuality, the integral in (7.6) corresponds to the measurement made by a power meter that senses the output of a bandpass filter between $f_{1}$ and $f_{2}$. This process involves folding the negative-frequency part of the spectrum around the vertical axis and adding it to the positive-frequency part. We refer to the representation in Fig. 7.9(a) as the \"two-sided\" spectrum and that in Fig. 7.9(b) as the \"one-sided\" spectrum. For instance, the two-sided white spectrum of Fig. 7.6 has a one-sided counterpart presented in Fig. 7.10.\n\n[The original descriptions of the figures are not included here as they are not part of the rephrased text.]\n\nIn summary, the spectrum indicates the power contained within a narrow bandwidth at each frequency, providing insight into the expected variability of the waveform over time."
},
{
    "text": "The concept of average power gains versatility when defined in terms of the frequency content of noise. Noise produced by a group of men has weaker high-frequency components compared to that produced by a group of women, a distinction noticeable in the \"spectrum\" of each noise type. Also referred to as the \"power spectral density\" (PSD), the spectrum indicates the power the signal carries at each frequency. Specifically, the PSD, \\( S_{x}(f) \\), of a noise waveform \\( x(t) \\), is defined as the average power carried by \\( x(t) \\) in a one-hertz bandwidth around \\( f \\). As depicted in Fig. 7.4(a), we feed \\( x(t) \\) into a bandpass filter centered at \\( f_{1} \\) with a one-hertz bandwidth, square the output \\( x_{f1}(t) \\), and compute the average over an extended period to obtain \\( S_{x}(f_{1}) \\). By repeating this process with bandpass filters of different center frequencies, we derive the overall shape of \\( S_{x}(f) \\) [Fig. 7.4(b)]. Generally, \\( S_{x}(f) \\) is measured in watts per hertz. The total area under \\( S_{x}(f) \\) represents the power carried by the signal (or the noise) across all frequencies; that is, the total power.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of voice for men and women. What does the difference imply about their time-domain waveforms?\n(b) Estimate the averaging time, \\( T \\), in Eq. (7.3) for voice signals.\n\nFigure 7.4(a) illustrates the process of shaping a signal's spectrum using a band-pass filter. The system includes the following main components:\n\n1. **Input Signal, \\( x(t) \\):**\n   The diagram starts with an input signal, denoted as \\( x(t) \\), depicted as a waveform with varying amplitude over time.\n\n2. **Band-Pass Filter:**\n   The input signal \\( x(t) \\) is fed into a band-pass filter with a specific frequency range centered at \\( f_1 \\) and a one-hertz bandwidth. This filter allows only frequencies within this narrow band to pass, isolating a portion of the signal's frequency spectrum.\n\n3. **Filtered Signal, \\( x_{f1}(t) \\):**\n   The output from the band-pass filter is a filtered version of the input signal, denoted as \\( x_{f1}(t) \\). This signal is shown as a sinusoidal waveform, indicating that only the frequency components around \\( f_1 \\) are present.\n\n4. **Squaring Block:**\n   The filtered signal \\( x_{f1}(t) \\) is then passed through a squaring block, which computes the square of the amplitude of resulting in \\( |x_{f1}(t)|^2 \\). Squaring the signal emphasizes the power of the signal components.\n\n5. **Output Signal, \\( |x_{f1}(t)|^2 \\):**\n   The final output is the squared amplitude of the filtered signal, \\( |x_{f1}(t)|^2 \\), shown as a waveform with increased amplitude variations over time. This represents the power of the signal components within the band-pass filter's frequency range.\n\nThe signal flow starts with the input \\( x(t) \\), processed by the band-pass filter to produce \\( x_{f1}(t) \\), then squared to yield \\( |x_{f1}(t)|^2 \\). The primary function of this system is to isolate a specific frequency component from the input signal using a band-pass filter and analyze the power of this component by squaring its amplitude. This process is useful in spectral analysis where the power at specific frequency bands is of interest.\n\nFigure 7.4(b) depicts the noise spectrum \\( S_x(f) \\) of a signal.\n\nThe spectrum displays a series of peaks and valleys, indicating varying power levels at different frequencies. The graph starts with a peak at \\( f_1 \\), followed by a dip at \\( f_2 \\), then another peak, and gradually decreases as the frequency increases towards \\( f_n \\). This suggests that the signal has strong frequency components at certain frequencies, which diminish as the frequency increases.\n\nPeaks are observed at specific frequencies (\\( f_1, f_2, \\ldots, f_n \\)), marked by vertical dashed lines. The highest peak is located between \\( f_2 \\) and \\( f_n \\), indicating the frequency with the most power. The spectrum shows a decreasing trend in power as the frequency increases beyond the highest peak.\n\nOverall, this graph provides a visual representation of how the power of the signal is distributed across different frequencies, with specific frequencies showing higher power levels, indicative of the signal's characteristics in the frequency domain.\n\nFigure 7.4 Calculation of noise spectrum.\n\n#### Solution\n\n(a) The human voice exhibits frequencies from 20 Hz to 20 kHz. Since women's voices contain stronger high-frequency components, we expect the two spectra to differ as shown in Fig. 7.5(a). In the time domain, we observe faster changes in women's voices [Fig. 7.5(b)].\nFigure 7.5(a) compares the spectral characteristics of men's and women's voices. The x-axis represents frequency \\( f \\) in hertz (Hz), ranging from 20 Hz to 20 kHz, covering the typical frequency range of human hearing. The y-axis represents the spectral power \\( S_x(f) \\), indicating the power or intensity of the sound at different frequencies.\n\nThe graph displays two curves: one for men's voices and one for women's voices. The curve for men's voices starts at a lower frequency with higher power, peaks at a mid-frequency range, and then decreases as the frequency increases towards 20 kHz. In contrast, the curve for women's voices shows a different trend, with lower power at low frequencies, increasing to a peak at higher frequencies compared to men's voices, before tapering off towards 20 kHz.\n\nOverall, the graph illustrates that men's voices tend to have stronger low-frequency components, while women's voices exhibit stronger high-frequency components. This difference is indicative of the typical spectral characteristics of male and female voices, with women's voices generally having higher frequency components due to physiological differences in vocal cord structure.\n\nFigure 7.5(a) Spectra of men's and women's voices, and (b) corresponding time-domain waveforms.\n(b) The averaging time must be long enough to include a sufficient number of cycles of the lowest frequencies. That is, the averaging must capture the slowest dynamics in the signal. We must therefore choose \\( T \\) to be at least about 10 cycles of 20 Hz, i.e., roughly 500 ms.\n\nAs with the definition of \\( P_{av} \\) in (7.3), it is customary to eliminate \\( R_L \\) from \\( S_x(f) \\). Thus, since each value on the plot in Fig. 7.4(b) is measured for a 1-Hz bandwidth, \\( S_x(f) \\) is expressed in \\( \\mathrm{V}^2/\\mathrm{Hz} \\) rather than W/Hz. It is also common to take the square root of \\( S_x(f) \\), expressing the result in \\( \\mathrm{V}/\\sqrt{\\mathrm{Hz}} \\). For example, we say that the input noise voltage of an amplifier at 100 MHz is equal to \\( 3 \\mathrm{nV}/\\sqrt{\\mathrm{Hz}} \\), simply to mean that the average power in a 1-Hz bandwidth at 100 MHz is equal to \\( (3 \\times 10^{-9})^2 \\mathrm{~V}^2 \\).\n\nFigure 7.6 represents a 'white spectrum' or white noise power spectral density (PSD). This type of graph is a frequency-domain representation, specifically showing the PSD of a noise signal.\n\nThe graph shows a constant value across all frequencies, indicating that the noise power is uniformly distributed across the frequency spectrum. This flat line is characteristic of white noise, where the power spectral density does not change with frequency.\n\nThe PSD is a powerful tool in analyzing the effect of noise in circuits, especially in conjunction with the following theorem.\n\nTheorem: If a signal with spectrum \\( S_x(f) \\) is applied to a linear time-invariant system with transfer function \\( H(s) \\), then the output spectrum is given by\n\n$$\nS_Y(f) = S_x(f) |H(f)|^2\n$$\n\nwhere \\( H(f) = H(s = 2 \\pi j f) \\). The proof can be found in textbooks on signal processing or communications.\n\nSomewhat similar to the relation \\( Y(s) = X(s) H(s) \\), this theorem agrees with our intuition that the spectrum of the signal should be \"shaped\" by the transfer function of the system (Fig. 7.7). For example, as illustrated in Fig. 7.8, since regular telephones have a bandwidth of approximately 4 kHz, they suppress the high-frequency components of the caller's voice. Note that, owing to its limited bandwidth, \\( x_{\\text{out}}(t) \\) exhibits slower changes than does \\( x_{\\text{in}}(t) \\). This bandwidth limitation sometimes makes it difficult to recognize the caller's voice.\n\nFigure 7.7 Noise shaping by a transfer function.\n\nSince \\( S_x(f) \\) is an even function of \\( f \\) for real \\( x(t) \\), as depicted in Fig. 7.9, the total power carried by \\( x(t) \\) in the frequency range \\([f_1, f_2]\\) is equal to\n\n$$\nP_{f_1, f_2} = \\int_{-f_2}^{-f_1} S_x(f) df + \\int_{+f_1}^{+f_2} S_x(f) df = \\int_{+f_1}^{+f_2} 2 S_x(f) df\n$$\n\nFigure 7.9(a) is a two-sided noise spectrum plot. It represents the spectral power density \\( S_X(f) \\) as a function of frequency \\( f \\). The plot is symmetric about the vertical axis, indicating that it includes both positive and negative frequencies. This symmetry is typical of two-sided spectra, where negative frequencies are mirrored and combined with positive frequencies.\n\nThe graph shows a central peak at the origin (0 frequency), indicating a significant spectral component at this frequency. On either side of the central peak, there are two additional peaks at frequencies \\( \\pm f_1 \\) and \\( \\pm f_2 \\), suggesting prominent spectral components at these frequencies as well. The power density decreases as the frequency moves away from these peaks, showing a typical bandpass filter shape that emphasizes certain frequency ranges while attenuating others.\n\nFigure 7.9(b) is a one-sided noise spectrum graph. It represents the spectral density \\( S_X(f) \\) on the vertical axis against frequency \\( f \\) on the horizontal axis. The axes are not labeled with specific units, but it is implied that the frequency is in hertz (Hz). The graph uses a linear scale for both axes.\n\nThe graph begins at a high value at frequency \\( f = 0 \\), indicating a peak at this point. As the frequency increases, the spectral density decreases, forming a downward slope. There is a noticeable peak between the frequencies \\( f_1 \\) and \\( f_2 \\), suggesting a region where the noise power is concentrated. Beyond \\( f_2 \\), the spectral density continues to decrease.\n\nThe graph does not provide specific numerical values or annotations for the peaks or the exact frequencies of \\( f_1 \\) and \\( f_2 \\). However, the presence of vertical dashed lines at these points highlights their significance in the spectrum.\n\nIn fact, the integral in (7.6) is the quantity measured by a power meter sensing the output of a bandpass filter between \\( f_1 \\) and \\( f_2 \\). That is, the negative-frequency part of the spectrum is folded around the vertical axis and added to the positive-frequency part. We call the representation of Fig. 7.9(a) the \"two-sided\" spectrum and that of Fig. 7.9(b) the \"one-sided\" spectrum. For example, the two-sided white spectrum of Fig. 7.6 has the one-sided counterpart shown in Fig. 7.10.\n\nThe left graph (two-sided spectrum) shows a rectangular shape centered around the frequency axis, extending equally into both positive and negative frequencies. The amplitude of the spectral density is \\( \\frac{\\eta}{2} \\). The right graph (one-sided spectrum) shows the spectrum folded around the vertical axis, resulting in a rectangular shape that only extends into the positive frequency domain. The amplitude of the spectral density is \\( \\eta \\).\n\nThis transformation indicates that the total power is conserved, as the negative frequency components are added to the positive frequency components in the one-sided spectrum.\n\nIn summary, the spectrum shows the power carried in a small bandwidth at each frequency, revealing how fast the waveform is expected to vary in the time domain."
},
{
    "text": "The versatility of the average power concept increases when defined with respect to the frequency composition of noise. For instance, the noise produced by a group of men typically has less prominent high-frequency components compared to the noise from a group of women, a distinction that can be discerned from the \"spectrum\" associated with each type of noise. This spectrum, also known as the \"power spectral density\" (PSD), illustrates the distribution of power across various frequencies within a signal. Specifically, the PSD, denoted as $S_{x}(f)$, for a noise waveform $x(t)$, is defined as the average power that $x(t)$ exhibits within a one-hertz bandwidth centered at frequency $f$. As depicted in Fig. 7.4(a), we process $x(t)$ through a bandpass filter with a center frequency of $f_{1}$ and a bandwidth of 1 Hz. The filtered output, $x_{f 1}(t)$, is then squared, and its average is computed over an extended period to yield $S_{x}\\left(f_{1}\\right)$. By repeating this process with bandpass filters of different center frequencies, we obtain the complete profile of $S_{x}(f)$, as shown in Fig. 7.4(b). Typically, $S_{x}(f)$ is quantified in watts per hertz. The aggregate area beneath the curve of $S_{x}(f)$ signifies the total power conveyed by the signal (or noise) across all frequencies, i.e., the aggregate power."
},
{
    "text": "Image Descriptions: Textual descriptions of any images referenced in the [Context Provided] section have been converted. Additionally, the text within [Context Provided] has been rephrased to retain the original meaning and length.\n\n---[Task]---\nRephrase the provided text in [Context Provided] Section, ensuring the rephrased version keeps the original meaning and length. Output only the rephrased text.\n\n---[Context Provided]---\nThe text to be rephrased:\n\nThe concept of average power assumes a broader scope when considering the frequency composition of noise. The noise produced by men typically includes weaker high-frequency elements compared to that generated by women, a distinction evident in the \"spectrum\" of each noise type. Known as the \"power spectral density\" (PSD), the spectrum reveals the amount of power the signal holds at each frequency. Specifically, the PSD, denoted as \\(S_{x}(f)\\), for a noise waveform \\(x(t)\\) represents the average power carried by \\(x(t)\\) within a one-hertz bandwidth centered around \\(f\\). This is demonstrated in Fig. 7.4(a), where we apply \\(x(t)\\) to a bandpass filter with a central frequency of \\(f_{1}\\) and a bandwidth of 1 Hz, square the output, \\(x_{f 1}(t)\\), and calculate the average over a long duration to obtain \\(S_{x}\\left(f_{1}\\right)\\). By repeating this process with bandpass filters of varying central frequencies, we obtain the comprehensive shape of \\(S_{x}(f)\\) [Fig. 7.4(b)]. Generally, \\(S_{x}(f)\\) is measured in watts per hertz. The total area under \\(S_{x}(f)\\) signifies the overall power of the signal (or noise) across all frequencies; that is, the total power.\n\n#### Example 7.1\n\n(a) Outline the frequency spectrum for both men's and women's voices. How does the discrepancy between their spectrums reflect on their time-domain waveforms?\n(b) Estimate the averaging time, \\(T\\), required in Eq. (7.3) for voice signals.\n\nimage_name:Figure 7.4(a)\ndescription:The diagram marked '(a)' depicts the process of constructing a signal's spectrum using a band-pass filter. The system is made up of the following principal components:\n\n1. **Input Signal, \\(x(t):\\)**\n- The diagram initiates with an input signal, designated as \\(x(t)\\), a time-domain waveform. The waveform is illustrated with varying amplitude over time.\n\n2. **Band-Pass Filter:**\n- The input signal \\(x(t)\\) is fed into a band-pass filter. The filter is defined by a specific frequency range, centered at \\(f_{1}\\), and has a bandwidth of 1 Hz. The band-pass filter allows only frequencies within this narrow range to pass through, isolating a segment of the signal's frequency spectrum.\n\n3. **Filtered Signal, \\(x_{f1}(t):\\)**\n- The output from the band-pass filter is a modified version of the input signal, referred to as \\(x_{f1}(t)\\). This output is shown as a sinusoidal waveform, indicating that only the frequency components around \\(f_{1}\\) are present.\n\n4. **Squaring Block:**\n- The filtered signal \\(x_{f1}(t)\\) is then squared, resulting in \\(|x_{f1}(t)|^2\\). Squaring the signal tends to emphasize the power of the signal components.\n\n5. **Output Signal, \\(|x_{f1}(t)|^2:\\)**\n- The final output is the squared amplitude of the filtered signal, \\(|x_{f1}(t)|^2\\), which is depicted as a waveform with enhanced amplitude variations over time. This represents the power of the signal components within the band-pass filter's frequency range.\n\n**Flow of Information:**\n- The information flow begins with the input \\(x(t)\\), which is processed by the band-pass filter to produce \\(x_{f1}(t)\\). The filtered signal is then squared to yield \\(|x_{f1}(t)|^2\\). The flow is linear, without any feedback loops or additional control mechanisms.\n\n**Overall System Function:**\n- The main function of this system is to isolate a specific frequency component from the input signal using a band-pass filter and then to assess the power of this component by squaring its amplitude. This process is valuable in spectral analysis, where the power at specific frequency bands is a focus.\nimage_name:Figure 7.4(b)\ndescription:The graph labeled (b) presents a frequency spectrum plot that illustrates the noise spectrum \\(S_x(f)\\) of a signal.\n\n1. **Type of Graph and Function:**\n- This is a frequency-domain graph that represents the power spectral density (PSD) of a signal, \\(S_x(f)\\).\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\(f\\), usually in Hertz (Hz).\n- The vertical axis denotes the power spectral density, \\(S_x(f)\\), commonly in watts per hertz (W/Hz).\n- Specific scales are not mentioned, but the axes likely use a linear scale.\n\n3. **Overall Behavior and Trends:**\n- The spectrum features a series of peaks and valleys, indicating different power levels at various frequencies.\n- The graph starts with a peak at \\(f_1\\), followed by a dip at \\(f_2\\), then another peak, and gradually diminishes as frequency ascends towards \\(f_n\\).\n\n4. **Key Features and Technical Details:**\n- Peaks are observed at particular frequencies (\\(f_1\\), \\(f_2\\), ..., \\(f_n\\)), marked by vertical dashed lines.\n- The highest peak is located between \\(f_2\\) and \\(f_n\\), indicating the frequency with the most power.\n- The spectrum demonstrates a declining trend in power as frequency surpasses the highest peak.\n\n5. **Annotations and Specific Data Points:**\n- The graph is annotated with open circles at key frequencies, highlighting significant points in the spectrum.\n- These markers likely correspond to the center frequencies of band-pass filters used to calculate the spectrum.\n\nOverall, this graph visually conveys the distribution of signal power across different frequencies, with certain frequencies displaying higher power levels, indicative of the signal's characteristics in the frequency domain.\n\nFigure 7.4 Calculation of noise spectrum.\n\n#### Solution\n\n(a) Human speech spans frequencies from 20 Hz to 20 kHz. Given that women's voices possess stronger high-frequency elements, the two spectrums should exhibit distinct differences as depicted in Fig. 7.5(a). In the time domain, we notice quicker fluctuations in women's voices [Fig. 7.5(b)].\nimage_name:Figure 7.5 (a)\ndescription:The graph in Figure 7.5 (a) is a frequency spectrum plot that contrasts the spectral attributes of men's and women's voices. The x-axis represents frequency \\( f \\) in hertz (Hz), extending from 20 Hz to 20 kHz, encompassing the typical range of human hearing. The y-axis represents the spectral power \\( S_x(f) \\), with units not specified, indicating the power or intensity of the sound at various frequencies.\n\nThe graph illustrates two curves: one for men's voices and one for women's voices. The curve for men's voices initiates at a lower frequency with higher power, reaches a peak at a mid-frequency range, and then diminishes as frequency approaches 20 kHz. Conversely, the curve for women's voices portrays a divergent pattern, with lower power at low frequencies, increasing to a peak at higher frequencies relative to men's voices, and then decreasing towards 20 kHz.\n\nOverall, the graph indicates that men's voices tend to have stronger low-frequency components, while women's voices show stronger high-frequency components. This difference suggests physiological differences in vocal cord structure, accounting for the distinct spectral characteristics of male and female voices.\n\nimage_name:Men's Voice\ndescription:The graph labeled \"Men's Voice\" is a time-domain waveform depiction of a male voice signal. The x-axis is labeled as 't' and denotes time, while the y-axis is labeled as 'x(t)' and signifies the amplitude of the voice signal. The waveform illustrates oscillations typical of a sound signal, displaying positive and negative amplitude fluctuations around a central axis, indicating the presence of compressions and rarefactions in the sound wave.\n\nThe waveform features a complex shape with multiple peaks and valleys, suggesting the presence of various frequency components. The amplitude of the oscillations varies over time, indicating changes in loudness and pitch in the voice. The waveform does not exhibit a simple periodic pattern, reflecting the inherent variability and complexity of human speech.\n\nKey features include several prominent peaks and valleys, which may correspond to louder and softer moments in the speech. The waveform crosses the zero amplitude line multiple times, indicating phase changes in the sound wave. This graph captures the typical attributes of a male voice, possibly highlighting lower frequency components as suggested by the context provided.\n\nimage_name:Women's Voice\ndescription:This graph illustrates a time-domain waveform representing a woman's voice. The x-axis is labeled 't' and denotes time, and the y-axis is labeled 'x(t)' and indicates the amplitude. The waveform is plotted on a linear scale, capturing the fluctuations in amplitude over time.\n\n**Overall Behavior and Trends:**\nThe waveform demonstrates a complex pattern of oscillations, characteristic of human speech. It does not adhere to a simple periodic pattern, reflecting the natural variability and intricacy of vocal sounds. The waveform shows multiple peaks and valleys, indicating moments of higher and lower amplitude, respectively. These fluctuations suggest changes in loudness and pitch typical in speech.\n\n**Key Features and Technical Details:**\n- **Zero Crossings:** The waveform crosses the zero amplitude line several times, indicating phase changes in the sound wave.\n- **Peaks and Valleys:** There are several pronounced peaks and valleys, which could correspond to louder and softer parts of the speech.\n- **Frequency Components:** The context suggests an emphasis on higher frequency components typical of a woman's voice, compared to a man's voice, which generally emphasizes lower frequencies.\n\n**Annotations and Specific Data Points:**\nThe graph lacks specific numerical annotations or reference lines, but it visually highlights the dynamic range and complexity of a woman's vocal waveform. The waveform's structure suggests the inclusion of a wide range of frequencies and amplitudes, capturing the essence of a woman's voice in speech.\n\nFigure 7.5 (a) Spectra of men's and women's voices, and (b) corresponding time-domain waveforms.\n(b) The averaging time should be lengthy enough to encompass a sufficient number of cycles of the lowest frequencies. In other words, the averaging should capture the slowest dynamics in the signal. Consequently, we must choose \\(T\\) to be at least approximately 10 cycles of 20 Hz, or roughly 500 ms.\n\nSimilar to the definition of \\(P_{a v}\\) in Eq. (7.3), it is customary to exclude \\(R_{L}\\) from \\(S_{x}(f)\\). Therefore, since each value on the plot in Fig. 7.4(b) is measured for a 1-Hz bandwidth, \\(S_{x}(f)\\) is expressed in \\(\\mathrm{V}^{2} / \\mathrm{Hz}\\) rather than W/Hz. It is also typical to take the square root of \\(S_{x}(f)\\), expressing the outcome in \\(\\mathrm{V} / \\sqrt{\\mathrm{Hz}}\\). For example, we state that the input noise voltage of an amplifier at 100 MHz is equivalent to \\(3 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}}\\), simply meaning that the average power in a 1-Hz bandwidth at 100 MHz is equal to \\(\\left(3 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2}\\).\nimage_name:Figure 7.6 White spectrum\ndescription:This graph in Figure 7.6 is a frequency-domain representation of a 'white spectrum' or white noise power spectral density (PSD). It is a graphical depiction of the PSD of a noise signal.\n\n1. **Type of Graph and Function:**\n- The graph is a frequency-domain plot, specifically a power spectral density (PSD) graph.\n\n2. **Axes Labels and Units:**\n- The horizontal axis is labeled 'f,' representing frequency, generally in hertz (Hz).\n- The vertical axis is labeled 'S_n(f),' indicating the power spectral density, often expressed in units of V²/Hz or W/Hz.\n- The scale of both axes is linear.\n\n3. **Overall Behavior and Trends:**\n- The graph depicts a constant value across all frequencies, illustrating that the noise power is uniformly distributed across the frequency spectrum. This constant line is characteristic of white noise, where the power spectral density does not vary with frequency.\n\n4. **Key Features and Technical Details:**\n- There are no peaks, valleys, or inflection points as the graph is a flat line.\n- The graph suggests that the noise has equal power at all frequencies within the band of interest.\n- The flat nature of the spectrum implies infinite total power when integrated over an infinite frequency range, which is a theoretical concept since practical systems have limited bandwidth.\n\n5. **Annotations and Specific Data Points:**\n- There are no specific annotations or markers on the graph as it is a simple representation of a white noise spectrum.\n- The graph is a typical illustration of the concept of white noise, demonstrating its uniform power distribution across frequencies.\n\nAn illustration of a common type of noise PSD is the \"white spectrum,\" also referred to as white noise. Shown in Fig. 7.6, such a PSD displays the same value at all frequencies (like white light). While white noise does not exist in reality due to the infinite total area under the power spectral density, representing the total power carried by the noise, the term \"white noise\" is commonly used to describe any noise spectrum that is flat within the band of interest.\n\nThe PSD is a valuable tool in analyzing the impact of noise in circuits, particularly when combined with the following theorem.\n\nTheorem: If a signal with spectrum \\(S_{x}(f)\\) is applied to a linear time-invariant system with transfer function \\(H(s)\\), then the output spectrum is given by\n\n$$\n\\begin{equation*}\nS_{Y}(f)=S_{x}(f)|H(f)|^{2} \\tag{7.4}\n\\end{equation*}\n$$\n\nwhere \\(H(f)=H(s=2 \\pi j f)\\). Proof can be found in textbooks on signal processing or communications, e.g., [1].\n\nSimilar to the relationship \\(Y(s)=X(s)H(s)\\), this theorem aligns with our intuition that the spectrum of the signal should be \"sculpted\" by the system's transfer function (Fig. 7.7). For instance, as illustrated in Fig. 7.8, regular telephones have a bandwidth of approximately 4 kHz, thus suppressing the high-frequency components of the caller's voice. Note that, due to its limited bandwidth, \\(x_{\\text {out }}(t)\\) exhibits slower changes than \\(x_{i n}(t)\\), which can sometimes make it challenging to discern the caller's voice.\nimage_name:Figure 7.7\ndescription:Figure 7.7 illustrates the concept of noise shaping by a transfer function. It consists of three sections, each representing a distinct stage of the frequency response transformation.\n\n1. **Type of Graph and Function:**\n- The graph is a frequency response diagram that shows how a signal's spectrum is influenced by a system's transfer function.\n\n2. **Axes Labels and Units:**\n- Each section of the diagram has the horizontal axis labeled as frequency \\( f \\), though specific units are not provided; it is generally in hertz (Hz).\n\n3. **Overall Behavior and Trends:**\n- **First Section (Left):** The initial spectrum \\( S_x(f) \\) is depicted as a flat, constant value across a certain frequency range, suggesting an even distribution of power across these frequencies.\n- **Middle Section:** The transfer function \\( |H(f)|^2 \\) is shown with a bell-shaped curve featuring two peaks. This indicates that the system emphasizes certain frequencies over others, corresponding to the peaks.\n- **Last Section (Right):** The resulting spectrum \\( S_y(f) \\) after the transfer function is applied demonstrates a shaped spectrum with peaks at the same frequencies as \\( |H(f)|^2 \\), indicating that these frequencies are amplified in the output.\n\n4. **Key Features and Technical Details:**\n- The flat spectrum \\( S_x(f) \\) suggests an input signal with equal power across a frequency range.\n- The transfer function \\( |H(f)|^2 \\) has a double-peaked shape, indicating selective enhancement or reduction at certain frequencies.\n- The output spectrum \\( S_y(f) \\) reflects the shaping effect of the transfer function, with noticeable peaks aligning with those of \\( |H(f)|^2 \\).\n\n5. **Annotations and Specific Data Points:**\n- No specific numerical values or annotations are provided, but the focus is on the transformation from \\( S_x(f) \\) to \\( S_y(f) \\) through \\( |H(f)|^2 \\).\n\nThis diagram effectively demonstrates how a transfer function can mold the spectrum of a signal, highlighting certain frequency components while suppressing others.\n\nFigure 7.7 Noise shaping by a transfer function.\nGiven that \\(S_{x}(f)\\) is an even function of \\(f\\) for real \\(x(t)\\) [1], as shown in Fig. 7.9, the total power carried by \\(x(t)\\) in the frequency range \\([f_1, f_2]\\) is equivalent to\n\n$$\n\\begin{align*}\nP_{f1, f2} & =\\int_{-f_2}^{-f_1} S_{x}(f) df + \\int_{+f_1}^{+f_2} S_{x}(f) df \\tag{7.5}\\\\\n& =\\int_{+f_1}^{+f_2} 2 S_{x}(f) df \\tag{7.6}\n\\end{align*}\n$$\n\nimage_name:x_in(t)\ndescription:This graph labeled \"x_in(t)\" depicts a time-domain waveform representing the input signal to a system, which could be an audio or other real-time signal.\n\n1. **Type of Graph and Function:**\n- The graph is a time-domain waveform graph.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents time, denoted as \"t,\" without specific units like seconds or milliseconds.\n- The vertical axis represents the amplitude of the signal, labeled as \"x_in(t),\" without specific units provided.\n\n3. **Overall Behavior and Trends:**\n- The waveform shows oscillations, indicating a signal with varying amplitude over time.\n- There are no clear trends of increasing or decreasing amplitude over time, suggesting a steady-state signal.\n\n4. **Key Features and Technical Details:**\n- The waveform exhibits several peaks and valleys, typical of a complex signal with multiple frequencies.\n- No specific numerical values or critical points are annotated on this graph.\n\n5. **Annotations and Specific Data Points:**\n- There are no additional annotations or markers on this graph, and no specific data points are highlighted.\n\nOverall, this waveform serves as the initial input signal before any processing"
},
{
    "text": "The notion of average power expands its utility when it is associated with the frequency composition of noise. The noise produced by a group of men possesses lesser high-frequency components compared to the noise generated by a group of women, a distinction that can be observed in the \"spectrum\" of each noise type. Known as the \"power spectral density\" (PSD), this spectrum delineates the amount of power carried by the signal at each frequency. Precisely, the PSD, \\( S_{x}(f) \\), of a noise waveform \\( x(t) \\) is the average power conveyed by \\( x(t) \\) across a one-hertz bandwidth surrounding \\( f \\). As depicted in Fig. 7.4(a), this is achieved by subjecting \\( x(t) \\) to a bandpass filter centered at \\( f_{1} \\) with a bandwidth of \\( 1-\\mathrm{Hz} \\). The output, \\( x_{f 1}(t) \\), is squared and its average is computed over a lengthy period to obtain \\( S_{x}\\left(f_{1}\\right) \\). By repeating this process with bandpass filters featuring various central frequencies, we obtain the complete shape of \\( S_{x}(f) \\) [Fig. 7.4(b)]. Typically, \\( S_{x}(f) \\) is gauged in watts per hertz. The total area beneath \\( S_{x}(f) \\) signifies the power conveyed by the signal (or noise) across all frequencies; in other words, the total power.\n\n#### Example 7.1\n\n(a) Portray the spectrum of voice for men and women. What does the divergence suggest regarding their time-domain waveforms?\n(b) Estimate the duration of the averaging time, \\( T \\), for voice signals.\n\nimage_name:Figure 7.4(a)\ndescription:Figure 7.4(a) illustrates the method of forming a signal's spectrum using a band-pass filter. The system encompasses the following principal components:\n\n1. **Input Signal, x(t):**\n- The process commences with an input signal, symbolized as \\( x(t) \\), which is a time-domain waveform. The waveform is represented graphically, with its amplitude fluctuating over time.\n\n2. **Band-Pass Filter:**\n- The input signal \\( x(t) \\) is channelled through a band-pass filter. Characterized by a frequency range, centered at \\( f_1 \\), and with a bandwidth of 1 Hz, this filter's role is to permit only the frequencies within this narrow range to pass, effectively extracting a segment of the signal's frequency spectrum.\n\n3. **Filtered Signal, x_{f1}(t):**\n- The output from the band-pass filter is a filtered version of the input signal, termed \\( x_{f1}(t) \\). This signal is depicted as a sinusoidal waveform, signifying the presence of frequency components around \\( f_1 \\).\n\n4. **Squaring Block:**\n- The filtered signal \\( x_{f1}(t) \\) is then passed through a squaring block. This block calculates the square of the signal's amplitude, resulting in \\( |x_{f1}(t)|^2 \\). Squaring the signal tends to highlight the power of the signal components.\n\n5. **Output Signal, |x_{f1}(t)|^2:**\n- The output is the squared amplitude of the filtered signal, \\( |x_{f1}(t)|^2 \\), depicted as a waveform with amplified amplitude variations over time. This represents the power of the signal components within the band-pass filter's frequency range.\n\n**Flow of Information:**\n- The information flow initiates with the input \\( x(t) \\), which is processed by the band-pass filter to yield \\( x_{f1}(t) \\). This filtered signal is then squared to give \\( |x_{f1}(t)|^2 \\). The flow of information is linear, without feedback loops or additional control mechanisms.\n\n**Overall System Function:**\n- The primary function of this system is to extract a specific frequency component from the input signal using a band-pass filter and then to evaluate the power of this component by squaring its amplitude. This process is advantageous in spectral analysis where the power at specific frequency bands is of interest.\nimage_name:Figure 7.4(b)\ndescription:Figure 7.4(b) presents a frequency spectrum plot that specifically portrays the noise spectrum \\( S_x(f) \\) of a signal.\n\n1. **Type of Graph and Function:**\n- This is a frequency-domain graph depicting the power spectral density (PSD) of a signal, \\( S_x(f) \\).\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency \\( f \\), usually in Hertz (Hz).\n- The vertical axis represents the power spectral density, \\( S_x(f) \\), typically in watts per hertz (W/Hz).\n- Specific scales for the axes are not mentioned, but both axes appear to be on a linear scale.\n\n3. **Overall Behavior and Trends:**\n- The spectrum exhibits a series of peaks and troughs, signifying fluctuating power levels at various frequencies.\n- The spectrum begins with a peak at \\( f_1 \\), followed by a dip at \\( f_2 \\), another peak, and then gradually diminishes as the frequency increases towards \\( f_n \\).\n- This indicates that the signal has robust frequency components at certain frequencies, which diminish as the frequency ascends.\n\n4. **Key Features and Technical Details:**\n- Peaks are visible at specific frequencies (\\( f_1 \\), \\( f_2 \\), ..., \\( f_n \\)), marked by vertical dashed lines.\n- The highest peak is situated between \\( f_2 \\) and \\( f_n \\), signifying the frequency with the greatest power.\n- The spectrum demonstrates a decreasing trend in power as the frequency exceeds the highest peak.\n\n5. **Annotations and Specific Data Points:**\n- The graph is annotated with open circles at key frequencies, highlighting significant points in the spectrum.\n- These markers correspond to the center frequencies of band-pass filters used in calculating the spectrum.\n\nOverall, this graph offers a visual depiction of how the power of the signal is dispersed across different frequencies, with specific frequencies exhibiting higher power levels, indicative of the signal's properties in the frequency domain.\n\nFigure 7.4 Calculation of noise spectrum.\n\n#### Solution\n\n(a) Human voices span frequencies from 20 Hz to 20 kHz. Given that women's voices contain more robust high-frequency components, we anticipate the two spectra to diverge as depicted in Fig. 7.5(a). In the time domain, we observe faster changes in women's voices [Fig. 7.5(b)].\nimage_name:Figure 7.5 (a)\ndescription:Figure 7.5(a) presents a frequency spectrum plot that contrasts the spectral attributes of men's and women's voices. The x-axis represents frequency \\( f \\) in hertz (Hz), spanning from 20 Hz to 20 kHz, which encompasses the typical hearing range of humans. The y-axis represents spectral power \\( S_x(f) \\), with the units unspecified, but they generally indicate the power or intensity of sound at different frequencies.\n\nThe plot features two curves: one for men's voices and another for women's voices. The curve for men's voices starts at a lower frequency with higher power, reaches a peak at a mid-frequency range, and then decreases as the frequency approaches 20 kHz. Conversely, the curve for women's voices displays a distinct pattern, with lower power at low frequencies, ascending to a peak at higher frequencies relative to men's voices, and then tapering off towards 20 kHz.\n\nOverall, the graph illustrates that men's voices tend to have stronger low-frequency components, while women's voices demonstrate stronger high-frequency components. This divergence is indicative of the usual spectral characteristics of male and female voices, with women's voices generally having higher frequency components due to physiological differences in vocal cord structure.\n\nimage_name:Men's Voice\ndescription:Figure labeled \"Men's Voice\" is a time-domain waveform representation of a male voice signal. The x-axis is labeled 't,' representing time, and the y-axis is labeled 'x(t),' indicating the amplitude of the voice signal. The waveform is characterized by oscillations, exhibiting both positive and negative amplitude fluctuations around a central axis, suggesting the presence of compressions and rarefactions in the sound wave.\n\nThe waveform has a complex shape, with numerous peaks and troughs, indicating the presence of various frequency components. The amplitude of the oscillations varies over time, signifying dynamic changes in loudness and pitch. The waveform does not exhibit a simple periodic pattern, reflecting the inherent variability and intricacy of human speech.\n\nKey features include several prominent peaks and valleys, which may correspond to louder and quieter moments in the speech. The waveform crosses the zero amplitude line multiple times, indicating changes in the phase of the sound wave. This graph captures the typical characteristics of a male voice, likely emphasizing lower frequency components as suggested by the context provided.\n\nimage_name:Women's Voice\ndescription:Figure illustrates a time-domain waveform representing a woman's voice. The x-axis is labeled as 't' for time, and the y-axis is labeled as 'x(t)' for amplitude. The waveform is plotted on a linear scale, capturing the variations in amplitude over time.\n\n**Overall Behavior and Trends:**\nThe waveform shows a complex pattern of oscillations, characteristic of human speech. It does not follow a simple periodic pattern, reflecting the inherent variability and complexity of vocal sounds. The waveform features multiple peaks and valleys, indicating moments of higher and lower amplitude, respectively. These variations suggest changes in loudness and pitch typical in speech.\n\n**Key Features and Technical Details:**\n- **Zero Crossings:** The waveform crosses the zero amplitude line several times, indicating phase changes in the sound wave.\n- **Peaks and Valleys:** There are several prominent peaks and valleys, which could correspond to louder and quieter parts of the speech.\n- **Frequency Components:** The context implies an emphasis on higher frequency components typical of a woman's voice, compared to a man's voice which often emphasizes lower frequencies.\n\n**Annotations and Specific Data Points:**\n- The graph does not have specific numerical annotations or reference lines, but it visually highlights the dynamic range and complexity of a woman's vocal waveform. The waveform's structure suggests the inclusion of a wide range of frequencies and amplitudes, capturing the essence of a woman's voice in speech.\n\nFigure 7.5 (a) Spectra of men's and women's voices, and (b) corresponding time-domain waveforms.\n(b) The averaging period must be lengthy enough to encompass a sufficient number of cycles of the lowest frequencies. Hence, the averaging must capture the slowest dynamics in the signal. Consequently, we must select \\( T \\) to be at least around 10 cycles of 20 Hz, which is roughly 500 milliseconds.\n\nAs with the definition of \\( P_{a v} \\) in (7.3), it is conventional to exclude \\( R_{L} \\) from \\( S_{x}(f) \\). Thus, since each value on the plot in Fig. 7.4(b) is measured for a 1-Hz bandwidth, \\( S_{x}(f) \\) is expressed in V²/Hz rather than W/Hz. It is also common to take the square root of \\( S_{x}(f) \\), expressing the result in V/√Hz. For instance, we assert that the input noise voltage of an amplifier at 100 MHz is equal to \\( 3 \\text{nV} / \\sqrt{\\text{Hz}} \\), which merely means that the average power in a 1-Hz bandwidth at 100 MHz is equal to \\( (3 \\times 10^{-9})^2 \\text{~V}^2 \\).\nimage_name:Figure 7.6 White spectrum\ndescription:Figure 7.6 depicts a 'white spectrum' or white noise power spectral density (PSD). This type of graph is a frequency-domain representation, particularly showcasing the PSD of a noise signal.\n\n1. **Type of Graph and Function:**\n- This is a frequency-domain plot, specifically a power spectral density (PSD) graph.\n\n2. **Axes Labels and Units:**\n- The horizontal axis is labeled as 'f,' representing frequency, typically in hertz (Hz).\n- The vertical axis is labeled as 'S_n(f),' which represents the power spectral density, often expressed in units of V²/Hz or W/Hz.\n- The scale of both axes is linear.\n\n3. **Overall Behavior and Trends:**\n- The graph shows a consistent value across all frequencies, indicating that the noise power is evenly distributed throughout the frequency spectrum. This flat line is characteristic of white noise, where the power spectral density does not vary with frequency.\n\n4. **Key Features and Technical Details:**\n- There are no peaks, valleys, or inflection points since the graph is a flat line.\n- The graph implies that the noise has equal power at all frequencies within the band of interest.\n- The flat nature of the spectrum suggests infinite total power if integrated over an infinite frequency range, which is a theoretical concept since practical systems have limited bandwidth.\n\n5. **Annotations and Specific Data Points:**\n- There are no specific annotations or markers on the graph, as it is a simple representation of a white noise spectrum.\n- The graph is a typical illustration of the concept of white noise, demonstrating its uniform power distribution across frequencies.\n\nAn example of a prevalent type of noise PSD is the \"white spectrum,\" also referred to as white noise. Displayed in Fig. 7.6, such a PSD exhibits the same value at all frequencies (akin to white light). In a strict sense, we acknowledge that white noise does not exist because the total area under the power spectral density, i.e., the total power carried by the noise, is infinite. In practice, however, any noise spectrum that is flat in the band of interest is typically termed white.\n\nThe PSD is a valuable tool in analyzing the impact of noise in circuits, particularly when combined with the following theorem.\n\nTheorem If a signal with spectrum \\( S_{x}(f) \\) is applied to a linear time-invariant system with transfer function \\( H(s) \\), then the output spectrum is given by\n$$\n\\begin{equation*}\nS_{Y}(f)=S_{x}(f)|H(f)|^{2} \\tag{7.4}\n\\end{equation*}\n$$\nwhere \\( H(f)=H(s=2 \\pi j f) \\). The proof can be found in textbooks on signal processing or communications, e.g., [1].\n\nThe relationship between \\( Y(s)=X(s) H(s) \\) is analogous, this theorem aligns with our intuition that the spectrum of the signal should be \"shaped\" by the system's transfer function (Fig. 7.7). For example, as illustrated in Fig. 7.8, since regular telephones have a bandwidth of approximately 4 kHz, they suppress the high-frequency components of the caller's voice. Note that, due to its limited bandwidth, \\( x_{\\text {out }}(t) \\) exhibits slower changes than \\( x_{i n}(t) \\). This bandwidth limitation sometimes makes it difficult to discern the caller's voice.\nimage_name:Figure 7.7\ndescription:Figure 7.7 illustrates the concept of noise shaping via a transfer function. The diagram comprises three sections, each representing a different stage of the frequency response transformation.\n\n1. **Type of Graph and Function:**\n- The graph is a frequency response diagram that illustrates how a signal's spectrum is influenced by a system's transfer function.\n\n2. **Axes Labels and Units:**\n- Each section of the diagram has the horizontal axis labeled as frequency \\( f \\), though specific units are not given, it is typically in hertz (Hz).\n\n3. **Overall Behavior and Trends:**\n- **First Section (Left):** The initial spectrum \\( S_x(f) \\) is presented as a flat, consistent value across a specific frequency range, suggesting a uniform distribution of power across those frequencies.\n- **Middle Section:** The transfer function \\( |H(f)|^2 \\) is depicted with a bell-shaped curve featuring two peaks. This indicates that the system enhances certain frequencies more than others, corresponding to the peaks.\n- **Last Section (Right):** The resulting spectrum \\( S_y(f) \\) after the transfer function is applied displays a shaped spectrum with peaks at the same frequencies as \\( |H(f)|^2 \\), showing that these frequencies are emphasized in the output.\n\n4. **Key Features and Technical Details:**\n- The flat spectrum \\( S_x(f) \\) suggests an input signal with equal power across a frequency range.\n- The transfer function \\( |H(f)|^2 \\) has a double-peaked shape, indicating preferential amplification or attenuation at certain frequencies.\n- The output spectrum \\( S_y(f) \\) reflects the shaping effect of the transfer function, with noticeable peaks aligning with those of \\( |H(f)|^2 \\).\n\n5. **Annotations and Specific Data Points:**\n- No specific numerical values or annotations are provided, but the focus is on the transformation process from \\( S_x(f) \\) to \\( S_y(f) \\) through \\( |H(f)|^2 \\).\n\nThis diagram effectively demonstrates how a transfer function can shape the spectrum of a signal, highlighting certain frequency components while suppressing others.\n\nFigure 7.7 Noise shaping by a transfer function.\nSince \\( S_{x}(f) \\) is an even function of \\( f \\) for real \\( x(t) \\) [1], as depicted in Fig. 7.9, the total power carried by \\( x(t) \\) within the frequency range \\([f_{1}, f_{2}]\\) is equal to\n$$\n\\begin{align*}\nP_{f_{1}, f_{2}} & =\\int_{-f_{2}}^{-f_{1}} S_{x}(f) df + \\int_{+f_{1}}^{+f_{2}} S_{x}(f) df \\tag{7.5}\\\\\n& =\\int_{+f_{1}}^{+f_{2}} 2 S_{x}(f) df \\tag{7.6}\n\\end{align*}\n$$\nimage_name:x_in(t)\ndescription:Figure labeled \"x_in(t)\" portrays a time-domain waveform depicting the input signal to a system, possibly an audio or some other real-time signal.\n\n1. **Type of Graph and Function:**\n- This is a time-domain waveform graph.\n\n2. **Axes Labels and Units:**\n- The horizontal axis is labeled as 't,' indicating time, but no specific units (like seconds or milliseconds) are given in the image.\n- The vertical axis represents the amplitude of the signal, denoted as \"x_in(t),\" without specific units provided.\n\n3. **Overall Behavior and Trends:**\n- The waveform depicts oscillations, suggesting a varying signal with multiple frequency components.\n- There are no discernible trends of increasing or decreasing amplitude over time, indicating a steady-state signal.\n\n4. **Key Features and Technical Details:**\n- The waveform features several peaks and troughs, typical of a complex signal with multiple frequencies.\n- No specific numerical values or critical points are annotated on this graph.\n\n5. **Annotations and Specific Data Points:**\n- There are no additional annotations or markers on this graph, and no specific data points are highlighted.\n\nOverall, this waveform serves as the initial input signal before any processing or filtering, as indicated by"
},
{
    "text": "The versatility of the concept of average power increases when it is defined in relation to the frequency content of noise. For instance, the noise produced by a group of men has weaker high-frequency components compared to the noise made by a group of women, a distinction that can be observed in the \"spectrum\" of each type of noise. Also referred to as the \"power spectral density\" (PSD), the spectrum indicates the amount of power the signal carries at each frequency. More specifically, the PSD, \\( S_{x}(f) \\), of a noise waveform \\( x(t) \\), is defined as the average power carried by \\( x(t) \\) in a one-hertz bandwidth around \\( f \\). As shown in Fig. 7.4(a), we apply \\( x(t) \\) to a bandpass filter with a center frequency of \\( f_{1} \\) and a 1-Hz bandwidth, square the output, \\( x_{f 1}(t) \\), and calculate the average over a long time to obtain \\( S_{x}\\left(f_{1}\\right) \\). By repeating this process with bandpass filters having different center frequencies, we derive the overall shape of \\( S_{x}(f) \\) [Fig. 7.4(b)]. Generally, \\( S_{x}(f) \\) is measured in watts per hertz. The total area under \\( S_{x}(f) \\) represents the power carried by the signal (or the noise) at all frequencies; that is, the total power.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of voice for men and women. What does the difference imply about their time-domain waveforms?\n(b) Estimate the averaging time, \\( T \\), in Eq. (7.3) for voice signals.\n\n[Image descriptions for Figures 7.4(a), 7.4(b), 7.5(a), 7.5(b), 7.6, 7.7, 7.8, 7.9(a), 7.9(b), and 7.10 have been provided as text.]\n\n#### Solution\n\n(a) The human voice exhibits frequencies from 20 Hz to 20 kHz. Since women's voices contain stronger high-frequency components, the two spectra are expected to differ as shown in Fig. 7.5(a). In the time domain, faster changes are observed in women's voices [Fig. 7.5(b)].\n(b) The averaging time must be long enough to include a sufficient number of cycles of the lowest frequencies. That is, the averaging must capture the slowest dynamics in the signal. We must therefore choose \\( T \\) to be at least about 10 cycles of 20 Hz, i.e., roughly 500 ms.\n\nAs with the definition of \\( P_{a v} \\) in (7.3), it is customary to eliminate \\( R_{L} \\) from \\( S_{x}(f) \\). Thus, since each value on the plot in Fig. 7.4(b) is measured for a 1-Hz bandwidth, \\( S_{x}(f) \\) is expressed in \\( \\mathrm{V}^{2} / \\mathrm{Hz} \\) rather than W/Hz. It is also common to take the square root of \\( S_{x}(f) \\), expressing the result in \\( \\mathrm{V} / \\sqrt{\\mathrm{Hz}} \\). For example, we say that the input noise voltage of an amplifier at 100 MHz is equal to \\( 3 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\), simply to mean that the average power in a 1-Hz bandwidth at 100 MHz is equal to \\( \\left(3 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2} \\).\n\nAn example of a common type of noise PSD is the \"white spectrum,\" also called white noise. Shown in Fig. 7.6, such a PSD displays the same value at all frequencies (similar to white light). Strictly speaking, we note that white noise does not exist because the total area under the power spectral density, i.e., the total power carried by the noise, is infinite. In practice, however, any noise spectrum that is flat in the band of interest is usually called white.\n\nThe PSD is a powerful tool in analyzing the effect of noise in circuits, especially in conjunction with the following theorem.\n\nTheorem If a signal with spectrum \\( S_{x}(f) \\) is applied to a linear time-invariant system with transfer function \\( H(s) \\), then the output spectrum is given by\n\n$$\n\\begin{equation*}\nS_{Y}(f)=S_{x}(f)|H(f)|^{2} \\tag{7.4}\n\\end{equation*}\n$$\n\nwhere \\( H(f)=H(s=2 \\pi j f) \\). The proof can be found in textbooks on signal processing or communications, e.g., [1].\n\nSomewhat similar to the relation \\( Y(s)=X(s) H(s) \\), this theorem agrees with our intuition that the spectrum of the signal should be \"shaped\" by the transfer function of the system (Fig. 7.7). For example, as illustrated in Fig. 7.8, since regular telephones have a bandwidth of approximately 4 kHz, they suppress the high-frequency components of the caller's voice. Note that, owing to its limited bandwidth, \\( x_{\\text {out }}(t) \\) exhibits slower changes than does \\( x_{i n}(t) \\). This bandwidth limitation sometimes makes it difficult to recognize the caller's voice.\n\nSince \\( S_{x}(f) \\) is an even function of \\( f \\) for real \\( x(t) \\) [1], as depicted in Fig. 7.9, the total power carried by \\( x(t) \\) in the frequency range \\([f_{1} f_{2}]\\) is equal to\n\n$$\n\\begin{align*}\nP_{f 1, f 2} & =\\int_{-f_{2}}^{-f_{1}} S_{x}(f) d f+\\int_{+f_{1}}^{+f_{2}} S_{x}(f) d f  \\tag{7.5}\\\\\n& =\\int_{+f_{1}}^{+f_{2}} 2 S_{x}(f) d f \\tag{7.6}\n\\end{align*}\n$$\n\nIn fact, the integral in (7.6) is the quantity measured by a power meter sensing the output of a bandpass filter between \\( f_{1} \\) and \\( f_{2} \\). That is, the negative-frequency part of the spectrum is folded around the vertical axis and added to the positive-frequency part. We call the representation of Fig. 7.9(a) the \"two-sided\" spectrum and that of Fig. 7.9(b) the \"one-sided\" spectrum. For example, the two-sided white spectrum of Fig. 7.6 has the one-sided counterpart shown in Fig. 7.10.\n\nIn summary, the spectrum shows the power carried in a small bandwidth at each frequency, revealing how fast the waveform is expected to vary in the time domain."
},
{
    "text": "Rephrased Text:\n\nThe adaptability of the average power concept increases when defined in relation to the frequency composition of noise. The noise produced by a group of men typically exhibits weaker high-frequency elements compared to the noise from a group of women, a distinction that can be discerned from the \"spectrum\" unique to each noise type. This spectrum, also known as the \"power spectral density\" (PSD), illustrates the distribution of power across various frequencies within a signal. Specifically, the PSD, denoted as $S_{x}(f)$, of a noise waveform $x(t)$, is defined as the average power that $x(t)$ exerts within a one-hertz bandwidth centered at $f$. As depicted in Fig. 7.4(a), we process $x(t)$ through a bandpass filter centered at $f_{1}$ with a bandwidth of one hertz, square the resulting output, $x_{f 1}(t)$, and compute the average over an extended period to determine $S_{x}\\left(f_{1}\\right)$. By repeating this process using bandpass filters with varying center frequencies, we can map out the complete profile of $S_{x}(f)$ [Fig. 7.4(b)]. Typically, $S_{x}(f)$ is quantified in watts per hertz. The total area beneath $S_{x}(f)$ signifies the cumulative power propagated by the signal (or noise) across all frequencies; in other words, the overall power.\n\n#### Example 7.1\n\n(a) Sketch the spectrum of male and female voices. What implications do these differences have regarding their time-domain waveforms?\n(b) Estimate the averaging time, $T$, in Eq. (7.3) for voice signals.\n\nFigure 7.4(a) illustrates the process of manipulating a signal's spectrum using a bandpass filter. The diagram includes:\n\n1. **Input Signal, x(t):**\n- The diagram starts with an input signal, represented by \\(x(t)\\), a waveform depicting amplitude fluctuations over time.\n\n2. **Band-Pass Filter:**\n- The input signal \\(x(t)\\) is directed into a band-pass filter. This filter is defined by a particular frequency range, centered around \\(f_1\\), and has a bandwidth of 1 Hz. Its purpose is to permit only frequencies within this narrow band to pass, effectively isolating a segment of the signal's frequency spectrum.\n\n3. **Filtered Signal, x_{f1}(t):**\n- The band-pass filter's output is a filtered iteration of the input signal, denoted as \\(x_{f1}(t)\\). This signal is depicted as a sinusoidal waveform, indicating that only the frequency components near \\(f_1\\) are present.\n\n4. **Squaring Block:**\n- The filtered signal \\(x_{f1}(t)\\) then undergoes squaring. This step calculates the square of the signal's amplitude, resulting in \\(|x_{f1}(t)|^2\\). Squaring the signal typically amplifies the prominence of the power of its components.\n\n5. **Output Signal, |x_{f1}(t)|^2:**\n- The ultimate output is the squared amplitude of the filtered signal, \\(|x_{f1}(t)|^2\\), displayed as a waveform with pronounced amplitude fluctuations over time. This represents the power of the signal components within the band-pass filter's frequency spectrum.\n\n**Flow of Information:**\n- The signal's journey starts with the input \\(x(t)\\), which is processed by the band-pass filter to generate \\(x_{f1}(t)\\). This filtered signal is then squared to produce \\(|x_{f1}(t)|^2\\). The flow of information is linear, devoid of feedback loops or additional control mechanisms.\n\n**Overall System Function:**\n- The primary role of this system is to extract a specific frequency component from the input signal using a band-pass filter and then to analyze the power of this component by squaring its amplitude. This process is instrumental in spectral analysis where the power at particular frequency bands is of interest.\n\nFigure 7.4(b) displays a frequency spectrum plot, specifically detailing the noise spectrum $S_x(f)$ of a signal.\n\n1. **Type of Graph and Function:**\n- This graph represents the power spectral density (PSD) of a signal, $S_x(f)$, in the frequency domain.\n\n2. **Axes Labels and Units:**\n- The horizontal axis denotes frequency ($f$), usually measured in Hertz (Hz).\n- The vertical axis represents the power spectral density, $S_x(f)$, measured in watts per hertz (W/Hz).\n- The scales for both axes appear to be linear.\n\n3. **Overall Behavior and Trends:**\n- The spectrum exhibits a pattern of peaks and troughs, indicating varying power levels across different frequencies.\n- The graph initiates with a peak at $f_1$, followed by a dip at $f_2$, another peak, and a gradual decline as frequency increases towards $f_n$.\n- This pattern suggests that the signal has dominant frequency components at certain frequencies, which diminish as the frequency rises.\n\n4. **Key Features and Technical Details:**\n- Peaks are evident at specific frequencies ($f_1$, $f_2$, ..., $f_n$), marked by vertical dashed lines.\n- The most prominent peak lies between $f_2$ and $f_n$, signifying the frequency with the highest power.\n- The spectrum exhibits a decreasing trend in power as the frequency surpasses the highest peak.\n\n5. **Annotations and Specific Data Points:**\n- The graph features open circles at pivotal frequencies, highlighting significant points in the spectrum.\n- These markers likely correspond to the center frequencies of band-pass filters used in calculating the spectrum.\n\nOverall, this graph visually represents the distribution of power across different frequencies in the signal, with certain frequencies displaying higher power levels, indicative of the signal's characteristics in the frequency domain.\n\nFigure 7.4 Calculation of noise spectrum.\n\n#### Solution\n\n(a) The human voice encompasses frequencies ranging from 20 Hz to 20 kHz. Since women's voices typically include stronger high-frequency components, we anticipate distinct spectra as depicted in Fig. 7.5(a). In the time domain, we observe more rapid fluctuations in women's voices [Fig. 7.5(b)].\nFigure 7.5 (a) Spectra of male and female voices, and (b) corresponding time-domain waveforms.\n(b) The averaging time must be sufficient to encapsulate a considerable number of cycles of the lowest frequencies. This implies that the averaging process must capture the slowest dynamics within the signal. Consequently, we must select $T$ to be at least approximately 10 cycles of 20 Hz, i.e., roughly 500 ms.\n\nSimilar to the definition of $P_{a v}$ in (7.3), it is standard practice to exclude $R_{L}$ from $S_{x}(f)$. Hence, since each data point on the plot in Fig. 7.4(b) corresponds to a 1-Hz bandwidth, $S_{x}(f)$ is expressed in $\\mathrm{V}^{2} / \\mathrm{Hz}$ instead of W/Hz. It is also customary to take the square root of $S_{x}(f)$, expressing the result in $\\mathrm{V} / \\sqrt{\\mathrm{Hz}}$. For instance, we might state that the input noise voltage of an amplifier at 100 MHz is equivalent to $3 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}}$, which implies that the average power within a 1-Hz bandwidth at 100 MHz is $\\left(3 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2}$.\n\nFigure 7.6 represents a 'white spectrum' or white noise power spectral density (PSD). This graph is a frequency-domain illustration, specifically depicting the PSD of a noise signal.\n\n1. **Type of Graph and Function:**\n- This is a frequency-domain plot, specifically a power spectral density (PSD) graph.\n\n2. **Axes Labels and Units:**\n- The horizontal axis represents frequency ($f$), typically measured in Hertz (Hz).\n- The vertical axis represents the power spectral density, $S_n(f)$, measured in V²/Hz or W/Hz.\n- The scale for both axes appears to be linear.\n\n3. **Overall Behavior and Trends:**\n- The graph exhibits a consistent value across all frequencies, indicating that the noise power is evenly distributed across the frequency spectrum. This flat line is characteristic of white noise, where the power spectral density remains constant with frequency.\n\n4. **Key Features and Technical Details:**\n- There are no peaks, valleys, or inflection points, as the graph is a straight line.\n- The graph suggests that the noise possesses equal power at all frequencies within the band of interest.\n- The flat nature of the spectrum implies infinite total power if integrated over an infinite frequency range, a theoretical concept since practical systems have limited bandwidth.\n\n5. **Annotations and Specific Data Points:**\n- There are no specific annotations or markers on the graph, as it is a straightforward representation of a white noise spectrum.\n- The graph is a typical depiction of the white noise concept, explaining its consistent power distribution across frequencies.\n\nAn example of a typical noise PSD is the \"white spectrum,\" also known as white noise. As shown in Fig. 7.6, such a PSD maintains the same value at all frequencies (analogous to white light). Strictly speaking, we note that white noise does not exist in reality because the total area under the power spectral density, i.e., the total power conveyed by the noise, is infinite. However, in practical scenarios, any noise spectrum that remains flat within the band of interest is commonly referred to as white.\n\nThe PSD is a potent instrument in assessing the impact of noise in circuits, particularly when used alongside the following theorem.\n\nTheorem: If a signal with spectrum $S_{x}(f)$ is transmitted through a linear time-invariant system with transfer function $H(s)$, then the resulting output spectrum is determined by:\n\n$$\n\\begin{equation*}\nS_{Y}(f)=S_{x}(f)|H(f)|^{2} \\tag{7.4}\n\\end{equation*}\n$$\n\nwhere $H(f)=H(s=2 \\pi j f)$. The proof of this theorem can be found in signal processing or communications textbooks, e.g., [1].\n\nIn a manner akin to the relation $Y(s)=X(s) H(s)$, this theorem aligns with our understanding that the signal's spectrum should be \"shaped\" by the system's transfer function (Fig. 7.7). For example, as depicted in Fig. 7.8, since traditional telephones have a bandwidth of roughly 4 kHz, they dampen the high-frequency elements of the caller's voice. It's important to note that, due to its restricted bandwidth, $x_{\\text {out }}(t)$ exhibits slower changes compared to $x_{i n}(t)$. This bandwidth limitation can occasionally hinder the recognition of the caller's voice.\n\nFigure 7.7 illustrates the concept of noise shaping by a transfer function. It consists of three segments, each depicting a different stage of the frequency response transformation.\n\n1. **Type of Graph and Function:**\n- The graph is a frequency response diagram showcasing how a signal's spectrum is altered by a system's transfer function.\n\n2. **Axes Labels and Units:**\n- Each segment of the diagram has the horizontal axis labeled as frequency ($f$), typically measured in Hertz (Hz).\n\n3. **Overall Behavior and Trends:**\n- **First Segment (Left):** The initial spectrum $S_x(f)$ is depicted as a flat, constant value across a certain frequency range, indicating a uniform distribution of power across these frequencies.\n- **Middle Segment:** The transfer function $|H(f)|^2$ is represented by a bell-shaped curve with two peaks. This suggests that the system amplifies or attenuates certain frequencies more than others, corresponding to the peaks.\n- **Last Segment (Right):** The resulting spectrum $S_y(f)$ after applying the transfer function exhibits a shaped spectrum with peaks at the same frequencies as $|H(f)|^2$, indicating that these frequencies are emphasized in the output.\n\n4. **Key Features and Technical Details:**\n- The flat spectrum $S_x(f)$ indicates an input signal with equal power across a range of frequencies.\n- The transfer function $|H(f)|^2$ has a double-peaked shape, indicating selective amplification or attenuation at certain frequencies.\n- The output spectrum $S_y(f)$ reflects the shaping effect of the transfer function, with noticeable peaks aligning with those of $|H(f)|^2$.\n\n5. **Annotations and Specific Data Points:**\n- No specific numerical values or annotations are provided, but the focus is on the transformation process from $S_x(f)$ to $S_y(f)$ via $|H(f)|^2$.\n\nThis diagram effectively demonstrates how a transfer function can shape the spectrum of a signal, highlighting certain frequency components while suppressing others.\n\nFigure 7.7 Noise shaping by a transfer function.\nSince $S_{x}(f)$ is an even function of $f$ for real $x(t)$ [1], as depicted in Fig. 7.9, the total power conveyed by $x(t)$ within the frequency range $[f_{1} f_{2}]$ is equal to:\n\n$$\n\\begin{align*}\nP_{f 1, f 2} & =\\int_{-f_{2}}^{-f_{1}} S_{x}(f) d f+\\int_{+f_{1}}^{+f_{2}} S_{x}(f) d f  \\tag{7.5}\\\\\n& =\\int_{+f_{1}}^{+f_{2}} 2 S_{x}(f) d f \\tag{7.6}\n\\end{align*}\n$$\n\nFigure 7.9 (a) Two-sided and (b) one-sided noise spectra.\n\nIndeed, the integral in (7.6) corresponds to the quantity measured by a power meter detecting the output of a bandpass filter between $f_{1}$ and $f_{2}$. This means that the negative-frequency portion of the spectrum is folded around the vertical axis and combined with the positive-frequency part. We refer to the representation in Fig. 7.9(a) as the \"two-sided\" spectrum and that in Fig. 7.9(b) as the \"one-sided\" spectrum. For example, the two-sided white spectrum of Fig. 7.6 has a one-sided counterpart shown in Fig. 7.10.\n\nFigure 7.10 Folded white spectrum.\n\nIn summary, the spectrum depicts the power contained within a narrow bandwidth at each frequency, revealing the expected rate of change of the waveform in the time domain."
},
{
    "text": "As previously stated, the instantaneous amplitude of noise is typically unpredictable. However, by examining the noise waveform over an extended period, we can create a \"distribution\" of the amplitude, showing how frequently each value occurs. This is also known as the \"probability density function\" (PDF), and the distribution of $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific time point.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, form bins of small width, set the bin height to the number of samples within the bin's range, and normalize these heights to the total sample count. Note that the PDF does not provide information on how quickly $x(t)$ changes in the time domain. For instance, the sound produced by a violin may share the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Graph Type**: This is a time-domain waveform plot.\n- **Axes Labels and Units**: The horizontal axis is labeled 't', indicating time, and the vertical axis is labeled 'x(t)', representing the signal amplitude at time 't'. No units are specified, indicating a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory behavior with varying amplitude, suggesting a signal with multiple frequency components. The oscillations are irregular, indicating noise or a complex signal.\n- **Key Features and Technical Details**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, indicating sample locations.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Graph Type**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x', representing amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram displays a roughly symmetrical distribution, resembling a Gaussian distribution, suggesting that signal amplitudes are centered around a mean value with decreasing frequency as amplitudes deviate from the center.\n- **Key Features and Technical Details**: The histogram has bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution tapers off symmetrically on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 illustrates the amplitude distribution of noise through two subplots.\n\n1. **Graph Type and Function**:\n- The left subplot is a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units**:\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. No specific units are given, suggesting a normalized distribution.\n\n3. **Overall Behavior and Trends**:\n- The left subplot shows a fluctuating waveform typical of noise, lacking any apparent periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot displays a bell-shaped histogram, indicating a normal distribution of the noise amplitude. The central bins have higher counts, suggesting that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details**:\n- The waveform in the left subplot shows varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points**:\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but its shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually represents how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if many independent random processes with arbitrary PDFs are combined, the PDF of the sum tends towards a Gaussian distribution [1]. Consequently, it is not unexpected that many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor results from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. However, for completeness, we note that the Gaussian PDF is defined as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously noted, the instantaneous amplitude of noise is typically unpredictable. However, by analyzing the noise waveform over an extended period, we can establish a \"distribution\" of the amplitude, showing the frequency of occurrence for each value. This distribution, also known as the \"probability density function\" (PDF), for $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific time point.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, create bins of small width, set the bin height to the count of samples falling within the bin's range, and normalize these heights to the total sample count. It's important to note that the PDF does not provide insights into the temporal variations of $x(t)$. For instance, the sound produced by a violin might share the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Type of Graph**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't', indicating time, and the vertical axis is labeled 'x(t)', denoting the signal amplitude at time 't'. Units are not specified, implying a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory patterns with varying amplitudes, suggesting a signal with multiple frequency components. The irregular oscillations indicate noise or a complex signal.\n- **Key Features and Technical Details**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitude values are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, highlighting the sampled signal points.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Type of Graph**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x', representing amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram reveals a roughly symmetrical amplitude distribution, akin to a Gaussian distribution, suggesting that signal amplitudes are centered around a mean with decreasing frequency as amplitudes deviate from the center.\n- **Key Features and Technical Details**: The histogram comprises bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution symmetrically tapers off on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 visualizes the amplitude distribution of noise through two subplots.\n\n1. **Type of Graph and Function:**\n- The left subplot is a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units:**\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. Again, no specific units are given, suggesting a normalized distribution.\n\n3. **Overall Behavior and Trends:**\n- The left subplot displays a fluctuating waveform typical of noise, lacking any apparent periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot presents a bell-shaped histogram, indicating a normal distribution of the noise amplitude. The central bins have higher counts, suggesting that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details:**\n- The waveform in the left subplot shows varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points:**\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but the histogram's shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 provides a visual representation of noise behavior in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if multiple independent random processes with arbitrary PDFs are combined, the PDF of the sum tends towards a Gaussian distribution [1]. Consequently, it is unsurprising that many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor arises from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. Nonetheless, for completeness, we define the Gaussian PDF as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously stated, the instantaneous amplitude of noise is typically unpredictable. However, by examining the noise waveform over an extended period, we can create a \"distribution\" of the amplitude, showing how frequently each value occurs. This is also known as the \"probability density function\" (PDF), where the distribution of $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nHere, $X$ represents the measured value of $x(t)$ at a specific point in time.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, create bins of small width, set the bin height to the number of samples whose values fall within the bin edges, and normalize these heights to the total number of samples. It's important to note that the PDF does not provide information on how quickly $x(t)$ changes in the time domain. For instance, the sound produced by a violin might have the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Type of Graph**: This is a time-domain waveform plot.\n- **Axes Labels and Units**: The horizontal axis is labeled 't', indicating time, and the vertical axis is labeled 'x(t)', representing the signal amplitude at time 't'. No units are specified, signifying a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory behavior with varying amplitude, suggesting a signal with multiple frequency components. The oscillations are irregular, indicating noise or a complex signal.\n- **Key Features and Technical Details**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, showing where the signal was sampled.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Type of Graph**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x', representing amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram displays an amplitude distribution that appears roughly symmetrical, resembling a Gaussian distribution. This indicates that the signal amplitudes are centered around a mean value, with decreasing frequency as the amplitude deviates from the center.\n- **Key Features and Technical Details**: The histogram has bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution symmetrically tapers off on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 graphically represents the amplitude distribution of noise through two subplots.\n\n1. **Type of Graph and Function:**\n- The left subplot is a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units:**\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. Again, no specific units are given, suggesting a normalized distribution.\n\n3. **Overall Behavior and Trends:**\n- The left subplot shows a fluctuating waveform typical of noise, lacking any apparent periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot displays a bell-shaped histogram, suggesting a normal distribution of the noise amplitude. The central bins have higher counts, indicating that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details:**\n- The waveform in the left subplot shows varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points:**\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but the histogram's shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually illustrates how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if many independent random processes with arbitrary PDFs are combined, the PDF of the sum tends to a Gaussian distribution [1]. Consequently, it is not unexpected that many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor results from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. However, for completeness, we note that the Gaussian PDF is defined as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously noted, the instantaneous amplitude of noise is generally unpredictable. However, by analyzing the noise waveform over an extended period, we can establish a \"distribution\" of the amplitude, reflecting the frequency of occurrence for each value. This distribution, also known as the \"probability density function\" (PDF), for $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific time point.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, create bins of small width, set the bin height to the count of samples falling within the bin's edges, and normalize these heights to the total sample count. It's important to note that the PDF does not provide insights into the temporal variations of $x(t)$. For instance, the sound produced by a violin might share the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image is divided into two main parts: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Graph Type**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't' for time, and the vertical axis is labeled 'x(t)' for the signal amplitude at time 't'. No units are specified, indicating a general representation.\n- **Behavior and Trends**: The waveform shows oscillatory patterns with varying amplitudes, suggesting a signal with multiple frequency components. The irregular oscillations indicate noise or a complex signal.\n- **Key Features**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations**: The waveform is sampled at discrete points, marked by circles along the curve.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Graph Type**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x' for amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Behavior and Trends**: The histogram displays a roughly symmetrical distribution, resembling a Gaussian distribution, suggesting that the signal amplitudes are centered around a mean value with decreasing frequency as the amplitude deviates from the center.\n- **Key Features**: The histogram has bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution tapers off symmetrically on both sides.\n- **Annotations**: No specific numerical values or annotations are present, but the shape indicates a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 visually represents the amplitude distribution of noise through two subplots.\n\n1. **Graph Types and Functions**:\n- The left subplot is a time-domain waveform of a random noise signal, labeled $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units**:\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. No specific units are given, suggesting a normalized distribution.\n\n3. **Behavior and Trends**:\n- The left subplot displays a fluctuating waveform typical of noise, lacking periodicity or regular patterns. The waveform crosses the time axis multiple times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot shows a bell-shaped histogram, indicating a normal distribution of the noise amplitude. The central bins have higher counts, suggesting that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features**:\n- The left subplot's waveform shows varying amplitudes and frequencies, characteristic of noise.\n- The right subplot's histogram is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations**:\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but its shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 illustrates how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if multiple independent random processes with arbitrary PDFs are combined, the PDF of the sum tends towards a Gaussian distribution [1]. Consequently, many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor arises from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. Nonetheless, for completeness, we define the Gaussian PDF as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously noted, the instantaneous amplitude of noise is typically unpredictable. However, by analyzing the noise waveform over an extended period, we can develop a \"distribution\" of the amplitude, which shows the frequency of occurrence for each value. This distribution is also known as the \"probability density function\" (PDF), and the distribution of $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific point in time.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we take multiple samples of $x(t)$, create bins of small width, set the bin height to the number of samples falling within the bin's edges, and normalize these heights to the total number of samples. It's important to note that the PDF does not provide information on how quickly $x(t)$ changes in the time domain. For instance, the sound produced by a violin might have the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Graph Type**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't' for time, and the vertical axis is labeled 'x(t)' for the signal amplitude at time 't'. No units are specified, indicating a general representation.\n- **Behavior and Trends**: The waveform displays oscillatory behavior with varying amplitudes, suggesting a signal with multiple frequency components. The oscillations are irregular, indicating noise or complexity.\n- **Key Features**: The waveform crosses the time axis multiple times, indicating zero crossings, with several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations**: The waveform is sampled at discrete points, marked by circles along the curve.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Graph Type**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x' for amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Behavior and Trends**: The histogram appears roughly symmetrical, resembling a Gaussian distribution, suggesting that signal amplitudes are centered around a mean with decreasing frequency as amplitudes deviate from the center.\n- **Key Features**: The histogram has bins of varying heights, with the tallest bins near the center, indicating the most common amplitudes. The distribution tapers off symmetrically on both sides.\n- **Annotations**: No specific numerical values or annotations are present, but the shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 illustrates the amplitude distribution of noise through two subplots.\n\n1. **Graph Type and Function**:\n- The left subplot shows a time-domain waveform of random noise, denoted as $x(t)$.\n- The right subplot presents a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units**:\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. No specific units are given, suggesting a normalized distribution.\n\n3. **Behavior and Trends**:\n- The left subplot displays a fluctuating waveform typical of noise, with no clear periodicity or pattern. The waveform crosses the time axis several times, indicating zero crossings, and shows varying peak amplitudes.\n- The right subplot shows a bell-shaped histogram, indicating a normal distribution of the noise amplitude. Central bins have higher counts, suggesting most sample values are near the mean, with fewer at the extremes.\n\n4. **Key Features**:\n- The left subplot's waveform exhibits varying amplitudes and frequencies, typical of noise.\n- The right subplot's histogram is symmetric around the central value, characteristic of Gaussian distributions.\n\n5. **Annotations**:\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but its shape is key to understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually represents noise behavior in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if many independent random processes with arbitrary PDFs are combined, the resulting PDF approaches a Gaussian distribution [1]. Consequently, many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor arises from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. Nevertheless, for completeness, we note that the Gaussian PDF is defined as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously stated, the instantaneous amplitude of noise is typically unpredictable. However, by analyzing the noise waveform over an extended period, we can create a \"distribution\" of the amplitude, showing how frequently each value occurs. This is also known as the \"probability density function\" (PDF), with the distribution of $x(t)$ defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific point in time.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, form bins of small width, set the bin height to the count of samples falling between the bin's edges, and normalize these heights to the total sample count. Note that the PDF does not provide insights into the rate of change of $x(t)$ in the time domain. For instance, the sound produced by a violin may share the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Type of Graph**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't' for time, and the vertical axis is labeled 'x(t)' for the signal amplitude at time 't'. No units are specified, indicating a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory behavior with varying amplitude, suggesting a signal with multiple frequency components. The oscillations are irregular, indicating noise or a complex signal.\n- **Key Features and Technical Details**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, showing the sampled signal points.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Type of Graph**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x' for amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram exhibits a roughly symmetrical distribution, resembling a Gaussian distribution, suggesting that the signal amplitudes are centered around a mean value with decreasing frequency as the amplitude deviates from the center.\n- **Key Features and Technical Details**: The histogram comprises several bins with varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution tapers off symmetrically on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 graphically represents the amplitude distribution of noise through two subplots.\n\n1. **Type of Graph and Function:**\n- The left subplot shows a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units:**\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. No specific units are given, suggesting a normalized distribution.\n\n3. **Overall Behavior and Trends:**\n- The left subplot displays a fluctuating waveform typical of noise, lacking any apparent periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and shows varying peak amplitudes.\n- The right subplot presents a bell-shaped histogram, indicating a normal distribution of the noise amplitude. The central bins have higher counts, suggesting that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details:**\n- The waveform in the left subplot exhibits varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points:**\n- The left subplot includes markers on the waveform, likely indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but its shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually depicts how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if multiple independent random processes with arbitrary PDFs are summed, the PDF of the resultant sum approaches a Gaussian distribution [1]. Consequently, many natural phenomena exhibit Gaussian statistics. For instance, the noise in a resistor arises from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. Nonetheless, for completeness, we note that the Gaussian PDF is defined as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously stated, the instantaneous amplitude of noise is generally unpredictable. Nonetheless, by examining the noise waveform over an extended period, we can establish a \"distribution\" of the amplitude, reflecting the frequency of each value's occurrence. This distribution is also known as the \"probability density function\" (PDF), and the distribution of $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific point in time.\n\nAs depicted in Fig. 7.11, to approximate the distribution, we take multiple samples of $x(t)$, create bins of narrow width, set the bin height to the count of samples within the bin's range, and normalize these heights to the total sample count. It is important to note that the PDF does not reveal how quickly $x(t)$ changes over time. For instance, the sound produced by a violin may share the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image is divided into two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Graph Type**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't' for time, and the vertical axis is labeled 'x(t)' for the signal's amplitude at time 't'. No units are specified, indicating a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory patterns with varying amplitudes, suggesting a signal with multiple frequency components. The irregular oscillations indicate noise or a complex signal.\n- **Key Features and Technical Details**: The waveform intersects the time axis multiple times, showing zero crossings, and features several peaks and troughs, though specific amplitude values are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, indicating the sampling locations.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Graph Type**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x' for amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram reveals a roughly symmetrical distribution, akin to a Gaussian distribution, suggesting that the signal's amplitudes are centered around a mean value with decreasing frequency as the amplitude deviates from the center.\n- **Key Features and Technical Details**: The histogram comprises bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution decreases symmetrically on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape implies a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 illustrates the amplitude distribution of noise through two subplots.\n\n1. **Graph Type and Function**:\n- The left subplot is a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units**:\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal's amplitude ($x(t)$). No specific units are provided, suggesting a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. Again, no specific units are given, indicating a normalized distribution.\n\n3. **Overall Behavior and Trends**:\n- The left subplot displays a fluctuating waveform typical of noise, lacking any evident periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot presents a bell-shaped histogram, suggesting a normal distribution of the noise amplitude. The central bins have higher counts, indicating that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details**:\n- The waveform in the left subplot shows varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points**:\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but the histogram's shape is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually represents how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. According to the central limit theorem, if numerous independent random processes with arbitrary PDFs are combined, the PDF of the sum tends to a Gaussian distribution [1]. Consequently, it is unsurprising that many natural phenomena exhibit Gaussian statistics. For instance, the noise in a resistor arises from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. Nonetheless, for completeness, we define the Gaussian PDF as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "As previously stated, the instantaneous amplitude of noise is typically unpredictable. However, by observing the noise waveform over an extended period, we can create a \"distribution\" of the amplitude, showing how frequently each value occurs. This is also known as the \"probability density function\" (PDF). The distribution of $x(t)$ is defined as\n\n$$\n\\begin{equation*}\np_{X}(x) d x=\\text { probability of } x<X<x+d x \\tag{7.7}\n\\end{equation*}\n$$\n\nwhere $X$ represents the measured value of $x(t)$ at a specific time point.\n\nAs depicted in Fig. 7.11, to estimate this distribution, we sample $x(t)$ at numerous points, form bins of small width, set the bin height to the number of samples whose values fall within the bin edges, and normalize these heights to the total number of samples. It's important to note that the PDF does not provide information on how quickly $x(t)$ changes in the time domain. For instance, the sound produced by a violin may have the same amplitude distribution as that from a drum, despite their significantly different frequency contents.\nimage_name:Figure 7.11 x(t)\ndescription:The image comprises two main sections: a time-domain waveform and a histogram depicting an amplitude distribution.\n\n1. **Time-Domain Waveform (x(t))**:\n- **Type of Graph**: This is a plot of a time-domain waveform.\n- **Axes Labels and Units**: The horizontal axis is labeled 't' for time, and the vertical axis is labeled 'x(t)' for the signal amplitude at time 't'. No units are specified, indicating a general representation.\n- **Overall Behavior and Trends**: The waveform displays oscillatory behavior with varying amplitudes, suggesting a signal with multiple frequency components. The oscillations are irregular, indicating noise or a complex signal.\n- **Key Features and Technical Details**: The waveform crosses the time axis multiple times, indicating zero crossings, and features several peaks and troughs, though specific amplitudes are not provided.\n- **Annotations and Specific Data Points**: The waveform is sampled at discrete points, marked by circles along the curve, showing where the signal has been sampled.\n\n2. **Amplitude Distribution (Histogram)**:\n- **Type of Graph**: This is a histogram showing the amplitude distribution of the sampled signal.\n- **Axes Labels and Units**: The horizontal axis is labeled 'x' for amplitude values, and the vertical axis is labeled 'Number of Samples', indicating the count of samples in each amplitude bin.\n- **Overall Behavior and Trends**: The histogram displays a roughly symmetrical distribution, resembling a Gaussian distribution, suggesting that the signal amplitudes are centered around a mean value with decreasing frequency as the amplitude deviates from the center.\n- **Key Features and Technical Details**: The histogram has bins of varying heights, with the tallest bins near the center, indicating the most common amplitude values. The distribution tapers off symmetrically on both sides.\n- **Annotations and Specific Data Points**: No specific numerical values or annotations are present on the histogram, but its shape suggests a normal distribution of amplitudes.\nimage_name:Figure 7.11 Amplitude distribution of noise\ndescription:Figure 7.11 graphically represents the amplitude distribution of noise through two subplots.\n\n1. **Type of Graph and Function:**\n- The left subplot is a time-domain waveform of a random noise signal, denoted as $x(t)$.\n- The right subplot is a histogram representing the probability density function (PDF) of the noise amplitude.\n\n2. **Axes Labels and Units:**\n- In the left subplot, the horizontal axis represents time ($t$), and the vertical axis represents the signal amplitude ($x(t)$). No specific units are provided, indicating a general representation.\n- In the right subplot, the horizontal axis represents amplitude ($x$), and the vertical axis shows the number of samples. Again, no specific units are given, suggesting a normalized distribution.\n\n3. **Overall Behavior and Trends:**\n- The left subplot shows a fluctuating waveform typical of noise, lacking any apparent periodicity or regular pattern. The waveform crosses the time axis several times, indicating zero crossings, and exhibits varying peak amplitudes.\n- The right subplot displays a bell-shaped histogram, indicating a normal distribution of the noise amplitude. The central bins have higher counts, suggesting that most sample values are near the mean, with fewer samples at the extremes.\n\n4. **Key Features and Technical Details:**\n- The waveform in the left subplot exhibits varying amplitudes and frequencies, characteristic of noise.\n- The histogram in the right subplot is symmetric around the central value, typical of Gaussian distributions.\n\n5. **Annotations and Specific Data Points:**\n- The left subplot includes markers on the waveform, possibly indicating sample points.\n- The right subplot lacks specific annotations or reference lines, but the shape of the histogram is essential for understanding the amplitude distribution.\n\nOverall, Figure 7.11 visually illustrates how noise behaves in both the time domain and its amplitude distribution, highlighting the Gaussian nature of the amplitude distribution.\n\nA significant example of PDFs is the Gaussian (or normal) distribution. The central limit theorem states that if many independent random processes with arbitrary PDFs are combined, the PDF of the sum tends towards a Gaussian distribution [1]. Consequently, it is not unexpected that many natural phenomena exhibit Gaussian statistics. For example, the noise in a resistor results from the random \"walk\" of a vast number of electrons, each with relatively independent statistics, leading to an overall amplitude that follows a Gaussian PDF.\n\nIn this book, we focus more on the spectrum and average power of noise rather than the amplitude distribution. However, for completeness, we note that the Gaussian PDF is defined as\n\n$$\n\\begin{equation*}\np_{X}(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\frac{-(x-m)^{2}}{2 \\sigma^{2}} \\tag{7.8}\n\\end{equation*}\n$$\n\nwhere $\\sigma$ and $m$ are the standard deviation and mean of the distribution, respectively. For a Gaussian distribution, $\\sigma$ equals the rms value of the noise."
},
{
    "text": "In the analysis of circuits, it is often necessary to combine the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents can be easily summed using the superposition principle, the approach for random noise differs because our focus is on the average noise power. Consider adding two noise waveforms and calculating the average power of the resultant:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),{ }^{4}$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to disappear. For instance, the noise from a resistor is unrelated to that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. Superposition also applies to noise voltages and currents, though this is often not useful in practice.\n\nA useful analogy is the noise in a sports stadium. Before the game, numerous uncorrelated conversations create noise components [Fig. 7.12(a)]. During the game, simultaneous applause or screaming by spectators generates correlated noise at a higher power level, corresponding to the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" illustrates the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This diagram is part of a discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nMain Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: Depicted as three separate waveforms entering the system from the left, each representing an independent noise source with its own time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, shown as a circle with a plus sign inside, combining the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation, representing the total noise output, also a time-varying signal.\n\nFlow of Information or Control:\n- Independent noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown moving to the right.\n\nLabels, Annotations, and Key Indicators:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing the signals' progression through the system.\n\nOverall System Function:\nThe system demonstrates how uncorrelated noise sources combine to produce a total noise output. Each input contributes independently to the output, with the summation block simply adding these contributions without correlation. This model helps understand the interaction of different noise components in a system, particularly when they are uncorrelated, as in pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) shows a system block diagram representing correlated noise in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction depicted by a circle with a plus sign.\n\n1. **Main Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: Represent individual noise signals from different sections of spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: Combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Flow of Information:**\n- Noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, with arrows indicating the direction towards the junction.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude compared to individual inputs, signifying correlation.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is indicated on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **Overall System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a much larger total noise signal. This is analogous to simultaneous applause or screams in a stadium, highlighting noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Main Components:**\nThe block diagram \"Figure 7.13 (a)\" illustrates signal amplification and the presence of noise in the output. The key component is the **Amplifier**. The diagram also shows the input signal **Vin** entering the amplifier.\n\n**Flow of Information or Control:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output comprising both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output.\n\n**Labels, Annotations, and Key Indicators:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output.\n\n**Overall System Function:**\nThe system amplifies the input signal and illustrates the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design to ensure a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) shows a frequency response graph, likely representing the output noise of an amplifier circuit. It is a Bode plot depicting the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph shows a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- Amplifier bandwidth from 0 to 1 MHz, showing the effective operating range.\n- Roll-off beyond 1 MHz indicates typical low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In circuit analysis, we frequently need to sum the effects of multiple noise sources to determine the total noise. While for deterministic voltages and currents, we apply the superposition principle directly, the approach differs for random noise due to our focus on average noise power. Let's combine two noise waveforms and calculate the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to vanish. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also applies to noise voltages and currents, it is often not helpful in most cases.\n\nA useful analogy is the noise in a sports stadium. Before the game, numerous unrelated conversations generate uncorrelated noise components [Fig. 7.12(a)]. During the game, synchronized applause or screams from spectators produce correlated noise with significantly higher power, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" illustrates the concept of uncorrelated noise generation using a block diagram to represent the superposition of multiple noise sources. This diagram is part of a discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: Depicted as three separate waveforms entering the system from the left, each representing an independent noise source with its own unique time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, shown as a circle with a plus sign, combining the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation, representing the total noise output, also a time-varying signal.\n\nInformation Flow:\n- Independent noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown moving right.\n\nLabels and Indicators:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating their time-dependent nature.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing signal progression through the system.\n\nSystem Function:\nThe diagram demonstrates how uncorrelated noise sources combine to produce a total noise output. Each input contributes independently to the output, with the summation block adding these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when uncorrelated, as in pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) shows a system block diagram representing correlated noise in a stadium. It includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction depicted as a circle with a plus sign.\n\n1. **Key Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: Represent individual noise signals from different spectator sections, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: Combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- Noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, directed by arrows.\n- The summing junction's output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude, indicating correlation.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is marked on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a much larger total noise signal. This mirrors the scenario of spectators simultaneously applauding or screaming in a stadium, highlighting noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Key Components:**\nThe block diagram \"Figure 7.13 (a)\" illustrates signal amplification and the presence of noise in the output. The main component is the **Amplifier**. The diagram also shows the input signal, **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output comprising both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal output waveform, indicating noise presence.\n\n**Labels and Indicators:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the output's horizontal axis, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe system amplifies the input signal and illustrates the introduction of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, emphasizing the importance of considering noise in amplification system design for a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) presents a frequency response graph likely representing an amplifier circuit's output noise. It is a Bode plot showing the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph shows a flat response up to 20 kHz in the audio range, indicating consistent amplifier gain. Beyond 20 kHz, the response remains flat until near 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- Amplifier bandwidth from 0 to 1 MHz, indicating effective operation range.\n- Roll-off beyond 1 MHz, typical of low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing high-frequency noise.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "When analyzing circuits, we frequently need to sum the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents can be combined using the superposition principle, the approach for random noise differs since our focus is on the average noise power. Let's consider adding two noise waveforms and calculating the average power of the resultant:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to消失. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. Superposition also applies to noise voltages and currents, though this is often not useful.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game, numerous uncorrelated noise components arise from various conversations [Fig. 7.12(a)]. During the game, synchronized applause or screams produce correlated noise at a significantly higher power level, corresponding to the third term in Eq. (7.11) [Fig. 7.12(b)].\n\n**Figure 7.12 (a) Description:**\nThe diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to represent the superposition of multiple noise sources. This is part of a discussion on noise in systems, particularly in a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: Illustrated as three separate waveforms entering from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, shown as a circle with a plus sign, combining the inputs into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation, representing the total noise output.\n\nFlow of Information:\n- Independent noise signals (x1(t), x2(t), x3(t)) flow into the summation block from left to right.\n- The summation block adds these signals to produce the total output noise signal, xtot(t).\n\nLabels and Annotations:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)).\n- The output is labeled xtot(t).\n- Arrows indicate the direction of time (t) and signal flow.\n\nSystem Function:\nThe diagram illustrates how uncorrelated noise sources combine to form a total noise output, with each source contributing independently.\n\n**Figure 7.12 (b) Description:**\nFigure 7.12(b) shows a system block diagram for correlated noise in a stadium. It includes noise sources \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction.\n\nMain Components:\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: Represent individual noise signals from different spectator sections.\n- **Summing Junction**: Combines the individual noise signals.\n\nFlow of Information:\n- Noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction.\n- The output, \\(x_{tot}(t)\\), is a larger amplitude waveform, indicating correlated noise.\n\nLabels and Annotations:\n- Time variable \\(t\\) on the horizontal axis.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\).\n\nSystem Function:\nThe diagram demonstrates how correlated individual noise signals combine to produce a larger total noise signal, analogous to simultaneous applause or screams in a stadium.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\n\n**Figure 7.13 (a) Description:**\nThis block diagram illustrates signal amplification and the presence of noise in the output, focusing on the **Amplifier**.\n\nKey Components:\n- **Amplifier**: Processes the input signal.\n- **Input Signal (Vin)**: Enters the amplifier.\n\nFlow of Information:\n- The input signal Vin enters the amplifier, producing an output with both amplified signal and noise.\n\nLabels and Annotations:\n- Input labeled Vin.\n- Output shown with Signal and Noise components.\n- Time variable t on the horizontal axis.\n\nSystem Function:\nThe diagram shows how noise is introduced during amplification, emphasizing the importance of noise consideration in amplifier design.\n\n**Figure 7.13 (b) Description:**\nFigure 7.13 (b) presents a frequency response graph, likely representing the output noise of an amplifier circuit. It is a Bode plot with magnitude \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis.\n\nKey Features:\n- Flat response up to 20 kHz, indicating consistent gain in the audio range.\n- Amplifier bandwidth from 0 to 1 MHz.\n- Roll-off beyond 1 MHz, suggesting low-pass filter behavior.\n\nAnnotations:\n- Dashed lines at 20 kHz and 1 MHz highlight transition points.\n\nBehavior:\nTypical for amplifiers designed for audio signals, minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise with excessive bandwidth."
},
{
    "text": "When analyzing circuits, it is often necessary to combine the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents are simply summed using the superposition principle, the approach differs for random noise because our primary interest lies in the average noise power. Let's consider adding two noise waveforms and calculating the average power of the resulting signal:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t)$, measures the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to disappear. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such cases, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not useful in most scenarios.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game, numerous conversations generate uncorrelated noise components [Fig. 7.12(a)]. During the game, spectators clap or scream in unison, producing correlated noise with significantly higher power due to the third term in Eq. (7.11) [Fig. 7.12(b)].\n\n**Figure 7.12 (a):** This diagram illustrates the concept of uncorrelated noise generation using a block diagram to represent the superposition of multiple noise sources. It includes:\n- **Noise Sources (x1(t), x2(t), x3(t))**: Three separate waveforms entering from the left, each representing an independent noise source.\n- **Summation Block (+)**: A central circle with a plus sign, combining the inputs into a single output signal.\n- **Output (xtot(t))**: The resulting total noise output waveform.\n\nThe flow of information moves from left to right, with each independent noise signal contributing to the total output without correlation.\n\n**Figure 7.12 (b):** This diagram shows a system block diagram representing correlated noise in a stadium. It includes:\n- **Noise Sources (x1(t), x2(t), x3(t))**: Individual noise signals from different spectator sections.\n- **Summing Junction**: A circle with a plus sign combining these signals.\n- **Output (xtot(t))**: The total noise signal with a larger amplitude, indicating correlation.\n\nThe flow of information shows individual noise signals combining to produce a significant total noise level, analogous to simultaneous applause or screams.\n\n**Figure 7.13 (a):** This block diagram illustrates signal amplification and the presence of noise in the output. It includes:\n- **Amplifier**: The key component processing the input signal.\n- **Input (Vin)**: The sinusoidal signal entering the amplifier.\n- **Output**: Comprising both the amplified signal and a smaller noise waveform.\n\nThe diagram highlights how noise is introduced during amplification, emphasizing the importance of signal-to-noise ratio considerations.\n\n**Figure 7.13 (b):** This frequency response graph represents the output noise of an amplifier circuit. It is a Bode plot showing:\n- A flat response up to 20 kHz, indicating consistent gain in the audio range.\n- A bandwidth from 0 to 1 MHz, with a roll-off beyond 1 MHz, suggesting low-pass filter behavior.\n\nAnnotated with dashed lines at 20 kHz and 1 MHz, the graph illustrates typical amplifier performance in handling audio signals while minimizing high-frequency noise.\n\n**Figure 7.12 (a) Uncorrelated noise and (b) correlated noise generated in a stadium.**\n\nIn most cases discussed in this book, noise sources are uncorrelated, with one exception explored in Section 7.3.\n\n**Figure 7.13 (a) Output noise produced by a circuit, and (b) additional noise if bandwidth is excessively wide.**"
},
{
    "text": "In the analysis of circuits, it is often necessary to combine the effects of multiple noise sources to determine the total noise. While for deterministic voltages and currents, the superposition principle is straightforwardly applied, the approach differs for random noise since our focus is on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),{ }^{4}$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to消失. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not particularly useful.\n\nA useful analogy is the behavior of spectators in a sports stadium. Prior to the game, numerous conversations generate uncorrelated noise components [Fig. 7.12(a)]. During the game, synchronized applause or screams from the spectators produce correlated noise with significantly higher power, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to represent the superposition of multiple noise sources. This diagram is part of a broader discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are illustrated as three distinct waveforms entering the system from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: This central element, depicted as a circle with a plus sign, combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) move from left to right into the summation block. Each signal is independent and uncorrelated with the others, meaning they do not affect each other’s characteristics.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its respective time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), denoting the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe main function of this system is to illustrate how uncorrelated noise sources combine to produce a total noise output. Each input noise source contributes independently to the output, and the summation block simply adds these contributions without any correlation between them. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in the pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) presents a system block diagram illustrating correlated noise generation in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign.\n\n1. **Key Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, with arrows indicating the direction of signal flow.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown as a waveform with a much larger amplitude compared to the individual inputs, highlighting the correlated nature of the noise.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is indicated on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- The labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The primary function of this diagram is to demonstrate how individual noise signals, when correlated, can combine to produce a significantly larger total noise signal. This is analogous to spectators in a stadium whose simultaneous applause or screams create a substantial noise level. The arrangement of the blocks and the flow of information highlight the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise generated in a stadium.\n\nIn most cases discussed in this book, the noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Key Components:**\nThe block diagram labeled \"Figure 7.13 (a)\" illustrates the process of signal amplification and the presence of noise in the output. The main component is the **Amplifier**. The diagram also shows the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output consisting of both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating the presence of noise in the amplified signal.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output is shown with two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe primary function of this system is to amplify an input signal while illustrating the presence of noise in the output. The arrangement of the blocks shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in the design and analysis of amplification systems to ensure a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) shows a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, depicting the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis. The frequency axis ranges from 0 to beyond 1 MHz, using a linear scale.\n\nThe graph displays a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting a decrease in gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- The amplifier bandwidth extends from 0 to 1 MHz, showing the effective operating range.\n- The roll-off beyond 1 MHz indicates typical low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise produced by a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In the analysis of circuits, it is often necessary to sum the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents are combined using the superposition principle, the approach differs for random noise since our focus is on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),{ }^{4}$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to disappear. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not helpful in most situations.\n\nA useful analogy is the behavior of spectators in a sports stadium. Prior to the game, numerous conversations occur, generating uncorrelated noise components [Fig. 7.12(a)]. During the game, spectators clap or scream in unison, producing correlated noise at a significantly higher power level due to the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This diagram is part of a broader discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are illustrated as three distinct waveforms entering the system from the left, each representing an independent noise source with its own time-varying signal.\n2. **Summation Block (+)**: This central element, depicted as a circle with a plus sign, combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not influence each other's characteristics.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its respective time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe primary function of this system is to illustrate how uncorrelated noise sources combine to produce a total noise output. Each input noise source contributes independently to the output, and the summation block simply adds these contributions without any correlation between them. This model aids in understanding how different noise components interact in a system, particularly when they are uncorrelated, as in the pre-game conversations analogy in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) shows a system block diagram representing correlated noise generated in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign inside it. Each noise source generates a signal that feeds into the summing junction.\n\n1. **Main Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the spectators. Each signal is depicted as a waveform, indicating its time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, as indicated by arrows.\n- The output of the summing junction, labeled \\(x_{tot}(t)\\), represents the total noise signal. This output is shown as a waveform with a much larger amplitude compared to the individual inputs, indicating the correlated nature of the noise.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is shown on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The main function of this diagram is to demonstrate how individual noise signals, when correlated, can combine to produce a significantly larger total noise signal. This is analogous to spectators in a stadium whose simultaneous applause or screams create a substantial noise level. The arrangement of the blocks and the flow of information highlight the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise generated in a stadium.\n\nIn most cases discussed in this book, the noise sources are uncorrelated. An exception is examined in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Main Components:**\nThe system block diagram labeled \"Figure 7.13 (a)\" shows the process of signal amplification and the presence of noise in the output. The key component is the **Amplifier**. The diagram also depicts the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output consisting of both the amplified signal and noise. The noise is shown as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence in the amplified signal.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output is shown with two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is depicted by a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe primary function of this system is to amplify an input signal while illustrating the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram underscores the importance of considering noise in the design and analysis of amplification systems to achieve a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) presents a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, showing the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, with a linear scale.\n\nThe graph displays a flat response in the audio range up to 20 kHz, indicating consistent amplifier gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it starts to roll off, suggesting a decrease in gain at higher frequencies.\n\nKey features include:\n- A clearly marked audio range up to 20 kHz, relevant for audio applications.\n- The amplifier bandwidth extends from 0 to 1 MHz, indicating the effective operating range.\n- The roll-off beyond 1 MHz typifies low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise produced by a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In the analysis of circuits, it is often necessary to sum the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents are combined using the superposition principle, the approach for random noise differs because our primary interest lies in the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to disappear. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not helpful in most cases.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game starts, numerous uncorrelated noise components arise from various conversations [Fig. 7.12(a)]. During the game, spectators clap or shout in unison, generating correlated noise with significantly higher power due to the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This diagram is part of a discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: Illustrated as three distinct waveforms entering the system from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, depicted as a circle with a plus sign, it combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation, representing the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving right.\n\nLabels and Annotations:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating their time-dependent nature.\n- The output is labeled xtot(t), denoting the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe diagram illustrates how uncorrelated noise sources combine to produce a total noise output. Each input contributes independently to the output, with the summation block adding these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) presents a system block diagram showing correlated noise generation in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign.\n\n1. **Main Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: Combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, with arrows indicating the direction.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude than the individual inputs, highlighting the correlated nature of the noise.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is indicated on the horizontal axis, emphasizing the temporal aspect.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a significantly larger total noise signal, analogous to simultaneous applause or screams in a stadium. The block arrangement and information flow highlight the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Main Components:**\nThe block diagram labeled \"Figure 7.13 (a)\" shows the process of signal amplification and the presence of noise in the output. The key component is the **Amplifier**. The diagram also includes the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output comprising both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the output's horizontal axis, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe system amplifies an input signal and illustrates the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design and analysis to maintain a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) displays a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, showing the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, with a linear scale.\n\nThe graph shows a flat response in the audio range up to 20 kHz, indicating consistent amplifier gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting reduced gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- Amplifier bandwidth from 0 to 1 MHz, indicating effective operation range.\n- Roll-off beyond 1 MHz, typical of low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is common in amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In the analysis of circuits, it is often necessary to sum the effects of multiple noise sources to determine the total noise. While for deterministic voltages and currents, the superposition principle is straightforwardly applied, the approach differs for random noise since our focus is on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),{ }^{4}$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to消失. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not helpful in practical situations.\n\nAn illustrative analogy is the noise in a sports stadium. Before the game, numerous conversations generate uncorrelated noise components [Fig. 7.12(a)]. During the game, spectators clap or scream in unison, producing correlated noise at a significantly higher power level, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This illustration is part of a broader discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are represented as three distinct waveforms entering the system from the left, each symbolizing an independent noise source with its own time-varying signal.\n2. **Summation Block (+)**: This central element, depicted as a circle with a plus sign, combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), representing the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe primary function of this system is to demonstrate how uncorrelated noise sources combine to produce a total noise output. Each input noise source contributes independently to the output, and the summation block simply adds these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in the pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) presents a system block diagram illustrating correlated noise generation in a stadium. The diagram comprises three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign.\n\n1. **Main Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, as indicated by arrows.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude compared to the individual inputs, highlighting the correlated nature of the noise.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is marked on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- The labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a significantly larger total noise signal. This is analogous to spectators in a stadium simultaneously applauding or screaming, creating a substantial noise level. The block arrangement and information flow highlight the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is examined in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Main Components:**\nThe block diagram labeled \"Figure 7.13 (a)\" illustrates the process of signal amplification and the presence of noise in the output. The key component is the **Amplifier**. The diagram also shows the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output comprising both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe primary function is to amplify an input signal while illustrating the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design to ensure a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) shows a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, depicting the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph displays a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- The amplifier bandwidth extends from 0 to 1 MHz, showing effective operation range.\n- The roll-off beyond 1 MHz indicates typical low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In the analysis of circuits, we frequently need to sum the effects of multiple noise sources to determine the total noise. While for deterministic voltages and currents, the superposition principle is directly applied, the approach differs for random noise due to our focus on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to消失. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such scenarios, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. Superposition also holds for noise voltages and currents, though this is often not useful in most cases.\n\nAn illustrative analogy is the noise in a sports stadium. Before the game, numerous independent conversations generate uncorrelated noise components [Fig. 7.12(a)]. During the game, synchronized applause or screams from the spectators produce correlated noise at a significantly higher power level, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:Figure 7.12 (a) depicts the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This diagram is part of a discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: Illustrated as three distinct waveforms entering the system from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, this component combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation, representing the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) move from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Indicators:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating their time-dependent nature.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe diagram illustrates how uncorrelated noise sources combine to produce a total noise output. Each input contributes independently to the output, with the summation block simply adding these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in pre-game stadium conversations.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) presents a system block diagram showing correlated noise generation in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign.\n\n1. **Key Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the audience, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: Combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, as indicated by arrows.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude compared to the individual inputs, indicating correlation.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is marked on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a significantly larger total noise signal. This is analogous to simultaneous applause or screams in a stadium, highlighting the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Key Components:**\nFigure 7.13 (a) shows a system block diagram illustrating signal amplification and the presence of noise in the output. The main component is the **Amplifier**. The diagram also includes the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe process begins with the input sinusoidal signal **Vin** entering the amplifier. The amplifier processes this signal, producing an output that includes both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the output's horizontal axis, showing the temporal nature of the signal and noise.\n\n**System Function:**\nThe primary function is to amplify the input signal while illustrating the introduction of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, emphasizing the importance of considering noise in amplification system design to maintain a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) shows a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, depicting the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph exhibits a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it starts to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- The amplifier bandwidth extends from 0 to 1 MHz, showing effective operation range.\n- The roll-off beyond 1 MHz indicates typical low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise with an excessively wide bandwidth."
},
{
    "text": "In the analysis of circuits, we frequently need to sum the effects of multiple noise sources to determine the total noise. While for deterministic voltages and currents, the superposition principle is directly applied, the approach differs for random noise due to our focus on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),{ }^{4}$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to消失. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such cases, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not useful in most scenarios.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game starts, numerous conversations create uncorrelated noise components [Fig. 7.12(a)]. During the game, synchronized applause or screams from the spectators generate correlated noise with significantly higher power, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" illustrates the concept of uncorrelated noise generation using a block diagram to depict the superposition of multiple noise sources. This diagram is part of a discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are shown as three separate waveforms entering the system from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: This central component, depicted as a circle with a plus sign, combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, also a time-varying signal.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not influence each other.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its respective time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe primary function of this system is to demonstrate how uncorrelated noise sources combine to produce a total noise output. Each input noise source contributes independently to the output, and the summation block simply adds these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in the pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) shows a system block diagram representing correlated noise generated in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction depicted by a circle with a plus sign.\n\n1. **Key Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, as indicated by arrows.\n- The output of the summing junction, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude compared to the individual inputs, signifying correlation.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is indicated on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a much larger total noise signal. This is analogous to spectators in a stadium whose simultaneous applause or screams create significant noise. The arrangement highlights the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Key Components:**\nThe block diagram labeled \"Figure 7.13 (a)\" illustrates the process of signal amplification and the presence of noise in the output. The main component is the **Amplifier**. The diagram also shows the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output consisting of both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output.\n\n**System Function:**\nThe primary function is to amplify an input signal while illustrating the presence of noise in the output. The direct path from input to output through the amplifier shows how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design to maintain a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) presents a frequency response graph, likely representing the output noise of an amplifier circuit. It is a Bode plot showing the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph shows a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- Amplifier bandwidth from 0 to 1 MHz, indicating the effective operating range.\n- Roll-off beyond 1 MHz, typical of low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "In the analysis of circuits, it is often necessary to sum the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents can be combined using the superposition principle, the approach for random noise differs because our primary interest lies in the average noise power. Let's consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the degree of similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to vanish. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such cases, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also holds for noise voltages and currents, it is often not useful in most scenarios.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game starts, numerous conversations occur, generating uncorrelated noise components [Fig. 7.12(a)]. During the game, spectators clap or scream in unison, producing correlated noise with significantly higher power due to the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:The diagram labeled \"Figure 7.12 (a)\" depicts the concept of uncorrelated noise generation using a block diagram to show the superposition of multiple noise sources. This illustration is part of a broader discussion on noise in systems, particularly in the context of a sports stadium analogy.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are represented as three distinct waveforms entering the system from the left, each symbolizing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: This central element, depicted as a circle with a plus sign, combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, which is also time-varying.\n\nInformation Flow:\n- The noise signals (x1(t), x2(t), x3(t)) move from left to right into the summation block. Each signal is independent and uncorrelated, meaning they do not affect each other's characteristics.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown as a waveform moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its respective time function (x1(t), x2(t), x3(t)), indicating their nature as time-dependent noise sources.\n- The output is labeled xtot(t), denoting the total noise output.\n- Arrows indicate the direction of time (t), showing the progression of signals through the system.\n\nSystem Function:\nThe primary function of this system is to demonstrate how uncorrelated noise sources combine to produce a total noise output. Each input noise source contributes independently to the output, and the summation block simply adds these contributions without any correlation between them. This model aids in understanding the interaction of different noise components in a system, particularly when they are uncorrelated, as in the pre-game conversations in a stadium.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) presents a system block diagram illustrating correlated noise generation in a stadium. The diagram includes three main components: noise sources labeled \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction represented by a circle with a plus sign.\n\n1. **Key Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different sections of the spectators, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Information Flow:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, as indicated by arrows.\n- The output of the summing junction, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude compared to the individual inputs, highlighting the correlated nature of the noise.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is shown on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- The labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **System Function:**\n- The main function of this diagram is to show how individual noise signals, when correlated, can combine to produce a much larger total noise signal. This is analogous to spectators in a stadium whose simultaneous applause or screams create a significant noise level. The arrangement of the blocks and the flow of information highlight the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise generated in a stadium.\n\nIn most scenarios discussed in this book, the noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Key Components:**\nThe block diagram labeled \"Figure 7.13 (a)\" illustrates the process of signal amplification and the presence of noise in the output. The main component is the **Amplifier**. The diagram also shows the input signal, denoted as **Vin**, entering the amplifier.\n\n**Information Flow:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output consisting of both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is represented by a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the horizontal axis of the output.\n\n**System Function:**\nThe primary function is to amplify the input signal while illustrating the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design to maintain a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) shows a frequency response graph, likely representing the output noise of an amplifier circuit. The graph is a Bode plot, depicting the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph displays a flat response in the audio range up to 20 kHz, indicating consistent gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A clearly marked audio range up to 20 kHz, relevant for audio applications.\n- The amplifier bandwidth extends from 0 to 1 MHz, showing the effective operating range.\n- The roll-off beyond 1 MHz indicates typical low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise produced by a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "When analyzing circuits, it is often necessary to sum the effects of multiple noise sources to determine the total noise. While deterministic voltages and currents are combined using the superposition principle, the approach for random noise differs because our focus is on the average noise power. Consider adding two noise waveforms and calculating the average of the resulting power:\n\n$$\n\\begin{align*}\nP_{a v}= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2}\\left[x_{1}(t)+x_{2}(t)\\right]^{2} d t  \\tag{7.9}\\\\\n= & \\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{1}^{2}(t) d t+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} x_{2}^{2}(t) d t \\\\\n& +\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t  \\tag{7.10}\\\\\n= & P_{a v 1}+P_{a v 2}+\\lim _{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T / 2}^{+T / 2} 2 x_{1}(t) x_{2}(t) d t \\tag{7.11}\n\\end{align*}\n$$\n\nHere, $P_{a v 1}$ and $P_{a v 2}$ represent the average power of $x_{1}(t)$ and $x_{2}(t)$, respectively. The third term in (7.11), known as the \"correlation\" between $x_{1}(t)$ and $x_{2}(t),$ indicates the similarity between these two waveforms. If the noise waveforms are generated by independent devices, they are typically \"uncorrelated,\" causing the integral in (7.11) to disappear. For instance, the noise from a resistor is uncorrelated with that from a transistor. In such cases, $P_{a v}=P_{a v 1}+P_{a v 2}$. This leads us to conclude that superposition applies to the power of uncorrelated noise sources. While superposition also applies to noise voltages and currents, it is often not helpful in most scenarios.\n\nA useful analogy is the behavior of spectators in a sports stadium. Before the game, numerous conversations create uncorrelated noise components [Fig. 7.12(a)]. During the game, simultaneous applause or screams generate correlated noise at a higher power level, as indicated by the third term in Eq. (7.11) [Fig. 7.12(b)].\nimage_name:Figure 7.12 (a)\ndescription:Figure 7.12 (a) depicts a block diagram illustrating the concept of uncorrelated noise generation, using a sports stadium analogy. This diagram is part of a discussion on noise in systems.\n\nKey Components:\n1. **Noise Sources (x1(t), x2(t), x3(t))**: These are shown as separate waveforms entering the system from the left, each representing an independent noise source with a unique time-varying signal.\n2. **Summation Block (+)**: Central to the diagram, this circle with a plus sign combines the inputs from the three noise sources into a single output signal.\n3. **Output (xtot(t))**: The resulting waveform after summation represents the total noise output, also a time-varying signal.\n\nFlow of Information:\n- The noise signals (x1(t), x2(t), x3(t)) flow from left to right into the summation block, each independent and uncorrelated with the others.\n- The summation block adds these signals to produce the total output noise signal, xtot(t), shown moving to the right.\n\nLabels and Annotations:\n- Each input signal is labeled with its time function (x1(t), x2(t), x3(t)), indicating they are time-dependent noise sources.\n- The output is labeled xtot(t), signifying the total noise output.\n- Arrows indicate the direction of time (t), showing the signals' progression through the system.\n\nOverall Function:\nThe system demonstrates how uncorrelated noise sources combine to produce a total noise output. Each input contributes independently to the output, with the summation block simply adding these contributions without correlation. This model aids in understanding the interaction of different noise components in a system, particularly when uncorrelated, as in pre-game stadium conversations.\nimage_name:Figure 7.12 (b)\ndescription:Figure 7.12(b) shows a block diagram representing correlated noise in a stadium. It includes three main components: noise sources \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\), and a summing junction depicted by a circle with a plus sign.\n\n1. **Main Components:**\n- **Noise Sources (\\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\))**: These represent individual noise signals from different spectator sections, depicted as waveforms indicating their time-varying nature.\n- **Summing Junction**: This combines the individual noise signals, symbolized by a circle with a plus sign.\n\n2. **Flow of Information:**\n- The noise signals \\(x_1(t)\\), \\(x_2(t)\\), and \\(x_3(t)\\) flow into the summing junction, with arrows indicating the direction towards the junction.\n- The output, labeled \\(x_{tot}(t)\\), represents the total noise signal, shown with a larger amplitude than the individual inputs, signifying correlation.\n\n3. **Labels and Annotations:**\n- The time variable \\(t\\) is indicated on the horizontal axis, emphasizing the temporal aspect of the noise signals.\n- Labels \\(x_1(t)\\), \\(x_2(t)\\), \\(x_3(t)\\), and \\(x_{tot}(t)\\) identify the individual and total noise signals.\n\n4. **Overall System Function:**\n- The diagram demonstrates how individual noise signals, when correlated, combine to produce a significantly larger total noise signal. This is analogous to simultaneous applause or screams in a stadium, highlighting the process of noise correlation and amplification.\n\nFigure 7.12 (a) Uncorrelated noise and (b) correlated noise in a stadium.\n\nIn most cases discussed in this book, noise sources are uncorrelated. An exception is explored in Section 7.3.\nimage_name:Figure 7.13 (a)\ndescription:**Main Components:**\nFigure 7.13 (a) shows a block diagram illustrating signal amplification and the presence of noise in the output. The key component is the **Amplifier**. The diagram also includes the input signal **Vin** entering the amplifier.\n\n**Flow of Information:**\nThe input sinusoidal signal **Vin** enters the amplifier, which processes it to produce an output comprising both the amplified signal and noise. The noise is depicted as a smaller, jagged waveform superimposed on the larger sinusoidal waveform at the output, indicating noise presence.\n\n**Labels and Annotations:**\nThe input is labeled **Vin**, and the output shows two components: **Signal** and **Noise**. The signal is a larger sinusoidal waveform, while the noise is a smaller, jagged waveform. The time variable **t** is indicated on the output's horizontal axis, showing the temporal nature of the signal and noise.\n\n**Overall System Function:**\nThe system amplifies the input signal and illustrates the presence of noise in the output. The block arrangement shows the direct path from input to output through the amplifier, highlighting how noise can be introduced during amplification. The diagram emphasizes the importance of considering noise in amplification system design and analysis to achieve a desirable signal-to-noise ratio.\nimage_name:Figure 7.13 (b)\ndescription:Figure 7.13 (b) presents a frequency response graph likely representing the output noise of an amplifier circuit. It is a Bode plot showing the magnitude of the transfer function \\(|H(\\omega)|\\) on the vertical axis and frequency \\(f\\) on the horizontal axis, using a linear scale.\n\nThe graph shows a flat response in the audio range up to 20 kHz, indicating consistent amplifier gain within this range. Beyond 20 kHz, the response remains flat until it approaches 1 MHz, where it begins to roll off, suggesting decreased gain at higher frequencies.\n\nKey features include:\n- A marked audio range up to 20 kHz, relevant for audio applications.\n- Amplifier bandwidth from 0 to 1 MHz, indicating the effective operating range.\n- Roll-off beyond 1 MHz, typical of low-pass filter behavior, attenuating higher frequencies.\n\nThe graph is annotated with dashed lines at 20 kHz and 1 MHz, highlighting transition points in the frequency response. This behavior is typical for amplifiers designed for audio signals while minimizing noise at higher frequencies.\n\nFigure 7.13 (a) Output noise from a circuit, and (b) additional noise if bandwidth is excessively wide."
},
{
    "text": "Consider an amplifier that receives a sinusoidal signal, as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be comprehensible, its power, $P_{\\text {sig }}$, must significantly exceed the noise power, $P_{\\text {noise }}$. Thus, we define the \"signal-to-noise ratio\" (SNR) as follows:\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text {sig }}}{P_{\\text {noise }}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text {sig }} / P_{\\text {noise }}=100$ ). ${ }^{5}$ For a sinusoid with a peak amplitude of $A, P_{\\text {sig }}=A^{2} / 2$, but how is $P_{\\text {noise }}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text {noise }}=\\int_{-\\infty}^{+\\infty} S_{\\text {noise }}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text {noise }}$ can become quite large if $S_{\\text {noise }}(f)$ covers a broad frequency range? Yes, it does. For example, if the aforementioned amplifier has a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)], the signal is distorted by all noise components within the 1-MHz bandwidth. Consequently, the circuit's bandwidth should always be constrained to the smallest acceptable value to reduce the integrated noise power. This bandwidth reduction can be achieved within the amplifier or by employing a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum defined by $S_{\\text {noise }}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text {noise }} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text {noise }}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power corresponds to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Consider a scenario where an amplifier processes a sinusoidal signal, as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise introduced by the circuit. For the output signal to be clear, its power, $P_{\\text {sig }}$, must significantly exceed the noise power, $P_{\\text {noise }}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as follows:\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text {sig }}}{P_{\\text {noise }}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text {sig }} / P_{\\text {noise }}=100$). ${ }^{5}$ For a sinusoid with a peak amplitude of $A, P_{\\text {sig }}=A^{2} / 2$. However, how is $P_{\\text {noise }}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text {noise }}=\\int_{-\\infty}^{+\\infty} S_{\\text {noise }}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text {noise }}$ can become quite substantial if $S_{\\text {noise }}(f)$ covers a broad frequency range? Yes, it does. For example, if the aforementioned amplifier has a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)], the signal will be distorted by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth must always be constrained to the smallest acceptable level to reduce the integrated noise power. This bandwidth reduction can be achieved within the amplifier or by using a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum defined by $S_{\\text {noise }}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text {noise }} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text {noise }}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nIt is important to note that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power equates to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Imagine an amplifier is fed a sinusoidal signal, as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be discernible, its power, $P_{\\text {sig }}$, must significantly exceed the noise power, $P_{\\text {noise }}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as follows:\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text {sig }}}{P_{\\text {noise }}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text {sig }} / P_{\\text {noise }}=100$ ). ${ }^{5}$ For a sinusoid with a peak amplitude of $A, P_{\\text {sig }}=A^{2} / 2$, but how is $P_{\\text {noise }}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text {noise }}=\\int_{-\\infty}^{+\\infty} S_{\\text {noise }}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text {noise }}$ can become quite large if $S_{\\text {noise }}(f)$ covers a broad frequency range? Yes, it does. Consider, for example, an amplifier with a bandwidth of 1 MHz while processing an audio signal [Fig. 7.13(b)]. In this case, the signal is degraded by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth should always be constrained to the smallest acceptable level to reduce the integrated noise power. This can be achieved either within the amplifier or by employing a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum described by $S_{\\text {noise }}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text {noise }} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text {noise }}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power equates to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Consider an amplifier that receives a sinusoidal signal as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be comprehensible, its power, $P_{\\text {sig }}$, must significantly exceed that of the noise, $P_{\\text {noise }}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text {sig }}}{P_{\\text {noise }}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text {sig }} / P_{\\text {noise }}=100$ ). ${ }^{5}$ For a sinusoid with a peak amplitude of $A, P_{\\text {sig }}=A^{2} / 2$, but how is $P_{\\text {noise }}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text {noise }}=\\int_{-\\infty}^{+\\infty} S_{\\text {noise }}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text {noise }}$ can become very large if $S_{\\text {noise }}(f)$ covers a broad frequency range? Yes, it does. For example, if the aforementioned amplifier has a bandwidth of 1 MHz while processing an audio signal [Fig. 7.13(b)], the signal is degraded by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth should always be constrained to the smallest acceptable value to minimize the integrated noise power. This can be achieved by reducing the bandwidth within the amplifier or by using a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum defined by $S_{\\text {noise }}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise in a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text {noise }} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text {noise }}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power corresponds to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Consider an amplifier that receives a sinusoidal signal as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be discernible, its power, $P_{\\text{sig}}$, must significantly exceed that of the noise, $P_{\\text{noise}}$. Thus, we define the \"signal-to-noise ratio\" (SNR) as follows:\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text{sig}}}{P_{\\text{noise}}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text{sig}} / P_{\\text{noise}} = 100$). ${}^{5}$ For a sinusoid with a peak amplitude of $A$, $P_{\\text{sig}} = A^{2} / 2$. However, how is $P_{\\text{noise}}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text{noise}}=\\int_{-\\infty}^{+\\infty} S_{\\text{noise}}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text{noise}}$ can become very large if $S_{\\text{noise}}(f)$ covers a broad frequency range? Yes, it does. For example, assume the aforementioned amplifier has a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)]. In this case, the signal is degraded by all noise components within the 1-MHz bandwidth. Consequently, the circuit's bandwidth should always be constrained to the smallest acceptable value to reduce the integrated noise power. This bandwidth reduction can be achieved within the amplifier or by employing a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum defined by $S_{\\text{noise}}(f) = 5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text{noise}} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text{noise}}(f) d f \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power corresponds to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}} = 22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Consider an amplifier that receives a sinusoidal signal as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be comprehensible, its power, $P_{\\text{sig}}$, must significantly exceed that of the noise, $P_{\\text{noise}}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text{sig}}}{P_{\\text{noise}}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text{sig}} / P_{\\text{noise}}=100$). ${}^{5}$ For a sinusoid with a peak amplitude of $A$, $P_{\\text{sig}}=A^{2} / 2$, but how is $P_{\\text{noise}}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text{noise}}=\\int_{-\\infty}^{+\\infty} S_{\\text{noise}}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text{noise}}$ can become very large if $S_{\\text{noise}}(f)$ covers a broad frequency range? Yes, it does. For example, assume the aforementioned amplifier has a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)]. In this case, the signal is degraded by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth should always be constrained to the smallest acceptable value to reduce the integrated noise power. This bandwidth reduction can be achieved within the amplifier or by using a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum described by $S_{\\text{noise}}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text{noise}} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text{noise}}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power equates to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Imagine an amplifier is fed a sinusoidal signal, as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be comprehensible, its power, $P_{\\text{sig}}$, must significantly exceed the noise power, $P_{\\text{noise}}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as follows:\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text{sig}}}{P_{\\text{noise}}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of approximately 20 dB (i.e., $P_{\\text{sig}} / P_{\\text{noise}} = 100$). ${}^{5}$ For a sinusoid with a peak amplitude of $A$, $P_{\\text{sig}} = A^{2} / 2$, but how is $P_{\\text{noise}}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text{noise}}=\\int_{-\\infty}^{+\\infty} S_{\\text{noise}}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text{noise}}$ can become quite large if $S_{\\text{noise}}(f)$ covers a broad frequency range? Yes, it does. For example, consider the aforementioned amplifier with a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)]. In this case, the signal is degraded by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth should always be constrained to the smallest acceptable level to reduce the integrated noise power. This can be achieved either within the amplifier or by employing a subsequent low-pass filter.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum represented by $S_{\\text{noise}}(f) = 5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1-MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text{noise}} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text{noise}}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power equates to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}} = 22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Imagine an amplifier is fed a sinusoidal signal, as depicted in Fig. 7.13. The output comprises both the amplified signal and the noise produced by the circuit. For the output signal to be discernible, its power, $P_{\\text {sig }}$, must significantly exceed the noise power, $P_{\\text {noise }}$. Consequently, we define the \"signal-to-noise ratio\" (SNR) as\n\n$$\n\\begin{equation*}\n\\mathrm{SNR}=\\frac{P_{\\text {sig }}}{P_{\\text {noise }}} \\tag{7.12}\n\\end{equation*}\n$$\n\n[^35]For instance, audio signals necessitate a minimum SNR of around 20 dB (i.e., $P_{\\text {sig }} / P_{\\text {noise }}=100$ ). ${ }^{5}$ For a sinusoid with a peak amplitude of $A, P_{\\text {sig }}=A^{2} / 2$, but how is $P_{\\text {noise }}$ determined? The total average power of the noise is equivalent to the area under its spectrum:\n\n$$\n\\begin{equation*}\nP_{\\text {noise }}=\\int_{-\\infty}^{+\\infty} S_{\\text {noise }}(f) d f \\tag{7.13}\n\\end{equation*}\n$$\n\nDoes this imply that $P_{\\text {noise }}$ can become quite large if $S_{\\text {noise }}(f)$ covers a broad frequency range? Yes, it does. For example, consider the aforementioned amplifier with a bandwidth of 1 MHz while detecting an audio signal [Fig. 7.13(b)]. In this case, the signal is degraded by all noise components within the 1-MHz bandwidth. Therefore, the circuit's bandwidth should always be constrained to the smallest acceptable level to reduce the integrated noise power. This can be achieved by limiting the bandwidth within the amplifier or by employing a low-pass filter随后.\n\n#### Example 7.2\n\nAn amplifier generates a one-sided noise spectrum defined by $S_{\\text {noise }}(f)=5 \\times 10^{-16} \\mathrm{~V}^{2} / \\mathrm{Hz}$. Calculate the total output noise within a 1 MHz bandwidth.\n\n#### Solution\n\nWe obtain\n\n$$\n\\begin{align*}\nP_{\\text {noise }} & =\\int_{0}^{1 \\mathrm{MHz}} S_{\\text {noise }}(f) d f  \\tag{7.14}\\\\\n& =5 \\times 10^{-10} \\mathrm{~V}^{2} \\tag{7.15}\n\\end{align*}\n$$\n\nNote that the total integrated noise is expressed in $\\mathrm{V}^{2}$ rather than $\\mathrm{V}^{2} / \\mathrm{Hz}$. This noise power equates to an rms voltage of $\\sqrt{5 \\times 10^{-10} \\mathrm{~V}^{2}}=22.4 \\mu \\mathrm{~V}$."
},
{
    "text": "Using the tools established in prior sections, we can now delineate a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach involves four stages:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source. (The input signal is assumed to be zero.)\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis process results in the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Using the tools established in earlier sections, we can now delineate a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach comprises four stages:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum for each.\n2. Establish the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source. (The input signal is assumed to be zero.)\n4. Sum all the output spectra, carefully considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Utilizing the tools established in earlier sections, we can now delineate a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach involves four stages:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum for each.\n2. Establish the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source, with the input signal set to zero.\n4. Sum all the output spectra, carefully considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Using the tools established in earlier sections, we can now delineate a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach involves four steps:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Calculate the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source. (The input signal is set to zero.)\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Using the tools established in earlier sections, we can now delineate a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach involves four steps:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Calculate the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source. (Note: The input signal is set to zero.)\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis process results in the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Utilizing the tools established in prior sections, we can now present a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources, making the noise at the output our focus. Our approach involves four steps:\n\n1. Identify noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum from each source (with the input signal set to zero).\n4. Sum all output spectra, considering both correlated and uncorrelated sources.\n\nThis method yields the output noise spectrum, which must be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. For the first step, we require the noise characteristics of various electronic devices, detailed in the upcoming section."
},
{
    "text": "Utilizing the tools established in earlier sections, we can now delineate a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by the internal noise sources. Consequently, our focus is on the noise present at the output. Our approach involves four steps:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source, with the input signal set to zero.\n4. Sum all the output spectra, carefully considering both correlated and uncorrelated sources.\n\nThis process yields the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Using the tools established in earlier sections, we can now present a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources, making the noise at the output our focus. Our approach involves four stages:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum for each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum from each source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. For the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the following section."
},
{
    "text": "Using the tools developed in earlier sections, we can now detail a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources. Consequently, our focus is on the noise present at the output. Our approach involves four steps:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum from each noise source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis process yields the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first step, we require the noise characteristics of various electronic devices, which will be covered in the following section."
},
{
    "text": "Using the tools established in prior sections, we can now present a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources. Consequently, our focus is on the noise detected at the output. Our approach involves four steps:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Calculate the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first step, we require the noise characteristics of various electronic devices, which will be detailed in the following section."
},
{
    "text": "Using the tools developed in earlier sections, we can now delineate a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by the noise sources present within it. Consequently, our focus is on the noise detected at the output. Our approach comprises four stages:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source. (The input signal is set to zero.)\n4. Sum all the output spectra, taking into account both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first stage, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Utilizing the tools established in prior sections, we can now delineate a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources. Consequently, our focus is on the noise present at the output. Our approach comprises four stages:\n\n1. Determine the noise sources (such as resistors and transistors) and document the spectrum for each.\n2. Establish the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum from each source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the initial step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Using the tools established in prior sections, we can now delineate a methodology for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources. Consequently, our focus is on the noise present at the output. Our approach involves four stages:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum contributed by each noise source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method provides the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. To execute the first stage, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Utilizing the tools from prior sections, we can now delineate a method for analyzing noise in circuits. The output signal of a specific circuit is degraded by internal noise sources. Thus, our focus is on the noise present at the output. Our approach involves four steps:\n\n1. Identify the noise sources (such as resistors and transistors) and document the spectrum of each.\n2. Determine the transfer function from each noise source to the output, treating the source as a deterministic signal.\n3. Apply the theorem $S_{Y}(f)=S_{x}(f)|H(f)|^{2}$ to compute the output noise spectrum from each source, with the input signal set to zero.\n4. Sum all the output spectra, considering both correlated and uncorrelated sources.\n\nThis method yields the output noise spectrum, which must then be integrated from $-\\infty$ to $+\\infty$ to obtain the total output noise. For the first step, we require the noise characteristics of various electronic devices, which will be detailed in the subsequent section."
},
{
    "text": "Thermal noise in resistors arises from the random movement of electrons within a conductor, which leads to fluctuations in the measured voltage across the conductor, regardless of whether the average current is zero. Consequently, the thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise in a resistor \\( R \\) can be modeled by a series voltage source, and the one-sided spectral density is given by\n\n$$\nS_{v}(f)=4 k T R, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe diagram in Fig. 7.14 shows a resistor \\( R \\) and a voltage source \\( V^2_n \\) that models the thermal noise voltage. The spectral density of the thermal noise is expressed as \\( S_v(f) = 4kTR \\).\n\nThe graph labeled \"S_v(f)\" represents the one-sided spectral density of thermal noise voltage across a noiseless resistor. It is a two-dimensional plot with the frequency on the horizontal axis (labeled as \"f\") and the spectral density of voltage noise on the vertical axis (labeled as \"S_v(f)\"). The units for the vertical axis are volts squared per hertz (V²/Hz).\n\nThe graph shows a constant spectral density across all frequencies, indicating that the thermal noise is white, meaning it has equal intensity at all frequencies. The value of the spectral density is constant at \\( 4kTR \\), where \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature in Kelvin, and \\( R \\) is the resistance in ohms.\n\nThe graph is a flat line parallel to the frequency axis, highlighting the frequency-independent nature of thermal noise. There are no peaks, valleys, or inflection points, as the plot is a constant line.\n\nThe line is marked at the vertical value of \\( 4kTR \\), indicating the magnitude of the spectral density. There are no specific data points or markers other than the constant value line, emphasizing the uniform distribution of noise across frequencies.\n\nThe Boltzmann constant \\( k \\) is \\( 1.38 \\times 10^{-23} \\mathrm{~J} / \\mathrm{K} \\). The spectral density \\( S_{v}(f) \\) is expressed in \\( \\mathrm{V}^{2} / \\mathrm{Hz} \\). Thus, we can also write \\( \\overline{V_{n}^{2}}=4 k T R \\), where the overline indicates averaging. We may even say that the noise \"voltage\" is given by \\( 4 k T R \\) even though this quantity is in fact the noise voltage squared. For example, a \\( 50-\\Omega \\) resistor held at \\( T=300 \\mathrm{~K} \\) exhibits \\( 8.28 \\times 10^{-19} \\mathrm{~V}^{2} / \\mathrm{Hz} \\) of thermal noise. To convert this number to a more familiar voltage quantity, we take the square root, obtaining \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\). While the square root of hertz may appear strange, it is helpful to remember that \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\) has little significance per se and simply means that the power in a \\( 1-\\mathrm{Hz} \\) bandwidth is equal to \\( \\left(0.91 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2} \\).\n\nThe equation \\( S_{v}(f)=4 k T R \\) suggests that thermal noise is white. In reality, \\( S_{v}(f) \\) is flat for up to roughly 100 THz, dropping at higher frequencies. For our purposes, the white spectrum is quite accurate.\n\nSince noise is a random quantity, the polarity used for the voltage source in Fig. 7.14 is unimportant. Nevertheless, once a polarity is chosen, it must be retained throughout the analysis of the circuit so as to obtain consistent results.\n\n#### Example 7.3\n\nConsider the \\( R C \\) circuit shown in Fig. 7.15. Calculate the noise spectrum and the total noise power in \\( V_{\\text {out }} \\).\n\nThe circuit in Fig. 7.15 is a low-pass filter with a resistor \\( R \\) and capacitor \\( C \\). Noise is modeled by a voltage source \\( V2R \\) in series with the resistor.\n\n#### Solution\n\nWe follow the four steps described in Section 7.1.5. The noise spectrum of \\( R \\) is given by \\( S_{v}(f)=4 k T R \\). Next, modeling the noise of \\( R \\) by a series voltage source \\( V_{R} \\), we compute the transfer function from \\( V_{R} \\) to \\( V_{\\text {out }} \\) :\n\n$$\n\\frac{V_{\\text {out }}}{V_{R}}(s)=\\frac{1}{R C s+1} \\tag{7.17}\n$$\n\nFrom the theorem in Section 7.1.1, we have\n\n$$\nS_{\\text {out }}(f) =S_{v}(f)\\left|\\frac{V_{\\text {out }}}{V_{R}}(j \\omega)\\right|^{2}  \\tag{7.18}\n$$\n\nThus, the white noise spectrum of the resistor is shaped by a low-pass characteristic (Fig. 7.16). To calculate the total noise power at the output, we write\n\n$$\nP_{n, \\text { out }}=\\int_{0}^{\\infty} \\frac{4 k T R}{4 \\pi^{2} R^{2} C^{2} f^{2}+1} d f \\tag{7.20}\n$$\n\nThe graph labeled \"S_out(f)\" is a frequency domain plot depicting the output noise power spectral density as a function of frequency for a system characterized by a low-pass filter. It is a power spectral density plot in the frequency domain, illustrating how the noise power is distributed across different frequencies.\n\nThe horizontal axis represents frequency \\( f \\), typically measured in hertz (Hz). The vertical axis represents the noise power spectral density \\( S_{\\text{out}}(f) \\), with units of power per frequency, often in \\( \\text{V}^2/\\text{Hz} \\). The scale appears to be linear for both axes.\n\nThe graph shows a characteristic low-pass filter response. At lower frequencies, the noise power spectral density is constant and equal to \\( 4kTR \\), where \\( k \\) is Boltzmann's constant, \\( T \\) is the temperature, and \\( R \\) is the resistance. As frequency increases, the noise power spectral density begins to decrease, exhibiting a roll-off that is typical of a low-pass filter.\n\nThe flat region at low frequencies indicates that the noise is white, meaning it has a constant power spectral density. The roll-off begins at a certain cutoff frequency, beyond which the noise power decreases, following the low-pass filter characteristic.\n\nThe value \\( 4kTR \\) is annotated on the vertical axis, emphasizing the level of noise power spectral density in the passband.\n\nThis graph is part of a broader analysis involving noise shaping by a low-pass filter, as indicated by the context and the accompanying schematic diagram of a resistor-capacitor (RC) circuit.\n\nThe integration must be with respect to \\( f \\) rather than \\( \\omega \\) (why?). Since\n\n$$\n\\int \\frac{d x}{x^{2}+1}=\\tan ^{-1} x \\tag{7.21}\n$$\n\nthe integral reduces to\n\n$$\nP_{n, \\text { out }} =\\left.\\frac{2 k T}{\\pi C} \\tan ^{-1} u\\right|_{u=0} ^{u=\\infty}  \\tag{7.22}\n$$\n\n$$\nP_{n, \\text { out }} =\\frac{k T}{C} \\tag{7.23}\n$$\n\nNote that the unit of \\( k T / C \\) is \\( \\mathrm{V}^{2} \\). We may also consider \\( \\sqrt{k T / C} \\) as the total rms noise voltage measured at the output. For example, with a 1-pF capacitor, the total noise voltage is equal to \\( 64.3 \\mu \\mathrm{~V}_{\\mathrm{rms}} \\) at \\( T=300 \\mathrm{~K} \\).\n\nEquation (7.23) implies that the total noise at the output of the circuit shown in Fig. 7.15 is independent of the value of \\( R \\). Intuitively, this is because for larger values of \\( R \\), the associated noise per unit bandwidth increases while the overall bandwidth of the circuit decreases. The fact that \\( k T / C \\) noise can be decreased only by increasing \\( C \\) (if \\( T \\) is fixed) introduces many difficulties in the design of analog circuits (Chapter 13).\n\nThe thermal noise of a resistor can be represented by a parallel current source as well (Fig. 7.17). For the representations of Figs. 7.14 and 7.17 to be equivalent, we have \\( \\overline{V_{n}^{2}} / R^{2}=\\overline{I_{n}^{2}} \\), that is, \\( \\overline{I_{n}^{2}}=4 k T / R \\). Note that \\( \\overline{I_{n}^{2}} \\) is expressed in \\( \\mathrm{A}^{2} / \\mathrm{Hz} \\). Depending on the circuit topology, one model may lead to simpler calculations than the other.\n\n#### Example 7.4\n\nCalculate the equivalent noise voltage of two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) [Fig. 7.18(a)].\n\nThe circuit in Fig. 7.18(a) represents two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) with their thermal noise modeled as parallel current sources \\( I_{n1} \\) and \\( I_{n2} \\). The total noise voltage across the resistors is represented as \\( V_{n,tot} \\).\n\n#### Solution\n\nAs shown in Fig. 7.18(b), each resistor exhibits an equivalent noise current with the spectral density \\( 4 k T / R \\). Since the two noise sources are uncorrelated, we add the powers:\n\n$$\n\\overline{I_{n, t o t}^{2}} =\\overline{I_{n 1}^{2}}+\\overline{I_{n 2}^{2}}  \\tag{7.24}\n$$\n\n$$\n\\overline{I_{n, t o t}^{2}} =4 k T\\left(\\frac{1}{R_{1}}+\\frac{1}{R_{2}}\\right) \\tag{7.25}\n$$\n\nThus, the equivalent noise voltage is given by\n\n$$\n\\overline{V_{n, t o t}^{2}} =\\overline{I_{n, t o t}^{2}}\\left(R_{1} \\| R_{2}\\right)^{2}  \\tag{7.26}\n$$\n\n$$\n\\overline{V_{n, t o t}^{2}} =4 k T\\left(R_{1} \\| R_{2}\\right) \\tag{7.27}\n$$\n\nas intuitively expected. Note that our notation assumes a \\( 1-\\mathrm{Hz} \\) bandwidth.\n\nThe dependence of thermal noise (and some other types of noise) upon \\( T \\) suggests that low-temperature operation can decrease the noise in analog circuits. This approach becomes more attractive with the observation that the mobility of charge carriers in MOS devices increases at low temperatures [2]. Nonetheless, the required cooling equipment limits the practicality of low-temperature circuits.\n\nMOSFETs also exhibit thermal noise. The most significant source is the noise generated in the channel. It can be proved [4] that for long-channel MOS devices operating in saturation, the channel noise can be modeled by a current source connected between the drain and source terminals (Fig. 7.19) with a spectral density:\n\n$$\n\\overline{I_{n}^{2}}=4 k T \\gamma g_{m} \\tag{7.28}\n$$\n\nThe coefficient \\( \\gamma \\) (not to be confused with the body effect coefficient!) is derived to be equal to \\( 2 / 3 \\) for long-channel transistors and may need to be replaced by a larger value for submicron MOSFETs [5]. It also varies to some extent with the drain-source voltage. As a rule of thumb, we assume \\( \\gamma \\approx 1 \\).\n\n#### Example 7.5\n\nFind the maximum noise voltage that a single MOSFET can generate.\n\n#### Solution\n\nAs shown in Fig. 7.20, the maximum output noise occurs if the transistor sees only its own output impedance as the load, i.e., if the external load is an ideal current source. The output noise voltage spectrum is then given by \\( S_{\\text {out }}(f)=S_{\\text {in }}(f)|H(f)|^{2} \\), i.e.,\n\n$$\n\\overline{V_{n}^{2}} =\\overline{I_{n}^{2}} r_{O}^{2}  \\tag{7.29}\n$$\n\n$$\n\\overline{V_{n}^{2}} =\\left(4 k T \\gamma g_{m}\\right) r_{O}^{2} \\tag{7.30}\n$$\n\nLet us make three observations. First, (7.30) suggests that the noise current of a MOS transistor decreases if the transconductance drops. For example, if the transistor operates as a constant current source, it is desirable to minimize its transconductance.\n\nSecond, the noise measured at the output of the circuit does not depend on where the input terminal is because for output noise calculation, the input is set to zero. For example, the circuit of Fig. 7.20 may be a common-source or a common-gate stage, exhibiting the same output noise.\n\nThird, the output resistance, \\( r_{O} \\), does not produce noise because it is not a physical resistor.\n\nThe ohmic sections of a MOSFET also contribute thermal noise. As conceptually illustrated in the top view of Fig. 7.21(a), the gate, source, and drain materials exhibit finite resistivity, thereby introducing noise. For a relatively wide transistor, the source and drain resistance is typically negligible whereas the gate distributed resistance may become noticeable.\n\nThe layout shows the source (S) and drain (D) terminals at the top and bottom, respectively, with the gate (G) on the left side. The resistive elements are represented as zigzag lines within the polysilicon gate material, suggesting finite resistivity and noise contribution. The polysilicon material is labeled, emphasizing its role in the gate's resistive properties.\n\nOverall, the diagram illustrates how the distributed gate resistance can affect the performance of the MOSFET by introducing thermal noise, particularly in wide transistors where this resistance becomes significant.\n\nIn the noise model of Fig. 7.21(b), a lumped resistor \\( R_{1} \\) represents the distributed gate resistance. Viewing the overall transistor as the distributed structure shown in Fig. 7.21(c), we observe that the unit transistors near the left end see the noise of only a fraction of \\( R_{G} \\) whereas those near the right end see the noise of most of \\( R_{G} \\). We therefore expect the lumped resistor in the noise model to be less than \\( R_{G} \\). In fact, it can be proved that \\( R_{1}=R_{G} / 3 \\) (Problem 7.3) [3], and hence the noise generated by the gate resistance is given by \\( \\overline{V_{n R G}^{2}}=4 k T R_{G} / 3 \\).\n\nWhile the thermal noise generated in the channel is controlled by only the transconductance of the device, the effect of \\( R_{G} \\) can be reduced by proper layout. Shown in Fig. 7.22 are two examples. In Fig. 7.22(a), the two ends of the gate are shorted by a metal line, thus reducing the distributed resistance from \\( R_{G} \\) to \\( R_{G} / 4 \\) (why?). Alternatively, the transistor can be folded as described in Chapter 19 [Fig. 7.22(b)] so that each gate \"finger\" exhibits a resistance of \\( R_{G} / 2 \\), yielding a total distributed resistance of \\( R_{G} / 4 \\) for the composite transistor.\n\n#### Example 7.6\n\nA transistor of width \\( W \\) is laid out with one gate finger and exhibits a total gate resistance of \\( R_{G} \\) [Fig. 7.23(a)]. Now, we reconfigure the device into four equal gate fingers [Fig. 7.23(b)]. Determine the total gate resistance thermal noise spectrum of the new structure.\n\n#### Solution\n\nWith a width of \\( W / 4 \\), each gate finger now has a distributed resistance of \\( R_{G} / 4 \\) and hence a lumped-model resistance of \\( R_{G} / 12 \\). Since the four fingers are in parallel, the net resistance is given by \\( R_{G} / 48 \\), yielding a noise spectrum of\n\n$$\n\\overline{V_{n R G}^{2}}=4 k T \\frac{R_{G}}{48} \\tag{7.31}\n$$\n\n(In general, if the gate is decomposed into \\( N \\) parallel fingers, the distributed resistance falls by a factor of \\( N^{2} \\).)\n\n#### Example 7.7\n\nFind the maximum thermal noise voltage that the gate resistance of a single MOSFET can generate. Neglect the device capacitances.\n\n#### Solution\n\nIf the total distributed gate resistance is \\( R_{G} \\), then from Fig. 7.24, the output noise voltage due to \\( R_{G} \\) is given by\n\n$$\n\\overline{V_{n, \\text { out }}^{2}}=4 k T \\frac{R_{G}}{3}\\left(g_{m} r_{O}\\right)^{2} \\tag{7.32}\n$$\n\nAn important observation here is that, for the gate resistance noise to be negligible, we must ensure that (7.32) is much less than (7.30), and thus\n\n$$\n\\frac{R_{G}}{3} \\ll \\frac{\\gamma}{g_{m}} \\tag{7.33}\n$$\n\nThe number of gate fingers is chosen large enough to guarantee this condition."
},
{
    "text": "The random movement of electrons in a conductor generates fluctuations in the measured voltage across the conductor, even if the average current is zero. Consequently, the spectrum of thermal noise is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise in a resistor \\( R \\) can be modeled by a series voltage source, with the one-sided spectral density given by:\n\n$$\nS_{v}(f) = 4 k T R, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe diagram in Fig. 7.14 represents a noiseless resistor \\( R \\) and a voltage source \\( V^2_n \\) that models the noise voltage. The spectral density of the thermal noise is expressed as \\( S_v(f) = 4kTR \\).\n\nThe graph labeled \"S_v(f)\" in Fig. 7.14 S_v(f) illustrates the one-sided spectral density of thermal noise voltage across a noiseless resistor. This is a two-dimensional plot with the frequency on the horizontal axis (labeled as \"f\") and the spectral density of voltage noise on the vertical axis (labeled as \"S_v(f)\"). The units for the vertical axis are volts squared per hertz (V²/Hz).\n\nFor a detailed analysis:\n\n1. **Type of Graph and Function:**\n   - This graph is a spectral density plot, specifically showing the thermal noise voltage across a resistor.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis (x-axis) represents frequency (f), typically measured in hertz (Hz).\n   - The vertical axis (y-axis) represents the spectral density of the noise voltage, \\( S_v(f) \\), in units of V²/Hz.\n\n3. **Overall Behavior and Trends:**\n   - The plot shows a constant value for the spectral density across all frequencies, indicating that the thermal noise is white, meaning it has equal intensity at all frequencies.\n   - The value of the spectral density is constant at \\( 4kTR \\), where \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature in Kelvin, and \\( R \\) is the resistance in ohms.\n\n4. **Key Features and Technical Details:**\n   - The graph is a flat line parallel to the frequency axis, highlighting the frequency-independent nature of thermal noise.\n   - There are no peaks, valleys, or inflection points, as the plot is a constant line.\n\n5. **Annotations and Specific Data Points:**\n   - The line is marked at the vertical value of \\( 4kTR \\), indicating the magnitude of the spectral density.\n   - There are no specific data points or markers other than the constant value line, emphasizing the uniform distribution of noise across frequencies.\n\nThe thermal noise of a resistor is represented in Fig. 7.14. Here, \\( k = 1.38 \\times 10^{-23} \\mathrm{~J} / \\mathrm{K} \\) is the Boltzmann constant. The expression \\( S_{v}(f) \\) is in \\( \\mathrm{V}^{2} / \\mathrm{Hz} \\). We also write \\( \\overline{V_{n}^{2}} = 4 k T R \\), where the overline indicates averaging. It is important to note that the noise \"voltage\" is given by \\( 4 k T R \\) even though this quantity is actually the noise voltage squared. For instance, a \\( 50-\\Omega \\) resistor at \\( T = 300 \\mathrm{~K} \\) exhibits \\( 8.28 \\times 10^{-19} \\mathrm{~V}^{2} / \\mathrm{Hz} \\) of thermal noise. To convert this to a more familiar voltage quantity, we take the square root, resulting in \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\). While the square root of hertz may seem unusual, it's helpful to remember that \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\) has little significance on its own and simply means that the power in a \\( 1-\\mathrm{Hz} \\) bandwidth is \\( \\left(0.91 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2} \\).\n\nThe equation \\( S_{v}(f) = 4 k T R \\) suggests that thermal noise is white. In reality, \\( S_{v}(f) \\) is flat for up to roughly 100 THz, decreasing at higher frequencies. For practical purposes, the white spectrum is quite accurate.\n\nSince noise is a random quantity, the polarity used for the voltage source in Fig. 7.14 is unimportant. However, once a polarity is chosen, it must be consistent throughout the circuit analysis to obtain reliable results.\n\n#### Example 7.3\n\nConsider the \\( R C \\) circuit shown in Fig. 7.15. Calculate the noise spectrum and the total noise power in \\( V_{\\text {out }} \\).\n\nFigure 7.15 depicts a low-pass filter with a resistor \\( R \\) and capacitor \\( C \\). Noise is modeled by a voltage source \\( V2R \\) in series with the resistor.\n\n#### Solution\n\nWe follow the four steps described in Section 7.1.5. The noise spectrum of \\( R \\) is given by \\( S_{v}(f) = 4 k T R \\). Next, modeling the noise of \\( R \\) by a series voltage source \\( V_{R} \\), we compute the transfer function from \\( V_{R} \\) to \\( V_{\\text {out }} \\):\n\n$$\n\\frac{V_{\\text {out }}}{V_{R}}(s) = \\frac{1}{R C s + 1} \\tag{7.17}\n$$\n\nFrom the theorem in Section 7.1.1, we have:\n\n$$\nS_{\\text {out }}(f) = S_{v}(f) \\left|\\frac{V_{\\text {out }}}{V_{R}}(j \\omega)\\right|^{2} \\tag{7.18}\n$$\n\nThus, the white noise spectrum of the resistor is shaped by a low-pass characteristic (Fig. 7.16). To calculate the total noise power at the output, we write:\n\n$$\nP_{n, \\text { out }} = \\int_{0}^{\\infty} \\frac{4 k T R}{4 \\pi^{2} R^{2} C^{2} f^{2} + 1} d f \\tag{7.20}\n$$\n\nThe graph labeled \"S_out(f)\" represents the output noise power spectral density as a function of frequency for a system characterized by a low-pass filter. Here is a detailed description of the graph:\n\n1. **Type of Graph and Function:**\n   - The graph is a power spectral density plot in the frequency domain, illustrating how the noise power is distributed across different frequencies.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis represents frequency \\( f \\), typically measured in hertz (Hz).\n   - The vertical axis represents the noise power spectral density \\( S_{\\text{out}}(f) \\), with units of power per frequency, often in \\( \\text{V}^2/\\text{Hz} \\).\n   - The scale appears to be linear for both axes.\n\n3. **Overall Behavior and Trends:**\n   - The graph shows a characteristic low-pass filter response. At lower frequencies, the noise power spectral density is constant and equal to \\( 4kTR \\), where \\( k \\) is Boltzmann's constant, \\( T \\) is the temperature, and \\( R \\) is the resistance.\n   - As frequency increases, the noise power spectral density begins to decrease, exhibiting a roll-off that is typical of a low-pass filter.\n   - The transition from the flat region to the declining region represents the cutoff behavior of the filter.\n\n4. **Key Features and Technical Details:**\n   - The flat region at low frequencies indicates that the noise is white, meaning it has a constant power spectral density.\n   - The roll-off begins at a certain cutoff frequency, beyond which the noise power decreases, following the low-pass filter characteristic.\n   - The graph does not explicitly mark the cutoff frequency, but the general shape indicates the filter's effect.\n\n5. **Annotations and Specific Data Points:**\n   - The value \\( 4kTR \\) is annotated on the vertical axis, emphasizing the level of noise power spectral density in the passband.\n   - There are no specific markers for the cutoff frequency or other critical points, but the general shape indicates the low-pass filtering effect.\n\nThe thermal noise of a resistor can also be represented by a parallel current source (Fig. 7.17). For the representations of Figs. 7.14 and 7.17 to be equivalent, we have \\( \\overline{V_{n}^{2}} / R^{2} = \\overline{I_{n}^{2}} \\), that is, \\( \\overline{I_{n}^{2}} = 4 k T / R \\). Note that \\( \\overline{I_{n}^{2}} \\) is expressed in \\( \\mathrm{A}^{2} / \\mathrm{Hz} \\). Depending on the circuit topology, one model may lead to simpler calculations than the other.\n\n#### Example 7.4\n\nCalculate the equivalent noise voltage of two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) [Fig. 7.18(a)].\n\nFigure 7.18(a) represents two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) with their thermal noise modeled as parallel current sources \\( I_{n1} \\) and \\( I_{n2} \\). The total noise voltage across the resistors is represented as \\( V_{n,tot} \\).\n\n#### Solution\n\nAs shown in Fig. 7.18(b), each resistor exhibits an equivalent noise current with the spectral density \\( 4 k T / R \\). Since the two noise sources are uncorrelated, we add the powers:\n\n$$\n\\overline{I_{n, t o t}^{2}} = \\overline{I_{n 1}^{2}} + \\overline{I_{n 2}^{2}} = 4 k T \\left(\\frac{1}{R_{1}} + \\frac{1}{R_{2}}\\right) \\tag{7.25}\n$$\n\nThus, the equivalent noise voltage is given by:\n\n$$\n\\overline{V_{n, t o t}^{2}} = \\overline{I_{n, t o t}^{2}} \\left(R_{1} \\| R_{2}\\right)^{2} = 4 k T \\left(R_{1} \\| R_{2}\\right) \\tag{7.27}\n$$\n\nThe thermal noise of a resistor can also be represented by a parallel current source (Fig. 7.17). For the representations of Figs. 7.14 and 7.17 to be equivalent, we have \\( \\overline{V_{n}^{2}} / R^{2} = \\overline{I_{n}^{2}} \\), that is, \\( \\overline{I_{n}^{2}} = 4 k T / R \\). Note that \\( \\overline{I_{n}^{2}} \\) is expressed in \\( \\mathrm{A}^{2} / \\mathrm{Hz} \\). Depending on the circuit topology, one model may lead to simpler calculations than the other.\n\n#### Example 7.5\n\nFind the maximum noise voltage that a single MOSFET can generate.\n\n#### Solution\n\nAs shown in Fig. 7.20, the maximum output noise occurs if the transistor sees only its own output impedance as the load, i.e., if the external load is an ideal current source. The output noise voltage spectrum is then given by \\( S_{\\text {out }}(f) = S_{\\text {in }}(f)|H(f)|^{2} \\), i.e.,\n\n$$\n\\overline{V_{n}^{2}} = \\overline{I_{n}^{2}} r_{O}^{2} = \\left(4 k T \\gamma g_{m}\\right) r_{O}^{2} \\tag{7.30}\n$$\n\nLet us make three observations. First, (7.30) suggests that the noise current of a MOS transistor decreases if the transconductance drops. For example, if the transistor operates as a constant current source, it is desirable to minimize its transconductance.\n\nSecond, the noise measured at the output of the circuit does not depend on where the input terminal is because for output noise calculation, the input is set to zero. For example, the circuit of Fig. 7.20 may be a common-source or a common-gate stage, exhibiting the same output noise.\n\nThird, the output resistance, \\( r_{O} \\), does not produce noise because it is not a physical resistor.\n\nThe ohmic sections of a MOSFET also contribute thermal noise. As conceptually illustrated in the top view of Fig. 7.21(a), the gate, source, and drain materials exhibit finite resistivity, thereby introducing noise. For a relatively wide transistor, the source and drain resistance is typically negligible whereas the gate distributed resistance may become noticeable.\n\nIn the noise model of Fig. 7.21(b), a lumped resistor \\( R_{1} \\) represents the distributed gate resistance. Viewing the overall transistor as the distributed structure shown in Fig. 7.21(c), we observe that the unit transistors near the left end see the noise of only a fraction of \\( R_{G} \\) whereas those near the right end see the noise of most of \\( R_{G} \\). We therefore expect the lumped resistor in the noise model to be less than \\( R_{G} \\). In fact, it can be proved that \\( R_{1} = R_{G} / 3 \\) (Problem 7.3) [3], and hence the noise generated by the gate resistance is given by \\( \\overline{V_{n R G}^{2}} = 4 k T R_{G} / 3 \\).\n\nWhile the thermal noise generated in the channel is controlled by only the transconductance of the device, the effect of \\( R_{G} \\) can be reduced by proper layout. Shown in Fig. 7.22 are two examples. In Fig. 7.22(a), the two ends of the gate are shorted by a metal line, thus reducing the distributed resistance from \\( R_{G} \\) to \\( R_{G} / 4 \\) (why?). Alternatively, the transistor can be folded as described in Chapter 19 [Fig. 7.22(b)] so that each gate \"finger\" exhibits a resistance of \\( R_{G} / 2 \\), yielding a total distributed resistance of \\( R_{G} / 4 \\) for the composite transistor.\n\n#### Example 7.6\n\nA transistor of width \\( W \\) is laid out with one gate finger and exhibits a total gate resistance of \\( R_{G} \\) [Fig. 7.23(a)]. Now, we reconfigure the device into four equal gate fingers [Fig. 7.23(b)]. Determine the total gate resistance thermal noise spectrum of the new structure.\n\n#### Solution\n\nWith a width of \\( W / 4 \\), each gate finger now has a distributed resistance of \\( R_{G} / 4 \\) and hence a lumped-model resistance of \\( R_{G} / 12 \\). Since the four fingers are in parallel, the net resistance is given by \\( R_{G} / 48 \\), yielding a noise spectrum of:\n\n$$\n\\overline{V_{n R G}^{2}} = 4 k T \\frac{R_{G}}{48} \\tag{7.31}\n$$\n\n#### Example 7.7\n\nFind the maximum thermal noise voltage that the gate resistance of a single MOSFET can generate. Neglect the device capacitances.\n\n#### Solution\n\nIf the total distributed gate resistance is \\( R_{G} \\), then from Fig. 7.24, the output noise voltage due to \\( R_{G} \\) is given by:\n\n$$\n\\overline{V_{n, \\text { out }}^{2}} = 4 k T \\frac{R_{G}}{3}\\left(g_{m} r_{O}\\right)^{2} \\tag{7.32}\n$$\n\nAn important observation here is that, for the gate resistance noise to be negligible, we must ensure that (7.32) is much less than (7.30), and thus:\n\n$$\n\\frac{R_{G}}{3} \\ll \\frac{\\gamma}{g_{m}} \\tag{7.33}\n$$\n\nThe number of gate fingers is chosen large enough to guarantee this condition."
},
{
    "text": "Thermal noise, resulting from the random motion of electrons within a conductor, introduces voltage fluctuations across the conductor, even in the absence of an average current. This thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be conceptualized as a series voltage source, characterized by a one-sided spectral density expressed as:\n\n$$\nS_{v}(f) = 4 k T R, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe graphical representation of the thermal noise, as shown in Fig. 7.14, models the resistor's thermal noise through a combination of a resistor \\( R \\) and a voltage source \\( V_n^2 \\) that signifies the noise voltage. The spectral density of this thermal noise is denoted by \\( S_v(f) = 4kTR \\).\n\nThe graph in Fig. 7.14 S_v(f) illustrates the one-sided spectral density of thermal noise voltage across a resistor devoid of noise. This graph is a two-dimensional plot with the frequency axis labeled \"f\" and the spectral density of voltage noise axis labeled \"S_v(f)\", measured in volts squared per hertz (V²/Hz).\n\nThis plot reveals a consistent spectral density across all frequencies, indicating that the thermal noise is white, i.e., it maintains equal intensity at all frequencies. The spectral density is constant at \\( 4kTR \\), where \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature in Kelvin, and \\( R \\) is the resistance in ohms.\n\nThe graphical representation is a flat line, emphasizing the independence of thermal noise from frequency. It lacks any peaks, valleys, or inflection points, indicating a constant spectral density.\n\nThe spectral density is marked at \\( 4kTR \\), signifying the magnitude of the spectral density. No specific data points or markers are present, underlining the uniform distribution of noise across frequencies.\n\nFig. 7.14 encapsulates the thermal noise characteristics of a resistor, where \\( k = 1.38 \\times 10^{-23} \\text{J/K} \\) represents the Boltzmann constant. The spectral density \\( S_v(f) \\) is expressed in \\( \\text{V}^2/\\text{Hz} \\). Therefore, the noise voltage squared is denoted by \\( \\overline{V_n^2} = 4 k T R \\), with the overline indicating averaging.\n\nIt's important to note that the noise \"voltage\" is represented by \\( 4 k T R \\), despite this quantity actually signifying the noise voltage squared. For instance, a \\( 50-\\Omega \\) resistor at \\( T = 300 \\text{K} \\) exhibits \\( 8.28 \\times 10^{-19} \\text{V}^2/\\text{Hz} \\) of thermal noise. To convert this to a more conventional voltage measure, we take the square root, resulting in \\( 0.91 \\text{nV}/\\sqrt{\\text{Hz}} \\). Although the square root of hertz may seem peculiar, it's crucial to understand that \\( 0.91 \\text{nV}/\\sqrt{\\text{Hz}} \\) holds little meaning on its own and merely signifies that the power in a \\( 1-\\text{Hz} \\) bandwidth equals \\( (0.91 \\times 10^{-9})^2 \\text{V}^2 \\).\n\nThe equation \\( S_v(f) = 4 k T R \\) implies that thermal noise is white. However, \\( S_v(f) \\) remains flat up to approximately 100 THz, after which it diminishes at higher frequencies. For practical purposes, the white spectrum provides a sufficiently accurate approximation.\n\nGiven that noise is inherently random, the polarity of the voltage source in Fig. 7.14 is inconsequential. Nonetheless, once a polarity is chosen, it must be consistently applied throughout the circuit analysis to ensure uniform results."
},
{
    "text": "---[Attention]---\nImage Descriptions: Any images linked in the [Context Provided] have been converted into textual descriptions. You also need to rephrase it to maintain the original meaning and length.\n---[Task]---\nPlease rephrase the provided text in [Context Provided] Section. Ensure the rephrased version maintains the original meaning and length. Only output the rephrased text.\n---[Context Provided]---\nThe text to be rephrased:\n\nThe random motion of electrons within a conductor leads to fluctuations in the measured voltage across the conductor, even when the average current is zero. Consequently, the thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be represented by a series voltage source, with the one-sided spectral density expressed as\n\n\\[\nS_{v}(f) = 4 k T R, \\quad f \\geq 0 \\tag{7.16}\n\\]\n\nwhere \\( k = 1.38 \\times 10^{-23} \\mathrm{~J} / \\mathrm{K} \\) is the Boltzmann constant, and \\( S_{v}(f) \\) is given in \\( \\mathrm{V}^{2} / \\mathrm{Hz} \\). Therefore, we can also write \\( \\overline{V_{n}^{2}} = 4 k T R \\), where the overline denotes averaging. We might even assert that the noise \"voltage\" is \\( 4 k T R \\), despite this quantity actually representing the noise voltage squared. For instance, a \\( 50-\\Omega \\) resistor at \\( T = 300 \\mathrm{~K} \\) exhibits \\( 8.28 \\times 10^{-19} \\mathrm{~V}^{2} / \\mathrm{Hz} \\) of thermal noise. To convert this to a more conventional voltage measure, we take the square root, resulting in \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\). Although the square root of hertz may seem peculiar, it is important to note that \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\) holds little significance on its own and merely indicates that the power in a \\( 1-\\mathrm{Hz} \\) bandwidth is \\( \\left(0.91 \\times 10^{-9}\\right)^{2} \\mathrm{~V}^{2} \\).\n\nThe equation \\( S_{v}(f) = 4 k T R \\) implies that thermal noise is white. However, \\( S_{v}(f) \\) remains flat only up to approximately 100 THz, after which it decreases at higher frequencies. For practical purposes, though, the white spectrum assumption is quite accurate.\n\nGiven that noise is a random phenomenon, the polarity assigned to the voltage source in Fig. 7.14 is inconsequential. Nonetheless, once a polarity is chosen, it must be consistently applied throughout the circuit analysis to ensure coherent results.\n\n#### Example 7.3\n\nConsider the \\( R C \\) circuit shown in Fig. 7.15. Calculate the noise spectrum and the total noise power at \\( V_{\\text {out }} \\).\nFigure 7.15 illustrates a low-pass filter comprising a resistor \\( R \\) and a capacitor \\( C \\). The noise is modeled by a voltage source \\( V_{2R} \\) in series with the resistor.\n\n#### Solution\n\nThe process involves four steps outlined in Section 7.1.5. The noise spectrum of \\( R \\) is \\( S_{v}(f) = 4 k T R \\). By modeling the noise of \\( R \\) with a series voltage source \\( V_{R} \\), we determine the transfer function from \\( V_{R} \\) to \\( V_{\\text {out }} \\):\n\n\\[\n\\frac{V_{\\text {out }}}{V_{R}}(s) = \\frac{1}{R C s + 1} \\tag{7.17}\n\\]\n\nApplying the theorem from Section 7.1.1 yields\n\n\\[\n\\begin{align*}\nS_{\\text {out }}(f) & = S_{v}(f) \\left|\\frac{V_{\\text {out }}}{V_{R}}(j \\omega)\\right|^{2} \\tag{7.18}\\\\\n& = 4 k T R \\frac{1}{4 \\pi^{2} R^{2} C^{2} f^{2} + 1} \\tag{7.19}\n\\end{align*}\n\\]\n\nThus, the resistor's white noise spectrum is modified by the low-pass filter characteristic (Fig. 7.16). To find the total noise power at the output, we integrate\n\n\\[\nP_{n, \\text { out }} = \\int_{0}^{\\infty} \\frac{4 k T R}{4 \\pi^{2} R^{2} C^{2} f^{2} + 1} d f \\tag{7.20}\n\\]\n\nwhich, due to the integral identity \\( \\int \\frac{d x}{x^{2} + 1} = \\tan^{-1} x \\), simplifies to\n\n\\[\n\\begin{align*}\nP_{n, \\text { out }} & = \\left.\\frac{2 k T}{\\pi C} \\tan^{-1} u\\right|_{u=0}^{u=\\infty} \\tag{7.22}\\\\\n& = \\frac{k T}{C} \\tag{7.23}\n\\end{align*}\n\\]\n\nindicating that the total noise at the output of the circuit in Fig. 7.15 is independent of \\( R \\). This is because as \\( R \\) increases, the noise per unit bandwidth increases, but the overall bandwidth decreases. The fact that \\( k T / C \\) noise can only be reduced by increasing \\( C \\) (if \\( T \\) is constant) poses challenges in analog circuit design (Chapter 13).\n\n#### Example 7.4\n\nDetermine the equivalent noise voltage of two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) [Fig. 7.18(a)].\nFigure 7.18(a) depicts two parallel resistors \\( R_{1} \\) and \\( R_{2} \\) with their thermal noise modeled as parallel current sources.\n\n#### Solution\n\nAs shown in Fig. 7.18(b), each resistor contributes an equivalent noise current with a spectral density of \\( 4 k T / R \\). Since the noise sources are uncorrelated, we sum their powers:\n\n\\[\n\\begin{align*}\n\\overline{I_{n, t o t}^{2}} & = \\overline{I_{n 1}^{2}} + \\overline{I_{n 2}^{2}} \\tag{7.24}\\\\\n& = 4 k T \\left(\\frac{1}{R_{1}} + \\frac{1}{R_{2}}\\right) \\tag{7.25}\n\\end{align*}\n\\]\n\nThus, the equivalent noise voltage is\n\n\\[\n\\begin{align*}\n\\overline{V_{n, t o t}^{2}} & = \\overline{I_{n, t o t}^{2}} \\left(R_{1} \\| R_{2}\\right)^{2} \\tag{7.26}\\\\\n& = 4 k T \\left(R_{1} \\| R_{2}\\right) \\tag{7.27}\n\\end{align*}\n\\]\n\nas expected. The unit of \\( k T / C \\) is \\( \\mathrm{V}^{2} \\), and \\( \\sqrt{k T / C} \\) represents the total rms noise voltage at the output.\n\nThe thermal noise's dependence on \\( T \\) suggests that operating at lower temperatures can reduce noise in analog circuits. This approach becomes more appealing with the realization that charge carrier mobility in MOS devices increases at lower temperatures [2]. However, the need for cooling equipment constrains the practicality of low-temperature circuits.\n\n#### Example 7.5\n\nFind the maximum noise voltage that a single MOSFET can generate.\n\n#### Solution\n\nThe maximum output noise occurs when the transistor's output impedance is the only load, i.e., when the external load is an ideal current source. The output noise voltage spectrum is then \\( S_{\\text {out }}(f) = S_{\\text {in }}(f)|H(f)|^{2} \\), leading to\n\n\\[\n\\begin{align*}\n\\overline{V_{n}^{2}} & = \\overline{I_{n}^{2}} r_{O}^{2} \\tag{7.29}\\\\\n& = \\left(4 k T \\gamma g_{m}\\right) r_{O}^{2} \\tag{7.30}\n\\end{align*}\n\\]\n\nThree observations can be made. First, (7.30) implies that the noise current of a MOS transistor decreases with decreasing transconductance. Second, the output noise is independent of the input terminal's location since the input is set to zero for output noise calculation. Third, the output resistance \\( r_{O} \\) does not generate noise as it is not a physical resistor.\n\nThe ohmic sections of a MOSFET also contribute to thermal noise. As depicted in Fig. 7.21(a), the gate, source, and drain materials have finite resistivity, introducing noise. For wider transistors, the source and drain resistance is usually negligible, but the gate distributed resistance may become significant.\n\nIn the noise model of Fig. 7.21(b), a lumped resistor \\( R_{1} \\) represents the distributed gate resistance. Observing the transistor as the distributed structure in Fig. 7.21(c), we note that unit transistors near the left end see only a portion of \\( R_{G} \\)'s noise, while those near the right end see most of it. Hence, the lumped resistor in the noise model should be less than \\( R_{G} \\). It can be shown that \\( R_{1} = R_{G} / 3 \\) [3], and thus the noise from the gate resistance is \\( \\overline{V_{n R G}^{2}} = 4 k T R_{G} / 3 \\).\n\nWhile the channel noise in a MOSFET is influenced solely by the device's transconductance, the effect of \\( R_{G} \\) can be mitigated through proper layout design. For example, as shown in Fig. 7.22, the gate's two ends can be shorted by a metal line, reducing the distributed resistance from \\( R_{G} \\) to \\( R_{G} / 4 \\). Alternatively, the transistor can be folded, as described in Chapter 19 [Fig. 7.22(b)], so that each gate \"finger\" has a resistance of \\( R_{G} / 2 \\), resulting in a total distributed resistance of \\( R_{G} / 4 \\) for the composite transistor.\n\n#### Example 7.6\n\nA transistor with a width \\( W \\) has a gate layout with one finger, exhibiting a total gate resistance of \\( R_{G} \\) [Fig. 7.23(a)]. Now, the device is reconfigured into four equal gate fingers [Fig. 7.23(b)]. Determine the total gate resistance thermal noise spectrum of the new structure.\n\n#### Solution\n\nWith a width of \\( W / 4 \\), each gate finger now has a distributed resistance of \\( R_{G} / 4 \\) and a lumped-model resistance of \\( R_{G} / 12 \\). Since the fingers are in parallel, the net resistance is \\( R_{G} / 48 \\), leading to a noise spectrum of\n\n\\[\n\\overline{V_{n R G}^{2}} = 4 k T \\frac{R_{G}}{48} \\tag{7.31}\n\\]\n\nIn general, if the gate is divided into \\( N \\) parallel fingers, the distributed resistance is reduced by a factor of \\( N^{2} \\).\n\n#### Example 7.7\n\nFind the maximum thermal noise voltage that the gate resistance of a single MOSFET can generate, neglecting device capacitances.\n\n#### Solution\n\nIf the total distributed gate resistance is \\( R_{G} \\), then from Fig. 7.24, the output noise voltage due to \\( R_{G} \\) is\n\n\\[\n\\overline{V_{n, \\text { out }}^{2}} = 4 k T \\frac{R_{G}}{3}\\left(g_{m} r_{O}\\right)^{2} \\tag{7.32}\n\\]\n\nAn important observation is that for the gate resistance noise to be negligible, (7.32) must be much smaller than (7.30), implying\n\n\\[\n\\frac{R_{G}}{3} \\ll \\frac{\\gamma}{g_{m}} \\tag{7.33}\n\\]\n\nThe number of gate fingers is chosen sufficiently large to satisfy this condition.\n```"
},
{
    "text": "The random movement of electrons within a conductor introduces fluctuations in the voltage measured across it, even when the average current is zero. Consequently, the spectrum of thermal noise is proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be modeled by a series voltage source, with the one-sided spectral density given by:\n\n$$\nS_v(f) = 4 k T R, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nwhere \\( k = 1.38 \\times 10^{-23} \\mathrm{~J} / \\mathrm{K} \\) is the Boltzmann constant. Note that \\( S_v(f) \\) is expressed in \\( \\mathrm{V}^{2} / \\mathrm{Hz} \\). Thus, we also write \\( \\overline{V_n^2} = 4 k T R \\), where the overline indicates averaging. We may even say that the noise \"voltage\" is given by \\( 4 k T R \\) even though this quantity is in fact the noise voltage squared. For example, a \\( 50-\\Omega \\) resistor held at \\( T = 300 \\mathrm{~K} \\) exhibits \\( 8.28 \\times 10^{-19} \\mathrm{~V}^{2} / \\mathrm{Hz} \\) of thermal noise. To convert this number to a more familiar voltage quantity, we take the square root, obtaining \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\). While the square root of hertz may appear strange, it is helpful to remember that \\( 0.91 \\mathrm{nV} / \\sqrt{\\mathrm{Hz}} \\) has little significance per se and simply means that the power in a \\( 1-\\mathrm{Hz} \\) bandwidth is equal to \\( (0.91 \\times 10^{-9})^{2} \\mathrm{~V}^{2} \\).\n\nThe equation \\( S_v(f) = 4 k T R \\) suggests that thermal noise is white. In reality, \\( S_v(f) \\) is flat for up to roughly 100 THz, dropping at higher frequencies. For our purposes, the white spectrum is quite accurate.\n\nSince noise is a random quantity, the polarity used for the voltage source in Fig. 7.14 is unimportant. Nevertheless, once a polarity is chosen, it must be retained throughout the analysis of the circuit so as to obtain consistent results."
},
{
    "text": "Thermal noise is the result of random electron motion within a conductor, causing voltage fluctuations across it, even when the average current is zero. This noise spectrum is directly proportional to the absolute temperature. As depicted in Figure 7.14, the thermal noise of a resistor \\( R \\) can be conceptualized as a series voltage source, with the one-sided spectral density expressed as:\n\n$$\nS_v(f) = 4 k T R, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nHere, \\( k = 1.38 \\times 10^{-23} \\text{ J/K} \\) represents the Boltzmann constant, and \\( S_v(f) \\) is measured in \\( \\text{V}^2/\\text{Hz} \\). The notation \\( \\overline{V_n^2} = 4 k T R \\) signifies the average noise voltage squared. We might also refer to \\( 4 k T R \\) as the noise \"voltage,\" even though technically it is the noise voltage squared. For instance, a \\( 50-\\Omega \\) resistor at \\( T = 300 \\text{ K} \\) exhibits \\( 8.28 \\times 10^{-19} \\text{ V}^2/\\text{Hz} \\) of thermal noise. Converting this value to a more recognizable voltage quantity involves taking the square root, resulting in \\( 0.91 \\text{ nV}/\\sqrt{\\text{Hz}} \\). \n\nThe equation \\( S_v(f) = 4 k T R \\) implies that thermal noise is white, meaning it has a flat spectrum across all frequencies. However, in reality, \\( S_v(f) \\) remains flat up to approximately 100 THz before decreasing at higher frequencies. For practical purposes, the white spectrum model is sufficiently accurate.\n\nSince noise is inherently random, the polarity of the voltage source in Figure 7.14 is inconsequential. Nonetheless, once a polarity is established, it must be consistently applied throughout the circuit analysis to ensure coherent results.\n\n#### Example 7.3\n\nGiven the \\( RC \\) circuit in Figure 7.15, we are tasked with calculating the noise spectrum and the total noise power at the output \\( V_{\\text{out}} \\).\n\n#### Solution\n\nWe proceed with the four-step process outlined in Section 7.1.5. The noise spectrum of the resistor \\( R \\) is \\( S_v(f) = 4 k T R \\). By modeling the noise of \\( R \\) as a series voltage source \\( V_R \\), we determine the transfer function from \\( V_R \\) to \\( V_{\\text{out}} \\):\n\n$$\n\\frac{V_{\\text{out}}}{V_R}(s) = \\frac{1}{R C s + 1} \\tag{7.17}\n$$\n\nApplying the theorem from Section 7.1.1, we derive:\n\n$$\nS_{\\text{out}}(f) = S_v(f) \\left| \\frac{V_{\\text{out}}}{V_R}(j \\omega) \\right|^2 = 4 k T R \\frac{1}{4 \\pi^2 R^2 C^2 f^2 + 1} \\tag{7.19}\n$$\n\nConsequently, the resistor's white noise spectrum is shaped by the low-pass filter characteristics (Figure 7.16). To compute the total noise power at the output, we integrate:\n\n$$\nP_{n, \\text{out}} = \\int_0^\\infty \\frac{4 k T R}{4 \\pi^2 R^2 C^2 f^2 + 1} df \\tag{7.20}\n$$\n\nThis integration results in \\( P_{n, \\text{out}} = \\frac{k T}{C} \\), indicating that the total noise at the output of the circuit in Figure 7.15 is independent of \\( R \\). Intuitively, this is because as \\( R \\) increases, the noise per unit bandwidth rises while the overall bandwidth decreases.\n\nThe thermal noise of a resistor can also be modeled using a parallel current source, as shown in Figure 7.17. For the representations in Figures 7.14 and 7.17 to be equivalent, we must have \\( \\overline{V_n^2}/R^2 = \\overline{I_n^2} \\), or \\( \\overline{I_n^2} = 4 k T/R \\), with \\( \\overline{I_n^2} \\) expressed in \\( \\text{A}^2/\\text{Hz} \\). Depending on the circuit topology, one model may simplify calculations more than the other.\n\n#### Example 7.4\n\nWe are to calculate the equivalent noise voltage of two parallel resistors \\( R_1 \\) and \\( R_2 \\) (Figure 7.18(a)).\n\n#### Solution\n\nAs depicted in Figure 7.18(b), each resistor contributes an equivalent noise current with a spectral density of \\( 4 k T/R \\). Since the noise sources are uncorrelated, we sum their powers:\n\n$$\n\\overline{I_{n, \\text{tot}}^2} = \\overline{I_{n1}^2} + \\overline{I_{n2}^2} = 4 k T \\left( \\frac{1}{R_1} + \\frac{1}{R_2} \\right) \\tag{7.25}\n$$\n\nThus, the equivalent noise voltage squared is:\n\n$$\n\\overline{V_{n, \\text{tot}}^2} = \\overline{I_{n, \\text{tot}}^2} (R_1 || R_2)^2 = 4 k T (R_1 || R_2) \\tag{7.27}\n$$\n\nThis result is intuitive and assumes a \\( 1-\\text{Hz} \\) bandwidth. The thermal noise's temperature dependence suggests that operating at low temperatures can reduce noise in analog circuits, although the cooling equipment required may limit the practicality of this approach.\n\n#### Example 7.5\n\nWe need to find the maximum noise voltage that a single MOSFET can generate.\n\n#### Solution\n\nThe maximum output noise occurs when the transistor's load is an ideal current source, as shown in Figure 7.20. The output noise voltage spectrum is given by \\( S_{\\text{out}}(f) = S_{\\text{in}}(f)|H(f)|^2 \\), leading to:\n\n$$\n\\overline{V_n^2} = \\overline{I_n^2} r_O^2 = (4 k T \\gamma g_m) r_O^2 \\tag{7.30}\n$$\n\nThis equation indicates that the noise current of a MOS transistor decreases with a drop in transconductance. Additionally, the output noise is independent of the input terminal's location because for output noise calculation, the input is set to zero.\n\n#### Example 7.6\n\nA transistor with a gate width \\( W \\) and a total gate resistance \\( R_G \\) (Figure 7.23(a)) is reconfigured into four equal gate fingers (Figure 7.23(b)). We determine the total gate resistance thermal noise spectrum of this new structure.\n\n#### Solution\n\nEach gate finger, now with a width of \\( W/4 \\), has a distributed resistance of \\( R_G/4 \\) and a lumped-model resistance of \\( R_G/12 \\). Since the fingers are in parallel, the net resistance is \\( R_G/48 \\), resulting in a noise spectrum of:\n\n$$\n\\overline{V_{n R_G}^2} = 4 k T \\frac{R_G}{48} \\tag{7.31}\n$$\n\n#### Example 7.7\n\nWe aim to find the maximum thermal noise voltage that the gate resistance of a single MOSFET can generate, neglecting device capacitances.\n\n#### Solution\n\nIf the total distributed gate resistance is \\( R_G \\), then from Figure 7.24, the output noise voltage due to \\( R_G \\) is:\n\n$$\n\\overline{V_{n, \\text{out}}^2} = 4 k T \\frac{R_G}{3}(g_m r_O)^2 \\tag{7.32}\n$$\n\nTo ensure that gate resistance noise is negligible, we must satisfy:\n\n$$\n\\frac{R_G}{3} \\ll \\frac{\\gamma}{g_m} \\tag{7.33}\n$$\n\nThis condition guides the choice of the number of gate fingers to guarantee minimal noise contribution from the gate resistance."
},
{
    "text": "Thermal noise in resistors is caused by the random motion of electrons within a conductor, which leads to fluctuations in voltage across the conductor even when the average current is zero. This thermal noise is proportional to the absolute temperature and can be modeled by a series voltage source, as depicted in Figure 7.14. The one-sided spectral density of this thermal noise, denoted as \\( S_v(f) \\), is given by the equation \\( S_v(f) = 4kTR \\) for frequencies \\( f \\geq 0 \\), where \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature, and \\( R \\) is the resistance.\n\nThe graphical representation of \\( S_v(f) \\) in Figure 7.14 S_v(f) shows a flat line, indicating that the thermal noise is white, meaning it has equal intensity at all frequencies. The value of the spectral density is constant at \\( 4kTR \\), which highlights the uniform distribution of noise across frequencies.\n\nIn practical scenarios, such as in an RC circuit, the noise spectrum of the resistor is shaped by the circuit's low-pass filter characteristic, as shown in Figure 7.16. The total noise power at the output of such a circuit, calculated using the integral \\( P_{n,\\text{out}} = \\int_{0}^{\\infty} \\frac{4kTR}{4\\pi^2R^2C^2f^2+1} df \\), is found to be independent of the resistor value \\( R \\) and is given by \\( P_{n,\\text{out}} = \\frac{kT}{C} \\).\n\nThermal noise can also be represented by a parallel current source, as shown in Figure 7.17, where the current source has a spectral density of \\( 4kT/R \\). This model can be more convenient for calculations in certain circuit topologies.\n\nWhen considering multiple resistors in parallel, as in Example 7.4, the equivalent noise voltage is calculated by adding the powers of the individual noise currents, resulting in \\( \\overline{V_{n,tot}^2} = 4kT(R_1 \\parallel R_2) \\), where \\( R_1 \\parallel R_2 \\) denotes the parallel combination of resistors \\( R_1 \\) and \\( R_2 \\).\n\nMOSFETs also exhibit thermal noise, primarily the most significant source being the noise generated in the channel, which depicted in Figure 7.19. The long-channel MOS devices operating in saturation, the channel noise can be modeled by a current source with a spectral density of \\( \\overline{I_n^2} = 4kT\\gamma g_m \\), where \\( \\gamma \\) is a coefficient that taken as \nThermal noise in resistors arises from the erratic\nThermal noise in resistors is from the random movement of electrons, a conductor. which results in voltage fluctuations across the conductor, even when the average current is zero. This thermal is proportional proportional to the absolute temperature and can be depicted as a series voltage source, as shown in Figure 7.14. The one-sided spectral density of this thermal noise, denoted as \\( S_v(f) \\), is expressed by \\( S_v(f) = 4kTR \\) for frequencies \\( f \\geq 0 \\), with \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature, and \\( R \\) is the resistance value.\n\nThe graphical representation of \\( S_v(f) \\) in Figure 7.14 S_v(f) presents a flat line, sign\nTheermal noise in resistors is from the random\nThe thermal noise inherent resistors originates\nTh thermal noise in resistors is a result of the random movement of electrons within the conductor, leading induces voltage fluctuations across the conductor, when there is no net current flow. This noise is directly proportional to the absolute temperature and can be depicted\nThe thermal noise in resistors is a by the random motion of electrons within the conductor, which to voltage fluctuations across the conductor even even when there average current is zero. This noise is directly proportional to the absolute temperature and can be"
},
{
    "text": "The random movement of electrons within a conductor leads to fluctuations in the voltage measured across the conductor, even when the average current is zero. Consequently, the thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be modeled using a series voltage source, characterized by the one-sided spectral density\n\n$$\nS_v(f) = 4kTR, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe diagram in Fig. 7.14 illustrates\n```\nThe random movement of electrons within a conductor leads to fluctuations in the voltage measured across the conductor, even when the average current is zero. Consequently, the thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be modeled using a series voltage source, characterized by the one-sided spectral density\n\n$$\nS_v(f) = 4kTR, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe diagram in Fig. 7.14 illustrates\nThe random movement of electrons within a conductor leads to fluctuations in the voltage measured across the conductor, even when the average current is zero. Consequently, the thermal noise spectrum is directly proportional to the absolute temperature. As depicted in Fig. 7.14, the thermal noise of a resistor \\( R \\) can be modeled using a series voltage source, characterized by the one-sided spectral density\n\n$$\nS_v(f) = 4kTR, \\quad f \\geq 0 \\tag{7.16}\n$$\n\nThe diagram in Fig. 7.14 models the thermal noise of a resistor with a noiseless resistor \\( R \\) and a voltage source \\( V_n^2 \\) representing the noise voltage. The spectral density of the thermal noise is given by \\( S_v(f) = 4kTR \\).\n\nThe graph labeled \"S_v(f)\" is a plot representing the one-sided spectral density of thermal noise voltage across a noiseless resistor. The graph is a two-dimensional plot with the horizontal axis labeled as frequency, denoted by \"f,\" and the vertical axis labeled as the spectral density of voltage noise, denoted by \"S_v(f).\" The units for the vertical axis are volts squared per hertz (V²/Hz).\n\n1. **Type of Graph and Function:**\n   - This is a spectral density plot, specifically showing the thermal noise voltage across a resistor.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis (x-axis) represents frequency (f) and is typically measured in hertz (Hz).\n   - The vertical axis (y-axis) represents the spectral density of the noise voltage, \\( S_v(f) \\), in units of V²/Hz.\n\n3. **Overall Behavior and Trends:**\n   - The plot shows a constant value for the spectral density across all frequencies, indicating that the thermal noise is white, meaning it has equal intensity at all frequencies.\n   - The value of the spectral density is constant at \\( 4kTR \\), where \\( k \\) is the Boltzmann constant, \\( T \\) is the absolute temperature in Kelvin, and \\( R \\) is the resistance in ohms.\n\n4. **Key Features and Technical Details:**\n   - The graph is a flat line parallel to the frequency axis, highlighting the frequency-independent nature of thermal noise.\n   - There are no peaks, valleys, or inflection points, as the plot is a constant line.\n\n5. **Annotations and Specific Data Points:**\n   - The line is marked at the vertical value of \\( 4kTR \\), indicating the magnitude of the spectral density.\n   - There are no specific data points or markers other than the constant value line, emphasizing the uniform distribution of noise across frequencies.\n\nFigure 7.14 shows the thermal noise of a resistor. Here, \\( k = 1.38 \\times 10^{-23} \\text{ J/K} \\) is the Boltzmann constant. Note that \\( S_v(f) \\) is expressed in \\( \\text{V}^2/\\text{Hz} \\). Thus, we also write \\( \\overline{V_n^2} = 4kTR \\), where the overline indicates averaging. We may even say that the noise \"voltage\" is given by \\( 4kTR \\) even though this quantity is in fact the noise voltage squared. For example, a \\( 50-\\Omega \\) resistor held at \\( T = 300 \\text{ K} \\) exhibits \\( 8.28 \\times 10^{-19} \\text{ V}^2/\\text{Hz} \\) of thermal noise. To convert this number to a more familiar voltage quantity, we take the square root, obtaining \\( 0.91 \\text{ nV}/\\sqrt{\\text{Hz}} \\). While the square root of hertz may appear strange, it is helpful to remember that \\( 0.91 \\text{ nV}/\\sqrt{\\text{Hz}} \\) has little significance per se and simply means that the power in a \\( 1-\\text{Hz} \\) bandwidth is equal to \\( (0.91 \\times 10^{-9})^2 \\text{ V}^2 \\).\n\nThe equation \\( S_v(f) = 4kTR \\) suggests that thermal noise is white. In reality, \\( S_v(f) \\) is flat for up to roughly 100 THz, dropping at higher frequencies. For our purposes, the white spectrum is quite accurate.\n\nSince noise is a random quantity, the polarity used for the voltage source in Fig. 7.14 is unimportant. Nevertheless, once a polarity is chosen, it must be retained throughout the analysis of the circuit to obtain consistent results.\n\n#### Example 7.3\n\nConsider the \\( RC \\) circuit shown in Fig. 7.15. Calculate the noise spectrum and the total noise power in \\( V_{\\text{out}} \\).\n\nFigure 7.15 shows a low-pass filter with a resistor \\( R \\) and capacitor \\( C \\). Noise is modeled by a voltage source \\( V_{2R} \\) in series with the resistor.\n\n#### Solution\n\nWe follow the four steps described in Section 7.1.5. The noise spectrum of \\( R \\) is given by \\( S_v(f) = 4kTR \\). Next, modeling the noise of \\( R \\) by a series voltage source \\( V_R \\), we compute the transfer function from \\( V_R \\) to \\( V_{\\text{out}} \\):\n\n$$\n\\frac{V_{\\text{out}}}{V_R}(s) = \\frac{1}{RCs+1} \\tag{7.17}\n$$\n\nFrom the theorem in Section 7.1.1, we have\n\n$$\nS_{\\text{out}}(f) = S_v(f) \\left| \\frac{V_{\\text{out}}}{V_R}(j\\omega) \\right|^2 \\tag{7.18}\n$$\n\n$$\nS_{\\text{out}}(f) = 4kTR \\frac{1}{4\\pi^2R^2C^2f^2+1} \\tag{7.19}\n$$\n\nThus, the white noise spectrum of the resistor is shaped by a low-pass characteristic (Fig. 7.16). To calculate the total noise power at the output, we write\n\n$$\nP_{n,\\text{out}} = \\int_0^\\infty \\frac{4kTR}{4\\pi^2R^2C^2f^2+1} df \\tag{7.20}\n$$\n\nThe graph labeled \"S_v(f)\" is a plot representing the white noise spectrum of a resistor, shaped by a low-pass filter characteristic. It is a frequency-domain graph with the following features:\n\n1. **Type of Graph and Function:**\n   - This is a spectrum plot showing the power spectral density of noise as a function of frequency.\n\n2. **Axes Labels and Units:**\n   - The horizontal axis represents frequency, labeled as \\( f \\), and is measured in hertz (Hz).\n   - The vertical axis represents the power spectral density, labeled as \\( S_v(f) \\), and is measured in units of \\( 4kTR \\), where \\( k \\) is Boltzmann's constant, \\( T \\) is the temperature, and \\( R \\) is the resistance.\n\n3. **Overall Behavior and Trends:**\n   - The graph shows a constant value of \\( 4kTR \\) across all frequencies, indicating a flat or white noise spectrum. This means the power spectral density is uniform across the frequency range.\n\n4. **Key Features and Technical Details:**\n   - The graph is a horizontal line, indicating that the noise power does not vary with frequency. This is characteristic of white noise, which contains equal power across all frequencies.\n   - There are no peaks, valleys, or inflection points in this graph, as it represents a constant power spectral density.\n\n5. **Annotations and Specific Data Points:**\n   - The value of \\( S_v(f) \\) is explicitly marked as \\( 4kTR \\), emphasizing the uniformity of the noise spectrum.\n\nThis graph is part of a broader analysis involving noise shaping by a low-pass filter, as indicated by the context and the accompanying schematic diagram of a resistor-capacitor (RC) circuit.\n\nFigure 7.16 shows the noise spectrum shaping by a low-pass filter. Note that the integration must be with respect to \\( f \\) rather than \\( \\omega \\) (why?). Since\n\n$$\n\\int \\frac{dx}{x^2+1} = \\tan^{-1} x \\tag{7.21}\n$$\n\nthe integral reduces to\n\n$$\nP_{n,\\text{out}} = \\left. \\frac{2kT}{\\pi C} \\tan^{-1} u \\right|_{u=0}^{u=\\infty} \\tag{7.22}\n$$\n\n$$\nP_{n,\\text{out}} = \\frac{kT}{C} \\tag{7.23}\n$$\n\nNote that the unit of \\( kT/C \\) is \\( \\text{V}^2 \\). We may also consider \\( \\sqrt{kT/C} \\) as the total rms noise voltage measured at the output. For example, with a 1-pF capacitor, the total noise voltage is equal to \\( 64.3 \\mu \\text{V}_{\\text{rms}} \\) at \\( T = 300 \\text{ K} \\).\n\nEquation (7.23) implies that the total noise at the output of the circuit shown in Fig. 7.15 is independent of the value of \\( R \\). Intuitively, this is because for larger values of \\( R \\), the associated noise per unit bandwidth increases while the overall bandwidth of the circuit decreases. The fact that \\( kT/C \\) noise can be decreased only by increasing \\( C \\) (if \\( T \\) is fixed) introduces many difficulties in the design of analog circuits (Chapter 13).\n\nThe thermal noise of a resistor can be represented by a parallel current source as well (Fig. 7.17). For the representations of Figs. 7.14 and 7.17 to be equivalent, we have \\( \\overline{V_n^2}/R^2 = \\overline{I_n^2} \\), that is, \\( \\overline{I_n^2} = 4kT/R \\). Note that \\( \\overline{I_n^2} \\) is expressed in \\( \\text{A}^2/\\text{Hz} \\). Depending on the circuit topology, one model may lead to simpler calculations than the other.\n\nFigure 7.17 shows the representation of resistor thermal noise by a current source.\n\n#### Example 7.4\n\nCalculate the equivalent noise voltage of two parallel resistors \\( R_1 \\) and \\( R_2 \\) [Fig. 7.18(a)].\n\nFigure 7.18(a) shows two parallel resistors \\( R_1 \\) and \\( R_2 \\) with their thermal noise modeled as parallel current sources \\( I_{n1} \\) and \\( I_{n2} \\). The total noise voltage across the resistors is represented as \\( V_{n,\\text{tot}} \\).\n\n#### Solution\n\nAs shown in Fig. 7.18(b), each resistor exhibits an equivalent noise current with the spectral density \\( 4kT/R \\). Since the two noise sources are uncorrelated, we add the powers:\n\n$$\n\\overline{I_{n,\\text{tot}}^2} = \\overline{I_{n1}^2} + \\overline{I_{n2}^2} \\tag{7.24}\n$$\n\n$$\n\\overline{I_{n,\\text{tot}}^2} = 4kT \\left( \\frac{1}{R_1} + \\frac{1}{R_2} \\right) \\tag{7.25}\n$$\n\nThus, the equivalent noise voltage is given by\n\n$$\n\\overline{V_{n,\\text{tot}}^2} = \\overline{I_{n,\\text{tot}}^2} \\left( R_1 || R_2 \\right)^2 \\tag{7.26}\n$$\n\n$$\n\\overline{V_{n,\\text{tot}}^2} = 4kT \\left( R_1 || R_2 \\right) \\tag{7.27}\n$$\n\nas intuitively expected. Note that our notation assumes a \\( 1-\\text{Hz} \\) bandwidth.\n\nThe dependence of thermal noise (and some other types of noise) upon \\( T \\) suggests that low-temperature operation can decrease the noise in analog circuits. This approach becomes more attractive with the observation that the mobility of charge carriers in MOS devices increases at low temperatures [2]. Nonetheless, the required cooling equipment limits the practicality of low-temperature circuits.\n\nMOSFETs also exhibit thermal noise. The most significant source is the noise generated in the channel. It can be proved [4] that for long-channel MOS devices operating in saturation, the channel noise can be modeled by a current source connected between the drain and source terminals (Fig. 7.19) with a spectral density:\n\n$$\n\\overline{I_n^2} = 4kT\\gamma g_m \\tag{7.28}\n$$\n\nFigure 7.19 shows the thermal noise of a MOSFET. The coefficient \\( \\gamma \\) (not to be confused with the body effect coefficient!) is derived to be equal to \\( 2/3 \\) for long-channel transistors and may need to be replaced by a larger value for submicron MOSFETs [5]. It also varies to some extent with the drain-source voltage. As a rule of thumb, we assume \\( \\gamma \\approx 1 \\).\n\n#### Example 7.5\n\nFind the maximum noise voltage that a single MOSFET can generate.\n\n#### Solution\n\nAs shown in Fig. 7.20, the maximum output noise occurs if the transistor sees only its own output impedance as the load, i.e., if the external load is an ideal current source. The output noise voltage spectrum is then given by \\( S_{\\text{out}}(f) = S_{\\text{in}}(f)|H(f)|^2 \\), i.e.,\n\n$$\n\\overline{V_n^2} = \\overline{I_n^2} r_O^2 \\tag{7.29}\n$$\n\n$$\n\\overline{V_n^2} = \\left( 4kT\\gamma g_m \\right) r_O^2 \\tag{7.30}\n$$\n\nLet us make three observations. First, (7.30) suggests that the noise current of a MOS transistor decreases if the transconductance drops. For example, if the transistor operates as a constant current source, it is desirable to minimize its transconductance.\n\nSecond, the noise measured at the output of the circuit does not depend on where the input terminal is because for output noise calculation, the input is set to zero. For example, the circuit of Fig. 7.20 may be a common-source or a common-gate stage, exhibiting the same output noise.\n\nThird, the output resistance, \\( r_O \\), does not produce noise because it is not a physical resistor.\n\nThe ohmic sections of a MOSFET also contribute thermal noise. As conceptually illustrated in the top view of Fig. 7.21(a), the gate, source, and drain materials exhibit finite resistivity, thereby introducing noise. For a relatively wide transistor, the source and drain resistance is typically negligible whereas the gate distributed resistance may become noticeable.\n\nFigure 7.21(a) shows the layout of a MOSFET indicating the terminal resistances. The diagram shows a top view of the MOSFET structure, focusing on the gate (G), source (S), and drain (D) terminals. The gate is connected to a polysilicon line that runs horizontally through the structure, and this line is depicted with multiple resistive elements, indicating distributed resistance along the gate. This resistance can introduce noise into the device, as described in the context.\n\nThe layout shows the source (S) and drain (D) terminals at the top and bottom, respectively, with the gate (G) on the left side. The resistive elements are represented as zigzag lines within the polysilicon gate material, suggesting finite resistivity and noise contribution. The polysilicon material is labeled, emphasizing its role in the gate's resistive properties.\n\nOverall, the diagram illustrates how the distributed gate resistance can affect the performance of the MOSFET by introducing thermal noise, particularly in wide transistors where this resistance becomes significant.\n\nIn the noise model of Fig. 7.21(b), a lumped resistor \\( R_1 \\) represents the distributed gate resistance. Viewing the overall transistor as the distributed structure shown in Fig. 7.21(c), we observe that the unit transistors near the left end see the noise of only a fraction of \\( R_G \\) whereas those near the right end see the noise of most of \\( R_G \\). We therefore expect the lumped resistor in the noise model to be less than \\( R_G \\). In fact, it can be proved that \\( R_1 = R_G/3 \\) (Problem 7.3) [3], and hence the noise generated by the gate resistance is given by \\( \\overline{V_{nRG}^2} = 4kT R_G/3 \\).\n\nWhile the thermal noise generated in the channel is controlled by only the transconductance of the device, the effect of \\( R_G \\) can be reduced by proper layout. Shown in Fig. 7.22 are two examples. In Fig. 7.22(a), the two ends of the gate are shorted by a metal line, thus reducing the distributed resistance from \\( R_G \\) to \\( R_G/4 \\) (why?). Alternatively, the transistor can be folded as described in Chapter 19 [Fig. 7.22(b)] so that each gate \""
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET presents an intriguing phenomenon. At this interface, the silicon crystal terminates, resulting in numerous \"dangling\" bonds that create additional energy states (Fig. 7.25). As charge carriers move across this interface, some are randomly captured and subsequently released by these energy states, causing \"flicker\" noise in the drain current. Beyond trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\nimage_name:Figure 7.25 Dangling bonds at the oxide-silicon interface\ndescription:Figure 7.25, titled \"Dangling bonds at the oxide-silicon interface,\" depicts the interface between different layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Below this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Beneath the SiO2 layer, a schematic of a 'Silicon Crystal' is illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These bonds represent the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds that introduce extra energy states capable of trapping and releasing charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate, and in the saturation region, it is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Consequently, flicker noise is also known as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\nimage_name:Figure 7.26 Flicker noise spectrum\ndescription:Figure 7.26 presents a logarithmic plot of the flicker noise spectrum, commonly referred to as $1/f$ noise. The graph is a Bode plot, typically used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, characteristic of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph is a straight line on a log-log scale, with no specific markers, peaks, or valleys.\n- The negative slope is typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph lacks specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, highlighting its inverse dependence on frequency and the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and hence trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a frequency band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThe above example raises an interesting question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) then yields an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero means considering arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly over roughly 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ over roughly one day. Second, the infinite flicker noise power implies that very slow noise components can randomly reach very high power levels over very long observation times. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications do not involve very-low-frequency components, our observation window need not be very long. For example, voice signals have negligible energy below 20 Hz, and noise components varying at lower rates do not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\nimage_name:Figure 7.27 Concept of flicker noise corner frequency\ndescription:Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise remains constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates the part of the band mostly affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThat is, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. The latter must therefore be added to each transistor by the designer."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET exhibits a notable phenomenon. At this interface, where the silicon crystal terminates, numerous \"dangling\" bonds emerge, resulting in additional energy states (Fig. 7.25). As charge carriers traverse this interface, some are randomly captured and subsequently released by these energy states, thereby introducing \"flicker\" noise into the drain current. Beyond trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\nimage_name:Figure 7.25 Dangling bonds at the oxide-silicon interface\ndescription:Illustrated in \"Figure 7.25 Dangling bonds at the oxide-silicon interface\" is the interface between various layers in a MOSFET structure. At the top, a layer marked 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Below the SiO2 layer, a schematic of a 'Silicon Crystal' is depicted as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' shown as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These dangling bonds symbolize the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, leading to dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also known as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\nimage_name:Figure 7.26 Flicker noise spectrum\ndescription:Figure 7.26 presents a logarithmic plot depicting the flicker noise spectrum, commonly referred to as $1/f$ noise. The graph is a Bode plot, typically used to show the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, characteristic of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph lacks specific markers, peaks, or valleys, appearing as a straight line on a log-log scale.\n- The slope of the line is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph does not provide specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points or markers suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and thus trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a frequency band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the frequency band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThis example raises an intriguing question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the frequency band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) would then yield an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero implies interest in extremely slow noise components. A noise component at 0.01 Hz varies significantly over roughly 10 seconds (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ over about one day. Second, the infinite flicker noise power simply means that if we observe the circuit for an extended period, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications' signals lack very-low-frequency components, our observation window need not be excessively long. For example, voice signals have negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\nimage_name:Figure 7.27 Concept of flicker noise corner frequency\ndescription:Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates which part of the frequency band is primarily affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThus, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. The latter must therefore be added to each transistor by the designer."
},
{
    "text": "The boundary between the gate oxide and the silicon substrate in a MOSFET exhibits a notable phenomenon. At this interface, where the silicon crystal terminates, numerous \"dangling\" bonds emerge, creating additional energy states (Fig. 7.25). As charge carriers traverse this interface, some become randomly trapped and subsequently released by these energy states, resulting in \"flicker\" noise in the drain current. Beyond trapping, various other mechanisms are thought to contribute to flicker noise [4].\n\n**Image Description: Figure 7.25 Dangling bonds at the oxide-silicon interface**\nThe image, titled \"Figure 7.25 Dangling bonds at the oxide-silicon interface,\" depicts the interface between different layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Below the SiO2 layer, a schematic of a 'Silicon Crystal' is illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These bonds represent the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, leading to dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also termed $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\n**Image Description: Figure 7.26 Flicker noise spectrum**\nThe graph in Figure 7.26 is a logarithmic plot representing the flicker noise spectrum, often referred to as $1/f$ noise. It is a Bode plot commonly used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, characteristic of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph is a straight line on a log-log scale with no specific markers, peaks, or valleys.\n- The slope is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph lacks specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse relationship of (7.34) with $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. Thus, it is common to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and hence trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a frequency band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThis example raises an intriguing question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) would then yield an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero means considering arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly in about 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ in roughly one day. Second, the infinite flicker noise power implies that over a very long observation period, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications' signals lack very-low-frequency components, our observation window need not be excessively long. For example, voice signals have negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\n**Image Description: Figure 7.27 Concept of flicker noise corner frequency**\nThe graph in Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates the part of the band predominantly affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThat is, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. Therefore, the designer must add gate resistance noise to each transistor."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET exhibits a notable phenomenon. At this interface, the termination of the silicon crystal results in numerous \"dangling\" bonds, leading to additional energy states (Fig. 7.25). As charge carriers traverse this interface, some are randomly captured and subsequently released by these energy states, thereby introducing \"flicker\" noise into the drain current. Beyond trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\nimage_name:Figure 7.25 Dangling bonds at the oxide-silicon interface\ndescription:Illustrated in \"Figure 7.25 Dangling bonds at the oxide-silicon interface\" is the interface between various layers in a MOSFET structure. The top layer, labeled 'Polysilicon,' is depicted as a solid gray block. Beneath this is a dotted layer marked 'SiO2,' representing the silicon dioxide gate oxide. Below the SiO2 layer, a schematic of a 'Silicon Crystal' is shown, characterized by a lattice structure of interconnected circles and lines.\n\nAt the boundary between the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines linking the SiO2 layer to the lattice structure of the Silicon Crystal. These dangling bonds symbolize the incomplete bonds present at the interface where the silicon crystal ends.\n\nThe diagram emphasizes the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds. These bonds create extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively conveys the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nContrary to thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as depicted in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also known as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is an approximation; in reality, the flicker noise equation is more complex [3].\n\nimage_name:Figure 7.26 Flicker noise spectrum\ndescription:Figure 7.26 presents a logarithmic plot of the flicker noise spectrum, often referred to as $1/f$ noise. This graph is a Bode plot, commonly used to illustrate the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ denotes frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot features a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, a hallmark of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, underscoring the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph lacks specific markers, peaks, or valleys, presenting a straight line on a log-log scale.\n- The slope is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though this is not explicitly noted.\n\n**Annotations and Specific Data Points:**\n- The graph does not provide specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points or markers suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, highlighting its inverse dependence on frequency and the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse relationship of (7.34) to $W L$ suggests that to mitigate $1 / f$ noise, the device area must be increased. Consequently, it is common to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades off with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and thus trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current over a frequency range from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the specified band is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThis example raises an intriguing question: What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) would then yield an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero implies interest in extremely slow noise components. A noise component at 0.01 Hz varies significantly over roughly 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ over about one day. Second, the infinite flicker noise power simply means that over a very long observation period, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to two conclusions. First, since most applications' signals lack very-low-frequency components, our observation window need not be excessively long. For example, voice signals have negligible energy below 20 Hz, and a noise component varying at a lower rate does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\nimage_name:Figure 7.27 Concept of flicker noise corner frequency\ndescription:Figure 7.27 illustrates the concept of the flicker noise corner frequency using a log-log plot. The x-axis represents frequency (f) on a logarithmic scale, while the y-axis represents the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different noise spectral densities across a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide frequency range.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, showing a negative slope on the log-log scale.\n- The thermal noise remains constant over frequency, depicted as a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations like \"1/f Corner\" and \"Thermal\" to differentiate the noise regions.\n- The corner frequency (fC) is marked with a dashed line, emphasizing its importance in noise analysis.\n\nThis graph is crucial for understanding the frequency range over which different noise types affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates the part of the band primarily affected by flicker noise. In the example above, the $1 / f$ noise corner, $f_{C}$, of the output current is determined by\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nwhich simplifies to\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result indicates that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, determine the flicker noise coefficient, $K$, for this technology.\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nSolving for $K$, we get $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. Therefore, the designer must add gate resistance noise to each transistor."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET presents an intriguing phenomenon. At this interface, where the silicon crystal terminates, numerous \"dangling\" bonds emerge, leading to additional energy states (Fig. 7.25). As charge carriers traverse this interface, some are randomly captured and subsequently released by these energy states, resulting in \"flicker\" noise in the drain current. Beyond trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\n**Image Description: Figure 7.25 Dangling bonds at the oxide-silicon interface**\nThe image, titled \"Figure 7.25 Dangling bonds at the oxide-silicon interface,\" depicts the interface between various layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Under the SiO2 layer, a schematic of a 'Silicon Crystal' is illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These bonds represent the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also known as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\n**Image Description: Figure 7.26 Flicker noise spectrum**\nThe graph in Figure 7.26 is a logarithmic plot representing the flicker noise spectrum, often referred to as $1/f$ noise. It is a Bode plot commonly used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, characteristic of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph is a straight line on a log-log scale with no specific markers, peaks, or valleys.\n- The slope is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph lacks specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and thus trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThe above example raises an interesting question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) then yields an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero means we are interested in arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly in roughly 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ in roughly one day. Second, the infinite flicker noise power simply means that if we observe the circuit for a very long time, the very slow noise components can randomly assume a very large power level. At such slow rates, noise becomes indistinguishable from thermal drift or aging of devices.\n\nThese observations lead to the following conclusions. First, since most applications do not involve very-low-frequency components, our observation window need not be very long. For example, voice signals exhibit negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). Called the $1 / f$ noise \"corner frequency,\" the\n\n**Image Description: Figure 7.27 Concept of flicker noise corner frequency**\nThe graph in Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nintersection point serves as a measure of what part of the band is mostly corrupted by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. Nonetheless, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling within the range of 10 MHz to 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThat is, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. The latter must therefore be added to each transistor by the designer."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET presents an intriguing phenomenon. At this interface, the silicon crystal terminates, resulting in numerous \"dangling\" bonds that create additional energy states (Fig. 7.25). As charge carriers traverse this interface, some are randomly captured and subsequently released by these energy states, leading to \"flicker\" noise in the drain current. Apart from trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\nimage_name:Figure 7.25 Dangling bonds at the oxide-silicon interface\ndescription:Figure 7.25, titled \"Dangling bonds at the oxide-silicon interface,\" depicts the interface between various layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Below the SiO2 layer, a schematic of a 'Silicon Crystal' is illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These bonds represent the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also referred to as $1 / f$ noise. Note that Eq. (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is more complex [3].\n\nimage_name:Figure 7.26 Flicker noise spectrum\ndescription:Figure 7.26 presents a logarithmic plot of the flicker noise spectrum, often called $1/f$ noise. The graph is a Bode plot, commonly used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency, characteristic of $1/f$ noise.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph is a straight line on a log-log scale with no specific markers, peaks, or valleys.\n- The slope is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph lacks specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of Eq. (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and thus trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a frequency band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the frequency band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThe above example raises an interesting question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the frequency band, $f_{L}$, is zero instead of 1 kHz? Eq. (7.39) would then yield an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero means considering arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly in about 10 seconds (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ in roughly one day. Second, the infinite flicker noise power implies that if we observe the circuit for a very long time, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications do not involve very-low-frequency components, our observation window need not be very long. For example, voice signals have negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in Eq. (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). The intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\nimage_name:Figure 7.27 Concept of flicker noise corner frequency\ndescription:Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates the part of the frequency band predominantly affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThus, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. Therefore, the designer must add gate resistance noise to each transistor."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET exhibits a notable phenomenon. At this interface, the silicon crystal terminates, resulting in numerous \"dangling\" bonds that create additional energy states (Fig. 7.25). As charge carriers traverse this interface, some are randomly captured and subsequently released by these energy states, leading to \"flicker\" noise in the drain current. Besides trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\n**Image Description: Figure 7.25 Dangling bonds at the oxide-silicon interface**\nThe image, titled \"Figure 7.25 Dangling bonds at the oxide-silicon interface,\" depicts the interface between various layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Under the SiO2 layer, there is a schematic of a 'Silicon Crystal,' illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These bonds represent the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also referred to as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\n**Image Description: Figure 7.26 Flicker noise spectrum**\nThe graph in Figure 7.26 is a logarithmic plot representing the flicker noise spectrum, often called $1/f$ noise. It is a Bode plot, commonly used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency. This is characteristic of $1/f$ noise, where noise intensity is inversely proportional to frequency.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing the inverse relationship.\n\n**Key Features and Technical Details:**\n- There are no specific markers, peaks, or valleys, as the graph is a straight line on a log-log scale.\n- The slope is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph does not provide specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and hence trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a band from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the band of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThe above example raises an interesting question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the band, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) then yields an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero means considering arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly in roughly 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ in roughly one day. Second, the infinite flicker noise power simply means that if we observe the circuit for a very long time, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications do not involve very-low-frequency components, our observation window need not be very long. For example, voice signals have negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\n**Image Description: Figure 7.27 Concept of flicker noise corner frequency**\nThe graph in Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nindicates the part of the band mostly affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling between 10 MHz and 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThat is, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. Therefore, the designer must add gate resistance noise to each transistor."
},
{
    "text": "The junction between the gate oxide and the silicon substrate in a MOSFET exhibits a notable phenomenon. At this interface, the silicon crystal terminates, resulting in numerous \"dangling\" bonds that create additional energy states (Fig. 7.25). As charge carriers move across this interface, some are randomly trapped and subsequently released by these energy states, leading to \"flicker\" noise in the drain current. Beyond trapping, several other mechanisms are thought to contribute to flicker noise [4].\n\nimage_name:Figure 7.25 Dangling bonds at the oxide-silicon interface\ndescription:The image, titled \"Figure 7.25 Dangling bonds at the oxide-silicon interface,\" depicts the interface between various layers in a MOSFET structure. At the top, a layer labeled 'Polysilicon' is shown as a solid gray block. Beneath this is a dotted layer labeled 'SiO2,' representing the silicon dioxide gate oxide. Below the SiO2 layer, a schematic of a 'Silicon Crystal' is illustrated as a lattice structure with interconnected circles and lines.\n\nBetween the SiO2 layer and the Silicon Crystal, dashed lines indicate 'Dangling Bonds,' depicted as vertical dashed lines connecting the SiO2 layer to the lattice structure of the Silicon Crystal. These dangling bonds signify the incomplete bonds at the interface where the silicon crystal ends.\n\nThe diagram highlights the interface where the silicon crystal meets the gate oxide, resulting in dangling bonds. These bonds introduce extra energy states that can trap and release charge carriers, contributing to flicker noise in the MOSFET's drain current. The image effectively illustrates the concept of dangling bonds and their role in noise generation within the device.\n\nFigure 7.25 Dangling bonds at the oxide-silicon interface.\n\nUnlike thermal noise, the average power of flicker noise is not easily predictable. Depending on the \"cleanliness\" of the oxide-silicon interface, flicker noise can vary significantly, differing from one CMOS technology to another. Flicker noise is more conveniently modeled as a voltage source in series with the gate and, in the saturation region, is approximately given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\tag{7.34}\n\\end{equation*}\n$$\n\nwhere $K$ is a process-dependent constant around $10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$. Note that our notation assumes a bandwidth of 1 Hz. Interestingly, as shown in Fig. 7.26, the noise spectral density is inversely proportional to the frequency. For instance, the trap-and-release phenomenon associated with dangling bonds occurs more frequently at low frequencies. Hence, flicker noise is also known as $1 / f$ noise. Note that (7.34) does not depend on the bias current or temperature. This is only an approximation; in reality, the flicker noise equation is somewhat more complex [3].\n\nimage_name:Figure 7.26 Flicker noise spectrum\ndescription:The graph in Figure 7.26 is a logarithmic plot representing the flicker noise spectrum, often referred to as $1/f$ noise. It is a Bode plot commonly used to depict the frequency response of a system.\n\n**Axes Labels and Units:**\n- The horizontal axis is labeled 'log $f$,' where $f$ represents frequency, indicating a logarithmic scale.\n- The vertical axis is labeled '10 log $\\overline{V_n^2}$,' representing the power spectral density of the noise voltage, also on a logarithmic scale.\n\n**Overall Behavior and Trends:**\n- The plot shows a downward-sloping line, indicating that the noise power spectral density decreases with increasing frequency. This is characteristic of $1/f$ noise, where noise intensity is inversely proportional to frequency.\n- The graph starts at a higher value on the vertical axis and slopes downward to the right, emphasizing this inverse relationship.\n\n**Key Features and Technical Details:**\n- The graph features no specific markers, peaks, or valleys, as it is a straight line on a log-log scale.\n- The slope of the line is negative, typical for $1/f$ noise, reflecting the inverse relationship.\n- The shaded area beneath the line may represent the integrated noise power over a specific frequency range, though this is not explicitly annotated.\n\n**Annotations and Specific Data Points:**\n- The graph does not provide specific numerical values or annotations for particular frequencies or noise power levels.\n- The absence of specific data points or markers suggests a general representation of $1/f$ noise behavior rather than specific measured data.\n\nThis graph effectively illustrates the concept of flicker noise, emphasizing its inverse dependence on frequency and highlighting the importance of considering noise characteristics in low-frequency applications.\n\nFigure 7.26 Flicker noise spectrum.\n\nThe inverse dependence of (7.34) on $W L$ suggests that to reduce $1 / f$ noise, the device area must be increased. It is therefore not surprising to see devices with areas of several hundred square microns in low-noise applications. (More fundamentally, the noise power trades with the gate capacitance, $W L C_{o x}$.) Generally, PMOS devices exhibit less $1 / f$ noise than NMOS transistors because the former carry holes in a \"buried channel,\" i.e., at some distance from the oxide-silicon interface, and thus trap and release carriers to a lesser extent.\n\n#### Example 7.8\n\nFor an NMOS current source, calculate the total thermal and $1 / f$ noise in the drain current for a bandwidth from 1 kHz to 1 MHz.\n\n#### Solution\n\nThe thermal noise current per unit bandwidth is given by $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$. Thus, the total thermal noise integrated across the bandwidth of interest is\n\n$$\n\\begin{align*}\n\\overline{I_{n, t h, t o t}^{2}} & =4 k T \\gamma g_{m}\\left(10^{6}-10^{3}\\right)  \\tag{7.35}\\\\\n& \\approx 4 k T \\gamma g_{m} \\times 10^{6} \\mathrm{~A}^{2} \\tag{7.36}\n\\end{align*}\n$$\n\nFor $1 / f$ noise, the drain noise current per unit bandwidth is obtained by multiplying the noise voltage at the gate by the device transconductance:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, 1 / f}^{2}}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2} \\tag{7.37}\n\\end{equation*}\n$$\n\nThe total $1 / f$ noise is then equal to\n\n$$\n\\begin{align*}\n\\overline{I_{n, 1 / f, t o t}^{2}} & =\\frac{K g_{m}^{2}}{C_{o x} W L} \\int_{1 \\mathrm{kHz}}^{1 \\mathrm{MHz}} \\frac{d f}{f}  \\tag{7.38}\\\\\n& =\\frac{K g_{m}^{2}}{C_{o x} W L} \\ln 10^{3}  \\tag{7.39}\\\\\n& =\\frac{6.91 K g_{m}^{2}}{C_{o x} W L} \\tag{7.40}\n\\end{align*}\n$$\n\nThe above example raises an interesting question. What happens to $\\overline{I_{n, 1 / f, t o t}^{2}}$ if the lower end of the bandwidth, $f_{L}$, is zero instead of 1 kHz? Equation (7.39) then yields an infinite value for the total noise. To address the concern of infinite noise, we make two observations. First, extending $f_{L}$ to zero implies interest in arbitrarily slow noise components. A noise component at 0.01 Hz varies significantly in roughly 10 s (one-tenth of the period), and one at $10^{-6} \\mathrm{~Hz}$ in roughly one day. Second, the infinite flicker noise power simply means that if we observe the circuit for a very long time, very slow noise components can randomly reach very high power levels. At such slow rates, noise becomes indistinguishable from thermal drift or device aging.\n\nThese observations lead to the following conclusions. First, since most applications' signals do not contain very-low-frequency components, our observation window need not be very long. For example, voice signals exhibit negligible energy below 20 Hz, and if a noise component varies at a lower rate, it does not significantly corrupt the voice. Second, the logarithmic dependence of flicker noise power on $f_{L}$ allows some margin for error in selecting $f_{L}$. For instance, if the integral in Eq. (7.38) starts from 100 Hz instead of 1 kHz, the coefficient in (7.40) increases from 6.91 to 9.21.\n\nTo quantify the significance of $1 / f$ noise relative to thermal noise for a given device, we plot both spectral densities on the same axes (Fig. 7.27). This intersection point, known as the $1 / f$ noise \"corner frequency,\"\n\nimage_name:Figure 7.27 Concept of flicker noise corner frequency\ndescription:The graph in Figure 7.27 illustrates the concept of the flicker noise corner frequency. It is a log-log plot with the x-axis representing frequency (f) on a logarithmic scale and the y-axis representing the logarithm of the power spectral density (10log(Vn^2)).\n\n1. **Type of Graph and Function:**\n- This is a log-log plot, commonly used to compare different types of noise spectral densities over a range of frequencies.\n\n2. **Axes Labels and Units:**\n- **X-axis:** Frequency (f), presented on a logarithmic scale, indicating a wide range of frequencies.\n- **Y-axis:** 10log(Vn^2), representing the logarithmic scale of the noise power spectral density.\n\n3. **Overall Behavior and Trends:**\n- The graph shows two distinct regions: the left side dominated by 1/f noise and the right side by thermal noise.\n- The 1/f noise decreases with increasing frequency, exhibiting a negative slope on the log-log scale.\n- The thermal noise is constant over frequency, represented by a horizontal line on the log-log scale.\n\n4. **Key Features and Technical Details:**\n- The intersection point of the 1/f noise curve and the thermal noise line is marked as the corner frequency (fC).\n- This corner frequency (fC) indicates the frequency beyond which thermal noise dominates over 1/f noise.\n- The shaded area highlights the region where 1/f noise is significant compared to thermal noise.\n\n5. **Annotations and Specific Data Points:**\n- The graph includes annotations such as \"1/f Corner\" and \"Thermal\" to differentiate the two noise regions.\n- The corner frequency (fC) is marked with a dashed line, indicating its critical role in noise analysis.\n\nThis graph is essential for understanding the frequency range over which different types of noise affect a system, particularly in electronic devices where flicker noise and thermal noise are significant factors.\n\nFigure 7.27 Concept of flicker noise corner frequency.\nserves as a measure of which part of the bandwidth is predominantly affected by flicker noise. In the above example, the $1 / f$ noise corner, $f_{C}$, of the output current is determined as\n\n$$\n\\begin{equation*}\n4 k T \\gamma g_{m}=\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f_{C}} \\cdot g_{m}^{2} \\tag{7.41}\n\\end{equation*}\n$$\n\nthat is,\n\n$$\n\\begin{equation*}\nf_{C}=\\frac{K}{\\gamma C_{o x} W L} g_{m} \\frac{1}{4 k T} \\tag{7.42}\n\\end{equation*}\n$$\n\nThis result implies that $f_{C}$ generally depends on the device area and transconductance. However, for a given $L$, the dependence is weak, and the $1 / f$ noise corner is relatively constant, typically falling within the range of 10 MHz to 50 MHz for nanometer transistors.\n\n#### Example 7.9\n\nFor a $100-\\mu \\mathrm{m} / 0.5-\\mu \\mathrm{m}$ MOS device with $g_{m}=1 /(100 \\Omega)$, the $1 / f$ noise corner frequency is measured to be 500 kHz. If $t_{o x}=90 \\AA$, what is the flicker noise coefficient, $K$, in this technology?\n\n#### Solution\n\nFor $t_{o x}=90 \\AA$, we have $C_{o x}=3.84 \\mathrm{fF} / \\mu \\mathrm{m}^{2}$. Using Eq. (7.42), we write\n\n$$\n\\begin{equation*}\n500 \\mathrm{kHz}=\\frac{K}{3.84 \\times 100 \\times 0.5 \\times 10^{-15}} \\cdot \\frac{1}{100} \\cdot \\frac{3}{8 \\times 1.38 \\times 10^{-23} \\times 300} \\tag{7.43}\n\\end{equation*}\n$$\n\nThat is, $K=1.06 \\times 10^{-25} \\mathrm{~V}^{2} \\mathrm{~F}$.\n\nIt is important to note that typical transistor models include thermal and flicker noise but not gate resistance noise. Therefore, the designer must add the latter to each transistor."
},
{
    "text": "Consider a typical circuit featuring one input and one output port (refer to Fig. 7.28). To gauge the impact of noise in this context, we typically set the input to zero and measure the cumulative noise at the output arising from the various noise sources within the circuit. This method mirrors how noise is quantified in both practical lab settings and simulations. The analysis outlined in Section 7.1.5 systematically leads to the derivation of the output noise spectrum.\n\n[Image Description: Figure 7.28 illustrates a circuit diagram depicting a noise model that includes three noise sources: two voltage-controlled voltage sources and a single current source. The diagram designates the input as Vin and the output as Vout, with these noise sources collectively contributing to the output noise.]\n\n#### Example 7.10\n\nDetermine the combined output noise voltage for the common-source stage depicted in Fig. 7.29(a), assuming that $\\lambda=0$.\n\n[Image Description: Figure 7.29(a) showcases a common-source amplifier stage that includes an NMOS transistor (M1), a resistor (RD), and a voltage source (VDD). The circuit's input is connected to the gate of M1, and the output is taken across RD. The diagram also references a separate figure (b) that illustrates additional noise sources.]\n\n#### Solution\n\nOur approach involves identifying the noise sources, determining their respective transfer functions relative to the output, multiplying their spectral densities by the square of the transfer function magnitudes, and summing these products. We model the thermal and flicker noise contributions of the transistor M1 using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. Additionally, we represent the thermal noise of the resistor RD with a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents pass through RD, the resulting output noise voltage per unit bandwidth is given by:\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nIt's worth noting that noise contributions are combined as \"power\" quantities due to their uncorrelated nature. The expression derived in (7.44) represents the noise power within a 1 Hz bandwidth at frequency $f$. Integrating this expression yields the total output noise.\n\nInput-Referred Noise\n\nWhile the concept of output-referred noise is intuitive, it does not facilitate a fair comparison of circuit performance, as it is gain-dependent. For instance, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$, the output noise as per (7.44) is multiplied by $A_{1}^{2}$. Focusing solely on the output noise might lead to the erroneous conclusion that increasing $A_{1}$ boosts circuit noise, which is incorrect because a higher $A_{1}$ also proportionally increases the output signal level. Consequently, the output signal-to-noise ratio is independent of $A_{1}$.\n\n[Image Description: Figure 7.30 depicts a common-source amplifier stage augmented with an op-amp (A1) for additional gain. The NMOS transistor M1 serves as the amplifying element, with RD providing the load, and the output is derived from the op-amp A1.]\n\nTo address this issue, we often specify the \"input-referred noise\" of circuits. As illustrated in Fig. 7.31, the idea is to represent the cumulative effect of all noise sources with a single source, $\\overline{V_{n, i n}^{2}}$, at the input such that the output noise depicted in Fig. 7.31(b) matches that of Fig. 7.31(a). If the voltage gain is $A_{v}$, then we have $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$, meaning that the input-referred noise voltage is simply the output noise voltage divided by the gain squared.\n\n#### Example 7.11\n\nFor the circuit shown in Fig. 7.29, compute the input-referred noise voltage.\n\n#### Solution\n\nWe find that:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\nThe first term in (7.47) can be interpreted as the thermal noise of a resistor with a value of $\\gamma /\\left(g_{m}\\right)$ in series with the gate. Similarly, the third term corresponds to the noise of a resistor with a value of $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. We sometimes refer to the \"equivalent thermal noise resistance\" of a circuit as $R_{T}$, indicating that the total input-referred thermal noise of the circuit within a unit bandwidth is $4 k T R_{T}$.\n\nThe decrease in $\\overline{V_{n, i n}^{2}}$ with increasing $R_{D}$ can be attributed to the fact that the noise voltage due to RD at the output is proportional to $\\sqrt{R_{D}}$, whereas the voltage gain of the circuit is proportional to $R_{D}$.\n\nAt this stage, we note two key points. First, both the input-referred noise and the input signal are amplified by the gain as they propagate through the circuit. Thus, the input-referred noise reflects how much the input signal is corrupted by the circuit's noise, i.e., the smallest input that the circuit can detect with an acceptable signal-to-noise ratio (SNR). This is why input-referred noise provides a level playing field for comparing different circuits. Second, the input-referred noise is a theoretical construct; it cannot be directly measured at the circuit's input. While the circuits depicted in Figs. 7.31(a) and (b) are mathematically equivalent, the physical circuit corresponds to Fig. 7.31(a).\n\nOur discussion thus far assumes that the input-referred noise can be modeled with a single voltage source in series with the input. This assumption is generally insufficient if the circuit has a finite input impedance and is driven by a source with finite impedance. To illustrate this, let's revisit the CS stage in Fig. 7.29 and observe that the output thermal noise due to M1 is $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$, irrespective of the network driving the gate. Dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$ yields an input-referred noise voltage of $4 k T \\gamma / g_{m}$, which is also independent of the preceding stage.\n\nNow, consider the common-source stage in Fig. 7.32(a), where the input capacitance is denoted as $C_{i n}$. The input-referred noise voltage due to M1 remains $4 k T \\gamma / g_{m}$. Suppose the preceding stage is modeled by a Thevenin equivalent with an output impedance of $R_{1}$ [Fig. 7.32(b)]. Simplifying the circuit for noise calculations as shown in Fig. 7.32(c), we aim to determine the output noise due to M1, expecting it to be $4 k T \\gamma g_{m} R_{D}^{2}$. However, due to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the output noise is actually:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { out }}^{2}} & =\\overline{V_{n, \\text { in }}^{2}}\\left|\\frac{1}{R_{1} C_{\\text {in }} j \\omega+1}\\right|^{2}\\left(g_{m} R_{D}\\right)^{2}  \\tag{7.48}\\\\\n& =\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1} \\tag{7.49}\n\\end{align*}\n$$\n\nThis result is flawed; the output noise due to M1 should not decrease with increasing $R_{1}$.\n\nTo address this issue, we model the input-referred noise using both a series voltage source and a parallel current source (Fig. 7.33), ensuring that even when the output impedance of the preceding stage increases, thereby diminishing the effect of $\\overline{V_{n, i n}^{2}}$, the noise current source still generates noise at the input through a finite impedance. It can be demonstrated that $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are necessary and sufficient to represent the noise of any linear two-port circuit.\n\n[Image Description: Figure 7.33 depicts a circuit model representing noise in a linear two-port circuit using a series voltage source (Vn^2,in) and a parallel current source (In^2,in).]\n\nHow do we calculate $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$? Given that the model holds for any source impedance, we consider two limiting cases: zero and infinite source impedances. As shown in Fig. 7.34(a), if the source impedance is zero, $\\overline{I_{n, i n}^{2}}$ flows through $\\overline{V_{n, i n}^{2}}$ and has no impact on the output. Thus, the measured output noise in this case is solely due to $\\overline{V_{n, i n}^{2}}$. Conversely, if the input is open [Fig. 7.34(b)], then $\\overline{V_{n, i n}^{2}}$ is irrelevant, and the output noise is solely due to $\\overline{I_{n, i n}^{2}}$. We apply this method to the circuit in Fig. 7.32.\n\n[Image Description: Figure 7.34 illustrates the calculation of input-referred noise voltage and current using a system block diagram that separates a noisy circuit from a noiseless circuit.]\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current for the circuit in Fig. 7.32, considering only the thermal noise of M1 and RD.\n\n#### Solution\n\nUsing (7.47), the input-referred noise voltage is:\n\n$$\n\\begin{equation*}\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.50}\n\\end{equation*}\n$$\n\nAs depicted in Fig. 7.35(a), this voltage generates the same output noise as the actual circuit when the input is shorted.\n\n[Image Description: Figure 7.35(a) illustrates the input-referred noise voltage analysis with the input shorted.]\n\nTo find the input-referred noise current, we open the input and express the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Fig.7.35(b)]. The noise current flows through $C_{i n}$, resulting in the following output noise:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2} \\tag{7.51}\n\\end{equation*}\n$$\n\nAccording to Fig. 7.34(b), this value must equal the output noise of the noisy circuit with its input open:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.52}\n\\end{equation*}\n$$\n\nFrom (7.51) and (7.52), we deduce that:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) \\tag{7.53}\n\\end{equation*}\n$$\n\nThe input noise current, $I_{n, i n}$, becomes significant if the circuit's input impedance, $Z_{i n}$, is not very high. To assess whether $I_{n, i n}$ can be neglected, we consider the scenario depicted in Fig. 7.36, where $Z_{S}$ represents the output impedance of the preceding circuit. The total noise voltage sensed by the second stage at node $X$ is given by:\n\n$$\n\\begin{equation*}\nV_{n, X}=\\frac{Z_{\\text {in }}}{Z_{\\text {in }}+Z_{S}} V_{n, i n}+\\frac{Z_{\\text {in }} Z_{S}}{Z_{\\text {in }}+Z_{S}} I_{n, i n} \\tag{7.54}\n\\end{equation*}\n$$\n\nIf $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the impact of $I_{n, i n}$ is negligible. In other words, it is the output impedance of the preceding stage, rather than $Z_{i n}$, that determines the relevance of $I_{n, i n}$. We conclude that the input-referred noise current can be disregarded if:\n\nA challenge with using input-referred noise voltages and currents is that they may be correlated. After all, $V_{n, i n}$ and $I_{n, i n}$ may originate from the same noise source. For example, in Fig. 7.35, if the noise voltage of RD increases at a certain point in time, both $V_{n, i n}$ and $I_{n, i n}$ will also exhibit this increase. Consequently, noise calculations must account for the correlation between $V_{n, i n}$ and $I_{n, i n}$ as indicated in Eq. (7.11). Methods for mitigating this correlation are discussed in Appendix A.\n\nOne might question whether using both a voltage source and a current source to represent the input-referred noise leads to double-counting the noise. We can illustrate this using the environment depicted in Fig. 7.37 and demonstrate that the output noise is accurate for any source impedance, $Z_{S}$. Assuming $Z_{S}$ is noiseless for simplicity, we first calculate the total noise voltage at the gate of M1 due to $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$. This voltage cannot be obtained by simply adding powers because $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are correlated. However, superposition still applies to voltages and currents since the circuit is linear and time-invariant. Equations (7.50) and (7.53) must be rewritten as:\n\n$$\n\\begin{align*}\nV_{n, i n} & =V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}  \\tag{7.56}\\\\\nI_{n, i n} & =C_{i n} s V_{n, M 1}+\\frac{C_{i n} s}{g_{m} R_{D}} V_{n, R D} \\tag{7.57}\n\\end{align*}\n$$\n\n[Image Description: Figure 7.37 illustrates a CS stage driven by a source impedance with an NMOS transistor (M1), a resistor (RD), and a capacitor (Cin). The input voltage noise is represented by Vn,in, and the output voltage noise by Vn,out.]\n\nwhere $V_{n, M 1}$ denotes the gate-referred noise voltage of M1, and $V_{n, R D}$ represents the noise voltage of RD. We recognize that $V_{n, M 1}$ and $V_{n, R D}$ appear in both $V_{n, i n}$ and $I_{n, i n}$, establishing a strong correlation between them. Hence, the calculations must employ superposition of voltages, treating $V_{n, i n}$ and $I_{n, i n}$ as deterministic quantities.\n\nAdding the contributions of $V_{n, i n}$ and $I_{n, i n}$ at node $X$ in Fig. 7.37, we have:\n\n$$\n\\begin{align*}\nV_{n, X} & =V_{n, i n} \\frac{\\frac{1}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S"
},
{
    "text": "Consider a generic circuit featuring a single input and a single output port (refer to Fig. 7.28). How do we measure the impact of noise on this circuit? The typical method involves setting the input to zero and then determining the total noise at the output caused by the various noise sources within the circuit. This is the approach used in both laboratory measurements and simulations. Our analytical method in Section 7.1.5 systematically leads to the output noise spectrum.\n\n#### Example 7.10\n\nDetermine the total output noise voltage for the common-source stage depicted in Fig. 7.29(a), assuming $\\lambda=0$.\nThe circuit is a common-source amplifier stage with an NMOS transistor M1. The output is taken across RD, and the input is applied to the gate of M1. The circuit operates with a supply voltage VDD, and the output node is labeled as Vout. The diagram also includes noise sources in a separate figure (b), but they are not part of the netlist for figure (a).\n\n#### Solution\n\nTo find the total output noise voltage, we need to identify the sources of noise, determine their transfer functions to the output, multiply their spectra by the squared magnitude of the transfer functions, and sum the results. We model the thermal and flicker noise of $M_{1}$ using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. We also represent the thermal noise of $R_{D}$ with a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents flow through $R_{D}$, the output noise voltage per unit bandwidth is given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nThe noise mechanisms are added as \"power\" quantities because they are uncorrelated. The value provided by (7.44) represents the noise power in 1 Hz at a frequency $f$. The total output noise is obtained by integration.\n\nInput-Referred Noise The output-referred noise, while intuitively clear, does not allow for a fair comparison of the performance of different circuits since it depends on the gain. For instance, as shown in Fig. 7.30, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$, the output noise is equal to the expression in (7.44) multiplied by $A_{1}^{2}$. Focusing only on the output noise, one might conclude that as $A_{1}$ increases, the circuit becomes noisier, which is incorrect because a larger $A_{1}$ also provides a proportionally higher signal level at the output. Thus, the output signal-to-noise ratio does not depend on $A_{1}$.\n\nTo address this issue, we typically specify the \"input-referred noise\" of circuits. As illustrated conceptually in Fig. 7.31, the idea is to represent the effect of all noise sources in the circuit with a single source, $\\overline{V_{n, i n}^{2}}$, at the input such that the output noise in Fig. 7.31(b) equals that in Fig. 7.31(a). If the voltage gain is $A_{v}$, then we must have $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$, meaning the input-referred noise voltage in this simple case is the output noise voltage divided by the gain.\n\n#### Example 7.11\n\nCalculate the input-referred noise voltage for the circuit in Fig. 7.29.\n\n#### Solution\n\nUsing the formula\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\nWe observe that the first term in (7.47) can be seen as the thermal noise of a resistor equal to $\\gamma /\\left(g_{m}\\right)$ placed in series with the gate. Similarly, the third term corresponds to the noise of a resistor equal to $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. We sometimes refer to the \"equivalent thermal noise resistance\" of a circuit as $R_{T}$, indicating that the total input-referred thermal noise of the circuit in unit bandwidth is equal to $4 k T R_{T}$.\n\nThe decrease in $\\overline{V_{n, i n}^{2}}$ as $R_{D}$ increases is due to the fact that the noise voltage due to $R_{D}$ at the output is proportional to $\\sqrt{R_{D}}$, while the voltage gain of the circuit is proportional to $R_{D}$.\n\nAt this stage, we note two important points. First, both the input-referred noise and the input signal are multiplied by the gain as they are processed by the circuit. Thus, the input-referred noise indicates how much the input signal is corrupted by the circuit's noise, i.e., how small an input the circuit can detect with acceptable SNR. This is why input-referred noise allows for a fair comparison of different circuits. Second, the input-referred noise is a theoretical quantity as it cannot be directly measured at the input of the circuit. The two circuits of Figs. 7.31(a) and (b) are mathematically equivalent, but the physical circuit is still that in Fig. 7.31(a).\n\nIn our discussion, we have assumed that the input-referred noise can be modeled by a single voltage source in series with the input. This is generally an incomplete representation if the circuit has a finite input impedance and is driven by a finite source impedance. To understand why, let's return to the CS stage of Fig. 7.29 and observe that the output thermal noise due to $M_{1}$ is equal to $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$, regardless of the network driving the gate (i.e., regardless of the preceding stage). Dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$, we obtain an input-referred noise voltage of $4 k T \\gamma / g_{m}$, also independent of the preceding stage.\n\nNow, consider the common-source stage of Fig. 7.32(a), where the input capacitance is denoted by $C_{i n}$. The input-referred noise voltage due to $M_{1}$ is still given by $4 k T \\gamma / g_{m}$. Suppose the preceding stage is modeled by a Thevenin equivalent having an output impedance of $R_{1}$ [Fig. 7.32(b)]. Simplifying the circuit for noise calculations as shown in Fig. 7.32(c), we seek the output noise due to $M_{1}$, hoping to obtain $4 k T \\gamma g_{m} R_{D}^{2}$. However, due to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the output noise emerges as\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { out }}^{2}} & =\\overline{V_{n, \\text { in }}^{2}}\\left|\\frac{1}{R_{1} C_{\\text {in }} j \\omega+1}\\right|^{2}\\left(g_{m} R_{D}\\right)^{2}  \\tag{7.48}\\\\\n& =\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1} \\tag{7.49}\n\\end{align*}\n$$\n\nThis result is incorrect; after all, the output noise due to $M_{1}$ must not diminish as $R_{1}$ increases.\n\nLet us summarize the problem. If the circuit has a finite input impedance, modeling the input-referred noise by merely a voltage source implies that the output noise vanishes as the source impedance becomes large, an incorrect conclusion. To resolve this issue, we model the input-referred noise by both a series voltage source and a parallel current source (Fig. 7.33) so that if the output impedance of the preceding stage assumes large values, thereby reducing the effect of $\\overline{V_{n, i n}^{2}}$, the noise current source still flows through a finite impedance, producing noise at the input. It can be demonstrated that $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are necessary and sufficient to represent the noise of any linear two-port circuit.\n\nHow do we calculate $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$? Since the model is valid for any source impedance, we consider two extreme cases: zero and infinite source impedances. As shown in Fig. 7.34(a), if the source impedance is zero, $\\overline{I_{n, i n}^{2}}$ flows through $\\overline{V_{n, i n}^{2}}$ and has no effect on the output. Thus, the output noise measured in this case arises solely from $\\overline{V_{n, i n}^{2}}$. Similarly, if the input is open [Fig. 7.34(b)], then $\\overline{V_{n, i n}^{2}}$ has no effect, and the output noise is due to only $\\overline{I_{n, i n}^{2}}$. Applying this method to the circuit of Fig. 7.32, we find the input-referred noise voltage and current.\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current for the circuit in Fig. 7.32, including only the thermal noise of $M_{1}$ and $R_{D}$.\n\n#### Solution\n\nUsing the formula\n\n$$\n\\begin{equation*}\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.50}\n\\end{equation*}\n$$\n\nAs depicted in Fig. 7.35(a), this voltage generates the same output noise as the actual circuit if the input is shorted.\n\nTo obtain the input-referred noise current, we open the input and find the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Fig.7.35(b)]. The noise current flows through $C_{i n}$, generating at the output\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2} \\tag{7.51}\n\\end{equation*}\n$$\n\nAccording to Fig. 7.34(b), this value must be equal to the output of the noisy circuit when its input is open:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.52}\n\\end{equation*}\n$$\n\nFrom (7.51) and (7.52), it follows that\n\n$$\n\\begin{equation*}\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) \\tag{7.53}\n\\end{equation*}\n$$\n\nThe input noise current, $I_{n, i n}$, becomes significant if the circuit's input impedance, $Z_{i n}$, is not very high. To see whether $I_{n, i n}$ can be neglected or not, we consider the scenario depicted in Fig. 7.36, where $Z_{S}$ denotes the output impedance of the preceding circuit. The total noise voltage sensed by the second stage at node $X$ is given by\n\n$$\n\\begin{equation*}\nV_{n, X}=\\frac{Z_{\\text {in }}}{Z_{\\text {in }}+Z_{S}} V_{n, i n}+\\frac{Z_{\\text {in }} Z_{S}}{Z_{\\text {in }}+Z_{S}} I_{n, i n} \\tag{7.54}\n\\end{equation*}\n$$\n\nIf $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the effect of $I_{n, i n}$ is negligible. In other words, ultimately, it is the output impedance of the preceding stage-rather than $Z_{i n}$-that determines the significance of $I_{n, i n}$. We conclude that the input-referred noise current can be neglected if\n\nA challenge in using input-referred noise voltages and currents is that they may be correlated. Since $V_{n, i n}$ and $I_{n, i n}$ may contain effects from the same noise source, noise calculations must account for the correlation between the two. Methods of avoiding this correlation are described in Appendix A.\n\nThe reader may question whether using both a voltage source and a current source to represent the input-referred noise \"counts the noise twice.\" We consider the environment depicted in Fig. 7.37 as an example and prove that the output noise is correct for any source impedance, $Z_{S}$. Assuming $Z_{S}$ is noiseless for simplicity, we first calculate the total noise voltage at the gate of $M_{1}$ due to $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$. This voltage cannot be obtained by superposition of powers because $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are correlated. Nonetheless, superposition still applies to voltages and currents because the circuit is linear and time-invariant. Equations (7.50) and (7.53) must be respectively rewritten as\n\n$$\n\\begin{align*}\nV_{n, i n} & =V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}  \\tag{7.56}\\\\\nI_{n, i n} & =C_{i n} s V_{n, M 1}+\\frac{C_{i n} s}{g_{m} R_{D}} V_{n, R D} \\tag{7.57}\n\\end{align*}\n$$\n\nwhere $V_{n, M 1}$ denotes the gate-referred noise voltage of $M_{1}$ and $V_{n, R D}$ the noise voltage of $R_{D}$. We recognize that $V_{n, M 1}$ and $V_{n, R D}$ appear in both $V_{n, i n}$ and $I_{n, i n}$, creating a strong correlation between the two. Thus, the calculations must use superposition of voltages-as if $V_{n, i n}$ and $I_{n, i n}$ were deterministic quantities.\n\nAdding the contributions of $V_{n, i n}$ and $I_{n, i n}$ at node $X$ in Fig. 7.37, we have\n\n$$\n\\begin{align*}\nV_{n, X} & =V_{n, i n} \\frac{\\frac{1}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S}}+I_{n, i n} \\frac{\\frac{Z_{S}}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S}}  \\tag{7.58}\\\\\n& =\\frac{V_{n, i n}+I_{n, i n} Z_{S}}{Z_{S} C_{i n} s+1} \\tag{7.59}\n\\end{align*}\n$$\n\nSubstituting for $V_{n, i n}$ and $I_{n, i n}$ from (7.56) and (7.57), respectively, we obtain\n\n$$\n\\begin{align*}\nV_{n, X} & =\\frac{1}{Z_{S} C_{i n} s+1}\\left[V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}+C_{i n} s Z_{S}\\left(V_{n, M 1}+\\frac{1}{g_{m} R_{D}}"
},
{
    "text": "---[Rephrased Text]---\n\nContemplate a typical electronic circuit equipped with a singular input and output terminal (refer to Fig. 7.28). The pivotal question is: how can we effectively measure the impact of noise within such a setup? A straightforward method involves grounding the input and assessing the cumulative noise at the output, which emanates from the diverse noise producers within the circuit. This technique mirrors the standard practice in both experimental labs and simulation environments. Our detailed analysis in Section 7.1.5 systematically arrives at the noise spectrum observed at the output.\n\n[Description of Figure 7.28]\nThe schematic displayed in Figure 7.28 encapsulates a noise model featuring three distinct noise sources: two voltage-controlled voltage sources and a solitary current source. The input and output terminals are denoted as Vin and Vout, respectively. These noise sources collectively contribute to the aggregate noise detected at the output.\n\n#### Example 7.10\n\nDetermine the cumulative output noise voltage for the common-source stage illustrated in Fig. 7.29(a), assuming $\\lambda=0$.\n\n[Description of Figure 7.29 (a) and (b)]\nThe circuit depicted in Figure 7.29(a) represents a common-source amplifier stage that utilizes an NMOS transistor, M1. The resistor RD serves as the load, and Vin is applied to the gate of M1. The circuit is powered by VDD, with the output terminal labeled as Vout. Figure 7.29(b) includes noise sources, but these are not integrated into the netlist for Figure 7.29(a).\n\n#### Solution\n\nOur task is to pinpoint all noise origins, ascertain their respective transfer functions to the output, multiply their spectral distributions by the square of the transfer functions' magnitudes, and aggregate these outcomes. We simulate the thermal and flicker noise emanating from $M_{1}$ using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. The thermal noise produced by $R_{D}$ is similarly modeled by a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Considering these currents pass through $R_{D}$, the resulting output noise voltage across a given bandwidth is expressed as:\n\n$$\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2}\n$$\n\nIt is essential to recognize that noise mechanisms are combined as \"power\" elements since they are statistically independent. The value derived from the aforementioned equation signifies the noise power contained within a 1 Hz bandwidth at frequency $f$. The complete output noise is subsequently determined through integration.\n\n[Description of Figure 7.30]\nThe concept of output-referred noise, while seemingly logical, is inadequate for benchmarking the efficacy of various circuits due to its dependency on gain. For instance, if a common-source stage is augmented by a noiseless amplifier with a voltage gain $A_{1}$, as depicted in Figure 7.30, the output noise is tantamount to the expression in the equation multiplied by $A_{1}^{2}$. Focusing solely on the output noise might lead to the erroneous conclusion that an increased $A_{1}$ results in a noisier circuit, neglecting the fact that a larger $A_{1}$ also enhances the signal level at the output proportionally. Thus, the output signal-to-noise ratio remains unaffected by changes in $A_{1}$.\n\n[Description of Figure 7.31]\nTo surmount this challenge, we often resort to specifying the \"input-referred noise\" of circuits. As depicted conceptually in Figure 7.31, the approach is to represent the cumulative impact of all circuit noise sources by a solitary source, $\\overline{V_{n, i n}^{2}}$, at the input such that the output noise depicted in Figure 7.31(b) mirrors that in Figure 7.31(a). Given a voltage gain $A_{v}$, the relationship $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$ holds, meaning the input-referred noise voltage in this simplified scenario is derived by dividing the output noise voltage by the gain.\n\n#### Example 7.11\n\nCalculate the input-referred noise voltage for the circuit shown in Figure 7.29.\n\n#### Solution\n\nUsing the previously outlined method, we derive the input-referred noise voltage as follows:\n\n$$\n\\overline{V_{n, \\text { in }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}\n$$\n\nWe observe that the first term in the equation can be interpreted as the thermal noise of a resistor equivalent to $\\gamma /\\left(g_{m}\\right)$ in series with the gate. The third term corresponds to the noise of a resistor equivalent to $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. Occasionally, we refer to the \"equivalent thermal noise resistance\" of a circuit as $R_{T}$, indicating that the total input-referred thermal noise of the circuit within a unit bandwidth equals $4 k T R_{T}$.\n\n[Description of Figure 7.32 and Figure 7.33]\nThe subsequent discussion assumes that the input-referred noise can be adequately modeled by a single voltage source in series with the input. However, this approximation falls short when the circuit exhibits a finite input impedance and is driven by a finite source impedance. To illustrate this, let us revisit the CS stage in Figure 7.29 and note that the output thermal noise sourced from $M_{1}$ remains $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$, irrespective of the network driving the gate. Dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$ yields an input-referred noise voltage of $4 k T \\gamma / g_{m}$, which is also independent of the preceding stage.\n\nConsidering the common-source stage in Figure 7.32(a), where the input capacitance is denoted as $C_{i n}$, the input-referred noise voltage sourced from $M_{1}$ remains $4 k T \\gamma / g_{m}$. Suppose the preceding stage is approximated by a Thevenin equivalent with an output impedance of $R_{1}$ [Figure 7.32(b)]. Simplifying the circuit for noise calculations as illustrated in Figure 7.32(c), we aim to ascertain the output noise sourced from $M_{1}$, expecting to obtain $4 k T \\gamma g_{m} R_{D}^{2}$. However, due to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the calculated output noise is given by:\n\n$$\n\\overline{V_{n, \\text { out }}^{2}}=\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1}\n$$\n\nThis outcome is inaccurate; the output noise due to $M_{1}$ should not diminish as $R_{1}$ increases.\n\nTo rectify this oversight, we model the input-referred noise using both a series voltage source and a parallel current source (Figure 7.33). This ensures that even when the output impedance of the preceding stage increases, thus diminishing the influence of $\\overline{V_{n, i n}^{2}}$, the noise current source continues to flow through a finite impedance, thereby generating noise at the input.\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current for the circuit depicted in Figure 7.32, incorporating only the thermal noise generated by $M_{1}$ and $R_{D}$.\n\n#### Solution\n\nThe input-referred noise voltage, as determined from the previous equation, is:\n\n$$\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}}\n$$\n\nThis voltage generates an output noise equivalent to that of the actual circuit if the input is shorted. To derive the input-referred noise current, we open the input and calculate the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Figure 7.35(b)]. The noise current flows through $C_{i n}$, resulting in the output noise given by:\n\n$$\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2}\n$$\n\nAccording to the analysis depicted in Figure 7.34(b), this value must correspond to the output of the noisy circuit when its input is open:\n\n$$\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2}\n$$\n\nFrom these equations, we can deduce the input-referred noise current:\n\n$$\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right)\n$$\n\n[Description of Figure 7.36]\nThe significance of the input noise current, $I_{n, i n}$, becomes pronounced if the circuit's input impedance, $Z_{i n}$, is not exceedingly high. To evaluate whether $I_{n, i n}$ can be disregarded, we examine the scenario depicted in Figure 7.36, where $Z_{S}$ represents the output impedance of the preceding circuit. The total noise voltage perceived by the second stage at node $X$ is given by:\n\n$$\nV_{n, X}=\\frac{Z_{\\text {in }}}{Z_{\\text {in }}+Z_{S}} V_{n, i n}+\\frac{Z_{\\text {in }} Z_{S}}{Z_{\\text {in }}+Z_{S}} I_{n, i n}\n$$\n\nIf $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the impact of $I_{n, i n}$ is negligible. In essence, it is the output impedance of the preceding stage, rather than $Z_{i n}$, that dictates the relevance of $I_{n, i n}$. We conclude that the input-referred noise current can be safely ignored if the aforementioned condition is met.\n\nA potential complication in utilizing input-referred noise voltages and currents is their potential correlation. Given that $V_{n, i n}$ and $I_{n, i n}$ may originate from the same noise source, their correlation must be accounted for in noise calculations. Techniques to circumvent this correlation are outlined in Appendix A.\n\n[Description of Figure 7.37]\nThe reader might question whether representing the input-referred noise with both a voltage source and a current source leads to a duplication of noise accounting. To address this, we consider the scenario depicted in Figure 7.37 and demonstrate that the output noise remains accurate for any source impedance, $Z_{S}$. Assuming $Z_{S}$ is devoid of noise for simplicity, we initially calculate the total noise voltage at the gate of $M_{1}$ due to $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$. This voltage cannot be derived through the superposition of powers, as $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are correlated. Nonetheless, superposition is still applicable to voltages and currents, given the circuit's linearity and time-invariance. The equations for $V_{n, i n}$ and $I_{n, i n}$ must be accordingly adjusted to account for this correlation.\n\nUpon adding the contributions of $V_{n, i n}$ and $I_{n, i n}$ at node $X$ in Figure 7.37, we obtain:\n\n$$\nV_{n, X}=\\frac{V_{n, i n}+I_{n, i n} Z_{S}}{Z_{S} C_{i n} s+1}\n$$\n\nSubstituting the expressions for $V_{n, i n}$ and $I_{n, i n}$ from the adjusted equations, we arrive at:\n\n$$\nV_{n, X}=V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}\n$$\n\nIt is evident that $V_{n, X}$ is independent of $Z_{S}$ and $C_{i n}$. Consequently, the output noise is:\n\n$$\n\\overline{V_{n, \\text { out }}^{2}}=4 k T\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) R_{D}^{2}\n$$\n\nThis confirms that $V_{n, i n}$ and $I_{n, i n}$ do not result in double-counting of noise.\n\nAn alternative approach in certain situations is to consider the output short-circuit noise current instead of the output open-circuit noise voltage for these calculations. This current is then multiplied by the circuit's output resistance to yield the output noise voltage or simply divided by an appropriate gain to derive the input-referred quantities. The following example elucidates this method.\n```"
},
{
    "text": "Consider a standard circuit design featuring a solitary input and a solitary output port (refer to Fig. 7.28). To measure the impact of noise within this circuit, the standard method involves setting the input to zero and then determining the cumulative noise present at the output, emanating from the diverse noise sources within the circuit. This technique is widely employed in both laboratory experiments and simulation environments. Our analytical procedure, outlined in Section 7.1.5, systematically arrives at the output noise spectrum.\n\nThe circuit diagram in Fig. 7.28 displays a noise model that incorporates three distinct noise sources: two voltage-controlled voltage sources and one current source. The input is denoted as Vin, while the output is designated as Vout. These noise sources collectively contribute to the overall noise detected at the output.\n\n#### Example 7.10\n\nDetermine the aggregate output noise voltage for the common-source stage illustrated in Fig. 7.29(a), assuming $\\lambda=0$.\n\nThe circuit depicted in Fig. 7.29(a) is a common-source amplifier stage that employs an NMOS transistor, M1. The output is measured across resistor RD, with the input signal applied to the gate of M1. The circuit is powered by a voltage source, VDD, and the output node is marked as Vout. A separate figure (b) illustrates the noise sources associated with the circuit, although these are not included in the netlist for figure (a).\n\nFigure 7.29 (a) presents the CS stage, while (b) includes the circuit with noise sources.\n\n#### Solution\n\nTo determine the total output noise voltage, we must first identify all noise sources, calculate their respective transfer functions to the output, multiply their spectral densities by the squared magnitude of the transfer functions, and sum the results. We model the thermal and flicker noise of the transistor $M_{1}$ using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. The thermal noise of resistor $R_{D}$ is represented by a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents flow through $R_{D}$, the output noise voltage per unit bandwidth is given by:\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nIt is important to note that the noise mechanisms are added as \"power\" quantities because they are uncorrelated. The value provided by (7.44) represents the noise power in 1 Hz at a frequency $f$. The complete output noise is obtained through integration.\n\nInput-Referred Noise: Although the output-referred noise is a straightforward concept, it does not allow for an equitable comparison of the performance of various circuits, as it is dependent on the gain. For instance, as shown in Fig. 7.30, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$, the output noise is equivalent to the expression in (7.44) multiplied by $A_{1}^{2}$. Focusing solely on the output noise might lead to the erroneous conclusion that as $A_{1}$ increases, the circuit becomes noisier. However, this overlooks the fact that a larger $A_{1}$ also results in a proportionally higher signal level at the output. Therefore, the output signal-to-noise ratio is independent of $A_{1}$.\n\nFigure 7.30 illustrates the addition of a gain stage to a CS stage.\n\nTo address this issue, we typically specify the \"input-referred noise\" of circuits. As depicted conceptually in Fig. 7.31, the objective is to represent the impact of all noise sources within the circuit as a single source, $\\overline{V_{n, i n}^{2}}$, at the input, such that the output noise in Fig. 7.31(b) matches that in Fig. 7.31(a). If the voltage gain is $A_{v}$, then we must have $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$. In simple terms, the input-referred noise voltage is calculated by dividing the output noise voltage by the gain.\n\n#### Example 7.11\n\nCalculate the input-referred noise voltage for the circuit shown in Fig. 7.29.\n\n#### Solution\n\nThe input-referred noise voltage is determined as follows:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\nIt is worth noting that the first term in (7.47) can be interpreted as the thermal noise of a resistor with a value of $\\gamma /\\left(g_{m}\\right)$ placed in series with the gate. Similarly, the third term corresponds to the noise of a resistor with a value of $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. We often refer to the \"equivalent thermal noise resistance\" of a circuit as $R_{T}$, indicating that the total input-referred thermal noise of the circuit in unit bandwidth is equal to $4 k T R_{T}$.\n\nThe reason $\\overline{V_{n, i n}^{2}}$ decreases with increasing $R_{D}$ is that the noise voltage due to $R_{D}$ at the output is proportional to $\\sqrt{R_{D}}$, whereas the voltage gain of the circuit is proportional to $R_{D}$.\n\nAt this stage of our analysis, we make two key observations. First, both the input-referred noise and the input signal are amplified by the gain as they pass through the circuit. Consequently, the input-referred noise indicates how much the input signal is corrupted by the circuit's noise, i.e., how small an input the circuit can detect with an acceptable signal-to-noise ratio (SNR). This is why input-referred noise enables a fair comparison of different circuits. Second, the input-referred noise is a theoretical construct; it cannot be directly measured at the input of the circuit. Although the circuits in Figs. 7.31(a) and (b) are mathematically equivalent, the physical circuit corresponds to Fig. 7.31(a).\n\nIn our previous discussion, we assumed that the input-referred noise could be modeled by a single voltage source in series with the input. However, this representation is generally inadequate if the circuit has a finite input impedance and is driven by a finite source impedance. To understand why, let us revisit the CS stage in Fig. 7.29 and observe that the output thermal noise due to $M_{1}$ is $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$, regardless of the network driving the gate (i.e., regardless of the preceding stage). Dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$ yields an input-referred noise voltage of $4 k T \\gamma / g_{m}$, which is also independent of the preceding stage.\n\nNow, consider the common-source stage in Fig. 7.32(a), where the input capacitance is denoted as $C_{i n}$. The input-referred noise voltage due to $M_{1}$ remains $4 k T \\gamma / g_{m}$. Suppose the preceding stage is modeled by a Thevenin equivalent with an output impedance of $R_{1}$ [Fig. 7.32(b)]. Simplifying the circuit for noise calculations, as shown in Fig. 7.32(c), we aim to determine the output noise due to $M_{1}$, expecting to obtain $4 k T \\gamma g_{m} R_{D}^{2}$. However, due to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the output noise is calculated as:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { out }}^{2}} & =\\overline{V_{n, \\text { in }}^{2}}\\left|\\frac{1}{R_{1} C_{\\text {in }} j \\omega+1}\\right|^{2}\\left(g_{m} R_{D}\\right)^{2}  \\tag{7.48}\\\\\n& =\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1} \\tag{7.49}\n\\end{align*}\n$$\n\nThis result is incorrect; the output noise due to $M_{1}$ should not decrease as $R_{1}$ increases.\n\nLet us summarize the problem. If the circuit has a finite input impedance, modeling the input-referred noise as merely a voltage source implies that the output noise diminishes as the source impedance grows larger, which is an inaccurate conclusion. To rectify this, we model the input-referred noise using both a series voltage source and a parallel current source (Fig. 7.33). This ensures that even if the output impedance of the preceding stage increases, thereby reducing the impact of $\\overline{V_{n, i n}^{2}}$, the noise current source still flows through a finite impedance, generating noise at the input. It can be demonstrated that $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are necessary and sufficient to represent the noise of any linear two-port circuit.\n\nHow do we calculate $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$? Since the model is applicable for any source impedance, we consider two extreme cases: zero and infinite source impedances. As shown in Fig. 7.34(a), if the source impedance is zero, $\\overline{I_{n, i n}^{2}}$ flows through $\\overline{V_{n, i n}^{2}}$ and has no effect on the output. Thus, the output noise measured in this case arises solely from $\\overline{V_{n, i n}^{2}}$. Similarly, if the input is open [Fig. 7.34(b)], then $\\overline{V_{n, i n}^{2}}$ has no effect, and the output noise is due to only $\\overline{I_{n, i n}^{2}}$. Let us apply this method to the circuit of Fig. 7.32.\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current of Fig. 7.32, considering only the thermal noise of $M_{1}$ and $R_{D}$.\n\n#### Solution\n\nFrom (7.47), the input-referred noise voltage is:\n\n$$\n\\begin{equation*}\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.50}\n\\end{equation*}\n$$\n\nAs depicted in Fig. 7.35(a), this voltage generates the same output noise as the actual circuit if the input is shorted.\n\nTo obtain the input-referred noise current, we open the input and find the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Fig.7.35(b)]. The noise current flows through $C_{i n}$, generating at the output:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2} \\tag{7.51}\n\\end{equation*}\n$$\n\nAccording to Fig. 7.34(b), this value must be equal to the output of the noisy circuit when its input is open:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.52}\n\\end{equation*}\n$$\n\nFrom (7.51) and (7.52), it follows that:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) \\tag{7.53}\n\\end{equation*}\n$$\n\nThe input noise current, $I_{n, i n}$, becomes significant if the circuit's input impedance, $Z_{i n}$, is not very high. To determine whether $I_{n, i n}$ can be neglected or not, we consider the scenario depicted in Fig. 7.36, where $Z_{S}$ denotes the output impedance of the preceding circuit. The total noise voltage sensed by the second stage at node $X$ is:\n\n$$\n\\begin{equation*}\nV_{n, X}=\\frac{Z_{\\text {in }}}{Z_{\\text {in }}+Z_{S}} V_{n, i n}+\\frac{Z_{\\text {in }} Z_{S}}{Z_{\\text {in }}+Z_{S}} I_{n, i n} \\tag{7.54}\n\\end{equation*}\n$$\n\nIf $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the effect of $I_{n, i n}$ is negligible. In other words, it is the output impedance of the preceding stage, rather than $Z_{i n}$, that determines the significance of $I_{n, i n}$. We conclude that the input-referred noise current can be neglected if:\n\nA challenge in utilizing input-referred noise voltages and currents is that they may be correlated. After all, $V_{n, i n}$ and $I_{n, i n}$ may contain effects from the same noise source. For example, in Fig. 7.35, if the noise voltage of $R_{D}$ increases at a certain point in time, then both $V_{n, i n}$ and $I_{n, i n}$ also exhibit this increase. Consequently, noise calculations must revert to Eq. (7.11) and account for the correlation between the two. Methods of avoiding this correlation are described in Appendix A.\n\nThe reader may question whether the use of both a voltage source and a current source to represent the input-referred noise \"counts the noise twice.\" We consider the environment depicted in Fig. 7.37 as an example and demonstrate that the output noise is accurate for any source impedance, $Z_{S}$. Assuming $Z_{S}$ is noiseless for simplicity, we first calculate the total noise voltage at the gate of $M_{1}$ due to $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$. This voltage cannot be obtained by superposition of powers because $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are correlated. Nonetheless, superposition still applies to voltages and currents because the circuit is linear and time-invariant. Equations (7.50) and (7.53) must be respectively rewritten as:\n\n$$\n\\begin{align*}\nV_{n, i n} & =V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}  \\tag{7.56}\\\\\nI_{n, i n} & =C_{i n} s V_{n, M 1}+\\frac{C_{i n} s}{g_{m} R_{D}} V_{n, R D} \\tag{7.57}\n\\end{align*}\n$$\n\nwhere $V_{n, M 1}$ denotes the gate-referred noise voltage of $M_{1}$ and $V_{n, R D}$ the noise voltage of $R_{D}$. We recognize that $V_{n, M 1}$ and $V_{n, R D}$ appear in both $V_{n, i n}$ and $I_{n, i n}$, creating a strong correlation between the two. Thus, the calculations must use superposition of voltages-as if $V_{n, i n}$ and $I_{n, i n}$ were deterministic quantities.\n\nAdding the contributions of $V_{n, i n}$ and $I_{n, i n}$ at node $X$ in Fig. 7.37, we have:\n\n$$\n\\begin{align*}\nV_{n, X} & =V_{n, i n} \\frac{\\frac{1}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S}}+I_{n, i n} \\frac{\\frac{Z_{"
},
{
    "text": "Consider a generic circuit featuring a solitary input and output port (refer to Fig. 7.28). The challenge lies in quantifying the impact of noise within this setup. A straightforward method involves setting the input to zero and assessing the cumulative noise at the output stemming from the various noise sources present in the circuit. This technique mirrors the approach employed in laboratory measurements and simulations. Our analytical procedure outlined in Section 7.1.5 systematically arrives at the output noise spectrum.\n\nThe circuit diagram in Fig. 7.28 portrays a noise model incorporating three sources of noise: two voltage-controlled voltage sources and a current source. The input is denoted as Vin, and the output as Vout. These noise sources collectively contribute to the overall noise observed at the output.\n\n#### Example 7.10\n\nDetermine the aggregate output noise voltage for the common-source stage depicted in Fig. 7.29(a), with the assumption that $\\lambda=0$.\nThe circuit is a common-source amplifier stage that employs an NMOS transistor, M1. The output is derived across RD, and the input is applied to the gate of M1. The circuit operates with a supply voltage VDD, and the output node is labeled as Vout. The diagram also encompasses noise sources in a separate figure (b), which are not integrated into the netlist for figure (a).\n\n#### Solution\n\nTo ascertain the total output noise voltage, we must identify the noise sources, determine their respective transfer functions relative to the output, multiply their spectral densities by the squared magnitude of these transfer functions, and sum the outcomes. We model the thermal and flicker noise of $M_{1}$ using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. Additionally, we represent the thermal noise of $R_{D}$ with a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Given that these currents flow through $R_{D}$, the output noise voltage per unit bandwidth is expressed as\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nIt is important to note that noise mechanisms are combined as \"power\" quantities due to their uncorrelated nature. The value derived from (7.44) signifies the noise power within a 1 Hz bandwidth at a frequency $f$. The overall output noise is subsequently obtained through integration.\n\n#### Input-Referred Noise\n\nAlthough the output-referred noise is conceptually straightforward, it doesn't facilitate a equitable comparison of circuit performance due to its dependence on gain. For instance, as illustrated in Fig. 7.30, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$, the output noise corresponds to the expression in (7.44) multiplied by $A_{1}^{2}$. Focusing solely on the output noise might lead to the misconception that an increase in $A_{1}$ results in a noisier circuit, which is inaccurate because a higher $A_{1}$ also boosts the signal level at the output proportionally. Consequently, the output signal-to-noise ratio remains unaffected by $A_{1}$.\n\n#### Example 7.11\n\nFor the circuit illustrated in Fig. 7.29, compute the input-referred noise voltage.\n\n#### Solution\n\nThe input-referred noise voltage can be calculated as follows:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current for the circuit in Fig. 7.32, considering only the thermal noise generated by $M_{1}$ and $R_{D}$.\n\n#### Solution\n\nThe input-referred noise voltage, as per (7.47), is given by:\n\n$$\n\\begin{equation*}\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.50}\n\\end{equation*}\n$$\n\nTo determine the input-referred noise current, we open the input and evaluate the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Fig.7.35(b)]. The noise current, flowing through $C_{i n}$, yields the following output noise:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2} \\tag{7.51}\n\\end{equation*}\n$$\n\nIn accordance with Fig. 7.34(b), this value must match the output noise of the noisy circuit when its input is open:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.52}\n\\end{equation*}\n$$\n\nFrom (7.51) and (7.52), the input-referred noise current is derived as:\n\n$$\n\\begin{equation*}\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) \\tag{7.53}\n\\end{equation*}\n$$\n\nThe significance of $I_{n, i n}$ is contingent upon the circuit's input impedance, $Z_{i n}$. If $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the impact of $I_{n, i n}$ can be disregarded. In essence, it is the output impedance of the preceding stage, rather than $Z_{i n}$, that dictates the relevance of $I_{n, i n}$. We can conclude that the input-referred noise current can be neglected if\n\nA potential complication in the utilization of input-referred noise voltages and currents arises from their potential correlation. Since $V_{n, i n}$ and $I_{n, i n}$ may originate from the same noise source, noise calculations must account for the correlation between the two. Techniques for mitigating this correlation are detailed in Appendix A.\n\nIn certain scenarios, it may be more convenient to analyze the output short-circuit noise current instead of the output open-circuit noise voltage for these calculations. This current is then multiplied by the circuit's output resistance to yield the output noise voltage or simply divided by the appropriate gain to derive the input-referred quantities. The following example exemplifies this approach."
},
{
    "text": "Consider a typical circuit configuration with one input and one output terminal (refer to Fig. 7.28). To assess the impact of noise within this setup, a conventional method involves grounding the input and evaluating the cumulative noise at the output, stemming from the various noise sources present in the circuit. This technique mirrors the approach employed in both experimental and simulated noise measurement. Our analytical procedure, as outlined in Section 7.1.5, systematically derives the output noise spectrum.\n\n---\n\n#### Example 7.10\n\nDetermine the combined output noise voltage for the common-source amplifier stage depicted in Fig. 7.29(a), assuming a value of $\\lambda=0$.\n\n---\n\n#### Solution\n\nTo calculate the total output noise voltage, it is essential to identify all noise sources, determine their respective transfer functions affecting the output, and then multiply each source's spectrum by the square of the magnitude of its transfer function. The resultant values are then summed. In modeling the thermal and flicker noise of the transistor $M_{1}$, we employ two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ for thermal noise and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$ for flicker noise. Additionally, we represent the thermal noise of resistor $R_{D}$ with a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents flow through $R_{D}$, the output noise voltage across a unit bandwidth is given by Equation (7.44).\n\n---\n\nInput-Referred Noise: The concept of output-referred noise, while straightforward, does not facilitate a equitable comparison of the performance of different circuits, as it is gain-dependent. For instance, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$ (refer to Fig. 7.30), the output noise is the product of the expression in (7.44) and $A_{1}^{2}$. A cursory examination of the output noise might lead to the erroneous conclusion that an increase in $A_{1}$ results in a noisier circuit. This is misleading, as a higher $A_{1}$ also boosts the signal level at the output proportionally, meaning that the signal-to-noise ratio at the output is independent of $A_{1}$.\n\n---\n\n#### Example 7.11\n\nCompute the input-referred noise voltage for the circuit shown in Fig. 7.29.\n\n---\n\n#### Solution\n\nThe input-referred noise voltage can be calculated using Equation (7.45), which yields (7.46) and further simplifies to (7.47).\n\n---\n\nIn the context of our discussion, two key observations are made. First, both the input-referred noise and the input signal are amplified by the gain as they traverse the circuit. Hence, the input-referred noise serves as an indicator of how much the input signal is degraded by the circuit's noise, essentially defining the minimum input signal level that the circuit can detect with an acceptable signal-to-noise ratio (SNR). This makes input-referred noise a suitable metric for comparing the performance of different circuits. Second, the input-referred noise is a theoretical construct, as it cannot be physically measured at the input of the circuit.\n\n---\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current for the circuit in Fig. 7.32, taking into account only the thermal noise from $M_{1}$ and $R_{D}$.\n\n---\n\n#### Solution\n\nUsing the previous equations, the input-referred noise voltage is given by (7.50). To determine the input-referred noise current, we consider the circuit with the input open, as shown in Fig. 7.35(b), leading to Equations (7.51) through (7.53).\n\n---\n\nIn certain situations, the input-referred noise voltage and current may exhibit correlation, as they could originate from the same noise source. For example, in Fig. 7.35, an increase in the noise voltage of $R_{D}$ would simultaneously affect both $V_{n, i n}$ and $I_{n, i n}$. Consequently, noise calculations must account for the correlation between these two quantities, as detailed in Appendix A.\n\n---\n\nIn conclusion, the use of both a voltage source and a current source to represent the input-referred noise does not result in double-counting the noise. An example is provided in Fig. 7.37 to demonstrate that the output noise calculation is accurate for any source impedance $Z_{S}$, as shown by Equations (7.56) through (7.62).\n\n---\n\nAn alternative approach in some scenarios is to consider the output short-circuit noise current instead of the output open-circuit noise voltage. This current is then multiplied by the circuit's output resistance to obtain the output noise voltage, or it can be directly divided by the appropriate gain to derive the input-referred quantities. The following example illustrates this method."
},
{
    "text": "Consider a general circuit with one input and one output (Fig. 7.28). How do we measure the impact of noise in this circuit? The straightforward method is to set the input to zero and calculate the total noise at the output due to the various noise sources in the circuit. This is how noise is measured in a laboratory or in simulations. Our analysis procedure in Section 7.1.5 systematically leads to the output noise spectrum.\n\n#### Example 7.10\n\nDetermine the total output noise voltage of the common-source stage shown in Fig. 7.29(a). Assume that $\\lambda=0$.\n\n#### Solution\n\nWe must identify the noise sources, determine their transfer functions to the output, multiply their spectra by the squared magnitude of the transfer functions, and sum the results. We model the thermal and flicker noise of $M_{1}$ by two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. We also represent the thermal noise of $R_{D}$ by a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents flow through $R_{D}$, the output noise voltage per unit bandwidth is equal to\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nNote that the noise mechanisms are added as \"power\" quantities because they are uncorrelated. The value given by (7.44) represents the noise power in 1 Hz at a frequency $f$. The total output noise is obtained by integration.\n\nInput-Referred Noise While intuitively appealing, the output-referred noise does not allow a fair comparison of the performance of different circuits because it depends on the gain. For example, as depicted in Fig. 7.30, if a common-source stage is followed by a noiseless amplifier having a voltage gain $A_{1}$, then the output noise is equal to the expression in (7.44) multiplied by $A_{1}^{2}$. Considering only the output noise, we may conclude that as $A_{1}$ increases, the circuit becomes noisier, an incorrect result because a larger $A_{1}$ also provides a proportionally higher signal level at the output. That is, the output signal-to-noise ratio does not depend on $A_{1}$.\n\nTo overcome the above quandary, we usually specify the \"input-referred noise\" of circuits. Illustrated conceptually in Fig. 7.31, the idea is to represent the effect of all noise sources in the circuit by a single source, $\\overline{V_{n, i n}^{2}}$, at the input such that the output noise in Fig. 7.31(b) equals that in Fig. 7.31(a). If the voltage gain is $A_{v}$, then we must have $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$, that is, the input-referred noise voltage in this simple case is given by the output noise voltage divided by the gain.\n\n#### Example 7.11\n\nFor the circuit of Fig. 7.29, calculate the input-referred noise voltage.\n\n#### Solution\n\nWe have\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\nNote that the first term in (7.47) can be viewed as the thermal noise of a resistor equal to $\\gamma /\\left(g_{m}\\right)$ placed in series with the gate. Similarly, the third term corresponds to the noise of a resistor equal to $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. We sometimes say the \"equivalent thermal noise resistance\" of a circuit is equal to $R_{T}$, meaning that the total input-referred thermal noise of the circuit in unit bandwidth is equal to $4 k T R_{T}$.\n\nWhy does $\\overline{V_{n, i n}^{2}}$ decrease as $R_{D}$ increases? This is because the noise voltage due to $R_{D}$ at the output is proportional to $\\sqrt{R_{D}}$ while the voltage gain of the circuit is proportional to $R_{D}$.\n\nAt this point of our study, we make two observations. First, the input-referred noise and the input signal are both multiplied by the gain as they are processed by the circuit. Thus, the input-referred noise indicates how much the input signal is corrupted by the circuit's noise, i.e., how small an input the circuit can detect with acceptable SNR. For this reason, input-referred noise allows a fair comparison of different circuits. Second, the input-referred noise is a fictitious quantity in that it cannot be measured at the input of the circuit. The two circuits of Figs. 7.31(a) and (b) are mathematically equivalent but the physical circuit is still that in Fig. 7.31(a).\n\nIn the foregoing discussion, we have assumed that the input-referred noise can be modeled by a single voltage source in series with the input. This is generally an incomplete representation if the circuit has a finite input impedance and is driven by a finite source impedance. To understand why, let us first return to the CS stage of Fig. 7.29 and observe that the output thermal noise due to $M_{1}$ is equal to $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$ regardless of the network driving the gate (i.e., regardless of the preceding stage). Upon dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$, we obtain an input-referred noise voltage of $4 k T \\gamma / g_{m}$-also independent of the preceding stage.\n\nNow, consider the common-source stage of Fig. 7.32(a), where the input capacitance is denoted by $C_{i n}$. The input-referred noise voltage due to $M_{1}$ is still given by $4 k T \\gamma / g_{m}$. Suppose the preceding stage is modeled by a Thevenin equivalent having an output impedance of $R_{1}$ [Fig. 7.32(b)]. Simplifying the circuit for noise calculations as shown in Fig. 7.32(c), we seek the output noise due to $M_{1}$, hoping to obtain $4 k T \\gamma g_{m} R_{D}^{2}$. Owing to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the output noise emerges as\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { out }}^{2}} & =\\overline{V_{n, \\text { in }}^{2}}\\left|\\frac{1}{R_{1} C_{\\text {in }} j \\omega+1}\\right|^{2}\\left(g_{m} R_{D}\\right)^{2}  \\tag{7.48}\\\\\n& =\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1} \\tag{7.49}\n\\end{align*}\n$$\n\nThis result is incorrect; after all, the output noise due to $M_{1}$ must not diminish as $R_{1}$ increases.\n\nLet us summarize the problem. If the circuit has a finite input impedance, modeling the input-referred noise by merely a voltage source implies that the output noise vanishes as the source impedance becomes large, an incorrect conclusion. To resolve this issue, we model the input-referred noise by both a series voltage source and a parallel current source (Fig. 7.33) so that if the output impedance of the preceding stage assumes large values-thereby reducing the effect of $\\overline{V_{n, i n}^{2}}$-the noise current source still flows through a finite impedance, producing noise at the input. It can be proved that $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are necessary and sufficient to represent the noise of any linear two-port circuit [5].\n\nHow do we calculate $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ ? Since the model is valid for any source impedance, we consider two extreme cases: zero and infinite source impedances. As shown in Fig. 7.34(a), if the source impedance is zero, $\\overline{I_{n, i n}^{2}}$ flows through $\\overline{V_{n, i n}^{2}}$ and has no effect on the output. Thus, the output noise measured in this case arises solely from $\\overline{V_{n, i n}^{2}}$. Similarly, if the input is open [Fig. 7.34(b)], then $\\overline{V_{n, i n}^{2}}$ has no effect and the output noise is due to only $\\overline{I_{n, i n}^{2}}$. Let us apply this method to the circuit of Fig. 7.32.\n\n#### Example 7.12\n\nCalculate the input-referred noise voltage and current of Fig. 7.32, including only the thermal noise of $M_{1}$ and $R_{D}$.\n\n#### Solution\n\nFrom (7.47), the input-referred noise voltage is simply\n\n$$\n\\begin{equation*}\n\\overline{V_{n, i n}^{2}}=4 k T \\frac{\\gamma}{g_{m}}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.50}\n\\end{equation*}\n$$\n\nAs depicted in Fig. 7.35(a), this voltage generates the same output noise as the actual circuit if the input is shorted.\n\nTo obtain the input-referred noise current, we open the input and find the output noise in terms of $\\overline{I_{n, i n}^{2}}$ [Fig.7.35(b)]. The noise current flows through $C_{i n}$, generating at the output\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\overline{I_{n, \\text { in }}^{2}}\\left(\\frac{1}{C_{\\text {in }} \\omega}\\right)^{2} g_{m}^{2} R_{D}^{2} \\tag{7.51}\n\\end{equation*}\n$$\n\nAccording to Fig. 7.34(b), this value must be equal to the output of the noisy circuit when its input is open:\n\n$$\n\\begin{equation*}\n\\overline{V_{n 2, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.52}\n\\end{equation*}\n$$\n\nFrom (7.51) and (7.52), it follows that\n\n$$\n\\begin{equation*}\n\\overline{I_{n, i n}^{2}}=\\left(C_{i n} \\omega\\right)^{2} \\frac{4 k T}{g_{m}^{2}}\\left(\\gamma g_{m}+\\frac{1}{R_{D}}\\right) \\tag{7.53}\n\\end{equation*}\n$$\n\nAs mentioned earlier, the input noise current, $I_{n, i n}$, becomes significant if the circuit's input impedance, $Z_{i n}$, is not very high. To see whether $I_{n, i n}$ can be neglected or not, we consider the scenario depicted in Fig. 7.36, where $Z_{S}$ denotes the output impedance of the preceding circuit. The total noise voltage sensed by the second stage at node $X$ is equal to\n\n$$\n\\begin{equation*}\nV_{n, X}=\\frac{Z_{\\text {in }}}{Z_{\\text {in }}+Z_{S}} V_{n, i n}+\\frac{Z_{\\text {in }} Z_{S}}{Z_{\\text {in }}+Z_{S}} I_{n, i n} \\tag{7.54}\n\\end{equation*}\n$$\n\nIf $\\overline{I_{n, i n}^{2}}\\left|Z_{S}\\right|^{2} \\ll \\overline{V_{n, i n}^{2}}$, then the effect of $I_{n, i n}$ is negligible. In other words, ultimately, it is the output impedance of the preceding stage-rather than $Z_{i n}$-that determines the significance of $I_{n, i n}$. We conclude that the input-referred noise current can be neglected if\n\nA difficulty in the use of input-referred noise voltages and currents is that they may be correlated. After all, $V_{n, i n}$ and $I_{n, i n}$ may contain effects from the same noise source. For example, in Fig. 7.35, if the noise voltage of $R_{D}$ is increasing at some point in time, then both $V_{n, i n}$ and $I_{n, i n}$ also inherit this increase. For this reason, noise calculations must revert to Eq. (7.11) and include the correlation between the two. Methods of avoiding this correlation are described in Appendix A.\n\nThe reader may wonder if the use of both a voltage source and a current source to represent the input-referred noise \"counts the noise twice.\" We consider the environment depicted in Fig. 7.37 as an example and prove that the output noise is correct for any source impedance, $Z_{S}$. Assuming $Z_{S}$ is noiseless for simplicity, we first calculate the total noise voltage at the gate of $M_{1}$ due to $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$. This voltage cannot be obtained by superposition of powers because $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are correlated. Nonetheless, superposition still applies to voltages and currents because the circuit is linear and timeinvariant. Equations (7.50) and (7.53) must be respectively rewritten as\n\n$$\n\\begin{align*}\nV_{n, i n} & =V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}  \\tag{7.56}\\\\\nI_{n, i n} & =C_{i n} s V_{n, M 1}+\\frac{C_{i n} s}{g_{m} R_{D}} V_{n, R D} \\tag{7.57}\n\\end{align*}\n$$\n\nwhere $V_{n, M 1}$ denotes the gate-referred noise voltage of $M_{1}$ and $V_{n, R D}$ the noise voltage of $R_{D}$. We recognize that $V_{n, M 1}$ and $V_{n, R D}$ appear in both $V_{n, i n}$ and $I_{n, i n}$, creating a strong correlation between the two. Thus, the calculations must use superposition of voltages-as if $V_{n, i n}$ and $I_{n, i n}$ were deterministic quantities.\n\nAdding the contributions of $V_{n, i n}$ and $I_{n, i n}$ at node $X$ in Fig. 7.37, we have\n\n$$\n\\begin{align*}\nV_{n, X} & =V_{n, i n} \\frac{\\frac{1}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S}}+I_{n, i n} \\frac{\\frac{Z_{S}}{C_{i n} s}}{\\frac{1}{C_{i n} s}+Z_{S}}  \\tag{7.58}\\\\\n& =\\frac{V_{n, i n}+I_{n, i n} Z_{S}}{Z_{S} C_{i n} s+1} \\tag{7.59}\n\\end{align*}\n$$\n\nSubstituting for $V_{n, i n}$ and $I_{n, i n}$ from (7.56) and (7.57), respectively, we obtain\n\n$$\n\\begin{align*}\nV_{n, X} & =\\frac{1}{Z_{S} C_{i n} s+1}\\left[V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}+C_{i n} s Z_{S}\\left(V_{n, M 1}+\\frac{1}{g_{m} R_{D}} V_{n, R D}\\right)\\right] \\\\\n"
},
{
    "text": "---[Attention]---\nImage Descriptions: Any images link in the [Context Provided] have been converted into textual descriptions. You also need to rephrase it to maintain the original meaning and length.\n---[Task]---\nPlease rephrase the provided text in [Context Provided] Section. Ensure the rephrased version maintains the original meaning and length. Only output the rephrased text.\n---[Context Provided]---\nConsider a generic circuit featuring a single input and a single output terminal (refer to Fig. 7.28). How do we measure the impact of noise within this context? A straightforward approach would be to set the input to zero and then calculate the cumulative noise at the output, stemming from the various noise sources within the circuit. This method is indeed the standard for noise measurement in both laboratory settings and simulations. Our analysis in Section 7.1.5 systematically leads to the derivation of the output noise spectrum.\nimage_name:Figure 7.28 Noise sources in a circuit.\ndescription:The circuit diagram depicts a noise model that includes three noise sources: two voltage-controlled voltage sources and a current source. The input is marked as Vin, and the output as Vout. These noise sources collectively contribute to the overall noise observed at the output.\n\n#### Example 7.10\n\nDetermine the aggregate output noise voltage for the common-source stage shown in Fig. 7.29(a), assuming $\\lambda=0$.\nimage_name:(a)\ndescription:\n[\nname: M1, type: NMOS, ports: {S: GND, D: Vout, G: Vin}\nname: RD, type: Resistor, value: RD, ports: {N1: VDD, N2: Vout}\nname: VDD, type: VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\n]\nextrainfo:The circuit is a common-source amplifier stage that incorporates an NMOS transistor, M1. The output is derived across RD, and the input signal is applied to the gate of M1. The circuit operates with a supply voltage VDD, and the output node is denoted as Vout. A separate figure (b) illustrates the noise sources, which are not included in the netlist for figure (a).\nimage_name:(b)\ndescription:\n[\nname: M1, type: NMOS, ports: {S: GND, D: Vn^2out, G: ac(GND)}\nname: RD, type: Resistor, value: RD, ports: {N1: VDD, N2: Vn^2out}\nname: VDD, type: VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\nname: I2nRD, type: CurrentSource, value: I^2nRD, ports: {Np: VDD, Nn: Vn^2ou}\nname: I^2n1, type: CurrentSource, value: I2n1, ports: {Np: Vn^2out, Nn: GND}\n]\nextrainfo:The circuit diagram includes noise sources modeled by two current sources (I2nRD and I2n1), which contribute to the output noise voltage V2n,out. The NMOS transistor M1 is driven by the input Vin and connected to the output Vout through the resistor RD. The circuit is powered by a voltage source VDD.\n\nFigure 7.29 (a) CS stage; (b) circuit including noise sources.\n\n#### Solution\n\nTo find the total output noise voltage, we need to identify the noise sources, determine their respective transfer functions to the output, multiply their spectra by the squared magnitude of these transfer functions, and sum the results. We model the thermal and flicker noise of $M_{1}$ using two current sources: $\\overline{I_{n, t h}^{2}}=4 k T \\gamma g_{m}$ and $\\overline{I_{n, 1 / f}^{2}}=K g_{m}^{2} /\\left(C_{o x} W L f\\right)$. We also model the thermal noise of $R_{D}$ with a current source $\\overline{I_{n, R D}^{2}}=4 k T / R_{D}$. Since these currents flow through $R_{D}$, the output noise voltage per unit bandwidth is given by\n\n$$\n\\begin{equation*}\n\\overline{V_{n, \\text { out }}^{2}}=\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\tag{7.44}\n\\end{equation*}\n$$\n\nNote that the noise mechanisms are combined as \"power\" quantities since they are uncorrelated. The expression in (7.44) represents the noise power in 1 Hz at a frequency $f$. The overall output noise is obtained by integrating this value.\n\nInput-Referred Noise The output-referred noise, while conceptually straightforward, does not allow for a fair comparison of the performance between different circuits, as it is dependent on the gain. For instance, as illustrated in Fig. 7.30, if a common-source stage is followed by a noiseless amplifier with a voltage gain $A_{1}$, the output noise is the expression in (7.44) multiplied by $A_{1}^{2}$. Focusing solely on the output noise might lead to the erroneous conclusion that an increase in $A_{1}$ results in a noisier circuit. However, this is incorrect because a larger $A_{1}$ also boosts the signal level at the output proportionally. In other words, the output signal-to-noise ratio is independent of $A_{1}$.\nimage_name:Figure 7.30\ndescription:\n[\nname: RD, type: Resistor, value: RD, ports: {N1: VDD, N2: d1}\nname: M1, type: NMOS, ports: {S: GND, D: d1, G: Vin}\nname: A1, type: OpAmp, value: A1, ports: {InP: d1, InN: GND, OutP: Vout, OutN: ''}\n]\nextrainfo:The circuit is a common-source amplifier stage augmented by an op-amp to enhance gain. The NMOS M1 serves as the amplifying element with RD as the load resistor. The output is derived from the op-amp A1, which further amplifies the signal.\n\nFigure 7.30 Addition of gain stage to a CS stage.\n\nTo address this issue, we typically specify the \"input-referred noise\" of circuits. As depicted conceptually in Fig. 7.31, the approach is to represent the impact of all noise sources in the circuit with a single source, $\\overline{V_{n, i n}^{2}}$, at the input such that the output noise in Fig. 7.31(b) matches that in Fig. 7.31(a). If the voltage gain is $A_{v}$, then we must have $\\overline{V_{n, \\text { out }}^{2}}=A_{v}^{2} \\overline{V_{n, i n}^{2}}$, which implies that the input-referred noise voltage in this simplified scenario is the output noise voltage divided by the gain.\n\n#### Example 7.11\n\nFor the circuit depicted in Fig. 7.29, calculate the input-referred noise voltage.\n\n#### Solution\n\nWe can calculate the input-referred noise voltage as follows:\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { in }}^{2}} & =\\frac{\\overline{V_{n, \\text { out }}^{2}}}{A_{v}^{2}}  \\tag{7.45}\\\\\n& =\\left(4 k T \\gamma g_{m}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f} \\cdot g_{m}^{2}+\\frac{4 k T}{R_{D}}\\right) R_{D}^{2} \\frac{1}{g_{m}^{2} R_{D}^{2}}  \\tag{7.46}\\\\\n& =4 k T \\frac{\\gamma}{g_{m}}+\\frac{K}{C_{o x} W L} \\cdot \\frac{1}{f}+\\frac{4 k T}{g_{m}^{2} R_{D}} \\tag{7.47}\n\\end{align*}\n$$\n\nIt is important to note that the first term in (7.47) can be interpreted as the thermal noise of a resistor equivalent to $\\gamma /\\left(g_{m}\\right)$ in series with the gate. Similarly, the third term corresponds to the noise of a resistor equivalent to $\\left(g_{m}^{2} R_{D}\\right)^{-1}$. We sometimes refer to the \"equivalent thermal noise resistance\" of a circuit as $R_{T}$, meaning that the total input-referred thermal noise of the circuit in unit bandwidth is equal to $4 k T R_{T}$.\n\nThe reason why $\\overline{V_{n, i n}^{2}}$ decreases as $R_{D}$ increases is that the noise voltage due to $R_{D}$ at the output is proportional to $\\sqrt{R_{D}}$, whereas the voltage gain of the circuit is proportional to $R_{D}$.\n\nAt this stage of our analysis, we note two key points. First, both the input-referred noise and the input signal are amplified by the gain as they pass through the circuit. Thus, the input-referred noise indicates the extent to which the input signal is corrupted by the circuit's noise, i.e., the smallest input signal that the circuit can detect with an acceptable signal-to-noise ratio (SNR). For this reason, input-referred noise provides a basis for a fair comparison between different circuits. Second, the input-referred noise is a theoretical construct in that it cannot be directly measured at the input of the circuit. Although the circuits shown in Figs. 7.31(a) and (b) are mathematically equivalent, the physical circuit corresponds to Fig. 7.31(a).\n\nIn the preceding discussion, we assumed that the input-referred noise can be modeled by a single voltage source in series with the input. However, this representation is generally incomplete if the circuit has a finite input impedance and is driven by a finite source impedance. To understand why, let's revisit the CS stage of Fig. 7.29 and observe that the output thermal noise due to $M_{1}$ is $\\left(4 k T \\gamma g_{m}\\right) R_{D}^{2}$, regardless of the network driving the gate (i.e., the preceding stage). Dividing this noise by $\\left(g_{m} R_{D}\\right)^{2}$ yields an input-referred noise voltage of $4 k T \\gamma / g_{m}$, which is also independent of the preceding stage.\n\nNow, consider the common-source stage of Fig. 7.32(a), where the input capacitance is denoted by $C_{i n}$. The input-referred noise voltage due to $M_{1}$ remains $4 k T \\gamma / g_{m}$. Suppose the preceding stage is modeled by a Thevenin equivalent with an output impedance of $R_{1}$ [Fig. 7.32(b)]. Simplifying the circuit for noise calculations, as shown in Fig. 7.32(c), we aim to determine the output noise due to $M_{1}$, expecting it to be $4 k T \\gamma g_{m} R_{D}^{2}$. However, due to the voltage division between $R_{1}$ and $1 /\\left(C_{i n} s\\right)$, the output noise is calculated as\n\n$$\n\\begin{align*}\n\\overline{V_{n, \\text { out }}^{2}} & =\\overline{V_{n, \\text { in }}^{2}}\\left|\\frac{1}{R_{1} C_{\\text {in }} j \\omega+1}\\right|^{2}\\left(g_{m} R_{D}\\right)^{2}  \\tag{7.48}\\\\\n& =\\frac{4 k T \\gamma g_{m} R_{D}^{2}}{R_{1}^{2} C_{i n}^{2} \\omega^{2}+1} \\tag{7.49}\n\\end{align*}\n$$\n\nThis result is incorrect; after all, the output noise due to $M_{1}$ should not decrease as $R_{1}$ increases.\nimage_name:(a)\ndescription:The circuit is a common-source (CS) amplifier stage featuring an NMOS transistor (M1) and includes a resistor (RD) connected to VDD and a capacitor (Cin) connected to the input noise voltage source (Vn,in). The output is taken across the drain of M1.\nimage_name:(b)\ndescription:The circuit diagram (b) represents a common-source stage with input noise modeled by a series voltage source and parallel current source. The NMOS transistor M1 amplifies the input signal, with RD serving as the load resistor. VDD provides the supply voltage. The presence of Cin and R1 affects the input impedance and noise characteristics.\nimage_name:(c)\ndescription:The circuit diagram (c) represents a common-source (CS) stage with an NMOS transistor M1, where the input-referred noise is modeled by both a series voltage source and a parallel current source at the input. The input signal is applied through a resistor R1, and the input capacitance Cin is connected to ground. The drain of M1 is connected to the output node Vout through the resistor RD, and the source is connected to ground. The circuit is powered by VDD.\n\nFigure 7.32 CS stage including input capacitance; (b) CS stage stimulated by a finite source impedance; (c) effect of single noise source.\n\nTo address this issue, we summarize the problem as follows. If the circuit has a finite input impedance, modeling the input-referred noise with just a voltage source suggests that the output noise diminishes as the source impedance grows larger, which is an erroneous conclusion. To rectify this, we model the input-referred noise using both a series voltage source and a parallel current source (Fig. 7.33) so that if the output impedance of the preceding stage increases significantly, thereby reducing the effect of $\\overline{V_{n, i n}^{2}}$, the noise current source still flows through a finite impedance, generating noise at the input. It can be demonstrated that $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$ are necessary and sufficient to represent the noise of any linear two-port circuit [5].\nimage_name:Figure 7.33 Representation of noise by voltage and current sources\ndescription:\n[\nname: Vn^2,in, type: VoltageSource, value: Vn^2,in, ports: {Np: X1, Nn: X2}\nname: In^2,in, type: CurrentSource, value: In^2,in, ports: {Np: X2, Nn: X3}\n]\nextrainfo:The circuit diagram represents noise in a linear two-port circuit using a series voltage source (Vn^2,in) and a parallel current source (In^2,in) connected to a noiseless circuit.\n\nFigure 7.33 Representation of noise by voltage and current sources.\n\nHow do we calculate $\\overline{V_{n, i n}^{2}}$ and $\\overline{I_{n, i n}^{2}}$? Since the model is valid for any source impedance, we consider two extreme cases: zero and infinite source impedances. As shown in Fig. 7.34(a), if the source impedance is zero, $\\overline{I_{n, i n}^{2}}$ flows through $\\overline{V_{n, i n}^{2}}$ and has no effect on the output. Thus, the output noise measured in this case arises solely from $\\overline{V_{n, i n}^{2}}$. Similarly, if the input is open [Fig. 7.34(b)], then $\\overline{V_{n, i n}^{2}}$ has no effect, and the output noise is due to only $\\overline{I_{n, i n}^{2}}$. Applying this method to the circuit of Fig. 7.32.\nimage_name:(a)\ndescription:The system block diagram labeled (a) illustrates the calculation of input-referred noise voltage and current for a given circuit setup. It consists of two main sections: a 'Noisy Circuit' and a 'Noiseless Circuit'.\n\n1. **Main Components:**\n- **Noisy Circuit:** This block represents a circuit that generates output noise, denoted as $\\overline{V_{n1,out}^{2}}$.\n- **Noiseless Circuit:** This block is intended to represent an ideal circuit with no noise contribution, used to analyze the effect of input-referred noise.\n- **Voltage Source ($\\overline{V_{n,in}^{2}}$):** Represents the input-referred noise voltage.\n- **Current Source ($\\overline{I_{n,in}^{2}}$):** Represents the input-referred noise current.\n\n2. **Flow of Information or Control:**\n- The output noise from the Noisy Circuit ($\\overline{V_{n1,out}^{2}}$) is considered equivalent to the input-referred noise voltage ($\\overline{V_{n,in}^{2}}$) and current ($\\overline{I_{n,in}^{2}}$) flowing through the Noiseless Circuit.\n- The voltage source $\\overline{V_{n,in}^{2}}$ is connected in series, and the current source $\\overline{I_{n,in}^{2}}$ is connected in parallel with the Noiseless Circuit.\n\n3. **Labels, Annotations, and Key Indicators:**\n- **$X_1$ and $X_2$:** These points indicate the connection nodes where the input-referred noise voltage and current are applied to the Noiseless Circuit.\n- The diagram uses arrows to indicate the direction of noise influence from the Noisy Circuit to the Noiseless Circuit.\n\n4. **Overall System Function:**\n- The primary function of this setup is to model how input-referred noise from a noisy circuit can be represented and analyzed in terms of equivalent noise sources (voltage and current) applied to a noiseless circuit. This helps in understanding the impact of noise on circuit performance and is essential for noise analysis in electronic circuits.\nimage_name:(b)\ndescription:The diagram labeled as (b) illustrates a method for calculating the input-referred noise current in a circuit. The system is divided into three main components:\n\n1. **Noisy"
},
{
    "text": "After developing fundamental mathematical tools and models for noise analysis, we now investigate the noise performance of single-stage amplifiers at low frequencies. Prior to examining specific topologies, we present a lemma that simplifies noise calculations.\n\n**Lemma:** The circuits depicted in Fig. 7.39(a) and (b) are equivalent at low frequencies if $\\overline{V_{n}^{2}}=\\overline{I_{n}^{2}} / g_{m}^{2}$ and the circuits are driven by a finite impedance.\n\n**Image Description (a):**\n- **Components:**\n  - **Vin:** VoltageSource, value: Vin, ports: {Np: Vin, Nn: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: VDD, N2: d1}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: Vin}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This circuit is a common-source amplifier featuring an NMOS transistor (M1), loaded with resistor ZL and driven by voltage source Vin. A current source I2n represents the noise current. The source resistor ZS is grounded, and the circuit is biased by VDD.\n\n**Image Description (b):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: gI}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: s1, Nn: GND}\n  - **V2n:** VoltageSource, value: V2n, ports: {Np: gI, Nn: GND}\n  - **VDD:** VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {Np: gI, Nn: GND}\n- **Extra Info:** Circuit (b) is a single-stage amplifier with an NMOS transistor M1, powered by VDD, and includes load resistor ZL and source resistor ZS. A voltage-controlled voltage source gI is connected to M1's gate. The design aims to analyze low-frequency noise performance.\n\n**Image Description (c):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This single-stage amplifier features NMOS M1, resistors ZL and ZS, and a current source I2n. The NMOS gate is grounded, the source connects to ground via ZS, and the drain connects to VDD through ZL. I2n injects current from the drain to the source.\n\n**Image Description (d):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: s1}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {N1: s1, N2: GND}\n- **Extra Info:** Diagram (d) shows a noise equivalent model with NMOS M1, load resistor ZL connected to VDD, and source resistor ZS grounded. A current source I2n models noise, and a voltage-controlled voltage source gI aids in noise analysis.\n\n**Figure 7.39 Equivalent CS stages.**\n\n**Proof:** Given that the circuits have identical output impedances, we analyze the output short-circuit currents [Figs. 7.39(c) and (d)]. It can be demonstrated (Problem 7.4) that the output noise current for the circuit in Fig. 7.39(c) is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 1}=\\frac{I_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{O}\\right)+1} \\tag{7.73}\n\\end{equation*}\n$$\n\nand for Fig. 7.39(d), it is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 2}=\\frac{g_{m} V_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{o}\\right)+1} \\tag{7.74}\n\\end{equation*}\n$$\n\nEquating (7.73) and (7.74) yields $V_{n}=I_{n} / g_{m}$. We term $V_{n}$ the \"gate-referred\" noise of $M_{1}$. This lemma indicates that the noise source can be converted from a drain-source current to a gate series voltage for any $Z_{S}$. This analysis is extended to include gate-source capacitance in Problem 7.29.\n\n#### Example 7.14\n\n**Prove the above lemma using Thevenin equivalents.**\n\n#### Solution\n\nWe create Thevenin models for the circuits in Figs. 7.39(a) and (b), excluding $Z_{L}$, as shown in Figs. 7.40(a) and (b). With $I_{n}=0$ and $V_{n}=0$, the topologies are the same, thus $Z_{T h e v 1}=Z_{\\text {Thev2 }}$. We need to find the condition for $V_{\\text {Thev1 }}=V_{T h e v 2}$.\n\nTo determine the Thevenin voltages, $Z_{L}$ is replaced with an open circuit [Fig.7.40(c)]. ${ }^{10}$ Since no current flows through $Z_{S}$ in both circuits, we get $V_{T h e v 1}=I_{n} r_{O}$ and $V_{T h e v}=g_{m} V_{n} r_{O}$. Consequently, $V_{n}=I_{n} / g_{m}$."
},
{
    "text": "Having developed fundamental mathematical tools and models for noise analysis, we now examine the noise performance of single-stage amplifiers at low frequencies. Before delving into specific topologies, we present a lemma that simplifies noise calculations.\n\n**Lemma:** The circuits depicted in Fig. 7.39(a) and (b) are equivalent at low frequencies if $\\overline{V_{n}^{2}}=\\overline{I_{n}^{2}} / g_{m}^{2}$ and the circuits are driven by a finite impedance.\n\n**Image Description (a):**\n- **Components:**\n  - **Vin:** VoltageSource, value: Vin, ports: {Np: Vin, Nn: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: VDD, N2: d1}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: Vin}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This circuit is a common-source amplifier featuring an NMOS transistor (M1), loaded with resistor ZL and driven by voltage source Vin. A current source I2n represents the noise current. The source resistor ZS is grounded, and the circuit is biased by VDD.\n\n**Image Description (b):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: gI}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: s1, Nn: GND}\n  - **V2n:** VoltageSource, value: V2n, ports: {Np: gI, Nn: GND}\n  - **VDD:** VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {Np: gI, Nn: GND}\n- **Extra Info:** Circuit (b) is a single-stage amplifier with an NMOS transistor M1, powered by VDD. It includes load resistor ZL, source resistor ZS, and a voltage-controlled voltage source gI connected to M1's gate. The design aims to analyze low-frequency noise performance.\n\n**Image Description (c):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This single-stage amplifier features NMOS M1, resistors ZL and ZS, and a current source I2n. The NMOS gate is grounded, the source connects to ground via ZS, and the drain connects to VDD through ZL. I2n injects current from the drain to the source.\n\n**Image Description (d):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: s1}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {N1: s1, N2: GND}\n- **Extra Info:** Diagram (d) shows a noise equivalent model with NMOS M1, load resistor ZL connected to VDD, and source resistor ZS grounded. A current source I2n models noise, and a voltage-controlled voltage source gI is used for noise analysis.\n\n**Figure 7.39 Equivalent CS stages.**\n\n**Proof:** Given that the circuits have identical output impedances, we analyze the output short-circuit currents [Figs. 7.39(c) and (d)]. It can be demonstrated (Problem 7.4) that the output noise current for the circuit in Fig. 7.39(c) is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 1}=\\frac{I_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{O}\\right)+1} \\tag{7.73}\n\\end{equation*}\n$$\n\nand for Fig. 7.39(d) it is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 2}=\\frac{g_{m} V_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{o}\\right)+1} \\tag{7.74}\n\\end{equation*}\n$$\n\nEquating (7.73) and (7.74) yields $V_{n}=I_{n} / g_{m}$. We term $V_{n}$ the \"gate-referred\" noise of $M_{1}$. This lemma indicates that the noise source can be converted from a drain-source current to a gate series voltage for any $Z_{S}$. This analysis is extended to include gate-source capacitance in Problem 7.29.\n\n#### Example 7.14\n\nVerify the above lemma using Thevenin equivalents.\n\n#### Solution\n\nWe create Thevenin models for the circuits in Figs. 7.39(a) and (b), excluding $Z_{L}$, as shown in Figs. 7.40(a) and (b). With $I_{n}=0$ and $V_{n}=0$, the topologies are identical, resulting in $Z_{T h e v 1}=Z_{\\text {Thev2 }}$. We then determine the condition for $V_{\\text {Thev1 }}=V_{T h e v 2}$.\n\nTo find the Thevenin voltages, $Z_{L}$ is replaced with an open circuit [Fig.7.40(c)]. ${ }^{10}$ Since no current flows through $Z_{S}$ in both circuits, we have $V_{T h e v 1}=I_{n} r_{O}$ and $V_{T h e v}=g_{m} V_{n} r_{O}$. Consequently, $V_{n}=I_{n} / g_{m}$."
},
{
    "text": "Having developed fundamental mathematical tools and models for noise analysis, we now examine the noise performance of single-stage amplifiers at low frequencies. Prior to exploring specific topologies, we present a lemma that simplifies noise calculations.\n\n**Lemma:** The circuits depicted in Fig. 7.39(a) and (b) are equivalent at low frequencies if $\\overline{V_{n}^{2}}=\\overline{I_{n}^{2}} / g_{m}^{2}$ and the circuits are driven by a finite impedance.\n\n**Image Description (a):**\n- **Components:**\n  - **Vin:** VoltageSource, value: Vin, ports: {Np: Vin, Nn: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: VDD, N2: d1}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: Vin}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** The circuit is a common-source amplifier with an NMOS transistor (M1), loaded by a resistor ZL and driven by a voltage source Vin. A current source I2n models the noise current. The source resistor ZS is connected to ground, and the circuit is biased by VDD.\n\n**Image Description (b):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: gI}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: s1, Nn: GND}\n  - **V2n:** VoltageSource, value: V2n, ports: {Np: gI, Nn: GND}\n  - **VDD:** VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {Np: gI, Nn: GND}\n- **Extra Info:** The circuit in diagram (b) is a single-stage amplifier with an NMOS transistor M1. It is powered by a voltage source VDD and includes a load resistor ZL and a source resistor ZS. A voltage-controlled voltage source gI is connected to the gate of M1, designed for analyzing noise performance at low frequencies.\n\n**Image Description (c):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This circuit is a single-stage amplifier with NMOS M1, featuring resistors ZL and ZS, and a current source I2n. The NMOS gate is grounded, the source is connected to ground through ZS, and the drain is connected to the supply voltage VDD through ZL. The current source I2n injects current from the drain to the source.\n\n**Image Description (d):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: s1}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {N1: s1, N2: GND}\n- **Extra Info:** The circuit in diagram (d) is a noise equivalent model with an NMOS transistor M1, a load resistor ZL connected to VDD, and a source resistor ZS connected to ground. A current source I2n models noise, and a voltage-controlled voltage source gI is used for noise analysis.\n\n**Figure 7.39 Equivalent CS stages.**\n\n**Proof:** Given that the circuits have identical output impedances, we analyze the output short-circuit currents [Figs. 7.39(c) and (d)]. It can be demonstrated (Problem 7.4) that the output noise current of the circuit in Fig. 7.39(c) is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 1}=\\frac{I_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{O}\\right)+1} \\tag{7.73}\n\\end{equation*}\n$$\n\nand that of Fig. 7.39(d) is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 2}=\\frac{g_{m} V_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{o}\\right)+1} \\tag{7.74}\n\\end{equation*}\n$$\n\nEquating (7.73) and (7.74), we find $V_{n}=I_{n} / g_{m}$. We refer to $V_{n}$ as the \"gate-referred\" noise of $M_{1}$. This lemma indicates that the noise source can be converted from a drain-source current to a gate series voltage for any $Z_{S}$. This analysis is extended to include gate-source capacitance in Problem 7.29.\n\n#### Example 7.14\n\n**Prove the above lemma using Thevenin equivalents.**\n\n#### Solution\n\nWe create Thevenin models for the circuits in Figs. 7.39(a) and (b), excluding $Z_{L}$, as shown in Figs. 7.40(a) and (b). With $I_{n}=0$ and $V_{n}=0$, the two topologies are the same, hence $Z_{T h e v 1}=Z_{\\text {Thev2 }}$. We need to determine the condition for $V_{\\text {Thev1 }}=V_{T h e v 2}$.\n\nTo find the Thevenin voltages, we replace $Z_{L}$ with an open circuit [Fig.7.40(c)]. Since no current flows through $Z_{S}$ in both circuits, we have $V_{T h e v 1}=I_{n} r_{O}$ and $V_{T h e v}=g_{m} V_{n} r_{O}$. Consequently, $V_{n}=I_{n} / g_{m}$."
},
{
    "text": "Having developed fundamental mathematical tools and models for noise analysis, we now examine the noise performance of single-stage amplifiers at low frequencies. Before delving into specific topologies, we introduce a lemma that simplifies noise calculations.\n\n**Lemma:** The circuits depicted in Fig. 7.39(a) and (b) are equivalent at low frequencies if $\\overline{V_{n}^{2}}=\\overline{I_{n}^{2}} / g_{m}^{2}$ and the circuits are driven by a finite impedance.\n\n**Image Description (a):**\n- **Components:**\n  - **Vin:** VoltageSource, value: Vin, ports: {Np: Vin, Nn: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: VDD, N2: d1}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: Vin}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This circuit is a common-source amplifier featuring an NMOS transistor (M1), loaded with a resistor ZL and driven by a voltage source Vin. A current source I2n represents the noise current. The source resistor ZS is grounded, and the circuit is biased by VDD.\n\n**Image Description (b):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: gI}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: s1, Nn: GND}\n  - **V2n:** VoltageSource, value: V2n, ports: {Np: gI, Nn: GND}\n  - **VDD:** VoltageSource, value: VDD, ports: {Np: VDD, Nn: GND}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {Np: gI, Nn: GND}\n- **Extra Info:** Circuit (b) is a single-stage amplifier with an NMOS transistor M1, powered by VDD, and includes a load resistor ZL and a source resistor ZS. A voltage-controlled voltage source gI is connected to M1's gate. This setup is designed for low-frequency noise performance analysis.\n\n**Image Description (c):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: GND}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n- **Extra Info:** This single-stage amplifier features an NMOS transistor M1, resistors ZL and ZS, and a current source I2n. The NMOS gate is grounded, the source is connected to ground via ZS, and the drain is connected to VDD through ZL. I2n injects current from the drain to the source.\n\n**Image Description (d):**\n- **Components:**\n  - **M1:** NMOS, ports: {S: s1, D: d1, G: s1}\n  - **ZL:** Resistor, value: ZL, ports: {N1: d1, N2: VDD}\n  - **ZS:** Resistor, value: ZS, ports: {N1: s1, N2: GND}\n  - **I2n:** CurrentSource, value: I2n, ports: {Np: d1, Nn: s1}\n  - **gI:** VoltageControlledVoltageSource, value: gI, ports: {N1: s1, N2: GND}\n- **Extra Info:** Diagram (d) shows a noise equivalent model with an NMOS transistor M1, a load resistor ZL connected to VDD, and a source resistor ZS grounded. A current source I2n models noise, and a voltage-controlled voltage source gI is used for noise analysis.\n\n**Figure 7.39 Equivalent CS stages.**\n\n**Proof:** Given that the circuits have identical output impedances, we analyze the output short-circuit currents [Figs. 7.39(c) and (d)]. It can be demonstrated (Problem 7.4) that the output noise current for the circuit in Fig. 7.39(c) is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 1}=\\frac{I_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{O}\\right)+1} \\tag{7.73}\n\\end{equation*}\n$$\n\nand for Fig. 7.39(d), it is\n\n$$\n\\begin{equation*}\nI_{n, \\text { out } 2}=\\frac{g_{m} V_{n}}{Z_{S}\\left(g_{m}+g_{m b}+1 / r_{o}\\right)+1} \\tag{7.74}\n\\end{equation*}\n$$\n\nEquating (7.73) and (7.74) yields $V_{n}=I_{n} / g_{m}$. We term $V_{n}$ the \"gate-referred\" noise of $M_{1}$. This lemma indicates that the noise source can be converted from a drain-source current to a gate series voltage for any $Z_{S}$. This analysis is extended to include gate-source capacitance in Problem 7.29.\n\n#### Example 7.14\n\nVerify the above lemma using Thevenin equivalents.\n\n#### Solution\n\nWe create Thevenin models for the circuits in Figs. 7.39(a) and (b), excluding $Z_{L}$, as shown in Figs. 7.40(a) and (b). With $I_{n}=0$ and $V_{n}=0$, the two configurations are the same, resulting in $Z_{T h e v 1}=Z_{\\text {Thev2 }}$. We then find the condition for $V_{\\text {Thev1 }}=V_{T h e v 2}$.\n\nTo determine the Thevenin voltages, we replace $Z_{L}$ with an open circuit [Fig.7.40(c)]. Since no current flows through $Z_{S}$ in either circuit, we have $V_{T h e v 1}=I_{n} r_{O}$ and $V_{T h e v}=g_{m} V_{n} r_{O}$. Consequently, $V_{n}=I_{n} / g_{m}$."
}
]